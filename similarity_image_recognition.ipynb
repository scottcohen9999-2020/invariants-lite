{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "### See the whitepaper in this repository for more description of the ideas.\n",
    "\n",
    "### This notebook is experiments with a tree of centroids with an option to append them to the image.\n",
    "\n",
    "### Experiments use one of two types of models for prediction: kNN and CNN. \n",
    "\n",
    "### kNN treats the 28x28 image as an array of 784 pixels and uses L2 distance metric. \n",
    "\n",
    "### CNN is lifted verbatim from the book \"Deep Learning with Python\" by Francois Chollet, 2018 (page 120-122) the inventor of Keras. The CNN is not SOTA but is useful to see whether adding information about centroids improve a neural net model.\n",
    "\n",
    "### The training/testing set of images is either small (6,000/1,000) or large (60,000/10,000).\n",
    "\n",
    "### The bottom line result is the error rate reduction.\n",
    "\n",
    "## Results from experiments\n",
    "\n",
    "| model\\#images | <font size=\"5\">6,000</font> | <font size=\"5\">60,000</font> |\n",
    "| --- | --- | --- |\n",
    "| baseline kNN | <font size=\"5\">91.6%</font> | <font size=\"5\">96.88%</font> |\n",
    "| improved kNN | <font size=\"5\">94.1%</font> | <font size=\"5\">97.12%</font> |\n",
    "\n",
    "### and\n",
    "\n",
    "| model\\#images | <font size=\"5\">6,000</font> | <font size=\"5\">60,000</font> |\n",
    "| --- | --- | --- |\n",
    "| baseline CNN | <font size=\"5\">96.29%</font> | <font size=\"5\">99.02%</font> |\n",
    "| improved CNN | <font size=\"5\">96.90%</font> | <font size=\"5\">99.10%</font> |\n",
    "\n",
    "### From these results, the _*error rate reduction*_ is\n",
    "\n",
    "| model\\#images | <font size=\"5\">6,000</font> | <font size=\"5\">60,000</font> |\n",
    "| --- | --- | --- |\n",
    "| kNN | <font size=\"5\">29.76%</font> | <font size=\"5\">7.7%</font> | \n",
    "| CNN | <font size=\"5\">16.4%</font> | <font size=\"5\">9%</font> | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc'></a>\n",
    "# Table of Contents\n",
    "\n",
    "## <a href='#section1'>section 1. import libraries and Configuration parameters</a>\n",
    "\n",
    "## <a href='#section1a'>section 1a. function defs only; no test runs</a>\n",
    "\n",
    "### list of all functions and a brief description of each.\n",
    "\n",
    "## <a href='#section2'>section 2. test runs only; no function defs</a>\n",
    "\n",
    "## <a href='#s2baselines'>section 2a. baselines</a>\n",
    "\n",
    "##  <a href='#s2improvements'>section 2b. improvements summary</a>\n",
    "\n",
    "## <a href='#s2quadrants'>section 2c. answering specific questions</a>\n",
    "\n",
    "### <a href='#s2quadrants'>trying overlapping quadrants</a>\n",
    "\n",
    "### <a href='#s2noappendimage'>try just the centroid info without the image; Do this with option parent centroids with overlap</a>\n",
    "\n",
    "### <a href='#s2weightcentroids'>try weighted centroids (no overlap) with image</a>\n",
    "\n",
    "### <a href='#s2treesizes'>try different sizes for the tree of centroids</a>\n",
    "\n",
    "### <a href='#s2weightedparents'>compare weighted parent centroids to just the image</a>\n",
    "\n",
    "### <a href='#s2relativebdy'>try using relation of image to boundary</a>\n",
    "\n",
    "### <a href='#s2onlyleaves'>try without image (just the centroid info); Use only the leaves of the tree of centroids</a>\n",
    "\n",
    "### <a href='#s2onlybigtree'>try without image (just the centroid info) and more neighbors, larger tree</a>\n",
    "\n",
    "### <a href='#s2norelativebdy'>try not getting points relative to the bounding rectangle. </a>\n",
    "\n",
    "### <a href='#s2weightcentroids'>append the image to the weighted centroids</a>\n",
    "\n",
    "### <a href='#s2onlyleaves2'>Try weighted centroids with parents</a>\n",
    "\n",
    "### <a href='#s2overlapparentweight'>...and now overlap the weighted centroids with parents improved CNN and kNN for small set of images</a>\n",
    "\n",
    "### <a href='#s2overlaponlyleaves'>...and now do without the parents; CNN did worse than baseline for small set of images</a>\n",
    "\n",
    "### <a href='#s2reprokNNimprove'>Reproduce the improvement for kNN with options weighted centroid but no overlap, nor parents,</a>\n",
    "\n",
    "## <a href='#section3'>section 3. reproduce results before summary</a>\n",
    "\n",
    "### Repeating baseline give the exact same result for kNN but CNN fluctuates significantly\n",
    "\n",
    "### Repeat the largest improvement for kNN small 6,000 set of images\n",
    "- overlapping quadrants by 1/8; all with weighted centroids\n",
    "\n",
    "### Repeat the largest improvement for kNN large 60,000 set of images\n",
    "- overlapping quadrants by 1/8; all with weighted centroids\n",
    "\n",
    "### Repeat the largest improvement for CNN small 6,000 set of images\n",
    "- using weighted centroids with parents\n",
    "\n",
    "### Repeat the largest improvement for CNN large 60,000 set of images\n",
    "- using weighted centroids with parents\n",
    "\n",
    "## <a href='#section4'>section 4. summary</a>\n",
    "\n",
    "## <a href='#section5'>section 5. areas for further work</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "<a href='#toc'>Goto Table of Contents</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import math as math\n",
    "import random as rand\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from datetime import datetime\n",
    "import statistics \n",
    "%matplotlib inline\n",
    "\n",
    "#\n",
    "# start comment out if Config.USE_AWS Amazon Web Service\n",
    "#\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "# end of comment out if Config.USE_AWS\n",
    "\n",
    "from numpy.linalg import svd\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import matrix_rank\n",
    "from numpy.linalg import norm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy import stats\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import re\n",
    "\n",
    "def debug(detail,the_output):\n",
    "    if detail < 2:\n",
    "        print(datetime.now(),the_output)\n",
    "    return\n",
    "\n",
    "pd.set_option('display.max_rows', 120)\n",
    "pd.set_option('display.max_columns', 999)\n",
    "pd.set_option('display.width', 1000)\n",
    "np.set_printoptions(edgeitems=150,linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "    NUM_KERAS_TRAIN_LABELS=NUM_KERAS_TRAIN_IMAGES\n",
    "    \n",
    "    NUM_KERAS_TEST_IMAGES=2_000\n",
    "    NUM_KERAS_TEST_LABELS=NUM_KERAS_TEST_IMAGES\n",
    "    \n",
    "    # the number of pixels of each image along x and y axis\n",
    "    NUM_X_PIXELS=28\n",
    "    NUM_Y_PIXELS=28\n",
    "    \n",
    "    NUM_PIXELS_PER_IMAGE=NUM_X_PIXELS*NUM_Y_PIXELS\n",
    "    \n",
    "    # the number of output classes i.e. digits 0-9\n",
    "    NUM_DIGITS=10\n",
    "\n",
    "    # only points whose intensity if greater than the cutoff are considered for centroids\n",
    "    # or any other purpose\n",
    "    PIXEL_CUTOFF=5\n",
    "\n",
    "    # kNN number of neighbors to vote on final classification\n",
    "    N_NEIGHBORS=5\n",
    "    \n",
    "    # run the train/tests with no options at all;\n",
    "    # do NOT append the centroid information to the image\n",
    "    JUST_DO_BASELINE=False\n",
    "    \n",
    "    # use the image as well as the centroid information of the image\n",
    "    APPEND_IMAGE=False\n",
    "    \n",
    "    # collect centroid information of each parent i.e. level(s) above the leaves of the tree of centroids\n",
    "    # of quadrants, subquadrants, subsubquadrants, etc.\n",
    "    USE_PARENT_CENTROIDS=False\n",
    "    \n",
    "    # scale the relative position to match the range of pixel intensities (0-255) so that they are\n",
    "    # of comparable importance in kNN distances\n",
    "    WEIGHTED_CENTROID=False\n",
    "    \n",
    "    # use quadrant subrectangles that overlap by some percentage;\n",
    "    # therefore, some points will be in more than one quadrant\n",
    "    OVERLAP_QUADS_RATIO=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1a'></a>\n",
    "<a href='#toc'>Goto Table of Contents</a>\n",
    "\n",
    "## Function defs only; no test runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of all functions and a brief description of each.\n",
    "\n",
    "### Terminology:\n",
    "\n",
    "### A rectangle is represented by the UpperLeft corner point and the LowerRight corner point\n",
    "\n",
    "### The leaves of the tree of centroids are the centroid of each subquadrant of each subquadrant of each... of each quadrant of the bounding rectangle.\n",
    "\n",
    "### Functions\n",
    "\n",
    "**Get the minimum bounding rectangle of a set of points**\n",
    "- get_max_min_rect(points)\n",
    "    return rect\n",
    "\n",
    "**Get the center of mass of a set of points**\n",
    "- get_centroid(points)\n",
    "    return centroid\n",
    "\n",
    "**Get all points in an image darker than PIXEL_CUTOFF**\n",
    "- get_dark_pixel_coords(one_image)\n",
    "    return points\n",
    "\n",
    "**Get the height of the tree of centroids \n",
    "The leaves are the centroid of each quadrant of each subquadrant of each...etc**\n",
    "- get_tree_height(rect)\n",
    "    return height\n",
    "\n",
    "**Get the rectangle that is one of the four quadrants of the given rectangle**\n",
    "- get_quadrant(quad_ndx,rect)\n",
    "    return subrect\n",
    "\n",
    "**Get the set of points inside a given subrectangle**\n",
    "- get_subrect_pts(subrect,points)\n",
    "    return subrect_pts\n",
    "\n",
    "**Get a numpy array of all centroids within a rectangle and its quadrants and its subquadrants etc.\n",
    "There is one centroid per tree leaf and, if parent centroids config option is true, one per node\n",
    "in the tree levels above the leaves.**\n",
    "- get_centroids_tree(points,rect,tree_level)\n",
    "    return centroids\n",
    "\n",
    "**Get all the centroids for one image, primarily it just calls get_centroids_tree()**\n",
    "- get_centroids(one_image)\n",
    "    return (centroids,rect)\n",
    "\n",
    "**Get the size of the rect along the y-axis in number of pixels**\n",
    "- get_length(rect)\n",
    "    return length\n",
    "\n",
    "**Get the size of the rect along the x-axis in number of pixels**\n",
    "- get_width(rect)\n",
    "    return width\n",
    "\t\n",
    "**Get the image's minimum bounding rectangle and then get all the centroids relative to that rectangle**\n",
    "- get_centroids_relative(one_image)\n",
    "    return centroids_relative\n",
    "\n",
    "**Create a deep learning CNN model for an image with a given number of pixels for width and length**\n",
    "- create_CNN_model(num_x_pixels,num_y_pixels)\n",
    "    return model\n",
    "\n",
    "**Evaluate the deep learning CNN model with the training and testing test and labels**\n",
    "- train_eval_CNN_model(model,train_images,train_labels,\\\n",
    "                         test_images,test_labels,num_extra_rows)\n",
    "    return scores\n",
    "\n",
    "**Output a report with accuracy for deep learning CNN model**\n",
    "- CNN_report(X,y,Xtest,ytest)\n",
    "    return cvscores\n",
    "\n",
    "**Output a report with accuracy when using kNN model for prediction**\n",
    "- kNN_report(centroids_array,y,test_centroids_array,ytest)\n",
    "    return\n",
    "\n",
    "**Run the test; assumes the configuration parameters are set to choose what options are used**\n",
    "- run_tests()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_min_rect(points):\n",
    "    x_coords=points[:,0]\n",
    "    y_coords=points[:,1]\n",
    "    \n",
    "    if len(points)>0:\n",
    "        max_x=np.max(x_coords)\n",
    "        min_x=np.min(x_coords)\n",
    "\n",
    "        max_y=np.max(y_coords)\n",
    "        min_y=np.min(y_coords)\n",
    "    else:\n",
    "        max_x=0\n",
    "        min_x=0\n",
    "        max_y=0\n",
    "        min_y=0\n",
    "    rect=((min_x,max_y),(max_x,min_y))\n",
    "    return rect\n",
    "# get_max_min_rect(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroid(points):\n",
    "    if len(points)>0:\n",
    "        x_centroid=np.mean(points[:,0])\n",
    "        y_centroid=np.mean(points[:,1])\n",
    "    else:\n",
    "        x_centroid=0\n",
    "        y_centroid=0\n",
    "    if Config.WEIGHTED_CENTROID:\n",
    "        centroid=np.ndarray((0,3))\n",
    "        if len(points)>0:\n",
    "            weight=len(points[0])\n",
    "        else:\n",
    "            weight=0\n",
    "        centroid=np.vstack((centroid,(x_centroid,y_centroid,weight)))\n",
    "    else:\n",
    "        centroid=np.ndarray((0,2))\n",
    "        centroid=np.vstack((centroid,(x_centroid,y_centroid)))\n",
    "#     print(type(centroid),centroid.shape)\n",
    "    return centroid\n",
    "# centroid=get_centroid(points)\n",
    "# print(centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dark_pixel_coords(one_image):\n",
    "    points=np.where(one_image>Config.PIXEL_CUTOFF)\n",
    "\n",
    "#     print('points',points)\n",
    "    points=np.vstack([points[0],points[1]]).T\n",
    "#     print('points[0]',points[0])\n",
    "#     print('points[-1]',points[-1])\n",
    "    \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tree_height(rect):\n",
    "    height=TREE_HEIGHT\n",
    "    return height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quadrant(quad_ndx,rect):\n",
    "#     print('get_quadrant:quad_ndx',quad_ndx,':rect',rect)\n",
    "    minx=rect[0][0]\n",
    "    maxy=rect[0][1]\n",
    "    \n",
    "    maxx=rect[1][0]\n",
    "    miny=rect[1][1]\n",
    "    \n",
    "    center_pt=((maxx+minx)/2,(maxy+miny)/2)\n",
    "    \n",
    "    is_y_axis_length=((maxx-minx)<(maxy-miny))\n",
    "#     print('is_y_axis_length',is_y_axis_length)\n",
    "\n",
    "    UR=(maxx,maxy)\n",
    "    LR=(maxx,miny)\n",
    "\n",
    "    UL=(minx,maxy)\n",
    "    LL=(minx,miny)\n",
    "        \n",
    "    top_center=np.sum((UL,UR),axis=0)/2\n",
    "    bottom_center=np.sum((LL,LR),axis=0)/2\n",
    "\n",
    "#     print('UL',UL)\n",
    "#     print('LL',LL)\n",
    "    left_center=np.sum((UL,LL),axis=0)/2\n",
    "    right_center=np.sum((UR,LR),axis=0)/2\n",
    "#     print('top_center',top_center)\n",
    "#     print('bottom_center',bottom_center)\n",
    "#     print('left_center',left_center)\n",
    "#     print('right_center',right_center)\n",
    "\n",
    "    if quad_ndx==0:\n",
    "        UL_subrect_corner=top_center\n",
    "        LR_subrect_corner=right_center\n",
    "    elif quad_ndx==1:\n",
    "        UL_subrect_corner=UL\n",
    "        LR_subrect_corner=center_pt\n",
    "    elif quad_ndx==2:\n",
    "        UL_subrect_corner=left_center\n",
    "        LR_subrect_corner=bottom_center\n",
    "    elif quad_ndx==3:\n",
    "        UL_subrect_corner=center_pt\n",
    "        LR_subrect_corner=LR\n",
    "        \n",
    "    if Config.OVERLAP_QUADS_RATIO!=1:\n",
    "        overlap_x=(LR_subrect_corner[0]-UL_subrect_corner[0])*\\\n",
    "                    Config.OVERLAP_QUADS_RATIO\n",
    "        overlap_y=(UL_subrect_corner[1]-LR_subrect_corner[1])*\\\n",
    "                    Config.OVERLAP_QUADS_RATIO\n",
    "#         print('overlap_x',overlap_x)\n",
    "#         print('overlap_y',overlap_y)\n",
    "        \n",
    "        UL_subrect_corner=UL_subrect_corner+(-overlap_x,overlap_y)\n",
    "        LR_subrect_corner=LR_subrect_corner+(overlap_x,-overlap_y)\n",
    "        subrect=(UL_subrect_corner,LR_subrect_corner)\n",
    "    else:\n",
    "        subrect=(UL_subrect_corner,LR_subrect_corner)\n",
    "#     print('return get_quadrant:subrect',subrect)\n",
    "    return subrect\n",
    "Config.OVERLAP_QUADS_RATIO=1\n",
    "get_quadrant(0,((5, 122), (24, 6)))\n",
    "# get_quadrant(1,((5, 122), (24, 6)))\n",
    "# get_quadrant(2,((5, 122), (24, 6)))\n",
    "# get_quadrant(3,((5, 122), (24, 6)))\n",
    "# get_quadrant(0,((5, 22), (124, 6)))\n",
    "# get_quadrant(1,((5, 22), (124, 6)))\n",
    "# get_quadrant(2,((5, 22), (124, 6)))\n",
    "# get_quadrant(3,((5, 22), (124, 6)))\n",
    "Config.OVERLAP_QUADS_RATIO=0.5\n",
    "get_quadrant(0,((5, 122), (24, 6)))\n",
    "# get_quadrant(1,((5, 122), (24, 6)))\n",
    "# get_quadrant(2,((5, 122), (24, 6)))\n",
    "# get_quadrant(3,((5, 122), (24, 6)))\n",
    "# get_quadrant(0,((5, 22), (124, 6)))\n",
    "# get_quadrant(1,((5, 22), (124, 6)))\n",
    "# get_quadrant(2,((5, 22), (124, 6)))\n",
    "# get_quadrant(3,((5, 22), (124, 6)))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [1., 3.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_subrect_pts(subrect,points):\n",
    "#     print('get_subrect_pts:subrect',subrect)\n",
    "#     print('get_subrect_pts:len(points)',len(points))\n",
    "    (UL,LR)=subrect\n",
    "    ULx=UL[0]\n",
    "    ULy=UL[1]\n",
    "    LRx=LR[0]\n",
    "    LRy=LR[1]\n",
    "    subrect_pts_ndx=np.where((points[:,0]>=ULx) & (points[:,0]<=LRx)&\\\n",
    "                     (points[:,1]<=ULy) & (points[:,1]>=LRy))\n",
    "#     print('subrect_pts_ndx',subrect_pts_ndx)\n",
    "    subrect_pts=points[subrect_pts_ndx]\n",
    "#     print('return get_subrect_pts:subrect_pts',len(subrect_pts),subrect_pts)\n",
    "    return subrect_pts\n",
    "points=np.array(((1,2),(1,3),(4,2),(5,4)),dtype=float)\n",
    "subrect=((0,3),(1,1))\n",
    "get_subrect_pts(subrect,points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroids_tree(points,rect,tree_level):\n",
    "\n",
    "    if Config.USE_PARENT_CENTROIDS:\n",
    "        centroids=get_centroid(points)\n",
    "    else:\n",
    "        if Config.WEIGHTED_CENTROID:\n",
    "            centroids=np.ndarray((0,3))\n",
    "        else:\n",
    "            centroids=np.ndarray((0,2))\n",
    "\n",
    "    if tree_level==0:\n",
    "        centroids=get_centroid(points)\n",
    "    else:\n",
    "        for quad_ndx in range(4):\n",
    "            subrect=get_quadrant(quad_ndx,rect)\n",
    "            subrect_pts=get_subrect_pts(subrect,points)\n",
    "            quad_centroids=get_centroids_tree(subrect_pts,subrect,tree_level-1)\n",
    "            centroids=np.vstack((centroids,quad_centroids))\n",
    "    \n",
    "    return centroids\n",
    "# get_centroids(points,rect,tree_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroids(one_image):\n",
    "\n",
    "    points=get_dark_pixel_coords(one_image)\n",
    "    rect=get_max_min_rect(points)\n",
    "    tree_height=get_tree_height(rect)\n",
    "    centroids=get_centroids_tree(points,rect,tree_height)\n",
    "#     print(type(centroids),centroids.shape)\n",
    "    return (centroids,rect)\n",
    "# centroids_list=get_centroids(one_image)\n",
    "# print(centroids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length(rect):\n",
    "    minx=rect[0][0]\n",
    "    maxy=rect[0][1]\n",
    "    \n",
    "    maxx=rect[1][0]\n",
    "    miny=rect[1][1]\n",
    "    \n",
    "    length=(maxy-miny)\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_width(rect):\n",
    "    minx=rect[0][0]\n",
    "    maxy=rect[0][1]\n",
    "    \n",
    "    maxx=rect[1][0]\n",
    "    miny=rect[1][1]\n",
    "    \n",
    "    width=(maxx-minx)\n",
    "    return width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroids_relative(one_image):\n",
    "    (centroids,boundary_rect)=get_centroids(one_image)\n",
    "    boundary_x_width=get_width(boundary_rect)\n",
    "    boundary_y_length=get_length(boundary_rect)\n",
    "    if Config.WEIGHTED_CENTROID:\n",
    "        boundary_x_width=boundary_x_width/255# scaleto max pixel intensity\n",
    "        boundary_y_length=boundary_y_length/255\n",
    "    if True or USE_REL_BDY:\n",
    "        LLx=boundary_rect[0][0]\n",
    "        LLy=boundary_rect[1][1]\n",
    "        centroids_relative=((centroids[:,0]-LLx),\\\n",
    "                            (centroids[:,1]-LLy))\n",
    "        centroids_relative=((centroids[:,0]-LLx)/boundary_x_width,\\\n",
    "                            (centroids[:,1]-LLy)/boundary_y_length)#-bottom_of_dark_pixels\n",
    "#         print('centroids_relative',centroids_relative)\n",
    "        centroids_relative=np.vstack((np.array(centroids_relative[0]),\\\n",
    "                                      np.array(centroids_relative[1])))\n",
    "#         centroids_relative=(centroids)/boundary_y_length#-bottom_of_dark_pixels\n",
    "    else:\n",
    "        centroids_relative=centroids#(centroids-bottom_of_dark_pixels)/boundary_length\n",
    "    centroids_relative=centroids_relative.flatten()\n",
    "\n",
    "#     print('centroids_relative flatten',centroids_relative)\n",
    "#     print('return get_centroids_relative centroids',type(centroids),centroids.shape)\n",
    "    return centroids_relative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CNN_model(num_x_pixels,num_y_pixels):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(32,(3,3), activation='relu',\\\n",
    "                            input_shape=(num_x_pixels,num_y_pixels,1)))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64,activation='relu'))\n",
    "    model.add(layers.Dense(Config.NUM_DIGITS,activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_CNN_model(model,train_images,train_labels,\\\n",
    "                         test_images,test_labels,num_extra_rows):\n",
    "    train_images=train_images.reshape((len(train_images),\\\n",
    "                                       Config.NUM_X_PIXELS+num_extra_rows,\\\n",
    "                                       Config.NUM_Y_PIXELS,1))#60000\n",
    "    train_images=train_images.astype('float32')/255\n",
    "\n",
    "    test_images=test_images.reshape((len(test_images),\\\n",
    "                                     Config.NUM_X_PIXELS+num_extra_rows,\\\n",
    "                                     Config.NUM_Y_PIXELS,1))#10000\n",
    "    test_images=test_images.astype('float32')/255\n",
    "\n",
    "    train_labels=to_categorical(train_labels)\n",
    "    test_labels=to_categorical(test_labels)\n",
    "\n",
    "    model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    debug(0,'Start of fit')\n",
    "    model.fit(train_images,train_labels,epochs=5,batch_size=64,verbose=1)\n",
    "    debug(0,'End of fit')\n",
    "\n",
    "    scores = model.evaluate(test_images,test_labels,verbose=0)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_report(X,y,Xtest,ytest):\n",
    "    X=np.vstack((X,Xtest))\n",
    "    Y=np.hstack((y,ytest))\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    cvscores = []\n",
    "    \n",
    "    X_num_images=X.shape[0]\n",
    "    X_image_num_pixels=X.shape[1]\n",
    "    num_extra_rows=\\\n",
    "        np.ceil((X_image_num_pixels-Config.NUM_PIXELS_PER_IMAGE)\\\n",
    "                /Config.NUM_X_PIXELS).astype(int)\n",
    "    if num_extra_rows>0:\n",
    "        fill_up_size=(X_image_num_pixels-Config.NUM_PIXELS_PER_IMAGE)\\\n",
    "                    %Config.NUM_X_PIXELS\n",
    "        fill_up_size=Config.NUM_X_PIXELS-fill_up_size\n",
    "        fill_up_last_row=np.zeros((X_num_images,fill_up_size))\n",
    "        print('fill_up_last_row.shape',fill_up_last_row.shape)\n",
    "        X=np.hstack((X,fill_up_last_row))\n",
    "    print('X_num_images',X_num_images,'X_image_num_pixels',X_image_num_pixels)\n",
    "    print('num_extra_rows',num_extra_rows)\n",
    "    \n",
    "    for train, test in kfold.split(X, Y):\n",
    "        model=None\n",
    "        model=create_CNN_model(Config.NUM_X_PIXELS+num_extra_rows,Config.NUM_Y_PIXELS)\n",
    "        scores=train_eval_CNN_model(model,X[train],Y[train],\\\n",
    "                                    X[test], Y[test],num_extra_rows)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        cvscores.append(scores[1] * 100)\n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "    debug(0,'end of verbatim_from_book_CNN')\n",
    "    return cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN_report(centroids_array,y,test_centroids_array,ytest):\n",
    "    kNN=KNeighborsClassifier(n_neighbors=Config.N_NEIGHBORS)\n",
    "    kNN.fit(centroids_array,y)\n",
    "    predicted_labels=kNN.predict(test_centroids_array)\n",
    "    print('predicted_labels',predicted_labels)\n",
    "\n",
    "    ndx_errs=np.where(predicted_labels!=ytest)\n",
    "    print('ndx_errs',ndx_errs)\n",
    "    print('num correct is ',len(ytest) - len(ndx_errs[0]),\\\n",
    "          ' an accuracy of ',1 - len(ndx_errs[0])/len(ytest))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tests():\n",
    "    debug(0,('start'))\n",
    "    (X, y),(Xtest,ytest)=mnist.load_data()\n",
    "\n",
    "    X=X[0:Config.NUM_KERAS_TRAIN_IMAGES]\n",
    "    y=y[0:Config.NUM_KERAS_TRAIN_LABELS]\n",
    "\n",
    "    Xtest=Xtest[0:Config.NUM_KERAS_TEST_IMAGES]\n",
    "    ytest=ytest[0:Config.NUM_KERAS_TEST_LABELS]\n",
    "    \n",
    "    print('ytest',ytest)\n",
    "    \n",
    "    # baseline results\n",
    "    if Config.JUST_DO_BASELINE:\n",
    "        X=np.reshape(X,(len(X),Config.NUM_PIXELS_PER_IMAGE))\n",
    "        Xtest=np.reshape(Xtest,(len(Xtest),Config.NUM_PIXELS_PER_IMAGE))\n",
    "        CNN_report(X,y,Xtest,ytest)\n",
    "        kNN_report(X,y,Xtest,ytest)\n",
    "        return\n",
    "\n",
    "    if Config.USE_PARENT_CENTROIDS:\n",
    "        centroids_array=np.ndarray((0,2*(4**(TREE_HEIGHT+1)-1)//3))#682))#170))#42))#10))\n",
    "    else:\n",
    "        centroids_array=np.ndarray((0,2*4**TREE_HEIGHT))#682))#170))#42))#10))\n",
    "    print(type(centroids_array),centroids_array.shape)\n",
    "    if Config.APPEND_IMAGE:\n",
    "        centroids_array=np.hstack((centroids_array,\\\n",
    "                                  np.ndarray((0,Config.NUM_PIXELS_PER_IMAGE))))\n",
    "        print(type(centroids_array),centroids_array.shape)\n",
    "    for ndx in range(len(X)):\n",
    "        if ndx%2000==0:\n",
    "            print(30*'*',ndx,30*'*')\n",
    "        centroids_relative=get_centroids_relative(X[ndx])\n",
    "        \n",
    "        if Config.APPEND_IMAGE:\n",
    "#             print('main():centroids_array.shape',centroids_array.shape)\n",
    "#             print('main():X[ndx].shape',X[ndx].shape)\n",
    "#             print('main():centroids_relative.shape',centroids_relative.shape)\n",
    "            centroids_relative=np.hstack((centroids_relative,\\\n",
    "                                       np.reshape(X[ndx],(Config.NUM_PIXELS_PER_IMAGE))))\n",
    "            centroids_array=np.vstack((centroids_array,centroids_relative))\n",
    "#             np.reshape(centroids_array,((1,len(centroids_array))))\n",
    "        else:\n",
    "            centroids_array=np.vstack((centroids_array,centroids_relative))\n",
    "            \n",
    "        if ndx<0:\n",
    "            print('main():centroids_array',centroids_array)\n",
    "            print('y[ndx]',y[ndx])\n",
    "            print('one_image',X[ndx])\n",
    "\n",
    "    centroids_array=np.nan_to_num(centroids_array)\n",
    "\n",
    "    if Config.USE_PARENT_CENTROIDS:\n",
    "        test_centroids_array=np.ndarray((0,2*(4**(TREE_HEIGHT+1)-1)//3))#682))#170))#42))#10))\n",
    "    else:\n",
    "        test_centroids_array=np.ndarray((0,2*4**TREE_HEIGHT))\n",
    "    if Config.APPEND_IMAGE:\n",
    "        test_centroids_array=np.hstack((test_centroids_array,\\\n",
    "                                  np.ndarray((0,Config.NUM_PIXELS_PER_IMAGE))))\n",
    "        print(type(test_centroids_array),test_centroids_array.shape)\n",
    "    for ndx in range(len(Xtest)):\n",
    "        if ndx%2000==1999:\n",
    "            print(30*'*',ndx,30*'*')\n",
    "            test_centroids_array=np.nan_to_num(test_centroids_array)\n",
    "            \n",
    "            CNN_report(centroids_array,y,test_centroids_array,ytest[:ndx])\n",
    "            kNN_report(centroids_array,y,test_centroids_array,ytest[:ndx])\n",
    "\n",
    "        test_centroids_relative=get_centroids_relative(Xtest[ndx])\n",
    "        if Config.APPEND_IMAGE:\n",
    "#             print('main():centroids_array.shape',centroids_array.shape)\n",
    "#             print('main():X[ndx].shape',X[ndx].shape)\n",
    "#             print('main():centroids_relative.shape',centroids_relative.shape)\n",
    "            test_centroids_relative=np.hstack((test_centroids_relative,\\\n",
    "                                       np.reshape(Xtest[ndx],(Config.NUM_PIXELS_PER_IMAGE))))\n",
    "            test_centroids_array=np.vstack((test_centroids_array,test_centroids_relative))\n",
    "#             np.reshape(centroids_array,((1,len(centroids_array))))\n",
    "        else:\n",
    "            test_centroids_array=np.vstack((test_centroids_array,test_centroids_relative))\n",
    "\n",
    "        if ndx<0:\n",
    "            print(type(test_centroids_array),test_centroids_array.shape)\n",
    "            print('main():test_centroids_array',test_centroids_array)\n",
    "\n",
    "    test_centroids_array=np.nan_to_num(test_centroids_array)\n",
    "\n",
    "    CNN_report(centroids_array,y,test_centroids_array,ytest)\n",
    "    kNN_report(centroids_array,y,test_centroids_array,ytest)\n",
    "    debug(0,('end'))\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "<a href='#toc'>Goto Table of Contents</a>\n",
    "\n",
    "# End of function defs; start of running tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s2baselines'></a>\n",
    "<a href='#toc'>Goto Table of Contents</a>\n",
    "\n",
    "## kNN baseline (6,000 acc is 91.6%; 60,000 acc is 96.88%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-31 09:14:45.643227 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 9 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 9 8 7 2 3 0 4 4 2 4 1 9 5 7 7 2 8 2 6 8 5 7 7 9 1 8 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 9 2 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 8 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 2 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 3 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 6 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 3 8 8 2 7 5 8 9 6 1 8 4 1 2 5 9 1 9 7 5 4 0 8 9 9 1 0 5 2 3 7\n",
      " 8 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 8 4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 2 1 7 0 6 5 4 3 8 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 2 3 1 9 7 5 1 0 8 4 6 2 6 7 9 3 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 5 8 0 3 7 2 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 7 8 3 3 6 7 2 8 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 8 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5 4 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 5\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 8 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 8 8 8 7 4 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 2 3 2 3 9 1 7 4 0 3 5 5 8 6 3 2 6 7 6 6 3 2 7 8 1 1 7 5 6 4 9 5 1 3 3 4 7 8 9 1 1 6 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 9 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 1 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 3 9 7 9 6 2 7 8 4 7 3 6 1 3 6 4 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 1 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 1 9 9 5 5 1 5 6 0 3 1 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 1 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 1 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 8 8 7 2 6 0 6 4 2 9 1 9 5 7 7 2 6 2 6 8 5 7 7 4 1 0 1 3 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 9 2 9 2 0 4 0\n",
      " 0 2 8 1 7 1 7 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 7 7 9 3 6 4 6 0 7 1 1 2 1 5 3 3 9 7 5 6 5 4 1 3 8 1 0 5 1 9 1 5 5 6 1 8 5 1 4 9 4 6 7 2 5 0 6 8 6 3 7 2 0 8 8 5 4 1 1 4 0 7 3 7 6 1 6 2 1 4 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 5 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 0 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 7 8 8 2 7 5 8 9 6 1 8 4 1 2 5 8 1 9 7 5 4 0 8 9 9 1 0 5 8 3 7\n",
      " 0 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 7 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 1 9 4 0 0 8 3 2 7 1 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 9 8 3 3 9 3 3 3 7 8 0 2 7 1 7 0 6 5 4 3 3 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 1 3 1 9 7 5 1 0 8 4 6 2 6 7 9 9 2 9 8 2 2 9 1 7 3 5 9 1 8 0 2 0 5 6 1 3 7 6 7 1 2 0 8 0 3 7 7 4 0 9 1 8 6 7 1 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 1 8 3 3 6 9 2 4 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 9 4 8 5 5 4 0 5 2 1 6 8 4 5 0 4 0 6 1 5 3 2 6 7 2 6 9 3 1 4 6 2 5 9 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 3 3 1 4 5 6 8 9 4 1 9\n",
      " 3 8 0 6 2 1 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 4 1 7 9 6 1 1 2 4 0 1 7 7 4 3 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 6 2 2 5 6 0 8 2 9 2 8 8 8 8 7 9 4 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 7 3 0 3 9 1 1 4 0 3 5 5 6 6 5 0 6 7 6 6 3 2 7 9 1 1 7 4 6 4 9 5 1 5 3 4 7 8 9 1 1 0 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "ndx_errs (array([ 24,  43,  77,  80,  92, 111, 115, 149, 159, 175, 195, 241, 245, 247, 250, 257, 264, 266, 268, 290, 300, 303, 320, 321, 324, 326, 338, 341, 349, 358, 362, 367, 381, 389, 403, 445, 464, 479,\n",
      "       492, 495, 511, 542, 543, 547, 551, 571, 582, 583, 591, 613, 628, 635, 646, 654, 659, 667, 684, 689, 691, 707, 714, 717, 726, 740, 781, 791, 795, 797, 830, 839, 844, 866, 881, 882, 924, 926,\n",
      "       930, 936, 938, 939, 947, 951, 957, 965], dtype=int64),)\n",
      "num correct is  916  an accuracy of  0.916\n"
     ]
    }
   ],
   "source": [
    "Config.JUST_DO_BASELINE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=6_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=1_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.JUST_DO_BASELINE=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-30 09:19:16.465133 start\n",
      "num correct is  9688  an accuracy of  0.9688\n"
     ]
    }
   ],
   "source": [
    "Config.JUST_DO_BASELINE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.JUST_DO_BASELINE=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN and kNN baseline (more recent code)  \n",
    "\n",
    "## For CNN baseline (6,000 acc is 96.06% (+/- 1.42%); 60,000 acc is 99.00% (+/- 0.21%))\n",
    "## For kNN baseline (6,000 acc is 91.6%; 60,000 acc is 96.88%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-02 10:29:22.461520 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 9 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 9 8 7 2 3 0 4 4 2 4 1 9 5 7 7 2 8 2 6 8 5 7 7 9 1 8 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 9 2 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 8 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 2 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 3 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 6 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 3 8 8 2 7 5 8 9 6 1 8 4 1 2 5 9 1 9 7 5 4 0 8 9 9 1 0 5 2 3 7\n",
      " 8 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 8 4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 2 1 7 0 6 5 4 3 8 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 2 3 1 9 7 5 1 0 8 4 6 2 6 7 9 3 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 5 8 0 3 7 2 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 7 8 3 3 6 7 2 8 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 8 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5 4 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 5\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 8 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 8 8 8 7 4 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 2 3 2 3 9 1 7 4 0 3 5 5 8 6 3 2 6 7 6 6 3 2 7 8 1 1 7 5 6 4 9 5 1 3 3 4 7 8 9 1 1 6 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "X_num_images 7000 X_image_num_pixels 784\n",
      "num_extra_rows 0\n",
      "2020-06-02 10:29:23.018560 Start of fit\n",
      "Epoch 1/5\n",
      "6296/6296 [==============================] - 3s 422us/sample - loss: 0.7363 - acc: 0.7646\n",
      "Epoch 2/5\n",
      "6296/6296 [==============================] - 2s 352us/sample - loss: 0.2341 - acc: 0.9252\n",
      "Epoch 3/5\n",
      "6296/6296 [==============================] - 2s 352us/sample - loss: 0.1391 - acc: 0.9546s - loss: 0.139\n",
      "Epoch 4/5\n",
      "6296/6296 [==============================] - 2s 343us/sample - loss: 0.1030 - acc: 0.9671\n",
      "Epoch 5/5\n",
      "6296/6296 [==============================] - 2s 379us/sample - loss: 0.0719 - acc: 0.9759\n",
      "2020-06-02 10:29:36.244672 End of fit\n",
      "acc: 93.47%\n",
      "2020-06-02 10:29:36.719203 Start of fit\n",
      "Epoch 1/5\n",
      "6297/6297 [==============================] - 3s 406us/sample - loss: 0.7027 - acc: 0.7788s - loss: 1.6138 - ac - ETA: 1s - loss:\n",
      "Epoch 2/5\n",
      "6297/6297 [==============================] - 2s 354us/sample - loss: 0.2164 - acc: 0.9362\n",
      "Epoch 3/5\n",
      "6297/6297 [==============================] - 2s 353us/sample - loss: 0.1277 - acc: 0.9627\n",
      "Epoch 4/5\n",
      "6297/6297 [==============================] - 2s 356us/sample - loss: 0.0955 - acc: 0.9727s - loss: 0.1000 - acc:  - ETA: 1s - loss: 0\n",
      "Epoch 5/5\n",
      "6297/6297 [==============================] - 2s 372us/sample - loss: 0.0725 - acc: 0.9779\n",
      "2020-06-02 10:29:49.037726 End of fit\n",
      "acc: 94.74%\n",
      "2020-06-02 10:29:49.535638 Start of fit\n",
      "Epoch 1/5\n",
      "6297/6297 [==============================] - 3s 428us/sample - loss: 0.6526 - acc: 0.7993\n",
      "Epoch 2/5\n",
      "6297/6297 [==============================] - 2s 368us/sample - loss: 0.1925 - acc: 0.9419s - loss: 0.1943 - acc:\n",
      "Epoch 3/5\n",
      "6297/6297 [==============================] - 2s 359us/sample - loss: 0.1203 - acc: 0.9624s - lo\n",
      "Epoch 4/5\n",
      "6297/6297 [==============================] - 2s 368us/sample - loss: 0.0807 - acc: 0.9749s - loss: 0.0792 - acc: 0\n",
      "Epoch 5/5\n",
      "6297/6297 [==============================] - 2s 361us/sample - loss: 0.0650 - acc: 0.9789\n",
      "2020-06-02 10:30:02.211044 End of fit\n",
      "acc: 97.72%\n",
      "2020-06-02 10:30:02.688657 Start of fit\n",
      "Epoch 1/5\n",
      "6298/6298 [==============================] - 3s 422us/sample - loss: 0.7193 - acc: 0.7675\n",
      "Epoch 2/5\n",
      "6298/6298 [==============================] - 2s 393us/sample - loss: 0.2092 - acc: 0.9355\n",
      "Epoch 3/5\n",
      "6298/6298 [==============================] - 2s 367us/sample - loss: 0.1269 - acc: 0.9608\n",
      "Epoch 4/5\n",
      "6298/6298 [==============================] - 2s 357us/sample - loss: 0.0912 - acc: 0.9719s - loss: 0.\n",
      "Epoch 5/5\n",
      "6298/6298 [==============================] - 2s 370us/sample - loss: 0.0652 - acc: 0.9803s - loss: 0.0631\n",
      "2020-06-02 10:30:15.545545 End of fit\n",
      "acc: 96.72%\n",
      "2020-06-02 10:30:16.060585 Start of fit\n",
      "Epoch 1/5\n",
      "6298/6298 [==============================] - 3s 412us/sample - loss: 0.6902 - acc: 0.7814\n",
      "Epoch 2/5\n",
      "6298/6298 [==============================] - 2s 380us/sample - loss: 0.1829 - acc: 0.9452s - loss: 0.1872 - acc: 0.94\n",
      "Epoch 3/5\n",
      "6298/6298 [==============================] - 2s 374us/sample - loss: 0.1182 - acc: 0.9619s - loss: 0.1219 - a\n",
      "Epoch 4/5\n",
      "6298/6298 [==============================] - 2s 362us/sample - loss: 0.0881 - acc: 0.9701s - loss: 0.0889 - \n",
      "Epoch 5/5\n",
      "6298/6298 [==============================] - 2s 371us/sample - loss: 0.0632 - acc: 0.9802s - loss: 0.0637 - a\n",
      "2020-06-02 10:30:28.956953 End of fit\n",
      "acc: 96.58%\n",
      "2020-06-02 10:30:29.477378 Start of fit\n",
      "Epoch 1/5\n",
      "6301/6301 [==============================] - 3s 418us/sample - loss: 0.7209 - acc: 0.7646\n",
      "Epoch 2/5\n",
      "6301/6301 [==============================] - 2s 373us/sample - loss: 0.2182 - acc: 0.9338\n",
      "Epoch 3/5\n",
      "6301/6301 [==============================] - 2s 389us/sample - loss: 0.1373 - acc: 0.9602\n",
      "Epoch 4/5\n",
      "6301/6301 [==============================] - 2s 365us/sample - loss: 0.0963 - acc: 0.9710s\n",
      "Epoch 5/5\n",
      "6301/6301 [==============================] - 2s 375us/sample - loss: 0.0721 - acc: 0.9744\n",
      "2020-06-02 10:30:42.463453 End of fit\n",
      "acc: 97.14%\n",
      "2020-06-02 10:30:43.026109 Start of fit\n",
      "Epoch 1/5\n",
      "6301/6301 [==============================] - 3s 411us/sample - loss: 0.6954 - acc: 0.7829\n",
      "Epoch 2/5\n",
      "6301/6301 [==============================] - 2s 369us/sample - loss: 0.2090 - acc: 0.9391 ETA: 0s - loss: 0.2134 - acc: 0.9\n",
      "Epoch 3/5\n",
      "6301/6301 [==============================] - 2s 372us/sample - loss: 0.1313 - acc: 0.9579\n",
      "Epoch 4/5\n",
      "6301/6301 [==============================] - 3s 410us/sample - loss: 0.0971 - acc: 0.9697s - loss: 0.0977 - \n",
      "Epoch 5/5\n",
      "6301/6301 [==============================] - 2s 374us/sample - loss: 0.0730 - acc: 0.9767s - loss: 0.0441 - ETA: 1s - loss: 0.0 - ETA: 0s - loss: 0.0692 - acc: 0.97 - ETA: 0s - loss: 0.0717 - acc: 0.97\n",
      "2020-06-02 10:30:56.122071 End of fit\n",
      "acc: 97.14%\n",
      "2020-06-02 10:30:56.723819 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 3s 418us/sample - loss: 0.7036 - acc: 0.7789s - loss: 0.8855 - acc: 0.7 - ETA: 0s - loss: 0.8410 - ac\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 2s 373us/sample - loss: 0.2014 - acc: 0.9392s \n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 2s 381us/sample - loss: 0.1260 - acc: 0.9611s - loss: 0.1297 - acc: 0.9 - ETA: 0s - loss: 0.1270 - ac\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 2s 391us/sample - loss: 0.0915 - acc: 0.9703\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 2s 378us/sample - loss: 0.0680 - acc: 0.9789s - loss: 0.0\n",
      "2020-06-02 10:31:09.922746 End of fit\n",
      "acc: 94.11%\n",
      "2020-06-02 10:31:10.487752 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 3s 422us/sample - loss: 0.7063 - acc: 0.7720\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 2s 383us/sample - loss: 0.2000 - acc: 0.9377\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 3s 430us/sample - loss: 0.1203 - acc: 0.9626s - loss:  - ETA: 0s - loss: 0.1167 - \n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 2s 368us/sample - loss: 0.0799 - acc: 0.9743s - loss: 0.0806 - acc: 0.\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 2s 363us/sample - loss: 0.0592 - acc: 0.9811s - loss: 0.0611 - acc\n",
      "2020-06-02 10:31:23.882297 End of fit\n",
      "acc: 95.55%\n",
      "2020-06-02 10:31:24.472755 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 3s 422us/sample - loss: 0.7051 - acc: 0.7763\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 2s 346us/sample - loss: 0.2106 - acc: 0.9339\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 2s 351us/sample - loss: 0.1281 - acc: 0.9607\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 2s 351us/sample - loss: 0.0894 - acc: 0.9721s \n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 2s 352us/sample - loss: 0.0643 - acc: 0.9805\n",
      "2020-06-02 10:31:36.977011 End of fit\n",
      "acc: 97.41%\n",
      "96.06% (+/- 1.42%)\n",
      "2020-06-02 10:31:37.422709 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 9 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 1 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 3 9 7 9 6 2 7 8 4 7 3 6 1 3 6 4 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 1 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 1 9 9 5 5 1 5 6 0 3 1 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 1 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 1 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 8 8 7 2 6 0 6 4 2 9 1 9 5 7 7 2 6 2 6 8 5 7 7 4 1 0 1 3 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 9 2 9 2 0 4 0\n",
      " 0 2 8 1 7 1 7 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 7 7 9 3 6 4 6 0 7 1 1 2 1 5 3 3 9 7 5 6 5 4 1 3 8 1 0 5 1 9 1 5 5 6 1 8 5 1 4 9 4 6 7 2 5 0 6 8 6 3 7 2 0 8 8 5 4 1 1 4 0 7 3 7 6 1 6 2 1 4 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 5 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 0 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 7 8 8 2 7 5 8 9 6 1 8 4 1 2 5 8 1 9 7 5 4 0 8 9 9 1 0 5 8 3 7\n",
      " 0 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 7 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 1 9 4 0 0 8 3 2 7 1 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 9 8 3 3 9 3 3 3 7 8 0 2 7 1 7 0 6 5 4 3 3 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 1 3 1 9 7 5 1 0 8 4 6 2 6 7 9 9 2 9 8 2 2 9 1 7 3 5 9 1 8 0 2 0 5 6 1 3 7 6 7 1 2 0 8 0 3 7 7 4 0 9 1 8 6 7 1 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 1 8 3 3 6 9 2 4 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 9 4 8 5 5 4 0 5 2 1 6 8 4 5 0 4 0 6 1 5 3 2 6 7 2 6 9 3 1 4 6 2 5 9 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 3 3 1 4 5 6 8 9 4 1 9\n",
      " 3 8 0 6 2 1 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 4 1 7 9 6 1 1 2 4 0 1 7 7 4 3 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 6 2 2 5 6 0 8 2 9 2 8 8 8 8 7 9 4 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 7 3 0 3 9 1 1 4 0 3 5 5 6 6 5 0 6 7 6 6 3 2 7 9 1 1 7 4 6 4 9 5 1 5 3 4 7 8 9 1 1 0 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "ndx_errs (array([ 24,  43,  77,  80,  92, 111, 115, 149, 159, 175, 195, 241, 245, 247, 250, 257, 264, 266, 268, 290, 300, 303, 320, 321, 324, 326, 338, 341, 349, 358, 362, 367, 381, 389, 403, 445, 464, 479,\n",
      "       492, 495, 511, 542, 543, 547, 551, 571, 582, 583, 591, 613, 628, 635, 646, 654, 659, 667, 684, 689, 691, 707, 714, 717, 726, 740, 781, 791, 795, 797, 830, 839, 844, 866, 881, 882, 924, 926,\n",
      "       930, 936, 938, 939, 947, 951, 957, 965], dtype=int64),)\n",
      "num correct is  916  an accuracy of  0.916\n"
     ]
    }
   ],
   "source": [
    "Config.JUST_DO_BASELINE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=6_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=1_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.JUST_DO_BASELINE=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-02 20:33:06.993948 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7 7\n",
      " 1 0 1 7 8 9 0 1 2 3 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "X_num_images 70000 X_image_num_pixels 784\n",
      "num_extra_rows 0\n",
      "2020-06-02 20:33:08.390259 Start of fit\n",
      "Epoch 1/5\n",
      "62995/62995 [==============================] - 33s 520us/sample - loss: 0.1733 - acc: 0.9453s - loss: 0.27 - ETA: 14s -  - ETA: 13s - loss: 0.24 - \n",
      "Epoch 2/5\n",
      "62995/62995 [==============================] - 30s 477us/sample - loss: 0.0436 - acc: 0.9859\n",
      "Epoch 3/5\n",
      "62995/62995 [==============================] - 29s 467us/sample - loss: 0.0307 - acc: 0.9900\n",
      "Epoch 4/5\n",
      "62995/62995 [==============================] - 30s 474us/sample - loss: 0.0229 - acc: 0.9925 - loss: 0. - ETA: 0s - loss: 0.0230 - acc:\n",
      "Epoch 5/5\n",
      "62995/62995 [==============================] - 30s 476us/sample - loss: 0.0187 - acc: 0.9940\n",
      "2020-06-02 20:35:48.166404 End of fit\n",
      "acc: 98.87%\n",
      "2020-06-02 20:35:53.905455 Start of fit\n",
      "Epoch 1/5\n",
      "62996/62996 [==============================] - 32s 503us/sample - loss: 0.1686 - acc: 0.9473 - loss: 0.1739 - acc:  - ETA: 1s - loss: 0.\n",
      "Epoch 2/5\n",
      "62996/62996 [==============================] - 31s 484us/sample - loss: 0.0447 - acc: 0.9865\n",
      "Epoch 3/5\n",
      "62996/62996 [==============================] - 29s 467us/sample - loss: 0.0312 - acc: 0.9904 - loss: 0 - \n",
      "Epoch 4/5\n",
      "62996/62996 [==============================] - 30s 468us/sample - loss: 0.0245 - acc: 0.9923 - loss: 0.0246  - ETA: 0s - loss: 0.0245 - acc: 0.992 - ETA: 0s - loss: 0.0245 - acc: 0.99\n",
      "Epoch 5/5\n",
      "62996/62996 [==============================] - 30s 476us/sample - loss: 0.0188 - acc: 0.9942\n",
      "2020-06-02 20:38:32.533659 End of fit\n",
      "acc: 99.26%\n",
      "2020-06-02 20:38:37.768268 Start of fit\n",
      "Epoch 1/5\n",
      "62996/62996 [==============================] - 32s 501us/sample - loss: 0.1595 - acc: 0.9504\n",
      "Epoch 2/5\n",
      "62996/62996 [==============================] - 31s 487us/sample - loss: 0.0438 - acc: 0.9860 - loss: 0.0439 - acc: 0\n",
      "Epoch 3/5\n",
      "62996/62996 [==============================] - 30s 483us/sample - loss: 0.0304 - acc: 0.9905 - loss: 0.030\n",
      "Epoch 4/5\n",
      "62996/62996 [==============================] - 30s 474us/sample - loss: 0.0231 - acc: 0.9931 - loss: 0.0232\n",
      "Epoch 5/5\n",
      "62996/62996 [==============================] - 30s 476us/sample - loss: 0.0184 - acc: 0.9942 - loss: 0.0186 - acc: 0.99 - ETA: 1s - loss: 0.0186 - acc: 0.994 - ETA: 1s -  - ETA: 0s - loss: 0.0185 - acc: 0. - ETA: 0s - loss: 0.0184 - acc: 0.99\n",
      "2020-06-02 20:41:17.553532 End of fit\n",
      "acc: 98.77%\n",
      "2020-06-02 20:41:22.702077 Start of fit\n",
      "Epoch 1/5\n",
      "62999/62999 [==============================] - 32s 502us/sample - loss: 0.1624 - acc: 0.9486\n",
      "Epoch 2/5\n",
      "62999/62999 [==============================] - 30s 481us/sample - loss: 0.0452 - acc: 0.9853\n",
      "Epoch 3/5\n",
      "62999/62999 [==============================] - 30s 470us/sample - loss: 0.0311 - acc: 0.9900 - loss: 0.03\n",
      "Epoch 4/5\n",
      "62999/62999 [==============================] - 30s 474us/sample - loss: 0.0228 - acc: 0.9929 ETA: 2s - loss - ETA: 1s - \n",
      "Epoch 5/5\n",
      "62999/62999 [==============================] - 29s 468us/sample - loss: 0.0176 - acc: 0.9947 - loss: 0.0176 - acc\n",
      "2020-06-02 20:44:00.873856 End of fit\n",
      "acc: 99.11%\n",
      "2020-06-02 20:45:03.203678 Start of fit\n",
      "Epoch 1/5\n",
      "63000/63000 [==============================] - 32s 511us/sample - loss: 0.1660 - acc: 0.9487\n",
      "Epoch 2/5\n",
      "63000/63000 [==============================] - 31s 488us/sample - loss: 0.0426 - acc: 0.9866\n",
      "Epoch 3/5\n",
      "63000/63000 [==============================] - 30s 483us/sample - loss: 0.0297 - acc: 0.9905\n",
      "Epoch 4/5\n",
      "63000/63000 [==============================] - 31s 485us/sample - loss: 0.0222 - acc: 0.9926\n",
      "Epoch 5/5\n",
      "63000/63000 [==============================] - 30s 480us/sample - loss: 0.0181 - acc: 0.9945 - loss: 0.0184 -  - ETA: 1s - loss: 0.0183 - acc: 0.994 - ETA: 1s - loss: 0.0182 - acc: 0.99 - ETA: 1s - loss: \n",
      "2020-06-02 20:47:45.887589 End of fit\n",
      "acc: 99.19%\n",
      "2020-06-02 20:47:52.386595 Start of fit\n",
      "Epoch 1/5\n",
      "63001/63001 [==============================] - 33s 517us/sample - loss: 0.1623 - acc: 0.9488 - loss: 0.1673 - acc: - ETA: 1s - loss: 0.1654 - acc - ETA: 0s - loss: 0.1637 - acc: 0.94 - ETA: 0s - loss: 0.1632 - acc:\n",
      "Epoch 2/5\n",
      "63001/63001 [==============================] - 30s 481us/sample - loss: 0.0453 - acc: 0.9859 - loss: 0.0 - ETA: 4s -\n",
      "Epoch 3/5\n",
      "63001/63001 [==============================] - 30s 481us/sample - loss: 0.0312 - acc: 0.9902\n",
      "Epoch 4/5\n",
      "63001/63001 [==============================] - 30s 479us/sample - loss: 0.0245 - acc: 0.9928 - l - ETA: 3s - loss: \n",
      "Epoch 5/5\n",
      "63001/63001 [==============================] - 30s 483us/sample - loss: 0.0187 - acc: 0.9944 - loss\n",
      "2020-06-02 20:50:34.819042 End of fit\n",
      "acc: 99.10%\n",
      "2020-06-02 20:50:40.060717 Start of fit\n",
      "Epoch 1/5\n",
      "63002/63002 [==============================] - 32s 501us/sample - loss: 0.1613 - acc: 0.9502\n",
      "Epoch 2/5\n",
      "63002/63002 [==============================] - 30s 477us/sample - loss: 0.0446 - acc: 0.9863 - loss: 0.\n",
      "Epoch 3/5\n",
      "63002/63002 [==============================] - 30s 479us/sample - loss: 0.0306 - acc: 0.9904\n",
      "Epoch 4/5\n",
      "63002/63002 [==============================] - 30s 477us/sample - loss: 0.0234 - acc: 0.9926 -  - ETA: 5s - loss: 0.0234 - acc: 0.99 - ETA: 5s - loss: 0. - ETA: \n",
      "Epoch 5/5\n",
      "63002/63002 [==============================] - 30s 472us/sample - loss: 0.0189 - acc: 0.9942 - loss: - ETA: 1s - loss:\n",
      "2020-06-02 20:53:19.577863 End of fit\n",
      "acc: 99.17%\n",
      "2020-06-02 20:53:25.272816 Start of fit\n",
      "Epoch 1/5\n",
      "63003/63003 [==============================] - 32s 501us/sample - loss: 0.1602 - acc: 0.9491  - ETA: 4s - loss: 0.1786 - acc: - ETA: 4s - loss: 0.1770 - acc: 0.943 - ETA: 4s -\n",
      "Epoch 2/5\n",
      "63003/63003 [==============================] - 30s 471us/sample - loss: 0.0449 - acc: 0.9859 - loss: 0.0450 - acc: 0\n",
      "Epoch 3/5\n",
      "63003/63003 [==============================] - 30s 478us/sample - loss: 0.0300 - acc: 0.9906\n",
      "Epoch 4/5\n",
      "63003/63003 [==============================] - 30s 477us/sample - loss: 0.0227 - acc: 0.9930 - loss: 0.02 - E - ETA: 2s - loss: 0.0219 - ac - ETA: 2s - loss: 0.0221 - acc: 0.99 - ETA:\n",
      "Epoch 5/5\n",
      "63003/63003 [==============================] - 30s 476us/sample - loss: 0.0179 - acc: 0.9943\n",
      "2020-06-02 20:56:11.922241 End of fit\n",
      "acc: 98.79%\n",
      "2020-06-02 20:56:17.430341 Start of fit\n",
      "Epoch 1/5\n",
      "63004/63004 [==============================] - 32s 501us/sample - loss: 0.1633 - acc: 0.9495\n",
      "Epoch 2/5\n",
      "63004/63004 [==============================] - 30s 478us/sample - loss: 0.0443 - acc: 0.9863s - loss:  - E - ETA: 3s  - ETA: 1s - los\n",
      "Epoch 3/5\n",
      "63004/63004 [==============================] - 29s 465us/sample - loss: 0.0305 - acc: 0.9910 - loss: 0.0305 -  - ETA: 5s  - ET - ET\n",
      "Epoch 4/5\n",
      "63004/63004 [==============================] - 29s 462us/sample - loss: 0.0230 - acc: 0.9927 - loss: 0.022 - - ETA: 1s - loss: 0.0229 - ETA: 0s - loss: 0.0229 -\n",
      "Epoch 5/5\n",
      "63004/63004 [==============================] - 29s 466us/sample - loss: 0.0188 - acc: 0.9942 - l - ETA: 0s - loss: 0.0189 - acc: 0.9\n",
      "2020-06-02 20:58:54.865281 End of fit\n",
      "acc: 98.60%\n",
      "2020-06-02 20:59:00.262672 Start of fit\n",
      "Epoch 1/5\n",
      "63004/63004 [==============================] - 31s 499us/sample - loss: 0.1607 - acc: 0.9504\n",
      "Epoch 2/5\n",
      "63004/63004 [==============================] - 30s 473us/sample - loss: 0.0430 - acc: 0.9865 - loss: 0.045 - ETA: 6s - loss: 0.0453 - acc: 0.9 - ETA: 6s - loss: 0.0450 - acc:  - ETA: 5s - loss: 0.\n",
      "Epoch 3/5\n",
      "63004/63004 [==============================] - 29s 464us/sample - loss: 0.0289 - acc: 0.9910 -  - ETA\n",
      "Epoch 4/5\n",
      "63004/63004 [==============================] - 29s 467us/sample - loss: 0.0236 - acc: 0.9928 - loss: 0.0232 - acc - ETA: 3s - loss: 0.0 - ETA:\n",
      "Epoch 5/5\n",
      "63004/63004 [==============================] - 29s 453us/sample - loss: 0.0182 - acc: 0.9943 - loss: 0.018 - ETA: 1s \n",
      "2020-06-02 21:01:36.375405 End of fit\n",
      "acc: 99.17%\n",
      "99.00% (+/- 0.21%)\n",
      "2020-06-02 21:01:40.900391 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 0 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 6 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7 7\n",
      " 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 5 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "ndx_errs (array([  33,  115,  195,  241,  247,  300,  318,  320,  321,  341,  358,  381,  444,  445,  464,  479,  495,  542,  551,  565,  582,  583,  628,  646,  659,  691,  707,  740,  791,  839,  844,  877,\n",
      "        881,  924,  938,  939,  947,  951,  957, 1014, 1039, 1062, 1068, 1082, 1089, 1107, 1112, 1192, 1202, 1226, 1242, 1247, 1260, 1289, 1299, 1319, 1325, 1326, 1364, 1394, 1465, 1466, 1500, 1522,\n",
      "       1523, 1530, 1553, 1559, 1681, 1709, 1717, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1823, 1850, 1855, 1865, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2053, 2063, 2082, 2093, 2098, 2109,\n",
      "       2118, 2129, 2130, 2135, 2168, 2177, 2182, 2189, 2197, 2224, 2237, 2293, 2298, 2299, 2325, 2339, 2371, 2387, 2393, 2406, 2422, 2426, 2437, 2454, 2462, 2488, 2533, 2582, 2597, 2607, 2648, 2654,\n",
      "       2730, 2758, 2771, 2810, 2863, 2896, 2901, 2927, 2939, 2952, 2953, 3005, 3060, 3062, 3073, 3117, 3160, 3206, 3225, 3262, 3269, 3333, 3369, 3384, 3405, 3456, 3475, 3503, 3520, 3558, 3559, 3597,\n",
      "       3599, 3629, 3654, 3662, 3702, 3727, 3751, 3757, 3767, 3780, 3796, 3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3976, 4017, 4027, 4056, 4065, 4075, 4078, 4116, 4140, 4163, 4176, 4194, 4199,\n",
      "       4224, 4289, 4306, 4317, 4330, 4341, 4344, 4374, 4435, 4451, 4483, 4497, 4500, 4504, 4521, 4575, 4578, 4635, 4639, 4671, 4690, 4699, 4731, 4737, 4761, 4785, 4807, 4814, 4823, 4837, 4860, 4879,\n",
      "       4886, 4890, 4966, 5068, 5176, 5209, 5586, 5600, 5676, 5678, 5691, 5714, 5734, 5757, 5835, 5841, 5887, 5888, 5891, 5906, 5936, 5937, 5955, 5997, 6011, 6023, 6035, 6059, 6071, 6081, 6091, 6166,\n",
      "       6172, 6173, 6505, 6555, 6569, 6571, 6577, 6597, 6625, 6651, 7121, 7432, 7434, 7492, 7545, 7637, 7797, 7821, 8059, 8094, 8095, 8277, 8279, 8290, 8325, 8408, 8416, 8520, 8527, 9009, 9015, 9024,\n",
      "       9280, 9544, 9613, 9624, 9634, 9642, 9655, 9664, 9686, 9719, 9729, 9741, 9745, 9751, 9768, 9770, 9779, 9808, 9811, 9839, 9879, 9904, 9905, 9944], dtype=int64),)\n",
      "num correct is  9688  an accuracy of  0.9688\n"
     ]
    }
   ],
   "source": [
    "Config.JUST_DO_BASELINE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.JUST_DO_BASELINE=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s2improvements'></a>\n",
    "<a href='#toc'>Goto Table of Contents</a>\n",
    "\n",
    "# Improvements by adding centroid information to each image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding 2**TREE_HEIGHT weighted centroids improves \n",
    "\n",
    "## - kNN to 97.0% from kNN baseline of 96.88% for 60,000 and to 93.90% from 91.60% for 6,000\n",
    "\n",
    "## Improved kNN (6,000 93.9%; 60,000 acc is 97.0%)\n",
    "## For kNN baseline (6,000 acc is 91.6%; 60,000 acc is 96.88%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-31 11:08:01.346483 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7 7\n",
      " 1 0 1 7 8 9 0 1 2 3 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "<class 'numpy.ndarray'> (0, 128)\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "****************************** 6000 ******************************\n",
      "****************************** 8000 ******************************\n",
      "****************************** 10000 ******************************\n",
      "****************************** 12000 ******************************\n",
      "****************************** 14000 ******************************\n",
      "****************************** 16000 ******************************\n",
      "****************************** 18000 ******************************\n",
      "****************************** 20000 ******************************\n",
      "****************************** 22000 ******************************\n",
      "****************************** 24000 ******************************\n",
      "****************************** 26000 ******************************\n",
      "****************************** 28000 ******************************\n",
      "****************************** 30000 ******************************\n",
      "****************************** 32000 ******************************\n",
      "****************************** 34000 ******************************\n",
      "****************************** 36000 ******************************\n",
      "****************************** 38000 ******************************\n",
      "****************************** 40000 ******************************\n",
      "****************************** 42000 ******************************\n",
      "****************************** 44000 ******************************\n",
      "****************************** 46000 ******************************\n",
      "****************************** 48000 ******************************\n",
      "****************************** 50000 ******************************\n",
      "****************************** 52000 ******************************\n",
      "****************************** 54000 ******************************\n",
      "****************************** 56000 ******************************\n",
      "****************************** 58000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "****************************** 1999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 4 7 9 6 9 6 8 3 6 6 8 5 1 4 2 4 4 5 1 1 9 0 2 4 9 5 7 1 8 3 5 6 9 8 7 1 1 6 7 6 3 2 2 0 8 9\n",
      " 2 5 1 0 8 1 4 5 7 9 6 9 0 6 1 5 5 8 3 8 2 6 5 0 7 4 6 1 3 4 7 3 2 3 4 2 5 2 7 1 7 2 6 4 1 5 7 8 6 0 1 8 2 5 7 7 6 5 3 5 2 4 2 4 0 8 8 3 4 9 2 7 5 8 6 3 6 0 8 6 7 3 6 4 9 4 6 6 3 0 4 1 0 1 4 6 2 9 1\n",
      " 1 0 6 3 9]\n",
      "ndx_errs (array([ 151,  241,  247,  320,  321,  338,  376,  381,  444,  445,  448,  464,  495,  542,  582,  628,  659,  691,  707,  716,  740,  760,  839,  844,  877,  883,  924,  938,  939,  947,  951,  956,\n",
      "        957, 1003, 1014, 1015, 1039, 1062, 1077, 1089, 1107, 1112, 1173, 1192, 1226, 1228, 1232, 1242, 1247, 1260, 1283, 1299, 1319, 1325, 1326, 1364, 1393, 1414, 1433, 1500, 1522, 1530, 1549, 1553,\n",
      "       1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1737, 1782, 1790, 1813, 1850, 1878, 1901, 1952, 1955, 1970, 1984], dtype=int64),)\n",
      "num correct is  1915  an accuracy of  0.9579789894947474\n",
      "****************************** 3999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 9 1 1 0 7 5 9 9 1 9 5 9 2 5 0 4 1 0 8 9 0 8 9 8 9 4 2 5 7 9 8 9 8 0 9 9 6 8 9 9 5 9 8 0 1\n",
      " 0 3 8 5 2 1 6 3 0 2 8 1 5 6 2 3 0 2 2 6 4 3 5 5 1 7 2 1 6 9 1 3 9 5 5 1 6 2 2 8 6 7 1 9 6 0 6 0 3 3 2 2 3 6 8 9 8 5 3 8 5 4 5 2 0 5 6 3 2 8 3 9 9 5 7 9 4 6 7 1 3 7 3 6 6 0 9 0 1 9 9 2 8 8 0 1 6 9 7\n",
      " 5 3 4 7 4]\n",
      "ndx_errs (array([ 151,  241,  247,  320,  321,  338,  376,  381,  444,  445,  448,  464,  495,  542,  582,  628,  659,  691,  707,  716,  740,  760,  839,  844,  877,  883,  924,  938,  939,  947,  951,  956,\n",
      "        957, 1003, 1014, 1015, 1039, 1062, 1077, 1089, 1107, 1112, 1173, 1192, 1226, 1228, 1232, 1242, 1247, 1260, 1283, 1299, 1319, 1325, 1326, 1364, 1393, 1414, 1433, 1500, 1522, 1530, 1549, 1553,\n",
      "       1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1737, 1782, 1790, 1813, 1850, 1878, 1901, 1952, 1955, 1970, 1984, 2004, 2044, 2052, 2070, 2098, 2109, 2118, 2129, 2130, 2135, 2168, 2177,\n",
      "       2182, 2189, 2224, 2237, 2282, 2293, 2298, 2299, 2387, 2393, 2406, 2414, 2422, 2447, 2454, 2462, 2488, 2574, 2582, 2597, 2607, 2654, 2730, 2771, 2810, 2863, 2896, 2927, 2939, 2945, 2952, 2953,\n",
      "       2979, 3005, 3060, 3062, 3073, 3117, 3136, 3160, 3206, 3225, 3240, 3262, 3289, 3323, 3333, 3336, 3369, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3629, 3654, 3662, 3702, 3726, 3727, 3742, 3767,\n",
      "       3780, 3808, 3811, 3838, 3853, 3893, 3897, 3902, 3926, 3938, 3941], dtype=int64),)\n",
      "num correct is  3828  an accuracy of  0.9572393098274569\n",
      "****************************** 5999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 2 3 4 5 6 7 8 9 8 4 1 3 7 5 2 8 0 7 5 9 9 0 9 1 1 5 8 8 6 3 2 1 8 3 2 6 5 6 9 0 1 0 3 3 1 9\n",
      " 2 1 9 6 0 4 6 1 7 3 8 7 2 9 6 5 8 3 5 7 1 6 1 0 9 6 2 5 4 2 3 4 4 6 0 0 2 0 1 2 3 4 3 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 8 4 5 6 7 8 9 8 6 5 0 6 8 9 4 1 9 5 8 0 4 8 9 1 4 0 5 3 2 1 5 4 0 7 6 0 1 7 0\n",
      " 6 8 9 3 1]\n",
      "ndx_errs (array([ 151,  241,  247,  320,  321,  338,  376,  381,  444,  445,  448,  464,  495,  542,  582,  628,  659,  691,  707,  716,  740,  760,  839,  844,  877,  883,  924,  938,  939,  947,  951,  956,\n",
      "        957, 1003, 1014, 1015, 1039, 1062, 1077, 1089, 1107, 1112, 1173, 1192, 1226, 1228, 1232, 1242, 1247, 1260, 1283, 1299, 1319, 1325, 1326, 1364, 1393, 1414, 1433, 1500, 1522, 1530, 1549, 1553,\n",
      "       1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1737, 1782, 1790, 1813, 1850, 1878, 1901, 1952, 1955, 1970, 1984, 2004, 2044, 2052, 2070, 2098, 2109, 2118, 2129, 2130, 2135, 2168, 2177,\n",
      "       2182, 2189, 2224, 2237, 2282, 2293, 2298, 2299, 2387, 2393, 2406, 2414, 2422, 2447, 2454, 2462, 2488, 2574, 2582, 2597, 2607, 2654, 2730, 2771, 2810, 2863, 2896, 2927, 2939, 2945, 2952, 2953,\n",
      "       2979, 3005, 3060, 3062, 3073, 3117, 3136, 3160, 3206, 3225, 3240, 3262, 3289, 3323, 3333, 3336, 3369, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3629, 3654, 3662, 3702, 3726, 3727, 3742, 3767,\n",
      "       3780, 3808, 3811, 3838, 3853, 3893, 3897, 3902, 3926, 3938, 3941, 4027, 4065, 4072, 4075, 4078, 4116, 4140, 4176, 4224, 4269, 4284, 4289, 4294, 4297, 4306, 4330, 4355, 4369, 4435, 4443, 4483,\n",
      "       4497, 4500, 4505, 4575, 4639, 4671, 4737, 4759, 4761, 4785, 4807, 4823, 4837, 4860, 4874, 4879, 4886, 4890, 4893, 4911, 4966, 4976, 4978, 4990, 5001, 5067, 5068, 5176, 5522, 5532, 5600, 5634,\n",
      "       5705, 5734, 5769, 5835, 5841, 5858, 5887, 5888, 5891, 5937, 5955, 5973, 5982, 5997], dtype=int64),)\n",
      "num correct is  5761  an accuracy of  0.9603267211201867\n",
      "****************************** 7999 ******************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 3 5 6 7 8 9 0 1 2 3 5 6 7 8 9 9 7 0 9 0 1 5 8 8 0 9 3 2 7 8 4 6 1 0 4 9 4 2 0 5 0 1 6 9 3 2\n",
      " 9 1 6 0 1 1 8 7 7 6 3 6 0 7 2 4 1 7 0 6 7 1 2 5 8 1 0 2 8 7 6 8 7 1 6 2 9 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 8 9 5 7 0 3 1 6 8 4 1 5 6 4 2 7 8 1 3 4 3 4 7 2 0 5 0 1 9 2 3\n",
      " 2 3 5 5 7]\n",
      "ndx_errs (array([ 151,  241,  247,  320,  321,  338,  376,  381,  444,  445,  448,  464,  495,  542,  582,  628,  659,  691,  707,  716,  740,  760,  839,  844,  877,  883,  924,  938,  939,  947,  951,  956,\n",
      "        957, 1003, 1014, 1015, 1039, 1062, 1077, 1089, 1107, 1112, 1173, 1192, 1226, 1228, 1232, 1242, 1247, 1260, 1283, 1299, 1319, 1325, 1326, 1364, 1393, 1414, 1433, 1500, 1522, 1530, 1549, 1553,\n",
      "       1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1737, 1782, 1790, 1813, 1850, 1878, 1901, 1952, 1955, 1970, 1984, 2004, 2044, 2052, 2070, 2098, 2109, 2118, 2129, 2130, 2135, 2168, 2177,\n",
      "       2182, 2189, 2224, 2237, 2282, 2293, 2298, 2299, 2387, 2393, 2406, 2414, 2422, 2447, 2454, 2462, 2488, 2574, 2582, 2597, 2607, 2654, 2730, 2771, 2810, 2863, 2896, 2927, 2939, 2945, 2952, 2953,\n",
      "       2979, 3005, 3060, 3062, 3073, 3117, 3136, 3160, 3206, 3225, 3240, 3262, 3289, 3323, 3333, 3336, 3369, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3629, 3654, 3662, 3702, 3726, 3727, 3742, 3767,\n",
      "       3780, 3808, 3811, 3838, 3853, 3893, 3897, 3902, 3926, 3938, 3941, 4027, 4065, 4072, 4075, 4078, 4116, 4140, 4176, 4224, 4269, 4284, 4289, 4294, 4297, 4306, 4330, 4355, 4369, 4435, 4443, 4483,\n",
      "       4497, 4500, 4505, 4575, 4639, 4671, 4737, 4759, 4761, 4785, 4807, 4823, 4837, 4860, 4874, 4879, 4886, 4890, 4893, 4911, 4966, 4976, 4978, 4990, 5001, 5067, 5068, 5176, 5522, 5532, 5600, 5634,\n",
      "       5705, 5734, 5769, 5835, 5841, 5858, 5887, 5888, 5891, 5937, 5955, 5973, 5982, 5997, 6011, 6023, 6035, 6037, 6059, 6071, 6081, 6091, 6157, 6166, 6172, 6173, 6505, 6555, 6560, 6577, 6597, 6598,\n",
      "       6641, 6651, 6755, 6783, 6883, 7216, 7248, 7333, 7432, 7434, 7492, 7545, 7637, 7821, 7921], dtype=int64),)\n",
      "num correct is  7728  an accuracy of  0.9661207650956369\n",
      "****************************** 9999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 2 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 6 2 3 3 5 7 0 6 8 6 3 9 9 8 8 7\n",
      " 7 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0\n",
      " 1 2 3 4 5]\n",
      "ndx_errs (array([ 151,  241,  247,  320,  321,  338,  376,  381,  444,  445,  448,  464,  495,  542,  582,  628,  659,  691,  707,  716,  740,  760,  839,  844,  877,  883,  924,  938,  939,  947,  951,  956,\n",
      "        957, 1003, 1014, 1015, 1039, 1062, 1077, 1089, 1107, 1112, 1173, 1192, 1226, 1228, 1232, 1242, 1247, 1260, 1283, 1299, 1319, 1325, 1326, 1364, 1393, 1414, 1433, 1500, 1522, 1530, 1549, 1553,\n",
      "       1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1737, 1782, 1790, 1813, 1850, 1878, 1901, 1952, 1955, 1970, 1984, 2004, 2044, 2052, 2070, 2098, 2109, 2118, 2129, 2130, 2135, 2168, 2177,\n",
      "       2182, 2189, 2224, 2237, 2282, 2293, 2298, 2299, 2387, 2393, 2406, 2414, 2422, 2447, 2454, 2462, 2488, 2574, 2582, 2597, 2607, 2654, 2730, 2771, 2810, 2863, 2896, 2927, 2939, 2945, 2952, 2953,\n",
      "       2979, 3005, 3060, 3062, 3073, 3117, 3136, 3160, 3206, 3225, 3240, 3262, 3289, 3323, 3333, 3336, 3369, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3629, 3654, 3662, 3702, 3726, 3727, 3742, 3767,\n",
      "       3780, 3808, 3811, 3838, 3853, 3893, 3897, 3902, 3926, 3938, 3941, 4027, 4065, 4072, 4075, 4078, 4116, 4140, 4176, 4224, 4269, 4284, 4289, 4294, 4297, 4306, 4330, 4355, 4369, 4435, 4443, 4483,\n",
      "       4497, 4500, 4505, 4575, 4639, 4671, 4737, 4759, 4761, 4785, 4807, 4823, 4837, 4860, 4874, 4879, 4886, 4890, 4893, 4911, 4966, 4976, 4978, 4990, 5001, 5067, 5068, 5176, 5522, 5532, 5600, 5634,\n",
      "       5705, 5734, 5769, 5835, 5841, 5858, 5887, 5888, 5891, 5937, 5955, 5973, 5982, 5997, 6011, 6023, 6035, 6037, 6059, 6071, 6081, 6091, 6157, 6166, 6172, 6173, 6505, 6555, 6560, 6577, 6597, 6598,\n",
      "       6641, 6651, 6755, 6783, 6883, 7216, 7248, 7333, 7432, 7434, 7492, 7545, 7637, 7821, 7921, 8020, 8277, 8279, 8325, 8408, 8520, 8527, 9009, 9015, 9024, 9280, 9422, 9587, 9634, 9642, 9664, 9719,\n",
      "       9729, 9745, 9768, 9770, 9779, 9811, 9839, 9879, 9893, 9904, 9905, 9982], dtype=int64),)\n",
      "num correct is  9699  an accuracy of  0.96999699969997\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 6 2 3 3 5 7 0 6 8 6 3 9 9 8 8 7 7\n",
      " 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "ndx_errs (array([ 151,  241,  247,  320,  321,  338,  376,  381,  444,  445,  448,  464,  495,  542,  582,  628,  659,  691,  707,  716,  740,  760,  839,  844,  877,  883,  924,  938,  939,  947,  951,  956,\n",
      "        957, 1003, 1014, 1015, 1039, 1062, 1077, 1089, 1107, 1112, 1173, 1192, 1226, 1228, 1232, 1242, 1247, 1260, 1283, 1299, 1319, 1325, 1326, 1364, 1393, 1414, 1433, 1500, 1522, 1530, 1549, 1553,\n",
      "       1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1737, 1782, 1790, 1813, 1850, 1878, 1901, 1952, 1955, 1970, 1984, 2004, 2044, 2052, 2070, 2098, 2109, 2118, 2129, 2130, 2135, 2168, 2177,\n",
      "       2182, 2189, 2224, 2237, 2282, 2293, 2298, 2299, 2387, 2393, 2406, 2414, 2422, 2447, 2454, 2462, 2488, 2574, 2582, 2597, 2607, 2654, 2730, 2771, 2810, 2863, 2896, 2927, 2939, 2945, 2952, 2953,\n",
      "       2979, 3005, 3060, 3062, 3073, 3117, 3136, 3160, 3206, 3225, 3240, 3262, 3289, 3323, 3333, 3336, 3369, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3629, 3654, 3662, 3702, 3726, 3727, 3742, 3767,\n",
      "       3780, 3808, 3811, 3838, 3853, 3893, 3897, 3902, 3926, 3938, 3941, 4027, 4065, 4072, 4075, 4078, 4116, 4140, 4176, 4224, 4269, 4284, 4289, 4294, 4297, 4306, 4330, 4355, 4369, 4435, 4443, 4483,\n",
      "       4497, 4500, 4505, 4575, 4639, 4671, 4737, 4759, 4761, 4785, 4807, 4823, 4837, 4860, 4874, 4879, 4886, 4890, 4893, 4911, 4966, 4976, 4978, 4990, 5001, 5067, 5068, 5176, 5522, 5532, 5600, 5634,\n",
      "       5705, 5734, 5769, 5835, 5841, 5858, 5887, 5888, 5891, 5937, 5955, 5973, 5982, 5997, 6011, 6023, 6035, 6037, 6059, 6071, 6081, 6091, 6157, 6166, 6172, 6173, 6505, 6555, 6560, 6577, 6597, 6598,\n",
      "       6641, 6651, 6755, 6783, 6883, 7216, 7248, 7333, 7432, 7434, 7492, 7545, 7637, 7821, 7921, 8020, 8277, 8279, 8325, 8408, 8520, 8527, 9009, 9015, 9024, 9280, 9422, 9587, 9634, 9642, 9664, 9719,\n",
      "       9729, 9745, 9768, 9770, 9779, 9811, 9839, 9879, 9893, 9904, 9905, 9982], dtype=int64),)\n",
      "num correct is  9700  an accuracy of  0.97\n",
      "2020-05-31 14:05:54.272504 end\n"
     ]
    }
   ],
   "source": [
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-31 11:03:46.507743 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 9 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 9 8 7 2 3 0 4 4 2 4 1 9 5 7 7 2 8 2 6 8 5 7 7 9 1 8 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 9 2 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 8 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 2 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 3 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 6 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 3 8 8 2 7 5 8 9 6 1 8 4 1 2 5 9 1 9 7 5 4 0 8 9 9 1 0 5 2 3 7\n",
      " 8 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 8 4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 2 1 7 0 6 5 4 3 8 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 2 3 1 9 7 5 1 0 8 4 6 2 6 7 9 3 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 5 8 0 3 7 2 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 7 8 3 3 6 7 2 8 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 8 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5 4 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 5\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 8 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 8 8 8 7 4 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 2 3 2 3 9 1 7 4 0 3 5 5 8 6 3 2 6 7 6 6 3 2 7 8 1 1 7 5 6 4 9 5 1 3 3 4 7 8 9 1 1 6 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "<class 'numpy.ndarray'> (0, 128)\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 4 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 4 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 8 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 3 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 8 8 4 2 6 0 6 4 2 9 1 9 5 7 7 2 6 2 6 8 5 7 7 4 1 0 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 0 5 7 7 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 5 6 5 4 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 7 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 7 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 8 0 6 4 8 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 7 8 8 2 7 5 8 9 6 1 8 4 1 2 6 8 1 9 7 5 4 0 8 9 7 1 0 5 8 3 7\n",
      " 0 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 7 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 3 4 0 0 8 3 2 9 9 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 9 8 3 3 9 3 3 3 7 8 0 8 2 1 7 0 6 5 4 3 3 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 1 3 1 9 7 5 1 0 8 4 6 2 6 7 9 9 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 0 8 0 3 7 8 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 9 8 3 3 6 7 2 9 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 3 2 7 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5 9 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 9\n",
      " 3 8 0 5 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 9 0 1 7 7 4 3 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 6 2 2 5 6 0 8 2 9 2 8 2 8 8 7 9 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 7 3 0 3 9 1 7 4 0 3 5 5 8 6 3 0 6 7 6 6 3 2 7 9 1 1 7 4 6 4 9 6 1 5 3 4 7 8 4 1 1 0 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "ndx_errs (array([ 62,  92, 151, 187, 241, 243, 245, 247, 250, 257, 264, 266, 318, 320, 321, 338, 341, 362, 381, 444, 445, 448, 464, 478, 479, 488, 492, 495, 511, 543, 547, 550, 551, 571, 591, 613, 628, 654,\n",
      "       659, 684, 691, 714, 716, 740, 791, 795, 838, 839, 844, 866, 877, 881, 924, 926, 939, 947, 951, 955, 957, 962, 965], dtype=int64),)\n",
      "num correct is  939  an accuracy of  0.9390000000000001\n",
      "2020-05-31 11:05:52.600515 end\n"
     ]
    }
   ],
   "source": [
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=6_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=1_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding weighted, parent centroids for TREE_HEIGHT=3 increased acc:\n",
    "\n",
    "## for 60,000: for CNN to 99.13% (+/- 0.09%) from baseline of ; increased acc for kNN to 96.97% from baseline of\n",
    "\n",
    "\n",
    "## increased kNN to (6,000 96.97%;  %)\n",
    "## from kNN baseline (6,000 91.6%; 60,000 96.88%)\n",
    "\n",
    "## increased CNN to (6,000 ; 60,000 99.13% (+/- 0.09%))\n",
    "## and CNN baseline (6,000 96.06% (+/- 1.42%); 60,000 acc is 99.00% (+/- 0.21%))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-02 13:27:17.891703 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7 7\n",
      " 1 0 1 7 8 9 0 1 2 3 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "<class 'numpy.ndarray'> (0, 170)\n",
      "<class 'numpy.ndarray'> (0, 954)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "****************************** 6000 ******************************\n",
      "****************************** 8000 ******************************\n",
      "****************************** 10000 ******************************\n",
      "****************************** 12000 ******************************\n",
      "****************************** 14000 ******************************\n",
      "****************************** 16000 ******************************\n",
      "****************************** 18000 ******************************\n",
      "****************************** 20000 ******************************\n",
      "****************************** 22000 ******************************\n",
      "****************************** 24000 ******************************\n",
      "****************************** 26000 ******************************\n",
      "****************************** 28000 ******************************\n",
      "****************************** 30000 ******************************\n",
      "****************************** 32000 ******************************\n",
      "****************************** 34000 ******************************\n",
      "****************************** 36000 ******************************\n",
      "****************************** 38000 ******************************\n",
      "****************************** 40000 ******************************\n",
      "****************************** 42000 ******************************\n",
      "****************************** 44000 ******************************\n",
      "****************************** 46000 ******************************\n",
      "****************************** 48000 ******************************\n",
      "****************************** 50000 ******************************\n",
      "****************************** 52000 ******************************\n",
      "****************************** 54000 ******************************\n",
      "****************************** 56000 ******************************\n",
      "****************************** 58000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 954)\n",
      "****************************** 1999 ******************************\n",
      "fill_up_last_row.shape (61999, 26)\n",
      "X_num_images 61999 X_image_num_pixels 954\n",
      "num_extra_rows 7\n",
      "2020-06-02 15:38:10.136845 Start of fit\n",
      "Epoch 1/5\n",
      "55796/55796 [==============================] - 30s 537us/sample - loss: 0.1667 - acc: 0.9471\n",
      "Epoch 2/5\n",
      "55796/55796 [==============================] - 27s 477us/sample - loss: 0.0464 - acc: 0.9854- ETA: 4s - loss: 0.0468 - acc: 0.98 - ETA: 3s - loss: 0.0 - ETA: 2s - loss: 0.0465 - - ETA: 2s - loss: 0.0467 - acc:  - ETA: 1\n",
      "Epoch 3/5\n",
      "55796/55796 [==============================] - 27s 486us/sample - loss: 0.0307 - acc: 0.9909 - E\n",
      "Epoch 4/5\n",
      "55796/55796 [==============================] - 27s 486us/sample - loss: 0.0237 - acc: 0.9928 - loss: 0.0246 - acc: - ETA\n",
      "Epoch 5/5\n",
      "55796/55796 [==============================] - 27s 484us/sample - loss: 0.0182 - acc: 0.9945s - loss: - ETA: - ETA: 4\n",
      "2020-06-02 15:40:34.679426 End of fit\n",
      "acc: 99.00%\n",
      "2020-06-02 15:40:38.698112 Start of fit\n",
      "Epoch 1/5\n",
      "55796/55796 [==============================] - 28s 506us/sample - loss: 0.1789 - acc: 0.9441\n",
      "Epoch 2/5\n",
      "55796/55796 [==============================] - 27s 490us/sample - loss: 0.0462 - acc: 0.9861 - loss: 0.0465 - acc:\n",
      "Epoch 3/5\n",
      "55796/55796 [==============================] - 27s 483us/sample - loss: 0.0306 - acc: 0.9905s - - ETA: 9s - loss: 0.0 - ETA: 8s - - ETA: 1s -\n",
      "Epoch 4/5\n",
      "55796/55796 [==============================] - 27s 478us/sample - loss: 0.0238 - acc: 0.9926 - los - ET - ETA: 1s - loss: 0\n",
      "Epoch 5/5\n",
      "55796/55796 [==============================] - 29s 516us/sample - loss: 0.0186 - acc: 0.9944 - loss: 0.0171 - acc: 0.994 - ETA: 5s - loss: 0.0171 - acc: 0. - ETA: 4s - loss: 0.0172 - a - ETA: 1s - loss: 0.0183 - acc - ETA: 1s - loss: 0.0182 - acc: 0.99 - ETA: 1s - loss: 0.0182  - ETA: 0s - loss: 0.0185 - acc: 0.\n",
      "2020-06-02 15:43:01.884341 End of fit\n",
      "acc: 99.05%\n",
      "2020-06-02 15:43:06.342192 Start of fit\n",
      "Epoch 1/5\n",
      "55796/55796 [==============================] - 28s 505us/sample - loss: 0.1743 - acc: 0.9445\n",
      "Epoch 2/5\n",
      "55796/55796 [==============================] - 28s 508us/sample - loss: 0.0441 - acc: 0.9865s - loss: 0.0471 - a - ETA: 14s - loss - ETA: 13s  - ETA: 12 - ETA: 10s - loss: 0.0460 - acc:  - ETA: 10s - loss: 0.0459 - acc:  - ETA: 10s - loss: 0.0459 - ETA: 9s - loss: 0.0456 - acc: 0.98 - ETA: 9s - \n",
      "Epoch 3/5\n",
      "55796/55796 [==============================] - 29s 518us/sample - loss: 0.0308 - acc: 0.9905s - loss: 0.03 - ETA: 26s -  - ETA: 22s - loss:  - ETA - ETA: 16s - loss - ETA: 11s - loss: 0.0304 - - ETA: 11s - loss: 0.03 - ETA: 10s - loss - ETA: 9s - loss:  - ETA: 8s - loss: 0.0302 - acc: 0. - ETA: 8s - loss: 0.0 - ETA: 4s - loss: 0.0308 - - ETA: 3s - l - ETA: 2s - loss - ETA: 0s - loss: 0.03\n",
      "Epoch 4/5\n",
      "55796/55796 [==============================] - 28s 501us/sample - loss: 0.0227 - acc: 0.9930s - loss: 0.0268 - E - ETA - ETA: 3s - loss: 0.0227 - acc: 0.99 - ETA: 3s -  - ETA: 2s - loss: 0.0230 - acc: - ETA: 1s - loss: 0.0229 - ac - ETA: 0s - loss: 0.0229 - acc: 0. - ETA: 0s - loss: 0.0228 -  - ETA: 0s - loss: 0.0228 - acc: 0.993\n",
      "Epoch 5/5\n",
      "55796/55796 [==============================] - 28s 510us/sample - loss: 0.0179 - acc: 0.9944 - loss: 0. - ETA: 6s - loss: 0.0168 - acc - ETA: 6s - loss: 0.0170 - acc: 0.99 - ETA: 6s - loss: 0.0169 - acc: 0.994 - ETA: 6s - loss: 0.0169 - acc: 0.9 - ETA: 5s - loss: 0.0174 - - ETA: 5s - loss: 0.0174 - acc:  - ETA: 4s - loss: 0.0 - ETA: 3s -  - ETA: 2s - loss: 0.0177 - acc: - ETA: 1s - loss: 0.0176 - acc: - ETA: 1s - loss: 0.01 - ETA: 0s - loss: 0.0177 - acc: 0.9\n",
      "2020-06-02 15:45:36.374999 End of fit\n",
      "acc: 98.92%\n",
      "2020-06-02 15:45:40.196353 Start of fit\n",
      "Epoch 1/5\n",
      "55798/55798 [==============================] - 28s 508us/sample - loss: 0.1718 - acc: 0.9461 ETA: 0s - loss: 0.1726 - acc: 0.945 - ETA: 0s - loss: 0.1723 - acc: 0.94\n",
      "Epoch 2/5\n",
      "55798/55798 [==============================] - 28s 497us/sample - loss: 0.0446 - acc: 0.9865s - loss: 0.0476  - ETA: 7s - loss: 0.04 - ETA: 6s - loss: 0.0460 -  - ETA: 5s - ETA: 3s - loss: 0.0452 - - ETA: 2s - loss: 0.0453 - acc: 0.986 - ETA: 2s - loss: 0.0453 - acc: 0. - ETA: 2s  - ETA: 0s - loss: 0.0450 - \n",
      "Epoch 3/5\n",
      "55798/55798 [==============================] - 28s 502us/sample - loss: 0.0309 - acc: 0.9900s - loss: 0 - ETA: 9s - loss: 0.0299 - acc: 0.9 - ETA: 8s - loss: 0.0299 - - ETA: 0s - loss: 0.0309 - a\n",
      "Epoch 4/5\n",
      "55798/55798 [==============================] - 28s 505us/sample - loss: 0.0237 - acc: 0.9926 -  - ETA: 1s - loss: 0.0234 - acc: 0.992 - ETA: 0s - loss: 0.0233 - a - ETA: 0s - loss: 0.0233 - acc: 0\n",
      "Epoch 5/5\n",
      "55798/55798 [==============================] - 28s 495us/sample - loss: 0.0187 - acc: 0.9944s - loss: 0.0182 - a - ETA: 11 - ETA:  - ETA: 8s - loss: 0.0179 - - ETA: 5s - loss: 0.0187 -  - ETA: 5s - loss: 0.0187 - ETA: 4s - loss: 0.0187 - acc: 0.994 - ETA: 4s - loss: - ETA: 2s - lo - ETA: 1s - loss: 0.0186 - acc: 0 - ETA: 0s - loss: 0.01\n",
      "2020-06-02 15:48:05.267496 End of fit\n",
      "acc: 99.11%\n",
      "2020-06-02 15:48:09.367039 Start of fit\n",
      "Epoch 1/5\n",
      "55798/55798 [==============================] - 29s 511us/sample - loss: 0.1743 - acc: 0.9445 - lo\n",
      "Epoch 2/5\n",
      "55798/55798 [==============================] - 29s 522us/sample - loss: 0.0476 - acc: 0.9851s - los - ETA: 5s - loss: 0.0488 - a - ETA: - ETA: 2s - loss: 0.0485 - acc: 0.98 - ETA: 2s - loss: 0.0483 - acc: 0.98 - ETA: 2s - los - ETA: 1s - loss: 0.0 - ETA: 0s - loss: 0.0476 - acc: 0.985\n",
      "Epoch 3/5\n",
      "55798/55798 [==============================] - 27s 488us/sample - loss: 0.0327 - acc: 0.9897 - loss: 0. - ETA: 7s - loss: 0.0331 - acc:  - ETA: 7s - los - ETA: 5s - loss - ETA:\n",
      "Epoch 4/5\n",
      "55798/55798 [==============================] - 28s 493us/sample - loss: 0.0241 - acc: 0.9921\n",
      "Epoch 5/5\n",
      "55798/55798 [==============================] - 27s 484us/sample - loss: 0.0195 - acc: 0.9940 - loss: 0.019\n",
      "2020-06-02 15:50:33.974414 End of fit\n",
      "acc: 98.97%\n",
      "2020-06-02 15:50:38.899000 Start of fit\n",
      "Epoch 1/5\n",
      "55798/55798 [==============================] - 29s 520us/sample - loss: 0.1764 - acc: 0.9443 ETA: 1s - lo\n",
      "Epoch 2/5\n",
      "55798/55798 [==============================] - 28s 494us/sample - loss: 0.0444 - acc: 0.9863 - loss: 0.0443 - a - ETA: 4 - ETA: 0s - loss: 0.0444 - acc: 0.9\n",
      "Epoch 3/5\n",
      "55798/55798 [==============================] - 28s 505us/sample - loss: 0.0320 - acc: 0.9903 - loss:  - ETA: 1s - loss: 0.0316 - ETA: 1s - loss: 0.0\n",
      "Epoch 4/5\n",
      "55798/55798 [==============================] - 28s 500us/sample - loss: 0.0224 - acc: 0.9933 - loss: 0.022 - ETA: 5s - lo - ETA: 4s - loss: 0.0225 - acc: 0.99 - ETA: 3s - loss: 0.0224 - ETA: 3s - loss: 0.0224 - acc:  - ETA: 2s - loss: 0.0224 - ac - E\n",
      "Epoch 5/5\n",
      "55798/55798 [==============================] - 28s 493us/sample - loss: 0.0181 - acc: 0.9946s - loss - ETA: 10s - loss: 0 - ETA - ETA: 7s - loss: 0.0180 -  - ETA: 4s - loss: 0 - ETA: 2s - loss: 0.0179 - acc: 0. - ETA: 2s - loss - ETA: 1s - loss:\n",
      "2020-06-02 15:53:04.314541 End of fit\n",
      "acc: 98.89%\n",
      "2020-06-02 15:53:08.407831 Start of fit\n",
      "Epoch 1/5\n",
      "55800/55800 [==============================] - 29s 517us/sample - loss: 0.1854 - acc: 0.9423 1s - loss: 0.1\n",
      "Epoch 2/5\n",
      "55800/55800 [==============================] - 28s 493us/sample - loss: 0.0475 - acc: 0.9854s -  - ETA: 3s - los - ET\n",
      "Epoch 3/5\n",
      "55800/55800 [==============================] - 28s 493us/sample - loss: 0.0325 - acc: 0.9896\n",
      "Epoch 4/5\n",
      "55800/55800 [==============================] - 27s 489us/sample - loss: 0.0245 - acc: 0.9924 - loss: - ETA: \n",
      "Epoch 5/5\n",
      "55800/55800 [==============================] - 27s 485us/sample - loss: 0.0180 - acc: 0.9946 - loss: 0.0173 - acc: 0. - ETA: 2s - loss: 0.0173 - acc: 0.994 - ETA: 2s - loss: 0.0173 -  - ETA: 1s - loss: 0.0177 - ac - ETA: 1s - lo\n",
      "2020-06-02 15:55:31.010878 End of fit\n",
      "acc: 99.21%\n",
      "2020-06-02 15:55:34.970197 Start of fit\n",
      "Epoch 1/5\n",
      "55801/55801 [==============================] - 28s 507us/sample - loss: 0.1805 - acc: 0.9423\n",
      "Epoch 2/5\n",
      "55801/55801 [==============================] - 27s 492us/sample - loss: 0.0484 - acc: 0.9848s - loss: 0.0512 - acc - ETA: 10 - ETA: 10s - loss: 0.0514 - acc: - ETA: 7s  - ETA: 5s - los - ETA: 4s - loss: 0.0479 - acc: 0.9 - ETA: 3s - lo\n",
      "Epoch 3/5\n",
      "55801/55801 [==============================] - 27s 492us/sample - loss: 0.0330 - acc: 0.9901s -  - ETA:\n",
      "Epoch 4/5\n",
      "55801/55801 [==============================] - 28s 495us/sample - loss: 0.0247 - acc: 0.9924\n",
      "Epoch 5/5\n",
      "55801/55801 [==============================] - 28s 495us/sample - loss: 0.0195 - acc: 0.9942A: 6s - loss: 0.0193 - acc: 0.99 - ETA:  - ETA: 4s - loss: 0.0196 - ETA: 3s - loss: 0.\n",
      "2020-06-02 15:57:57.692878 End of fit\n",
      "acc: 98.97%\n",
      "2020-06-02 15:58:01.594319 Start of fit\n",
      "Epoch 1/5\n",
      "55803/55803 [==============================] - 29s 511us/sample - loss: 0.1826 - acc: 0.9425 - loss: 0.20 - ETA: 3s  - ETA: 2s - loss - ETA: 0s - loss: 0.1855 - a\n",
      "Epoch 2/5\n",
      "55803/55803 [==============================] - 27s 488us/sample - loss: 0.0459 - acc: 0.9856 - loss: 0.0458 - acc: 0.98 - ETA: 0s - loss: 0.0456 - acc: 0.\n",
      "Epoch 3/5\n",
      "55803/55803 [==============================] - 27s 489us/sample - loss: 0.0322 - acc: 0.9905 - loss: 0.0319\n",
      "Epoch 4/5\n",
      "55803/55803 [==============================] - 27s 493us/sample - loss: 0.0232 - acc: 0.9928s - loss: 0.023 - ETA: 8s - lo - ETA: 4s - loss: 0.0233 - acc: 0.9 - ETA: 3s - loss: 0.0233 - acc: 0. - ETA: 3s - loss: 0.02\n",
      "Epoch 5/5\n",
      "55803/55803 [==============================] - 28s 497us/sample - loss: 0.0181 - acc: 0.9946: 0s - loss: 0.0180 - \n",
      "2020-06-02 16:00:23.854021 End of fit\n",
      "acc: 99.11%\n",
      "2020-06-02 16:00:27.878114 Start of fit\n",
      "Epoch 1/5\n",
      "55805/55805 [==============================] - 29s 513us/sample - loss: 0.1761 - acc: 0.9455 - loss: 0.2005 - acc: 0.937 - ETA: 5s - loss: 0.2002  - ETA: 1s - l\n",
      "Epoch 2/5\n",
      "55805/55805 [==============================] - 27s 492us/sample - loss: 0.0466 - acc: 0.9858s - loss:  - ETA: 9s - loss: 0.0485 - acc: 0.985 - ETA: 9s - loss: 0 - ETA: 8s - loss: 0.0483 - ETA: 7s - loss: 0.0 - ETA: 6s - loss\n",
      "Epoch 3/5\n",
      "55805/55805 [==============================] - 27s 489us/sample - loss: 0.0320 - acc: 0.9902s - loss: 0.0332 - - ETA: 15s -  - ETA: 14s - loss:  - ETA: 14s - loss: 0.0331 - acc:  - E - E -  - ETA: 5s - loss - ETA:\n",
      "Epoch 4/5\n",
      "55805/55805 [==============================] - 27s 491us/sample - loss: 0.0238 - acc: 0.9927 - loss: 0.0240 - acc: 0.99 - ETA: 2s - loss: 0.0239 - acc: 0.99\n",
      "Epoch 5/5\n",
      "55805/55805 [==============================] - 27s 491us/sample - loss: 0.0186 - acc: 0.9943 - ETA: 0s - loss: 0.0186 \n",
      "2020-06-02 16:02:50.928579 End of fit\n",
      "acc: 98.69%\n",
      "98.99% (+/- 0.14%)\n",
      "2020-06-02 16:02:54.202606 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 4 8 9 6 9 6 8 3 6 6 8 5 1 4 2 4 4 5 1 1 9 0 2 4 9 5 7 1 8 3 5 6 9 8 7 1 1 6 7 6 3 2 2 0 8 9\n",
      " 2 5 1 0 8 1 4 5 7 9 6 9 0 6 1 5 5 8 3 8 2 6 5 0 7 4 6 1 3 4 7 3 2 3 4 2 5 2 7 1 7 2 6 4 1 5 7 8 6 0 1 8 2 5 7 7 6 9 3 5 2 4 2 4 0 8 8 3 4 9 2 7 5 8 6 3 6 0 8 6 7 3 6 4 9 4 6 6 3 0 4 1 0 1 4 6 2 9 1\n",
      " 1 0 6 3 9]\n",
      "ndx_errs (array([ 151,  241,  247,  318,  320,  321,  362,  376,  381,  444,  445,  448,  464,  479,  495,  519,  550,  578,  582,  628,  659,  691,  716,  726,  740,  760,  839,  881,  883,  924,  926,  938,\n",
      "        939,  947,  951,  956, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1181, 1192, 1226, 1228, 1232, 1242, 1247, 1248, 1270, 1283, 1289, 1299, 1319, 1326, 1331, 1364, 1393, 1414,\n",
      "       1500, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1732, 1737, 1790, 1813, 1878, 1901, 1955, 1970, 1984], dtype=int64),)\n",
      "num correct is  1912  an accuracy of  0.9564782391195598\n",
      "****************************** 3999 ******************************\n",
      "fill_up_last_row.shape (63999, 26)\n",
      "X_num_images 63999 X_image_num_pixels 954\n",
      "num_extra_rows 7\n",
      "2020-06-02 16:06:23.421463 Start of fit\n",
      "Epoch 1/5\n",
      "57595/57595 [==============================] - 30s 513us/sample - loss: 0.1724 - acc: 0.9456s - lo - ETA: 13s - loss: 0.2582 - - ETA: 13 - ETA: 12s - loss: 0. - ET - ETA: 2s - loss: 0.1837 - ETA: 1s - \n",
      "Epoch 2/5\n",
      "57595/57595 [==============================] - 29s 504us/sample - loss: 0.0466 - acc: 0.9853TA: 3 - ETA: 1s - loss: 0.0466 - acc: 0. - ETA: 1s - loss: 0.0464 - ac - ETA: 0s - loss: 0.046\n",
      "Epoch 3/5\n",
      "57595/57595 [==============================] - 29s 503us/sample - loss: 0.0315 - acc: 0.9901 - loss: 0.0309 - acc: - ETA: 3s - loss: 0.0313 - acc: 0 - ETA: 0s - loss: 0.0317 - ac\n",
      "Epoch 4/5\n",
      "57595/57595 [==============================] - 29s 507us/sample - loss: 0.0235 - acc: 0.9929\n",
      "Epoch 5/5\n",
      "57595/57595 [==============================] - 29s 503us/sample - loss: 0.0187 - acc: 0.9945\n",
      "2020-06-02 16:08:58.597231 End of fit\n",
      "acc: 99.09%\n",
      "2020-06-02 16:09:02.501196 Start of fit\n",
      "Epoch 1/5\n",
      "57595/57595 [==============================] - 29s 512us/sample - loss: 0.1660 - acc: 0.9485s - loss: 0.2433 - a - ETA: 12 - ETA:  - ETA: 8s - loss: - ETA: 7s  - ETA: 5s - loss: 0. - ETA: 1s - \n",
      "Epoch 2/5\n",
      "57595/57595 [==============================] - 29s 497us/sample - loss: 0.0451 - acc: 0.9862A: 5s - loss: 0.0467 - acc: 0.9 - ETA: 5s - loss: 0.0466 -  - ETA: 4s - loss: 0.0461 - acc: 0 - ETA: 4\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57595/57595 [==============================] - 29s 497us/sample - loss: 0.0320 - acc: 0.9904s - loss:  - E - ETA: 24s - loss: 0.0376 - acc:  - ETA: 24s - loss: 0.0389 - acc:  - ETA: 24s - loss: 0. - ETA: 22s - loss: 0.0341 - - ETA: 21s - loss: 0.0330  - ETA: 9s - lo - ETA: 2s - loss: 0.0322 - acc: 0.99 - ETA: 2s - loss: 0.0321 - acc: 0. - ETA: 2s - loss: 0.0321 - acc: - ETA: 1s - loss: 0.0321 - acc: - ETA: 1s - loss: 0 - ETA: 0s - loss: 0.0321 - acc: 0.9\n",
      "Epoch 4/5\n",
      "57595/57595 [==============================] - 29s 498us/sample - loss: 0.0232 - acc: 0.9924 - loss: 0 - ETA: 4s\n",
      "Epoch 5/5\n",
      "57595/57595 [==============================] - 29s 497us/sample - loss: 0.0180 - acc: 0.9947 - loss: 0.0185 - acc: 0.9 - ETA: 6s - loss: 0.0184 - - ETA: 0s - loss: 0.0181 - acc - ETA: 0s - loss: 0.0181 - acc: 0.99\n",
      "2020-06-02 16:11:31.146086 End of fit\n",
      "acc: 98.95%\n",
      "2020-06-02 16:11:35.177780 Start of fit\n",
      "Epoch 1/5\n",
      "57596/57596 [==============================] - 30s 520us/sample - loss: 0.1802 - acc: 0.9431 - loss: 0.1822 - acc\n",
      "Epoch 2/5\n",
      "57596/57596 [==============================] - 29s 503us/sample - loss: 0.0461 - acc: 0.9855 - loss: 0.0463 - acc:\n",
      "Epoch 3/5\n",
      "57596/57596 [==============================] - 28s 490us/sample - loss: 0.0309 - acc: 0.9903: 4s - loss: 0.0311 - acc: 0.990 - ETA: 4s - loss: 0.0311 - acc: 0 - ETA: 4s - E - ETA: 0s - loss: 0.0311 - acc: 0\n",
      "Epoch 4/5\n",
      "57596/57596 [==============================] - 28s 494us/sample - loss: 0.0232 - acc: 0.9929\n",
      "Epoch 5/5\n",
      "57596/57596 [==============================] - ETA: 0s - loss: 0.0185 - acc: 0.9946- ETA: 3s - loss: 0 - ETA:  - 28s 494us/sample - loss: 0.0184 - acc: 0.9946\n",
      "2020-06-02 16:14:03.590131 End of fit\n",
      "acc: 98.95%\n",
      "2020-06-02 16:14:07.544199 Start of fit\n",
      "Epoch 1/5\n",
      "57598/57598 [==============================] - 30s 523us/sample - loss: 0.1767 - acc: 0.9454 - loss: 0.1785 - acc:\n",
      "Epoch 2/5\n",
      "57598/57598 [==============================] - 29s 495us/sample - loss: 0.0461 - acc: 0.9853s -   - ETA: 7\n",
      "Epoch 3/5\n",
      "57598/57598 [==============================] - 28s 493us/sample - loss: 0.0322 - acc: 0.9903 - loss: 0.0323 - acc: 0.9\n",
      "Epoch 4/5\n",
      "57598/57598 [==============================] - 29s 495us/sample - loss: 0.0246 - acc: 0.9926 - loss: 0.0245 \n",
      "Epoch 5/5\n",
      "57598/57598 [==============================] - 28s 491us/sample - loss: 0.0202 - acc: 0.9939 - - ETA: 0s - loss: 0.0202 - acc: 0.9\n",
      "2020-06-02 16:16:36.812338 End of fit\n",
      "acc: 99.17%\n",
      "2020-06-02 16:16:40.727313 Start of fit\n",
      "Epoch 1/5\n",
      "57598/57598 [==============================] - 30s 526us/sample - loss: 0.1696 - acc: 0.9455 - loss: 0.2048 - acc: 0.93 - ETA: 7s - loss: 0.2042 - acc: 0.93 - ETA: 7s - loss: 0.2033 - ET - ETA: 1s - loss: 0.1757 - acc: 0 - ETA: 1s - loss: 0.1743 - acc: 0.9 - ETA: 1s - loss: 0.17\n",
      "Epoch 2/5\n",
      "57598/57598 [==============================] - 29s 511us/sample - loss: 0.0458 - acc: 0.9859 - loss: 0.04  - ETA: 0s - loss: 0.0458 - acc: 0\n",
      "Epoch 3/5\n",
      "57598/57598 [==============================] - 29s 498us/sample - loss: 0.0310 - acc: 0.9903\n",
      "Epoch 4/5\n",
      "57598/57598 [==============================] - 29s 504us/sample - loss: 0.0239 - acc: 0.9929\n",
      "Epoch 5/5\n",
      "57598/57598 [==============================] - 28s 494us/sample - loss: 0.0184 - acc: 0.9945 - ETA: 6s - loss: 0.0174 - ETA: 5s  -  - ETA: 1s\n",
      "2020-06-02 16:19:11.053668 End of fit\n",
      "acc: 99.06%\n",
      "2020-06-02 16:19:15.181542 Start of fit\n",
      "Epoch 1/5\n",
      "57599/57599 [==============================] - ETA: 0s - loss: 0.1744 - acc: 0.9450  ETA: 12s - loss: 0. - E - ETA: 10s - loss: 0.2294 - acc  - ETA: 2s - loss: 0.1852 - acc - ET - 30s 526us/sample - loss: 0.1742 - acc: 0.9451\n",
      "Epoch 2/5\n",
      "57599/57599 [==============================] - 29s 495us/sample - loss: 0.0456 - acc: 0.9861s - loss:  - ETA: 9s  - ETA: 8s - loss: 0.047 - ETA: 4s - l - ETA: 3s - loss: 0.0461 - a - \n",
      "Epoch 3/5\n",
      "57599/57599 [==============================] - 29s 502us/sample - loss: 0.0309 - acc: 0.9903s - loss: 0.0330 -  - ETA: 1s - ETA: 0s - loss: 0.0311 - acc: 0.9\n",
      "Epoch 4/5\n",
      "57599/57599 [==============================] - 29s 505us/sample - loss: 0.0238 - acc: 0.9927s - loss: 0.0235 - a - ETA:  - ETA: 10s - loss: 0\n",
      "Epoch 5/5\n",
      "57599/57599 [==============================] - 29s 497us/sample - loss: 0.0175 - acc: 0.9947  - ETA: 6s - loss: 0.0168  -  - ETA: 3s - loss: 0.0169 - ac - ETA: 0s - loss: 0.0173 - acc: 0.9 - ETA: 0s - loss: 0.0173 - acc: 0\n",
      "2020-06-02 16:21:45.319868 End of fit\n",
      "acc: 98.83%\n",
      "2020-06-02 16:21:49.582200 Start of fit\n",
      "Epoch 1/5\n",
      "57602/57602 [==============================] - 30s 522us/sample - loss: 0.1703 - acc: 0.9473A: 4s -\n",
      "Epoch 2/5\n",
      "57602/57602 [==============================] - 29s 503us/sample - loss: 0.0455 - acc: 0.9866\n",
      "Epoch 3/5\n",
      "57602/57602 [==============================] - 29s 501us/sample - loss: 0.0315 - acc: 0.9902\n",
      "Epoch 4/5\n",
      "57602/57602 [==============================] - 29s 496us/sample - loss: 0.0236 - acc: 0.9930  - ETA: 1s - loss: 0.022 - ETA: 0s - loss: 0.0229 \n",
      "Epoch 5/5\n",
      "57602/57602 [==============================] - 29s 500us/sample - loss: 0.0184 - acc: 0.9944s - loss:  - ETA:  - ETA: 12s - loss: 0.0167 - acc: 0.99 - ETA: 12s - loss: 0.0169 - acc: 0.99 -\n",
      "2020-06-02 16:24:19.748084 End of fit\n",
      "acc: 99.00%\n",
      "2020-06-02 16:24:23.999648 Start of fit\n",
      "Epoch 1/5\n",
      "57602/57602 [==============================] - 30s 525us/sample - loss: 0.1810 - acc: 0.9432 - \n",
      "Epoch 2/5\n",
      "57602/57602 [==============================] - 29s 507us/sample - loss: 0.0434 - acc: 0.9864 - loss:\n",
      "Epoch 3/5\n",
      "57602/57602 [==============================] - 29s 503us/sample - loss: 0.0296 - acc: 0.9907s - loss: 0.0297 - acc: - ETA: 2s - loss: 0.0296 - acc: 0 - ETA: 1s \n",
      "Epoch 4/5\n",
      "57602/57602 [==============================] - 29s 502us/sample - loss: 0.0225 - acc: 0.9932 - loss: 0.0221 - ETA: 8s - loss: 0.02 - ETA: 7s - loss: 0.0225 - ac - ETA: 6s - loss: 0.0228 - acc: 0. - ETA: 6s - loss: 0.0227 - acc: 0. - ETA: 6s - loss: 0.0228 - a - ETA: 5s - loss: 0.0229 - acc: 0.99 - ETA: 5s - loss: 0.0229 - acc: \n",
      "Epoch 5/5\n",
      "57602/57602 [==============================] - 29s 497us/sample - loss: 0.0173 - acc: 0.99491s - loss: 0.0172 - acc: 0.994 - ETA: 1s - loss: 0.0172 - acc: - ETA: 1s - los\n",
      "2020-06-02 16:26:54.479336 End of fit\n",
      "acc: 99.14%\n",
      "2020-06-02 16:26:58.295362 Start of fit\n",
      "Epoch 1/5\n",
      "57602/57602 [==============================] - 30s 524us/sample - loss: 0.1675 - acc: 0.9469\n",
      "Epoch 2/5\n",
      "57602/57602 [==============================] - 30s 517us/sample - loss: 0.0465 - acc: 0.9856 - loss: 0.0471  - E - ETA: 0s - loss: 0.046\n",
      "Epoch 3/5\n",
      "57602/57602 [==============================] - 29s 509us/sample - loss: 0.0317 - acc: 0.9906 - loss: 0.031 - ETA: 2s - loss: 0.0318 - acc: 0.9 - ET\n",
      "Epoch 4/5\n",
      "57602/57602 [==============================] - 29s 508us/sample - loss: 0.0241 - acc: 0.9927  - ETA: 7s - loss: 0 - ETA: 6s - loss: \n",
      "Epoch 5/5\n",
      "57602/57602 [==============================] - 29s 507us/sample - loss: 0.0187 - acc: 0.9944 - loss: 0.0196 - acc: 0.994 - ETA: 8s - - ETA: 1s\n",
      "2020-06-02 16:29:30.789420 End of fit\n",
      "acc: 99.23%\n",
      "2020-06-02 16:29:34.731593 Start of fit\n",
      "Epoch 1/5\n",
      "57604/57604 [==============================] - 30s 525us/sample - loss: 0.1729 - acc: 0.9458\n",
      "Epoch 2/5\n",
      "57604/57604 [==============================] - 29s 500us/sample - loss: 0.0471 - acc: 0.9849 7s - - ETA: 5s -  - ETA: 3s - loss: 0.0484 - - ETA: 3s - l - ETA: 1s - loss\n",
      "Epoch 3/5\n",
      "57604/57604 [==============================] - 30s 512us/sample - loss: 0.0320 - acc: 0.9897 - ETA: 9s  - ETA: 5s - loss: 0.0332 - ETA: 4s - loss: 0.0327 -  - ETA: 3s - loss: 0.0326 - acc:  - ETA: 3s - loss: 0.0325 - acc:  - ETA: 2s - loss: 0. - ETA: 1s - loss:\n",
      "Epoch 4/5\n",
      "57604/57604 [==============================] - 29s 509us/sample - loss: 0.0242 - acc: 0.9930 - loss: 0.0240 - a\n",
      "Epoch 5/5\n",
      "57604/57604 [==============================] - 30s 517us/sample - loss: 0.0187 - acc: 0.9944 - loss: 0.0187 - acc: 0.9\n",
      "2020-06-02 16:32:06.912795 End of fit\n",
      "acc: 99.00%\n",
      "99.04% (+/- 0.11%)\n",
      "2020-06-02 16:32:10.579627 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 9 1 1 0 7 5 9 9 1 9 5 9 2 5 0 4 1 0 8 9 0 8 9 8 9 4 2 5 7 9 8 9 8 0 9 9 6 8 9 9 5 9 8 6 1\n",
      " 0 3 3 5 2 1 6 3 0 2 8 1 5 6 2 3 0 2 2 6 4 3 5 5 1 7 2 1 6 9 1 3 9 5 5 1 6 2 2 8 6 7 1 4 6 0 6 0 3 3 2 2 3 6 8 9 8 5 3 8 5 4 5 2 0 5 6 3 2 8 3 9 9 3 7 9 4 6 7 1 3 7 3 6 6 0 9 0 1 9 9 2 8 8 0 1 6 9 7\n",
      " 5 3 4 7 4]\n",
      "ndx_errs (array([ 151,  241,  247,  318,  320,  321,  362,  376,  381,  444,  445,  448,  464,  479,  495,  519,  550,  578,  582,  628,  659,  691,  716,  726,  740,  760,  839,  881,  883,  924,  926,  938,\n",
      "        939,  947,  951,  956, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1181, 1192, 1226, 1228, 1232, 1242, 1247, 1248, 1270, 1283, 1289, 1299, 1319, 1326, 1331, 1364, 1393, 1414,\n",
      "       1500, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1732, 1737, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2098, 2109, 2118, 2129, 2130, 2135,\n",
      "       2177, 2182, 2189, 2224, 2237, 2282, 2292, 2293, 2298, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2462, 2574, 2607, 2648, 2654, 2721, 2730, 2758, 2771, 2810, 2851, 2853, 2896, 2927, 2939, 2945,\n",
      "       2952, 2953, 2998, 3005, 3030, 3060, 3062, 3073, 3117, 3136, 3206, 3240, 3262, 3289, 3323, 3333, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3629, 3664, 3702, 3718, 3726, 3742, 3757, 3767, 3780,\n",
      "       3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3968], dtype=int64),)\n",
      "num correct is  3830  an accuracy of  0.9577394348587147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 5999 ******************************\n",
      "fill_up_last_row.shape (65999, 26)\n",
      "X_num_images 65999 X_image_num_pixels 954\n",
      "num_extra_rows 7\n",
      "2020-06-02 16:38:38.298435 Start of fit\n",
      "Epoch 1/5\n",
      "59395/59395 [==============================] - 32s 531us/sample - loss: 0.1757 - acc: 0.9443 - loss: 0.2160 - acc: - ETA: 8s - loss: 0.2127  - ETA: 7s - loss: 0.2072 - acc: - ETA: 6s - loss: - ETA: 5s - loss: 0.1970 - acc: 0.93\n",
      "Epoch 2/5\n",
      "59395/59395 [==============================] - 30s 501us/sample - loss: 0.0467 - acc: 0.9856 - loss: 0.0481 - acc: 0.985 - ETA: 9s - - ETA: 7s - loss:  - ETA: 6s - loss: 0 - ETA: 5s - loss: 0.0467 - acc:  - ETA: 5s  - ETA: 0s - loss: 0.0465 \n",
      "Epoch 3/5\n",
      "59395/59395 [==============================] - 30s 513us/sample - loss: 0.0313 - acc: 0.9899\n",
      "Epoch 4/5\n",
      "59395/59395 [==============================] - 30s 505us/sample - loss: 0.0233 - acc: 0.9931 - loss: 0.0238 - acc: 0.9 - ETA: 1 - ETA: 0s - loss: 0.0234 - acc: 0.993\n",
      "Epoch 5/5\n",
      "59395/59395 [==============================] - 30s 507us/sample - loss: 0.0184 - acc: 0.9944 - loss: 0.0174 - acc: 0. - ET - ETA: 6s - loss: 0.0177 - - ETA: 1s - loss: 0.0182 - acc: 0.9 - ETA: 0s - loss: 0.0181\n",
      "2020-06-02 16:41:14.772799 End of fit\n",
      "acc: 98.85%\n",
      "2020-06-02 16:41:18.916787 Start of fit\n",
      "Epoch 1/5\n",
      "59397/59397 [==============================] - 31s 526us/sample - loss: 0.1716 - acc: 0.9454 - loss: 0 - ETA:\n",
      "Epoch 2/5\n",
      "59397/59397 [==============================] - 30s 508us/sample - loss: 0.0447 - acc: 0.9860\n",
      "Epoch 3/5\n",
      "59397/59397 [==============================] - 32s 536us/sample - loss: 0.0303 - acc: 0.9908 - loss: 0.0306 - a - ETA: 5s -  - ETA: 3s - loss: 0.0303 - a - ETA: 2s - l - ETA: 1s - loss: 0.0305 - acc: - ETA: 0s - loss: 0.0304 - a\n",
      "Epoch 4/5\n",
      "59397/59397 [==============================] - 32s 543us/sample - loss: 0.0230 - acc: 0.9932\n",
      "Epoch 5/5\n",
      "59397/59397 [==============================] - 34s 572us/sample - loss: 0.0190 - acc: 0.9942\n",
      "2020-06-02 16:44:03.223378 End of fit\n",
      "acc: 99.12%\n",
      "2020-06-02 16:44:08.044080 Start of fit\n",
      "Epoch 1/5\n",
      "59397/59397 [==============================] - 32s 541us/sample - loss: 0.1692 - acc: 0.9459A - ETA: 4s - loss: 0.1873 - ac - ETA: 4s - loss\n",
      "Epoch 2/5\n",
      "59397/59397 [==============================] - 31s 517us/sample - loss: 0.0445 - acc: 0.9864 - loss: 0.0455 - a - ETA: 6s - loss: 0.0455 - ac - ETA: 6s - loss: 0.0458 - acc: 0.98 - ETA: 5s - loss: 0.0456 -\n",
      "Epoch 3/5\n",
      "59397/59397 [==============================] - 31s 516us/sample - loss: 0.0309 - acc: 0.990618s - loss: 0.0296 - acc: 0. - ETA: 17s - loss: 0.0291 - acc:  - ETA: 16s - loss: 0.0288 - acc:  - E - ETA: 10s - loss: 0.0307 - acc:  - ETA: 10s - loss: 0.03 - ETA: 9s - loss: 0.0311 -  - ETA: 8s - loss: 0.03 - ETA: 7s - loss: 0.0312 - acc: 0 - ETA: 6s - loss: 0.031 - ETA: 5s - loss: 0.0310 - acc: 0.9 - ETA: 5s - loss: 0.0310 - acc: 0. - ETA: 5s - loss: 0.0310 - - ETA: 4s - loss: 0.0318 - acc: 0. - ETA: 4s - loss: 0.0320 - acc: 0. - ETA: 4s - loss: 0.0320 -  - ETA: 3s - loss: - ET\n",
      "Epoch 4/5\n",
      "59397/59397 [==============================] - 31s 520us/sample - loss: 0.0234 - acc: 0.9928s - loss:  - ETA: 9s - loss: 0.0235 - acc: 0.99 - ETA: 8s - loss: 0.023 - ETA: 8s - loss: 0.0230 - acc: - ETA: 7s -  - ETA: 5s - loss: 0.0229 - ac - ETA: 2s - loss: 0.0234 - acc: 0 - ET - ETA: 0s - loss: 0.0234 - acc: 0\n",
      "Epoch 5/5\n",
      "59397/59397 [==============================] - 30s 507us/sample - loss: 0.0182 - acc: 0.9946 - los - ETA: 6s - loss: 0.0189 - acc: 0.9 - ETA: 6 \n",
      "2020-06-02 16:46:47.715090 End of fit\n",
      "acc: 98.99%\n",
      "2020-06-02 16:46:52.070873 Start of fit\n",
      "Epoch 1/5\n",
      "59399/59399 [==============================] - 33s 548us/sample - loss: 0.1682 - acc: 0.9476\n",
      "Epoch 2/5\n",
      "59399/59399 [==============================] - 30s 509us/sample - loss: 0.0469 - acc: 0.9855 - loss: 0.04 - ETA: 6s - loss - ETA: 2s - lo - ETA: 1s - loss: 0.0\n",
      "Epoch 3/5\n",
      "59399/59399 [==============================] - 31s 519us/sample - loss: 0.0316 - acc: 0.9896 ETA: 8s - loss:  - ETA: 7s - loss: 0.0321 - acc: 0.989 - ETA: 7s - loss: 0.0321 - acc: 0.9 - ETA - ETA: 2s - loss: 0.0322 - acc: 0. - ETA: 2s - loss: 0.0321 - ac - ETA: 1s \n",
      "Epoch 4/5\n",
      "59399/59399 [==============================] - 30s 513us/sample - loss: 0.0242 - acc: 0.9924 - loss - ETA: 5s - loss: 0.02 - ETA: 4s - loss: 0.0235 - acc: - ETA: 3s - loss: 0.0236  - ETA: 2s - loss: 0.0236 - acc: 0.99 - ETA: 2s - loss - ETA: 1s - loss: 0. - ETA: 0s - loss: 0.0242 - acc: 0\n",
      "Epoch 5/5\n",
      "59399/59399 [==============================] - 30s 510us/sample - loss: 0.0183 - acc: 0.9942 - ETA: 6s - loss: 0.0174 - ac - ETA: 6s - loss: 0. - ETA: 5s - loss: 0.018 - ETA: 4s - loss: 0.0179 - acc:  - ETA: 3s - loss:\n",
      "2020-06-02 16:49:31.906811 End of fit\n",
      "acc: 99.17%\n",
      "2020-06-02 16:49:36.666117 Start of fit\n",
      "Epoch 1/5\n",
      "59399/59399 [==============================] - 34s 566us/sample - loss: 0.1652 - acc: 0.9487 - loss: 0.1802 - acc:  - ETA: 3s - loss: 0.1784 - acc: 0.944 - ETA: 3s - loss: 0.1784 - acc: 0.944 - ETA: 3s - loss: 0.1783 - acc: 0.944 - ETA: 3s - loss: 0.1779 -\n",
      "Epoch 2/5\n",
      "59399/59399 [==============================] - 32s 547us/sample - loss: 0.0449 - acc: 0.9860 - loss: 0 - E\n",
      "Epoch 3/5\n",
      "59399/59399 [==============================] - 31s 524us/sample - loss: 0.0317 - acc: 0.9902 - loss: 0\n",
      "Epoch 4/5\n",
      "59399/59399 [==============================] - 32s 531us/sample - loss: 0.0231 - acc: 0.9929\n",
      "Epoch 5/5\n",
      "59399/59399 [==============================] - 31s 523us/sample - loss: 0.0182 - acc: 0.9943 - loss: 0.0169 - - ETA: 1s - loss: 0.0179 - - ETA: 0s - loss: 0.0183 - acc:  - ETA: 0s - loss: 0.0182 - acc: 0. - ETA: 0s - loss: 0.0183 - acc: 0.9\n",
      "2020-06-02 16:52:21.586248 End of fit\n",
      "acc: 99.05%\n",
      "2020-06-02 16:52:30.796444 Start of fit\n",
      "Epoch 1/5\n",
      "59399/59399 [==============================] - 32s 540us/sample - loss: 0.1690 - acc: 0.9475 ETA: 9s - loss: 0.2121 - acc: 0.93 - ETA: 9s -  - ETA: 2s - loss: 0.1 - ETA: 1s - loss: 0.\n",
      "Epoch 2/5\n",
      "59399/59399 [==============================] - 31s 522us/sample - loss: 0.0436 - acc: 0.9864s - loss - ETA: 3s - los - ETA: 2s - loss: 0.044 - ETA: 1s - loss: 0.\n",
      "Epoch 3/5\n",
      "59399/59399 [==============================] - 33s 548us/sample - loss: 0.0298 - acc: 0.9904 - loss: 0.0285 - acc: 0.990 - ETA: 9s - loss: 0.02 - ETA: 5s -  - ETA: 1s - loss:\n",
      "Epoch 4/5\n",
      "59399/59399 [==============================] - 31s 517us/sample - loss: 0.0230 - acc: 0.9926s - lo - ETA: 11s - loss: 0.02 - ETA: 4s \n",
      "Epoch 5/5\n",
      "59399/59399 [==============================] - 31s 520us/sample - loss: 0.0184 - acc: 0.9942 - loss: 0.017 - ETA: 5s - loss: 0.0174 - acc: 0. - ETA: 5s - loss: 0.0173 - ac - ETA: 5s - loss - ETA: 1s - loss: 0.01\n",
      "2020-06-02 16:55:12.995814 End of fit\n",
      "acc: 99.08%\n",
      "2020-06-02 16:55:17.280435 Start of fit\n",
      "Epoch 1/5\n",
      "59400/59400 [==============================] - 32s 540us/sample - loss: 0.1824 - acc: 0.9428s -  - ETA: 17s -  - ETA: 16s - loss: 0.28 - ETA - ETA: 14s - loss: 0.2695 - acc: 0.91 - ETA: 14\n",
      "Epoch 2/5\n",
      "59400/59400 [==============================] - 30s 509us/sample - loss: 0.0457 - acc: 0.9855 - loss: 0.0460 - acc: 0. - ETA: 0s - loss: 0.046\n",
      "Epoch 3/5\n",
      "59400/59400 [==============================] - 30s 510us/sample - loss: 0.0325 - acc: 0.9900 - loss: 0.0331 - ac - ETA: 8s - ETA: 3s - ETA: 2s - loss: 0.0326 - acc: 0 - ETA: 1s - loss: 0.0325 - acc - ETA: 1s - loss:\n",
      "Epoch 4/5\n",
      "59400/59400 [==============================] - 30s 509us/sample - loss: 0.0250 - acc: 0.9924s - loss:  - ETA: 9s - loss: 0. - ETA: 8s - l - ETA: 1s - loss: 0.0252 - acc:  - ETA: 1s - loss: 0.0\n",
      "Epoch 5/5\n",
      "59400/59400 [==============================] - 30s 508us/sample - loss: 0.0194 - acc: 0.9943s  - ETA: 1 - ETA: 8s - loss: 0.0191 - a - ETA: 7 - ETA: - ETA: - ETA: \n",
      "2020-06-02 16:57:55.490457 End of fit\n",
      "acc: 98.92%\n",
      "2020-06-02 16:57:59.673409 Start of fit\n",
      "Epoch 1/5\n",
      "59400/59400 [==============================] - 32s 545us/sample - loss: 0.1622 - acc: 0.9492 - los - ETA: 5s - loss: - ETA: 0s - loss: 0.1653\n",
      "Epoch 2/5\n",
      "59400/59400 [==============================] - 32s 531us/sample - loss: 0.0446 - acc: 0.9860\n",
      "Epoch 3/5\n",
      "59400/59400 [==============================] - 30s 512us/sample - loss: 0.0295 - acc: 0.9911 - loss: 0.0290 - acc: - ETA: 5s - loss: 0.0296 - acc: 0. - ETA: 4s - loss: 0.0295 - acc: 0.9 - E\n",
      "Epoch 4/5\n",
      "59400/59400 [==============================] - 31s 517us/sample - loss: 0.0231 - acc: 0.9929 - loss: 0.023\n",
      "Epoch 5/5\n",
      "59400/59400 [==============================] - 31s 515us/sample - loss: 0.0177 - acc: 0.9938\n",
      "2020-06-02 17:00:40.405389 End of fit\n",
      "acc: 98.94%\n",
      "2020-06-02 17:00:44.578713 Start of fit\n",
      "Epoch 1/5\n",
      "59402/59402 [==============================] - 32s 542us/sample - loss: 0.1653 - acc: 0.9476\n",
      "Epoch 2/5\n",
      "59402/59402 [==============================] - 31s 514us/sample - loss: 0.0449 - acc: 0.9862 - loss: 0.0468 - acc: 0.9 - ETA: 8s - loss: 0.0468 - - ETA: 7s - loss:  - ETA: 1s - loss: 0.0460 - acc: 0.98 - ETA: 1s - loss: 0.0458 - a - ETA: 0s - loss: 0.0454 - acc\n",
      "Epoch 3/5\n",
      "59402/59402 [==============================] - 31s 516us/sample - loss: 0.0307 - acc: 0.9905 - loss: 0.0306 - acc: 0.\n",
      "Epoch 4/5\n",
      "59402/59402 [==============================] - 30s 509us/sample - loss: 0.0223 - acc: 0.9932  - ETA: 1s - loss: 0.\n",
      "Epoch 5/5\n",
      "59402/59402 [==============================] - 30s 506us/sample - loss: 0.0180 - acc: 0.9943\n",
      "2020-06-02 17:03:22.972066 End of fit\n",
      "acc: 98.88%\n",
      "2020-06-02 17:03:27.281461 Start of fit\n",
      "Epoch 1/5\n",
      "59403/59403 [==============================] - 33s 547us/sample - loss: 0.1695 - acc: 0.9467 - loss: 0.1734 - acc: 0. - ETA: 0s - loss: 0.1722 - acc: 0.9 - ETA: 0s - loss: 0.1717 - acc: 0.9 - ETA: 0s - loss: 0.1710 - acc\n",
      "Epoch 2/5\n",
      "59403/59403 [==============================] - 31s 528us/sample - loss: 0.0444 - acc: 0.9862\n",
      "Epoch 3/5\n",
      "59403/59403 [==============================] - 33s 550us/sample - loss: 0.0312 - acc: 0.9901\n",
      "Epoch 4/5\n",
      "59403/59403 [==============================] - 33s 550us/sample - loss: 0.0223 - acc: 0.9932s - loss  - ETA: 5s  - ETA: 3s - loss: 0.02 - ETA: 2s - loss: 0.0220 - acc: - ETA:\n",
      "Epoch 5/5\n",
      "59403/59403 [==============================] - 30s 506us/sample - loss: 0.0186 - acc: 0.9941- ETA: 1s - loss: 0.0187 - ac - ETA: 1s - loss - ETA: 0s - loss: 0.0186 - acc: 0.994\n",
      "2020-06-02 17:06:11.495226 End of fit\n",
      "acc: 99.06%\n",
      "99.00% (+/- 0.10%)\n",
      "2020-06-02 17:06:15.017683 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 2 3 4 5 6 7 8 9 8 4 1 3 7 5 2 8 0 7 3 9 9 0 9 1 1 5 8 8 6 3 2 1 8 3 2 6 5 6 9 6 1 0 5 3 1 9\n",
      " 2 1 9 6 0 4 6 1 7 3 8 9 2 9 6 5 8 3 5 4 1 6 1 0 9 6 2 5 4 2 3 4 4 6 0 0 2 0 1 2 3 4 3 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 8 4 5 6 7 8 9 8 6 5 0 6 8 9 4 1 9 5 8 0 9 8 9 1 4 0 5 3 2 1 5 4 0 7 6 0 1 7 0\n",
      " 6 8 9 3 1]\n",
      "ndx_errs (array([ 151,  241,  247,  318,  320,  321,  362,  376,  381,  444,  445,  448,  464,  479,  495,  519,  550,  578,  582,  628,  659,  691,  716,  726,  740,  760,  839,  881,  883,  924,  926,  938,\n",
      "        939,  947,  951,  956, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1181, 1192, 1226, 1228, 1232, 1242, 1247, 1248, 1270, 1283, 1289, 1299, 1319, 1326, 1331, 1364, 1393, 1414,\n",
      "       1500, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1732, 1737, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2098, 2109, 2118, 2129, 2130, 2135,\n",
      "       2177, 2182, 2189, 2224, 2237, 2282, 2292, 2293, 2298, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2462, 2574, 2607, 2648, 2654, 2721, 2730, 2758, 2771, 2810, 2851, 2853, 2896, 2927, 2939, 2945,\n",
      "       2952, 2953, 2998, 3005, 3030, 3060, 3062, 3073, 3117, 3136, 3206, 3240, 3262, 3289, 3323, 3333, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3629, 3664, 3702, 3718, 3726, 3742, 3757, 3767, 3780,\n",
      "       3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3968, 4007, 4065, 4072, 4075, 4078, 4116, 4176, 4224, 4269, 4271, 4284, 4289, 4294, 4297, 4306, 4355, 4360, 4437, 4483, 4489, 4497, 4500, 4505,\n",
      "       4567, 4575, 4578, 4598, 4639, 4671, 4731, 4737, 4743, 4761, 4785, 4807, 4823, 4837, 4860, 4874, 4886, 4890, 4893, 4911, 4943, 4966, 4976, 4990, 5068, 5176, 5278, 5532, 5600, 5634, 5705, 5769,\n",
      "       5835, 5841, 5858, 5867, 5887, 5888, 5906, 5914, 5937, 5955, 5973, 5975, 5982, 5997], dtype=int64),)\n",
      "num correct is  5761  an accuracy of  0.9603267211201867\n",
      "****************************** 7999 ******************************\n",
      "fill_up_last_row.shape (67999, 26)\n",
      "X_num_images 67999 X_image_num_pixels 954\n",
      "num_extra_rows 7\n",
      "2020-06-02 17:15:37.119643 Start of fit\n",
      "Epoch 1/5\n",
      "61195/61195 [==============================] - 33s 545us/sample - loss: 0.1621 - acc: 0.9478ETA: 8s - loss: 0.1950 - - - ETA: 4s\n",
      "Epoch 2/5\n",
      "61195/61195 [==============================] - 32s 529us/sample - loss: 0.0440 - acc: 0.9865 - loss\n",
      "Epoch 3/5\n",
      "61195/61195 [==============================] - 32s 524us/sample - loss: 0.0305 - acc: 0.9907\n",
      "Epoch 4/5\n",
      "61195/61195 [==============================] - 32s 525us/sample - loss: 0.0223 - acc: 0.9927 - los - ETA: 8s - loss:  - ETA: 6s - loss: 0.0227 - acc: 0.99 - ETA: 6s - loss: 0.0227 - acc:  - ETA: 6s - l - ETA: 1s -  - ETA: 0s - loss: 0.0223 - acc: 0.99\n",
      "Epoch 5/5\n",
      "61195/61195 [==============================] - 31s 511us/sample - loss: 0.0173 - acc: 0.9948   - ETA: 4s - loss: 0.0168 - acc: 0 - ETA: 4s - lo\n",
      "2020-06-02 17:18:23.495812 End of fit\n",
      "acc: 98.96%\n",
      "2020-06-02 17:18:27.822858 Start of fit\n",
      "Epoch 1/5\n",
      "61195/61195 [==============================] - 34s 558us/sample - loss: 0.1653 - acc: 0.9485 - loss: 0. - ETA: 1s - loss\n",
      "Epoch 2/5\n",
      "61195/61195 [==============================] - 32s 525us/sample - loss: 0.0427 - acc: 0.9869\n",
      "Epoch 3/5\n",
      "61195/61195 [==============================] - 33s 543us/sample - loss: 0.0298 - acc: 0.9907 - loss: 0.0298 - ac\n",
      "Epoch 4/5\n",
      "61195/61195 [==============================] - 33s 532us/sample - loss: 0.0228 - acc: 0.9926\n",
      "Epoch 5/5\n",
      "61195/61195 [==============================] - 32s 516us/sample - loss: 0.0169 - acc: 0.9947s - loss - ETA: 22 - ETA: 11s - loss:  - ETA: - ETA: 8s - loss: 0.016\n",
      "2020-06-02 17:21:17.057041 End of fit\n",
      "acc: 98.82%\n",
      "2020-06-02 17:21:21.318051 Start of fit\n",
      "Epoch 1/5\n",
      "61196/61196 [==============================] - 34s 550us/sample - loss: 0.1628 - acc: 0.9487 - ETA: 8s - los - ETA: 1s - loss: 0.1669 - ac - ETA: 0s - loss: 0.1650 - ac\n",
      "Epoch 2/5\n",
      "61196/61196 [==============================] - 32s 527us/sample - loss: 0.0432 - acc: 0.9869s - loss: 0.0445 - acc: 0. - ETA - ETA: 10s - loss: 0.0437 - a - ETA: 8s - loss: 0.0431 -  - ETA: 7s - loss: 0.0429  - ETA: 1s - loss: 0.0428 - acc: - ETA: 1s - loss: 0\n",
      "Epoch 3/5\n",
      "61196/61196 [==============================] - 31s 510us/sample - loss: 0.0295 - acc: 0.9910 - loss: 0.0297  - ETA: 1s - loss: 0.0294 - acc: 0.991 - ETA: 1s - loss: 0.0294 - - ETA: 0s - loss: 0.0296 - acc: 0\n",
      "Epoch 4/5\n",
      "61196/61196 [==============================] - 32s 518us/sample - loss: 0.0230 - acc: 0.9932 \n",
      "Epoch 5/5\n",
      "61196/61196 [==============================] - 31s 514us/sample - loss: 0.0177 - acc: 0.9950\n",
      "2020-06-02 17:24:07.642387 End of fit\n",
      "acc: 99.22%\n",
      "2020-06-02 17:24:12.162535 Start of fit\n",
      "Epoch 1/5\n",
      "61196/61196 [==============================] - 34s 548us/sample - loss: 0.1590 - acc: 0.9496 - loss: 0.\n",
      "Epoch 2/5\n",
      "61196/61196 [==============================] - 32s 526us/sample - loss: 0.0431 - acc: 0.9867s - lo - ETA: 4s - loss: 0.0430 - acc: 0 - ETA: 4s - loss: 0.04 - ETA - ETA: 1s - loss: 0.0\n",
      "Epoch 3/5\n",
      "61196/61196 [==============================] - 32s 529us/sample - loss: 0.0296 - acc: 0.9907\n",
      "Epoch 4/5\n",
      "61196/61196 [==============================] - 32s 530us/sample - loss: 0.0225 - acc: 0.9933\n",
      "Epoch 5/5\n",
      "61196/61196 [==============================] - 32s 519us/sample - loss: 0.0179 - acc: 0.9947\n",
      "2020-06-02 17:26:59.786630 End of fit\n",
      "acc: 98.69%\n",
      "2020-06-02 17:27:04.468536 Start of fit\n",
      "Epoch 1/5\n",
      "61199/61199 [==============================] - 34s 555us/sample - loss: 0.1653 - acc: 0.9469 - loss: 0 - ETA: 1s - loss: 0.1701 - acc: 0. - ETA: 1s - loss: 0.169\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61199/61199 [==============================] - 33s 532us/sample - loss: 0.0441 - acc: 0.9867 - loss - ETA: 0s - loss: 0.0444 - acc: 0.986 - ETA: 0s - loss: 0.0443 - acc:\n",
      "Epoch 3/5\n",
      "61199/61199 [==============================] - 32s 522us/sample - loss: 0.0311 - acc: 0.9909s - lo - ETA: 10s - loss: 0.0314 - - ETA: 10s - los - ETA: 8s - loss: 0.0312 - acc: 0.9 - ETA: 8s - los - ETA: 7s - lo - - ETA: 0s - loss: 0.0315 - a\n",
      "Epoch 4/5\n",
      "61199/61199 [==============================] - 32s 521us/sample - loss: 0.0231 - acc: 0.9927s - loss: 0.0224 - - ETA - ETA: 7s  - ETA: 5s - loss: 0.0227 - - ETA: 4s - loss: 0.0228 - - ETA: 3s - loss:\n",
      "Epoch 5/5\n",
      "61199/61199 [==============================] - 31s 511us/sample - loss: 0.0181 - acc: 0.9946\n",
      "2020-06-02 17:30:05.990878 End of fit\n",
      "acc: 99.09%\n",
      "2020-06-02 17:30:12.687764 Start of fit\n",
      "Epoch 1/5\n",
      "61199/61199 [==============================] - 34s 555us/sample - loss: 0.1689 - acc: 0.9475 - loss - ETA: 4s - lo - ETA: 3s - loss: 0.1806 - acc: 0.944 - ETA: 3s - loss: 0.1804 - acc: 0.94 - ETA: 2s - ETA: 0s - loss: 0.172\n",
      "Epoch 2/5\n",
      "61199/61199 [==============================] - 32s 530us/sample - loss: 0.0451 - acc: 0.9857\n",
      "Epoch 3/5\n",
      "61199/61199 [==============================] - 32s 530us/sample - loss: 0.0317 - acc: 0.9897 -  - ETA: 0s - loss: 0.0317 - acc: 0.98\n",
      "Epoch 4/5\n",
      "61199/61199 [==============================] - 32s 527us/sample - loss: 0.0230 - acc: 0.9924\n",
      "Epoch 5/5\n",
      "61199/61199 [==============================] - 33s 532us/sample - loss: 0.0188 - acc: 0.9945 - loss: 0.0186 - acc: 0. - ETA: 5s - loss: 0.0188 -   - ETA: 2s  - ETA: 0s - loss: 0.0188 - acc: 0.99\n",
      "2020-06-02 17:33:02.543107 End of fit\n",
      "acc: 99.12%\n",
      "2020-06-02 17:33:07.282576 Start of fit\n",
      "Epoch 1/5\n",
      "61200/61200 [==============================] - 34s 548us/sample - loss: 0.1600 - acc: 0.9494\n",
      "Epoch 2/5\n",
      "61200/61200 [==============================] - 32s 519us/sample - loss: 0.0430 - acc: 0.9871\n",
      "Epoch 3/5\n",
      "61200/61200 [==============================] - 31s 513us/sample - loss: 0.0297 - acc: 0.9911 - loss: 0.0292 - \n",
      "Epoch 4/5\n",
      "61200/61200 [==============================] - 31s 513us/sample - loss: 0.0223 - acc: 0.9931 - l\n",
      "Epoch 5/5\n",
      "61200/61200 [==============================] - 31s 513us/sample - loss: 0.0174 - acc: 0.9948\n",
      "2020-06-02 17:35:53.434072 End of fit\n",
      "acc: 99.13%\n",
      "2020-06-02 17:35:58.113865 Start of fit\n",
      "Epoch 1/5\n",
      "61203/61203 [==============================] - 34s 550us/sample - loss: 0.1648 - acc: 0.9487 - loss: 0.1965 - acc: - ETA: 7s - loss: 0.1948 - ac - ETA:  - ETA: \n",
      "Epoch 2/5\n",
      "61203/61203 [==============================] - 32s 528us/sample - loss: 0.0426 - acc: 0.9869 -  - ETA: 0s - loss: 0.0426 - acc: 0.98 - ETA: 0s - loss: 0.0426 - acc - ETA: 0s - loss: 0.0427 - acc: 0.\n",
      "Epoch 3/5\n",
      "61203/61203 [==============================] - 32s 528us/sample - loss: 0.0287 - acc: 0.9910 - loss: - ETA: 0s - loss: 0.0288 - acc: 0.9\n",
      "Epoch 4/5\n",
      "61203/61203 [==============================] - 32s 526us/sample - loss: 0.0228 - acc: 0.9934\n",
      "Epoch 5/5\n",
      "61203/61203 [==============================] - 32s 520us/sample - loss: 0.0178 - acc: 0.9942 - loss: 0.0179 - ac - ETA: 5s - loss: 0.0182 - acc - ETA: 2s - loss: 0.0176 - ETA: 1s - loss: 0.0177 - a - ETA: 0s - loss: 0.0178 - \n",
      "2020-06-02 17:38:47.052798 End of fit\n",
      "acc: 98.96%\n",
      "2020-06-02 17:38:52.090528 Start of fit\n",
      "Epoch 1/5\n",
      "61204/61204 [==============================] - 34s 552us/sample - loss: 0.1581 - acc: 0.9500 - loss: 0.1633 - acc:  - ETA: 0s - loss: 0.161\n",
      "Epoch 2/5\n",
      "61204/61204 [==============================] - 32s 528us/sample - loss: 0.0427 - acc: 0.9873 - loss: 0.0429 - acc -  - ETA: 1s - loss\n",
      "Epoch 3/5\n",
      "61204/61204 [==============================] - 32s 515us/sample - loss: 0.0297 - acc: 0.9909\n",
      "Epoch 4/5\n",
      "61204/61204 [==============================] - 32s 519us/sample - loss: 0.0229 - acc: 0.9928 - loss: 0.0214 - acc: 0. - ETA: 0s - loss: 0.0226 - ac\n",
      "Epoch 5/5\n",
      "61204/61204 [==============================] - 32s 516us/sample - loss: 0.0175 - acc: 0.99484s - loss: - ETA: 3s - loss: 0.0173 - acc: 0.995 -  - ETA: 1s - loss: 0.01\n",
      "2020-06-02 17:41:38.696353 End of fit\n",
      "acc: 98.98%\n",
      "2020-06-02 17:41:43.401187 Start of fit\n",
      "Epoch 1/5\n",
      "61204/61204 [==============================] - 34s 561us/sample - loss: 0.1769 - acc: 0.9438\n",
      "Epoch 2/5\n",
      "61204/61204 [==============================] - 33s 534us/sample - loss: 0.0454 - acc: 0.9866 - loss: 0.0454 \n",
      "Epoch 3/5\n",
      "61204/61204 [==============================] - 32s 531us/sample - loss: 0.0310 - acc: 0.9906\n",
      "Epoch 4/5\n",
      "61204/61204 [==============================] - 32s 523us/sample - loss: 0.0234 - acc: 0.9927\n",
      "Epoch 5/5\n",
      "61204/61204 [==============================] - 33s 533us/sample - loss: 0.0184 - acc: 0.9944\n",
      "2020-06-02 17:44:33.506395 End of fit\n",
      "acc: 99.04%\n",
      "99.00% (+/- 0.15%)\n",
      "2020-06-02 17:44:37.620925 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 3 5 6 7 8 9 0 1 2 3 5 6 7 8 9 9 7 0 9 0 1 5 8 8 0 9 3 2 7 8 4 6 1 0 4 9 4 2 0 5 0 1 6 9 3 2\n",
      " 9 1 6 0 1 1 8 7 7 6 3 6 0 7 2 4 1 7 0 6 7 1 2 5 8 1 1 2 8 7 6 8 7 1 6 2 9 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 8 9 5 7 0 3 1 6 8 4 1 5 6 4 2 7 8 1 3 4 3 4 7 2 0 5 0 1 9 2 3\n",
      " 2 3 5 5 7]\n",
      "ndx_errs (array([ 151,  241,  247,  318,  320,  321,  362,  376,  381,  444,  445,  448,  464,  479,  495,  519,  550,  578,  582,  628,  659,  691,  716,  726,  740,  760,  839,  881,  883,  924,  926,  938,\n",
      "        939,  947,  951,  956, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1181, 1192, 1226, 1228, 1232, 1242, 1247, 1248, 1270, 1283, 1289, 1299, 1319, 1326, 1331, 1364, 1393, 1414,\n",
      "       1500, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1732, 1737, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2098, 2109, 2118, 2129, 2130, 2135,\n",
      "       2177, 2182, 2189, 2224, 2237, 2282, 2292, 2293, 2298, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2462, 2574, 2607, 2648, 2654, 2721, 2730, 2758, 2771, 2810, 2851, 2853, 2896, 2927, 2939, 2945,\n",
      "       2952, 2953, 2998, 3005, 3030, 3060, 3062, 3073, 3117, 3136, 3206, 3240, 3262, 3289, 3323, 3333, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3629, 3664, 3702, 3718, 3726, 3742, 3757, 3767, 3780,\n",
      "       3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3968, 4007, 4065, 4072, 4075, 4078, 4116, 4176, 4224, 4269, 4271, 4284, 4289, 4294, 4297, 4306, 4355, 4360, 4437, 4483, 4489, 4497, 4500, 4505,\n",
      "       4567, 4575, 4578, 4598, 4639, 4671, 4731, 4737, 4743, 4761, 4785, 4807, 4823, 4837, 4860, 4874, 4886, 4890, 4893, 4911, 4943, 4966, 4976, 4990, 5068, 5176, 5278, 5532, 5600, 5634, 5705, 5769,\n",
      "       5835, 5841, 5858, 5867, 5887, 5888, 5906, 5914, 5937, 5955, 5973, 5975, 5982, 5997, 6023, 6035, 6037, 6071, 6081, 6091, 6157, 6166, 6172, 6173, 6555, 6560, 6597, 6641, 6651, 6755, 6783, 6813,\n",
      "       7216, 7333, 7432, 7434, 7492, 7545, 7797, 7921], dtype=int64),)\n",
      "num correct is  7735  an accuracy of  0.9669958744843106\n",
      "****************************** 9999 ******************************\n",
      "fill_up_last_row.shape (69999, 26)\n",
      "X_num_images 69999 X_image_num_pixels 954\n",
      "num_extra_rows 7\n",
      "2020-06-02 17:56:56.845075 Start of fit\n",
      "Epoch 1/5\n",
      "62994/62994 [==============================] - 37s 580us/sample - loss: 0.1633 - acc: 0.9482ETA: 0s - loss: 0.1662 \n",
      "Epoch 2/5\n",
      "62994/62994 [==============================] - 33s 524us/sample - loss: 0.0418 - acc: 0.9873s - loss - ETA: 27s - loss: 0.0491 - acc - ETA: 27s - loss:  - ET - ETA: 2s - loss: 0.0425 - a - ETA: 1s - loss: 0.0422 - ac - ETA: 1s - loss: 0.042 - ETA: 0s - loss: 0.0419 - acc: 0.98\n",
      "Epoch 3/5\n",
      "62994/62994 [==============================] - 33s 531us/sample - loss: 0.0296 - acc: 0.9909 - loss:  - ETA: 1s - l - ETA: 0s - loss: 0.0296 - acc: 0.990\n",
      "Epoch 4/5\n",
      "62994/62994 [==============================] - 33s 524us/sample - loss: 0.0225 - acc: 0.9931\n",
      "Epoch 5/5\n",
      "62994/62994 [==============================] - 33s 522us/sample - loss: 0.0177 - acc: 0.9945 - loss: 0.0171  - ETA: 2s - loss: 0.0174 - acc: 0.99 - ETA: 2s - loss: 0.017 - ETA: 1s - \n",
      "2020-06-02 17:59:59.562179 End of fit\n",
      "acc: 98.99%\n",
      "2020-06-02 18:00:06.529545 Start of fit\n",
      "Epoch 1/5\n",
      "62995/62995 [==============================] - 36s 565us/sample - loss: 0.1593 - acc: 0.9502A: 1s - loss: 0.16 - ETA: 0s - loss: 0.1621 \n",
      "Epoch 2/5\n",
      "62995/62995 [==============================] - 33s 524us/sample - loss: 0.0419 - acc: 0.9866s - los - ETA: 9s - - - E\n",
      "Epoch 3/5\n",
      "62995/62995 [==============================] - 33s 524us/sample - loss: 0.0286 - acc: 0.9912\n",
      "Epoch 4/5\n",
      "62995/62995 [==============================] - 34s 541us/sample - loss: 0.0214 - acc: 0.9933 - loss - ETA: 4s - loss: 0.0213  - ETA: 3s - loss: 0.0208\n",
      "Epoch 5/5\n",
      "62995/62995 [==============================] - 33s 523us/sample - loss: 0.0176 - acc: 0.9947 - ETA: 11s - loss - ETA: 4s - loss: 0 - ETA: 0s - loss: 0.0175 - ac\n",
      "2020-06-02 18:03:03.818144 End of fit\n",
      "acc: 99.20%\n",
      "2020-06-02 18:03:09.636805 Start of fit\n",
      "Epoch 1/5\n",
      "62995/62995 [==============================] - 37s 581us/sample - loss: 0.1575 - acc: 0.9497 - loss: 0.1577 - acc: 0.949\n",
      "Epoch 2/5\n",
      "62995/62995 [==============================] - 33s 524us/sample - loss: 0.0411 - acc: 0.9878\n",
      "Epoch 3/5\n",
      "62995/62995 [==============================] - 34s 532us/sample - loss: 0.0292 - acc: 0.9907 - loss: 0.0291 - a - ETA: 1s - loss: 0.0295 - acc:  - ETA: 1s - loss\n",
      "Epoch 4/5\n",
      "62995/62995 [==============================] - 33s 528us/sample - loss: 0.0223 - acc: 0.9933\n",
      "Epoch 5/5\n",
      "62995/62995 [==============================] - 33s 529us/sample - loss: 0.0171 - acc: 0.9945 - loss: 0.0172 -  - ETA: 0s - loss: 0.0173 - acc:\n",
      "2020-06-02 18:06:07.892124 End of fit\n",
      "acc: 99.07%\n",
      "2020-06-02 18:06:13.405456 Start of fit\n",
      "Epoch 1/5\n",
      "62998/62998 [==============================] - 36s 564us/sample - loss: 0.1643 - acc: 0.9487s  - ETA: 11s - los - ETA: 1s \n",
      "Epoch 2/5\n",
      "62998/62998 [==============================] - 34s 534us/sample - loss: 0.0453 - acc: 0.9860\n",
      "Epoch 3/5\n",
      "62998/62998 [==============================] - 34s 533us/sample - loss: 0.0304 - acc: 0.9905 - loss: 0.0317 - acc: - ETA: 8s - loss: 0.0316 \n",
      "Epoch 4/5\n",
      "62998/62998 [==============================] - 32s 515us/sample - loss: 0.0238 - acc: 0.9928 ETA: 8s - loss: 0. - ETA: 7s - loss: 0.0227 - ac - ETA: 7s - loss: 0.0225 -  - ETA: 6s - loss: 0.0 - ETA: 0s - loss: 0.0237 - acc: 0.\n",
      "Epoch 5/5\n",
      "62998/62998 [==============================] - 34s 542us/sample - loss: 0.0174 - acc: 0.9946\n",
      "2020-06-02 18:09:10.231532 End of fit\n",
      "acc: 99.11%\n",
      "2020-06-02 18:09:15.794744 Start of fit\n",
      "Epoch 1/5\n",
      "62999/62999 [==============================] - 35s 556us/sample - loss: 0.1567 - acc: 0.9512 - loss: 0.1573 - acc: 0.9\n",
      "Epoch 2/5\n",
      "62999/62999 [==============================] - 34s 536us/sample - loss: 0.0413 - acc: 0.9870\n",
      "Epoch 3/5\n",
      "62999/62999 [==============================] - 33s 530us/sample - loss: 0.0291 - acc: 0.9907  - ETA: 0s - loss: 0.0290 - acc: 0.\n",
      "Epoch 4/5\n",
      "62999/62999 [==============================] - 34s 537us/sample - loss: 0.0219 - acc: 0.9933\n",
      "Epoch 5/5\n",
      "62999/62999 [==============================] - 33s 522us/sample - loss: 0.0170 - acc: 0.9945 - loss: 0.0171 - acc: 0.99\n",
      "2020-06-02 18:12:11.284578 End of fit\n",
      "acc: 98.99%\n",
      "2020-06-02 18:12:16.674482 Start of fit\n",
      "Epoch 1/5\n",
      "63001/63001 [==============================] - 36s 577us/sample - loss: 0.1670 - acc: 0.9472 - loss: - ETA: 0s - loss: 0.1680 - acc: 0.\n",
      "Epoch 2/5\n",
      "63001/63001 [==============================] - 35s 549us/sample - loss: 0.0437 - acc: 0.9867\n",
      "Epoch 3/5\n",
      "63001/63001 [==============================] - 35s 548us/sample - loss: 0.0301 - acc: 0.9905 - l\n",
      "Epoch 4/5\n",
      "63001/63001 [==============================] - 35s 556us/sample - loss: 0.0231 - acc: 0.9930\n",
      "Epoch 5/5\n",
      "63001/63001 [==============================] - 34s 542us/sample - loss: 0.0176 - acc: 0.9944 ETA: - ETA:\n",
      "2020-06-02 18:15:18.936090 End of fit\n",
      "acc: 98.93%\n",
      "2020-06-02 18:15:24.411849 Start of fit\n",
      "Epoch 1/5\n",
      "63001/63001 [==============================] - 36s 568us/sample - loss: 0.1587 - acc: 0.9495\n",
      "Epoch 2/5\n",
      "63001/63001 [==============================] - 34s 536us/sample - loss: 0.0422 - acc: 0.9865 - loss: 0.0424 - acc - ETA: 2s - loss: 0.0427 - a - ETA: 1s - l\n",
      "Epoch 3/5\n",
      "63001/63001 [==============================] - 34s 540us/sample - loss: 0.0294 - acc: 0.9909\n",
      "Epoch 4/5\n",
      "63001/63001 [==============================] - 34s 541us/sample - loss: 0.0218 - acc: 0.9932 - loss:  - ETA: 0s - loss: 0.0221 - acc\n",
      "Epoch 5/5\n",
      "63001/63001 [==============================] - 34s 538us/sample - loss: 0.0172 - acc: 0.9943 \n",
      "2020-06-02 18:18:22.518827 End of fit\n",
      "acc: 99.16%\n",
      "2020-06-02 18:18:27.756627 Start of fit\n",
      "Epoch 1/5\n",
      "63002/63002 [==============================] - 37s 589us/sample - loss: 0.1648 - acc: 0.9483\n",
      "Epoch 2/5\n",
      "63002/63002 [==============================] - 35s 561us/sample - loss: 0.0437 - acc: 0.9865\n",
      "Epoch 3/5\n",
      "63002/63002 [==============================] - 35s 557us/sample - loss: 0.0293 - acc: 0.9905 - loss: 0.0294 - acc: 0.990 - ETA: 0s - loss: 0.0294 - acc:\n",
      "Epoch 4/5\n",
      "63002/63002 [==============================] - 34s 535us/sample - loss: 0.0219 - acc: 0.9927  - ETA: 0s - loss: 0.0219 - acc: 0.992\n",
      "Epoch 5/5\n",
      "63002/63002 [==============================] - 34s 547us/sample - loss: 0.0182 - acc: 0.9945 - loss: 0.0 - ETA: 4s - loss: 0.0176 - acc: - ETA: 3s - loss: - ETA: 2s - loss: 0.0179 - acc:  - ETA: 1s - loss:  - ETA: 0s - loss: 0.0183 - ac\n",
      "2020-06-02 18:21:30.118252 End of fit\n",
      "acc: 98.91%\n",
      "2020-06-02 18:21:35.740789 Start of fit\n",
      "Epoch 1/5\n",
      "63003/63003 [==============================] - 36s 570us/sample - loss: 0.1604 - acc: 0.9490 - loss: 0. - ETA: 1s - loss: 0.\n",
      "Epoch 2/5\n",
      "63003/63003 [==============================] - 34s 543us/sample - loss: 0.0425 - acc: 0.9868\n",
      "Epoch 3/5\n",
      "63003/63003 [==============================] - 34s 541us/sample - loss: 0.0291 - acc: 0.9910\n",
      "Epoch 4/5\n",
      "63003/63003 [==============================] - 33s 525us/sample - loss: 0.0222 - acc: 0.9932\n",
      "Epoch 5/5\n",
      "63003/63003 [==============================] - 34s 538us/sample - loss: 0.0167 - acc: 0.9950 \n",
      "2020-06-02 18:24:34.679949 End of fit\n",
      "acc: 98.10%\n",
      "2020-06-02 18:24:39.829879 Start of fit\n",
      "Epoch 1/5\n",
      "63003/63003 [==============================] - 36s 573us/sample - loss: 0.1708 - acc: 0.9473 - loss: 0.1984 - acc - ETA: 6s -  - ETA: 2\n",
      "Epoch 2/5\n",
      "63003/63003 [==============================] - 34s 538us/sample - loss: 0.0441 - acc: 0.9862\n",
      "Epoch 3/5\n",
      "63003/63003 [==============================] - 34s 544us/sample - loss: 0.0302 - acc: 0.9906 - loss: 0.0299 - ETA: 3s - loss: 0.03\n",
      "Epoch 4/5\n",
      "63003/63003 [==============================] - 34s 541us/sample - loss: 0.0226 - acc: 0.9934 - loss: 0.0225 - acc: \n",
      "Epoch 5/5\n",
      "63003/63003 [==============================] - 34s 537us/sample - loss: 0.0178 - acc: 0.9944s - loss: 0.0163 - acc - ETA: 10s - loss: 0.0164 - acc:  - ETA: 10s - loss: 0.0164 - - ETA: 9s - loss: 0.0164 - a - ETA: 1s - loss: 0\n",
      "2020-06-02 18:27:39.978664 End of fit\n",
      "acc: 98.94%\n",
      "98.94% (+/- 0.30%)\n",
      "2020-06-02 18:27:44.271030 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 2 0 7 7 5 8 2 9 8 6 7 3 4 6 5 7 0 4 7 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 6 7 0 6 8 6 3 9 9 8 8 7\n",
      " 7 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0\n",
      " 1 2 3 4 5]\n",
      "ndx_errs (array([ 151,  241,  247,  318,  320,  321,  362,  376,  381,  444,  445,  448,  464,  479,  495,  519,  550,  578,  582,  628,  659,  691,  716,  726,  740,  760,  839,  881,  883,  924,  926,  938,\n",
      "        939,  947,  951,  956, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1181, 1192, 1226, 1228, 1232, 1242, 1247, 1248, 1270, 1283, 1289, 1299, 1319, 1326, 1331, 1364, 1393, 1414,\n",
      "       1500, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1732, 1737, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2098, 2109, 2118, 2129, 2130, 2135,\n",
      "       2177, 2182, 2189, 2224, 2237, 2282, 2292, 2293, 2298, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2462, 2574, 2607, 2648, 2654, 2721, 2730, 2758, 2771, 2810, 2851, 2853, 2896, 2927, 2939, 2945,\n",
      "       2952, 2953, 2998, 3005, 3030, 3060, 3062, 3073, 3117, 3136, 3206, 3240, 3262, 3289, 3323, 3333, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3629, 3664, 3702, 3718, 3726, 3742, 3757, 3767, 3780,\n",
      "       3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3968, 4007, 4065, 4072, 4075, 4078, 4116, 4176, 4224, 4269, 4271, 4284, 4289, 4294, 4297, 4306, 4355, 4360, 4437, 4483, 4489, 4497, 4500, 4505,\n",
      "       4567, 4575, 4578, 4598, 4639, 4671, 4731, 4737, 4743, 4761, 4785, 4807, 4823, 4837, 4860, 4874, 4886, 4890, 4893, 4911, 4943, 4966, 4976, 4990, 5068, 5176, 5278, 5532, 5600, 5634, 5705, 5769,\n",
      "       5835, 5841, 5858, 5867, 5887, 5888, 5906, 5914, 5937, 5955, 5973, 5975, 5982, 5997, 6023, 6035, 6037, 6071, 6081, 6091, 6157, 6166, 6172, 6173, 6555, 6560, 6597, 6641, 6651, 6755, 6783, 6813,\n",
      "       7216, 7333, 7432, 7434, 7492, 7545, 7797, 7921, 8095, 8277, 8279, 8325, 8406, 8408, 8410, 8520, 8527, 9009, 9024, 9211, 9280, 9382, 9422, 9587, 9624, 9634, 9642, 9664, 9719, 9729, 9745, 9749,\n",
      "       9751, 9768, 9770, 9779, 9792, 9811, 9832, 9839, 9863, 9867, 9883, 9893, 9904, 9905, 9982], dtype=int64),)\n",
      "num correct is  9696  an accuracy of  0.9696969696969697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_up_last_row.shape (70000, 26)\n",
      "X_num_images 70000 X_image_num_pixels 954\n",
      "num_extra_rows 7\n",
      "2020-06-02 18:41:09.607828 Start of fit\n",
      "Epoch 1/5\n",
      "62995/62995 [==============================] - 35s 559us/sample - loss: 0.1674 - acc: 0.9468\n",
      "Epoch 2/5\n",
      "62995/62995 [==============================] - 33s 531us/sample - loss: 0.0440 - acc: 0.9863\n",
      "Epoch 3/5\n",
      "62995/62995 [==============================] - 34s 532us/sample - loss: 0.0309 - acc: 0.9911 - loss: 0.03\n",
      "Epoch 4/5\n",
      "62995/62995 [==============================] - 33s 530us/sample - loss: 0.0227 - acc: 0.9930 - loss - ETA: 5s - loss: 0.0227 - acc: 0.992 - ETA: 5s - loss: 0.0227 - acc: - ETA:\n",
      "Epoch 5/5\n",
      "62995/62995 [==============================] - 34s 533us/sample - loss: 0.0180 - acc: 0.9946 - loss: 0.0183 - a - ETA: 3s - loss: 0.0182 \n",
      "2020-06-02 18:44:06.301131 End of fit\n",
      "acc: 99.10%\n",
      "2020-06-02 18:44:12.226555 Start of fit\n",
      "Epoch 1/5\n",
      "62996/62996 [==============================] - 36s 572us/sample - loss: 0.1535 - acc: 0.9519\n",
      "Epoch 2/5\n",
      "62996/62996 [==============================] - 35s 552us/sample - loss: 0.0417 - acc: 0.9867\n",
      "Epoch 3/5\n",
      "62996/62996 [==============================] - 35s 549us/sample - loss: 0.0288 - acc: 0.9913  - ETA: 0s - loss: 0.0290 - acc: 0.\n",
      "Epoch 4/5\n",
      "62996/62996 [==============================] - 35s 550us/sample - loss: 0.0222 - acc: 0.9930 - loss: 0.0218  - ETA: 3s - loss:\n",
      "Epoch 5/5\n",
      "62996/62996 [==============================] - 34s 547us/sample - loss: 0.0173 - acc: 0.9946\n",
      "2020-06-02 18:47:14.027849 End of fit\n",
      "acc: 99.16%\n",
      "2020-06-02 18:47:19.392418 Start of fit\n",
      "Epoch 1/5\n",
      "62996/62996 [==============================] - 35s 563us/sample - loss: 0.1600 - acc: 0.9508\n",
      "Epoch 2/5\n",
      "62996/62996 [==============================] - 35s 553us/sample - loss: 0.0420 - acc: 0.9865\n",
      "Epoch 3/5\n",
      "62996/62996 [==============================] - 37s 581us/sample - loss: 0.0283 - acc: 0.9913 - loss: 0.0278 - acc: - ETA: 1s - loss: 0.0282 - ac - ETA: 0s - loss: 0.0282 - ac\n",
      "Epoch 4/5\n",
      "62996/62996 [==============================] - 34s 540us/sample - loss: 0.0212 - acc: 0.9935 - loss: 0.0206 - - ETA: - ETA: 0s - loss: 0.0213 - a - ETA: 0s - loss: 0.0212 - acc: 0.99\n",
      "Epoch 5/5\n",
      "62996/62996 [==============================] - 34s 539us/sample - loss: 0.0167 - acc: 0.9947TA: 3s - loss: 0.0165  - ETA: 3s - loss: 0.0165 - acc: 0.99 - ETA:  - ETA: 0s - loss: 0.0168 - acc: 0 - ETA: 0s - loss: 0.0168 - acc:\n",
      "2020-06-02 18:50:21.610132 End of fit\n",
      "acc: 99.11%\n",
      "2020-06-02 18:50:27.439952 Start of fit\n",
      "Epoch 1/5\n",
      "62999/62999 [==============================] - 36s 572us/sample - loss: 0.1603 - acc: 0.9503s - loss: 0.2115 - acc: 0.93 - ETA: 12 - ETA: 1s - loss: \n",
      "Epoch 2/5\n",
      "62999/62999 [==============================] - 37s 589us/sample - loss: 0.0453 - acc: 0.9859s - loss: 0.04 - ETA: 0s - loss: 0.0454 - acc: 0.98\n",
      "Epoch 3/5\n",
      "62999/62999 [==============================] - 36s 576us/sample - loss: 0.0309 - acc: 0.9906 - loss: 0.0309 - acc: - ETA: 1s - loss: 0.0309 - a - ETA: 0s - loss: 0.0308 - acc:\n",
      "Epoch 4/5\n",
      "62999/62999 [==============================] - 37s 582us/sample - loss: 0.0227 - acc: 0.9928\n",
      "Epoch 5/5\n",
      "62999/62999 [==============================] - 36s 566us/sample - loss: 0.0181 - acc: 0.9947\n",
      "2020-06-02 18:53:36.654994 End of fit\n",
      "acc: 99.21%\n",
      "2020-06-02 18:53:42.301260 Start of fit\n",
      "Epoch 1/5\n",
      "63000/63000 [==============================] - 38s 603us/sample - loss: 0.1613 - acc: 0.9487\n",
      "Epoch 2/5\n",
      "63000/63000 [==============================] - 37s 582us/sample - loss: 0.0417 - acc: 0.9869\n",
      "Epoch 3/5\n",
      "63000/63000 [==============================] - 36s 569us/sample - loss: 0.0277 - acc: 0.9914\n",
      "Epoch 4/5\n",
      "63000/63000 [==============================] - 36s 569us/sample - loss: 0.0216 - acc: 0.9928 - l - ETA: 6s - loss: 0.02 - ETA: 2s - loss: 0.0210 -  - ETA: 1s \n",
      "Epoch 5/5\n",
      "63000/63000 [==============================] - 35s 557us/sample - loss: 0.0170 - acc: 0.9945 - loss: 0.0172 - a - ETA: 5s - loss:  - ETA: 4s - loss - ETA: 3s - loss: 0.017 - ETA: 2s - loss: 0.0172 - acc - ETA: 1s - lo\n",
      "2020-06-02 18:56:52.414997 End of fit\n",
      "acc: 98.91%\n",
      "2020-06-02 18:57:00.260000 Start of fit\n",
      "Epoch 1/5\n",
      "63001/63001 [==============================] - 37s 595us/sample - loss: 0.1543 - acc: 0.9517 - loss: 0.1653 \n",
      "Epoch 2/5\n",
      "63001/63001 [==============================] - 36s 565us/sample - loss: 0.0407 - acc: 0.9870 - loss: 0.0413 - - ETA: 1s - \n",
      "Epoch 3/5\n",
      "63001/63001 [==============================] - 36s 573us/sample - loss: 0.0289 - acc: 0.9907 - loss: 0.0286\n",
      "Epoch 4/5\n",
      "63001/63001 [==============================] - 37s 583us/sample - loss: 0.0215 - acc: 0.9938 - ETA: 5s - loss:  - ETA: 4s - loss: 0.02 - ETA:  - ETA: 1s - loss: \n",
      "Epoch 5/5\n",
      "63001/63001 [==============================] - 36s 572us/sample - loss: 0.0172 - acc: 0.9950 - loss: 0.0164 - acc: 0.99 - E\n",
      "2020-06-02 19:00:10.980063 End of fit\n",
      "acc: 99.11%\n",
      "2020-06-02 19:00:16.847021 Start of fit\n",
      "Epoch 1/5\n",
      "63002/63002 [==============================] - 37s 593us/sample - loss: 0.1652 - acc: 0.9483\n",
      "Epoch 2/5\n",
      "63002/63002 [==============================] - 36s 567us/sample - loss: 0.0433 - acc: 0.9865 - loss: 0.0451 - acc - ETA: 9s - - ETA: 7\n",
      "Epoch 3/5\n",
      "63002/63002 [==============================] - 36s 565us/sample - loss: 0.0302 - acc: 0.9906 - loss: - ETA: 1s - loss: 0.0302 - acc: 0 - ETA: 1s - loss: \n",
      "Epoch 4/5\n",
      "63002/63002 [==============================] - 36s 572us/sample - loss: 0.0230 - acc: 0.9928\n",
      "Epoch 5/5\n",
      "63002/63002 [==============================] - 35s 561us/sample - loss: 0.0181 - acc: 0.9946 - loss: 0.0190 - ETA: 6s -  - ETA: 1s - loss: 0.0180 - acc: 0. - ETA: 1s - l\n",
      "2020-06-02 19:03:25.184930 End of fit\n",
      "acc: 99.23%\n",
      "2020-06-02 19:03:30.922134 Start of fit\n",
      "Epoch 1/5\n",
      "63003/63003 [==============================] - 37s 581us/sample - loss: 0.1623 - acc: 0.9484 - loss: 0.1649 - acc: 0 - ETA: 0s - loss: 0.1643 -\n",
      "Epoch 2/5\n",
      "63003/63003 [==============================] - 35s 553us/sample - loss: 0.0439 - acc: 0.9867 - loss: 0.0456 - acc - ETA: 6s - loss: 0.0455  - ETA: 5s - loss: 0.0455 - acc:\n",
      "Epoch 3/5\n",
      "63003/63003 [==============================] - 35s 557us/sample - loss: 0.0293 - acc: 0.9907\n",
      "Epoch 4/5\n",
      "63003/63003 [==============================] - 35s 558us/sample - loss: 0.0225 - acc: 0.9928 - loss: 0.0226 - a\n",
      "Epoch 5/5\n",
      "63003/63003 [==============================] - 35s 562us/sample - loss: 0.0180 - acc: 0.9947 - loss: 0.0183\n",
      "2020-06-02 19:06:35.368690 End of fit\n",
      "acc: 99.26%\n",
      "2020-06-02 19:06:41.031468 Start of fit\n",
      "Epoch 1/5\n",
      "63004/63004 [==============================] - 37s 581us/sample - loss: 0.1558 - acc: 0.9508\n",
      "Epoch 2/5\n",
      "63004/63004 [==============================] - 35s 551us/sample - loss: 0.0419 - acc: 0.9871 - loss: 0.0420 - acc: 0.9\n",
      "Epoch 3/5\n",
      "63004/63004 [==============================] - 35s 559us/sample - loss: 0.0306 - acc: 0.9903\n",
      "Epoch 4/5\n",
      "63004/63004 [==============================] - 35s 560us/sample - loss: 0.0222 - acc: 0.9931 - loss: 0.0225 \n",
      "Epoch 5/5\n",
      "63004/63004 [==============================] - 34s 540us/sample - loss: 0.0184 - acc: 0.9943\n",
      "2020-06-02 19:09:44.496714 End of fit\n",
      "acc: 99.14%\n",
      "2020-06-02 19:09:49.969834 Start of fit\n",
      "Epoch 1/5\n",
      "63004/63004 [==============================] - 37s 586us/sample - loss: 0.1645 - acc: 0.9489 - loss: 0.167\n",
      "Epoch 2/5\n",
      "63004/63004 [==============================] - 35s 557us/sample - loss: 0.0427 - acc: 0.9867\n",
      "Epoch 3/5\n",
      "63004/63004 [==============================] - 36s 566us/sample - loss: 0.0286 - acc: 0.9912\n",
      "Epoch 4/5\n",
      "63004/63004 [==============================] - 35s 555us/sample - loss: 0.0225 - acc: 0.9930 - loss:  - ETA: 3s - - ETA: 1s - loss: 0.0224 - acc:  - ETA: 1s - los\n",
      "Epoch 5/5\n",
      "63004/63004 [==============================] - 35s 558us/sample - loss: 0.0171 - acc: 0.9946 - loss: 0.0174 - acc - ETA: 2s - loss: 0.0173 - acc: 0 - \n",
      "2020-06-02 19:12:54.951853 End of fit\n",
      "acc: 99.09%\n",
      "99.13% (+/- 0.09%)\n",
      "2020-06-02 19:12:59.454908 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 5 7 0 4 7 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 6 7 0 6 8 6 3 9 9 8 8 7 7\n",
      " 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "ndx_errs (array([ 151,  241,  247,  318,  320,  321,  362,  376,  381,  444,  445,  448,  464,  479,  495,  519,  550,  578,  582,  628,  659,  691,  716,  726,  740,  760,  839,  881,  883,  924,  926,  938,\n",
      "        939,  947,  951,  956, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1181, 1192, 1226, 1228, 1232, 1242, 1247, 1248, 1270, 1283, 1289, 1299, 1319, 1326, 1331, 1364, 1393, 1414,\n",
      "       1500, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1732, 1737, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2098, 2109, 2118, 2129, 2130, 2135,\n",
      "       2177, 2182, 2189, 2224, 2237, 2282, 2292, 2293, 2298, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2462, 2574, 2607, 2648, 2654, 2721, 2730, 2758, 2771, 2810, 2851, 2853, 2896, 2927, 2939, 2945,\n",
      "       2952, 2953, 2998, 3005, 3030, 3060, 3062, 3073, 3117, 3136, 3206, 3240, 3262, 3289, 3323, 3333, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3629, 3664, 3702, 3718, 3726, 3742, 3757, 3767, 3780,\n",
      "       3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3968, 4007, 4065, 4072, 4075, 4078, 4116, 4176, 4224, 4269, 4271, 4284, 4289, 4294, 4297, 4306, 4355, 4360, 4437, 4483, 4489, 4497, 4500, 4505,\n",
      "       4567, 4575, 4578, 4598, 4639, 4671, 4731, 4737, 4743, 4761, 4785, 4807, 4823, 4837, 4860, 4874, 4886, 4890, 4893, 4911, 4943, 4966, 4976, 4990, 5068, 5176, 5278, 5532, 5600, 5634, 5705, 5769,\n",
      "       5835, 5841, 5858, 5867, 5887, 5888, 5906, 5914, 5937, 5955, 5973, 5975, 5982, 5997, 6023, 6035, 6037, 6071, 6081, 6091, 6157, 6166, 6172, 6173, 6555, 6560, 6597, 6641, 6651, 6755, 6783, 6813,\n",
      "       7216, 7333, 7432, 7434, 7492, 7545, 7797, 7921, 8095, 8277, 8279, 8325, 8406, 8408, 8410, 8520, 8527, 9009, 9024, 9211, 9280, 9382, 9422, 9587, 9624, 9634, 9642, 9664, 9719, 9729, 9745, 9749,\n",
      "       9751, 9768, 9770, 9779, 9792, 9811, 9832, 9839, 9863, 9867, 9883, 9893, 9904, 9905, 9982], dtype=int64),)\n",
      "num correct is  9697  an accuracy of  0.9697\n",
      "2020-06-02 19:26:23.698695 end\n"
     ]
    }
   ],
   "source": [
    "Config.USE_PARENT_CENTROIDS=True\n",
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.USE_PARENT_CENTROIDS=False\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s2quadrants'></a>\n",
    "<a href='#toc'>Goto Table of Contents</a>\n",
    "\n",
    "## Try overlapping quadrants with different amounts of overlap; all with weighted centroids\n",
    "\n",
    "## kNN acc overlap 1/8   (6,000 94.1%; 60,000 97.12%)\n",
    "## kNN acc overlap 1/16 (6,000 94.2%; 60,000 97.09%)\n",
    "## kNN acc overlap 1/32 (6,000 93.9%; 60,000 )\n",
    "\n",
    "## from kNN baseline of (6,000 91.6%; 60,000 96.88%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-01 07:31:53.020183 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 9 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 9 8 7 2 3 0 4 4 2 4 1 9 5 7 7 2 8 2 6 8 5 7 7 9 1 8 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 9 2 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 8 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 2 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 3 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 6 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 3 8 8 2 7 5 8 9 6 1 8 4 1 2 5 9 1 9 7 5 4 0 8 9 9 1 0 5 2 3 7\n",
      " 8 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 8 4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 2 1 7 0 6 5 4 3 8 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 2 3 1 9 7 5 1 0 8 4 6 2 6 7 9 3 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 5 8 0 3 7 2 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 7 8 3 3 6 7 2 8 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 8 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5 4 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 5\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 8 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 8 8 8 7 4 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 2 3 2 3 9 1 7 4 0 3 5 5 8 6 3 2 6 7 6 6 3 2 7 8 1 1 7 5 6 4 9 5 1 3 3 4 7 8 9 1 1 6 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "<class 'numpy.ndarray'> (0, 128)\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 8 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 9 9 8 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 9 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 3 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 5 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 8 8 7 2 6 0 6 4 2 9 1 9 5 7 7 2 8 2 6 8 5 7 7 9 1 0 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 0 5 7 7 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 5 6 5 6 1 3 8 1 0 5 1 3 1 5 0 6 1 8 5 1 4 9 4 6 7 2 5 0 6 5 6 3 7 2 0 8 8 5 9 1 1 4 0 7 3 7 6 1 6 2 1 7 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 8 0 6 4 8 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 7 8 8 2 7 5 8 9 6 1 8 4 1 2 6 3 1 9 7 5 4 0 8 9 9 1 0 5 2 3 7\n",
      " 0 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 9 4 6 4 2 1 8 2 5 4 8 3 4 0 0 2 3 2 7 4 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 9 8 3 3 9 3 3 3 7 8 0 8 7 1 7 0 6 5 4 3 3 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 9 8 6 0 2 4 0 2 2 3 1 9 7 5 1 0 8 4 6 2 6 7 9 9 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 0 8 0 3 7 8 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 9 8 3 3 6 7 2 4 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 3 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 3 5 9 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 9 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 5\n",
      " 3 8 0 1 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 0 1 7 7 4 2 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 6 2 2 5 6 0 8 2 9 2 8 8 8 8 7 9 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 7 3 0 3 9 1 7 4 0 3 5 5 8 6 3 0 6 7 6 6 3 2 7 9 1 1 7 4 6 4 9 6 1 3 0 4 7 8 9 1 1 0 9 1 4 4 5 4 0 6 2 2 8 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "ndx_errs (array([115, 119, 149, 151, 169, 187, 217, 241, 245, 247, 250, 266, 318, 320, 321, 338, 352, 358, 362, 376, 381, 389, 444, 445, 448, 464, 478, 479, 495, 532, 543, 551, 571, 583, 591, 605, 628, 654,\n",
      "       659, 684, 691, 714, 738, 740, 760, 795, 839, 844, 866, 881, 924, 926, 939, 947, 951, 955, 958, 965, 976], dtype=int64),)\n",
      "num correct is  941  an accuracy of  0.9410000000000001\n",
      "2020-06-01 07:34:00.871301 end\n"
     ]
    }
   ],
   "source": [
    "Config.OVERLAP_QUADS_RATIO=0.125\n",
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=6_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=1_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "Config.OVERLAP_QUADS_RATIO=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-01 12:39:08.737056 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 9 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 9 8 7 2 3 0 4 4 2 4 1 9 5 7 7 2 8 2 6 8 5 7 7 9 1 8 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 9 2 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 8 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 2 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 3 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 6 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 3 8 8 2 7 5 8 9 6 1 8 4 1 2 5 9 1 9 7 5 4 0 8 9 9 1 0 5 2 3 7\n",
      " 8 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 8 4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 2 1 7 0 6 5 4 3 8 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 2 3 1 9 7 5 1 0 8 4 6 2 6 7 9 3 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 5 8 0 3 7 2 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 7 8 3 3 6 7 2 8 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 8 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5 4 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 5\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 8 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 8 8 8 7 4 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 2 3 2 3 9 1 7 4 0 3 5 5 8 6 3 2 6 7 6 6 3 2 7 8 1 1 7 5 6 4 9 5 1 3 3 4 7 8 9 1 1 6 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "<class 'numpy.ndarray'> (0, 128)\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 8 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 3 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 8 8 4 2 6 0 6 4 2 9 1 9 5 7 7 2 8 2 6 8 5 7 7 4 1 0 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 7 7 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 5 6 5 4 1 3 8 1 0 5 1 3 1 5 0 6 1 8 5 1 7 9 4 6 7 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 7 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 8 0 6 4 8 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 7 8 8 2 7 5 8 9 6 1 8 4 1 2 6 8 1 9 7 5 4 0 8 9 9 1 0 5 8 3 7\n",
      " 0 9 9 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 9 4 6 4 2 1 8 2 5 4 8 3 4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 9 8 3 3 9 3 3 3 7 8 0 8 7 1 7 0 6 5 4 3 3 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 8 3 1 9 7 5 1 0 8 4 6 2 6 7 9 9 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 0 8 0 3 7 8 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 9 8 3 3 6 7 2 7 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 3 2 7 6 8 4 5 0 4 0 6 1 5 3 2 6 7 2 6 9 3 1 4 6 3 5 9 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 9 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 3 6 8 9 4 1 5\n",
      " 3 8 0 1 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 0 1 7 7 4 7 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 6 2 2 5 6 0 8 2 9 2 8 8 8 8 7 9 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 7 3 0 3 9 1 7 4 0 3 5 5 8 6 3 0 6 7 6 6 3 2 7 9 1 1 7 4 6 4 9 6 1 3 3 4 7 8 4 1 1 0 9 1 4 4 5 4 0 6 2 2 8 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "ndx_errs (array([151, 187, 241, 243, 245, 247, 250, 264, 266, 320, 321, 338, 341, 352, 362, 381, 444, 445, 448, 464, 478, 479, 492, 495, 497, 532, 543, 571, 583, 591, 613, 628, 654, 659, 684, 691, 714, 716,\n",
      "       717, 726, 738, 740, 760, 785, 795, 839, 844, 866, 881, 924, 926, 939, 947, 951, 955, 962, 965, 976], dtype=int64),)\n",
      "num correct is  942  an accuracy of  0.942\n",
      "2020-06-01 12:41:16.674818 end\n"
     ]
    }
   ],
   "source": [
    "Config.OVERLAP_QUADS_RATIO=0.0625\n",
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=6_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=1_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "Config.OVERLAP_QUADS_RATIO=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-01 12:43:54.150585 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 9 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 9 8 7 2 3 0 4 4 2 4 1 9 5 7 7 2 8 2 6 8 5 7 7 9 1 8 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 9 2 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 8 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 2 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 3 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 6 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 3 8 8 2 7 5 8 9 6 1 8 4 1 2 5 9 1 9 7 5 4 0 8 9 9 1 0 5 2 3 7\n",
      " 8 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 8 4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 2 1 7 0 6 5 4 3 8 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 2 3 1 9 7 5 1 0 8 4 6 2 6 7 9 3 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 5 8 0 3 7 2 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 7 8 3 3 6 7 2 8 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 8 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5 4 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 5\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 8 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 8 8 8 7 4 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 2 3 2 3 9 1 7 4 0 3 5 5 8 6 3 2 6 7 6 6 3 2 7 8 1 1 7 5 6 4 9 5 1 3 3 4 7 8 9 1 1 6 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "<class 'numpy.ndarray'> (0, 128)\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 4 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 8 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 3 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 7 7 9 2 2 4 1 5 8 8 4 2 3 0 6 4 2 9 1 9 5 7 7 2 6 2 6 8 5 7 7 4 1 0 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 7 7 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 5 6 5 4 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 7 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 7 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 8 0 6 4 8 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 7 8 8 2 7 5 8 9 6 1 8 4 1 2 5 8 1 9 7 5 4 0 8 9 9 1 0 5 8 3 7\n",
      " 0 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 7 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 9 4 6 4 2 1 8 2 5 4 8 3 4 0 0 8 3 2 9 4 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 7 1 7 0 6 5 4 3 3 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 9 8 6 0 2 4 0 2 8 3 1 9 7 5 1 0 8 4 6 2 6 7 9 9 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 0 8 0 3 7 8 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 9 8 3 3 6 7 2 7 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 3 2 7 6 8 4 5 0 4 0 6 1 4 3 2 6 7 2 6 9 3 1 4 6 3 5 9 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 9 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 5\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 9 0 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 2 8 8 7 9 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 7 3 0 3 9 1 4 4 0 3 5 5 8 6 3 0 6 7 6 6 3 2 7 9 1 1 7 4 6 4 9 6 1 5 3 4 7 8 7 1 1 0 9 1 4 4 5 4 0 6 2 2 8 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "ndx_errs (array([ 12, 151, 187, 233, 241, 243, 247, 250, 257, 264, 266, 320, 321, 338, 341, 362, 381, 444, 445, 448, 464, 479, 492, 495, 511, 532, 543, 547, 550, 551, 583, 591, 605, 613, 628, 654, 659, 684,\n",
      "       691, 714, 716, 717, 726, 738, 740, 760, 838, 839, 877, 881, 924, 926, 930, 939, 947, 951, 955, 957, 962, 965, 976], dtype=int64),)\n",
      "num correct is  939  an accuracy of  0.9390000000000001\n",
      "2020-06-01 12:46:01.265071 end\n"
     ]
    }
   ],
   "source": [
    "Config.OVERLAP_QUADS_RATIO=0.03125\n",
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=6_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=1_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "Config.OVERLAP_QUADS_RATIO=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-01 12:47:26.354540 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7 7\n",
      " 1 0 1 7 8 9 0 1 2 3 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "<class 'numpy.ndarray'> (0, 128)\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "****************************** 6000 ******************************\n",
      "****************************** 8000 ******************************\n",
      "****************************** 10000 ******************************\n",
      "****************************** 12000 ******************************\n",
      "****************************** 14000 ******************************\n",
      "****************************** 16000 ******************************\n",
      "****************************** 18000 ******************************\n",
      "****************************** 20000 ******************************\n",
      "****************************** 22000 ******************************\n",
      "****************************** 24000 ******************************\n",
      "****************************** 26000 ******************************\n",
      "****************************** 28000 ******************************\n",
      "****************************** 30000 ******************************\n",
      "****************************** 32000 ******************************\n",
      "****************************** 34000 ******************************\n",
      "****************************** 36000 ******************************\n",
      "****************************** 38000 ******************************\n",
      "****************************** 40000 ******************************\n",
      "****************************** 42000 ******************************\n",
      "****************************** 44000 ******************************\n",
      "****************************** 46000 ******************************\n",
      "****************************** 48000 ******************************\n",
      "****************************** 50000 ******************************\n",
      "****************************** 52000 ******************************\n",
      "****************************** 54000 ******************************\n",
      "****************************** 56000 ******************************\n",
      "****************************** 58000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "****************************** 1999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 7 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 4 8 9 6 9 6 8 3 6 6 8 5 1 4 2 4 4 5 1 1 9 0 2 4 9 5 7 1 8 3 5 6 9 8 7 1 1 6 7 6 3 2 2 0 8 9\n",
      " 2 5 1 0 8 1 4 5 7 9 6 9 0 6 1 5 5 8 3 8 2 6 5 0 7 4 6 1 3 4 7 3 2 3 4 2 5 2 7 1 7 2 6 4 1 5 7 8 6 0 1 8 2 5 7 7 6 9 3 5 2 4 2 4 0 8 8 3 4 9 2 7 5 8 6 3 6 0 8 6 7 3 6 4 9 4 6 6 3 0 4 1 0 1 4 6 2 9 1\n",
      " 1 0 6 3 9]\n",
      "ndx_errs (array([  73,  115,  151,  241,  247,  320,  321,  338,  362,  376,  381,  444,  445,  448,  464,  478,  479,  495,  519,  582,  628,  659,  716,  740,  791,  810,  839,  924,  938,  939,  947,  951,\n",
      "        956,  957, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1156, 1173, 1181, 1192, 1226, 1232, 1242, 1247, 1270, 1283, 1289, 1299, 1319, 1326, 1328, 1393, 1414, 1500, 1523, 1530, 1549,\n",
      "       1553, 1559, 1637, 1681, 1695, 1709, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1878, 1901, 1955, 1970, 1984], dtype=int64),)\n",
      "num correct is  1917  an accuracy of  0.9589794897448725\n",
      "****************************** 3999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 7 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 9 1 1 0 7 5 9 9 1 9 5 9 2 5 0 4 1 0 8 9 0 8 9 8 9 4 2 5 7 9 8 9 8 0 9 9 6 8 9 9 5 9 8 6 1\n",
      " 0 3 3 5 2 1 6 3 0 2 8 1 5 6 2 3 0 2 2 6 4 3 5 5 1 7 2 1 6 9 1 3 9 5 5 1 6 2 2 8 6 7 1 4 6 0 6 0 3 3 2 2 3 6 8 9 8 5 3 8 5 4 5 2 0 5 6 3 2 8 3 9 9 3 7 9 4 6 7 1 3 7 3 6 6 0 9 0 1 9 9 2 8 8 0 1 6 9 7\n",
      " 5 3 4 7 4]\n",
      "ndx_errs (array([  73,  115,  151,  241,  247,  320,  321,  338,  362,  376,  381,  444,  445,  448,  464,  478,  479,  495,  519,  582,  628,  659,  716,  740,  791,  810,  839,  924,  938,  939,  947,  951,\n",
      "        956,  957, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1156, 1173, 1181, 1192, 1226, 1232, 1242, 1247, 1270, 1283, 1289, 1299, 1319, 1326, 1328, 1393, 1414, 1500, 1523, 1530, 1549,\n",
      "       1553, 1559, 1637, 1681, 1695, 1709, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2044, 2052, 2093, 2098, 2109, 2118, 2129, 2130, 2135, 2177, 2182, 2189, 2224, 2237,\n",
      "       2282, 2292, 2293, 2298, 2299, 2371, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2454, 2457, 2462, 2574, 2597, 2607, 2648, 2654, 2721, 2730, 2771, 2810, 2853, 2863, 2896, 2927, 2939, 2945, 2953,\n",
      "       2998, 3060, 3062, 3073, 3115, 3117, 3160, 3206, 3262, 3289, 3333, 3405, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3604, 3629, 3686, 3702, 3726, 3742, 3767, 3780, 3808, 3811, 3838, 3853, 3893,\n",
      "       3902, 3926, 3941, 3968], dtype=int64),)\n",
      "num correct is  3835  an accuracy of  0.9589897474368592\n",
      "****************************** 5999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 7 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 2 3 4 5 6 7 8 9 8 4 1 3 7 5 2 8 0 9 3 9 9 0 9 1 1 5 8 8 6 3 2 1 8 3 2 6 5 6 9 4 1 0 5 3 1 9\n",
      " 2 1 9 6 0 4 6 1 7 3 8 9 2 9 6 5 8 3 5 7 1 6 1 0 9 6 2 5 4 2 3 4 4 6 0 0 2 0 1 2 3 4 3 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 8 4 5 6 7 8 9 8 6 5 0 6 8 9 4 1 9 5 8 0 4 8 9 1 4 0 5 3 2 1 5 4 0 7 6 0 1 7 0\n",
      " 6 8 9 3 1]\n",
      "ndx_errs (array([  73,  115,  151,  241,  247,  320,  321,  338,  362,  376,  381,  444,  445,  448,  464,  478,  479,  495,  519,  582,  628,  659,  716,  740,  791,  810,  839,  924,  938,  939,  947,  951,\n",
      "        956,  957, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1156, 1173, 1181, 1192, 1226, 1232, 1242, 1247, 1270, 1283, 1289, 1299, 1319, 1326, 1328, 1393, 1414, 1500, 1523, 1530, 1549,\n",
      "       1553, 1559, 1637, 1681, 1695, 1709, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2044, 2052, 2093, 2098, 2109, 2118, 2129, 2130, 2135, 2177, 2182, 2189, 2224, 2237,\n",
      "       2282, 2292, 2293, 2298, 2299, 2371, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2454, 2457, 2462, 2574, 2597, 2607, 2648, 2654, 2721, 2730, 2771, 2810, 2853, 2863, 2896, 2927, 2939, 2945, 2953,\n",
      "       2998, 3060, 3062, 3073, 3115, 3117, 3160, 3206, 3262, 3289, 3333, 3405, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3604, 3629, 3686, 3702, 3726, 3742, 3767, 3780, 3808, 3811, 3838, 3853, 3893,\n",
      "       3902, 3926, 3941, 3968, 4065, 4072, 4075, 4078, 4116, 4140, 4163, 4176, 4224, 4238, 4269, 4284, 4289, 4294, 4297, 4306, 4355, 4360, 4483, 4497, 4500, 4551, 4639, 4671, 4731, 4737, 4761, 4785,\n",
      "       4807, 4823, 4837, 4860, 4874, 4879, 4886, 4890, 4911, 4943, 4966, 4978, 4990, 5001, 5068, 5138, 5176, 5278, 5600, 5634, 5734, 5769, 5835, 5858, 5866, 5867, 5887, 5906, 5937, 5955, 5973, 5982,\n",
      "       5997], dtype=int64),)\n",
      "num correct is  5774  an accuracy of  0.9624937489581596\n",
      "****************************** 7999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 7 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 3 5 6 7 8 9 0 1 2 3 5 6 7 8 9 9 7 0 9 0 1 5 8 8 0 9 3 2 7 8 4 6 1 0 4 9 4 2 0 5 0 1 6 9 3 2\n",
      " 9 1 6 0 1 1 8 7 7 6 3 6 0 7 2 4 1 7 0 6 7 1 2 5 8 1 8 2 8 7 6 8 7 1 6 2 9 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 8 9 5 7 0 3 1 6 8 4 1 5 6 4 2 7 8 1 3 4 3 4 7 2 0 5 0 1 9 2 3\n",
      " 2 3 5 5 7]\n",
      "ndx_errs (array([  73,  115,  151,  241,  247,  320,  321,  338,  362,  376,  381,  444,  445,  448,  464,  478,  479,  495,  519,  582,  628,  659,  716,  740,  791,  810,  839,  924,  938,  939,  947,  951,\n",
      "        956,  957, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1156, 1173, 1181, 1192, 1226, 1232, 1242, 1247, 1270, 1283, 1289, 1299, 1319, 1326, 1328, 1393, 1414, 1500, 1523, 1530, 1549,\n",
      "       1553, 1559, 1637, 1681, 1695, 1709, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2044, 2052, 2093, 2098, 2109, 2118, 2129, 2130, 2135, 2177, 2182, 2189, 2224, 2237,\n",
      "       2282, 2292, 2293, 2298, 2299, 2371, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2454, 2457, 2462, 2574, 2597, 2607, 2648, 2654, 2721, 2730, 2771, 2810, 2853, 2863, 2896, 2927, 2939, 2945, 2953,\n",
      "       2998, 3060, 3062, 3073, 3115, 3117, 3160, 3206, 3262, 3289, 3333, 3405, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3604, 3629, 3686, 3702, 3726, 3742, 3767, 3780, 3808, 3811, 3838, 3853, 3893,\n",
      "       3902, 3926, 3941, 3968, 4065, 4072, 4075, 4078, 4116, 4140, 4163, 4176, 4224, 4238, 4269, 4284, 4289, 4294, 4297, 4306, 4355, 4360, 4483, 4497, 4500, 4551, 4639, 4671, 4731, 4737, 4761, 4785,\n",
      "       4807, 4823, 4837, 4860, 4874, 4879, 4886, 4890, 4911, 4943, 4966, 4978, 4990, 5001, 5068, 5138, 5176, 5278, 5600, 5634, 5734, 5769, 5835, 5858, 5866, 5867, 5887, 5906, 5937, 5955, 5973, 5982,\n",
      "       5997, 6011, 6023, 6035, 6059, 6071, 6081, 6091, 6157, 6160, 6166, 6172, 6173, 6505, 6555, 6560, 6597, 6651, 6755, 6813, 7216, 7333, 7432, 7434, 7492, 7545, 7595, 7797], dtype=int64),)\n",
      "num correct is  7747  an accuracy of  0.968496062007751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 9999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 7 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 2 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 6 7 0 6 8 6 3 9 9 8 8 7\n",
      " 7 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 8 5 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0\n",
      " 1 2 3 4 5]\n",
      "ndx_errs (array([  73,  115,  151,  241,  247,  320,  321,  338,  362,  376,  381,  444,  445,  448,  464,  478,  479,  495,  519,  582,  628,  659,  716,  740,  791,  810,  839,  924,  938,  939,  947,  951,\n",
      "        956,  957, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1156, 1173, 1181, 1192, 1226, 1232, 1242, 1247, 1270, 1283, 1289, 1299, 1319, 1326, 1328, 1393, 1414, 1500, 1523, 1530, 1549,\n",
      "       1553, 1559, 1637, 1681, 1695, 1709, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2044, 2052, 2093, 2098, 2109, 2118, 2129, 2130, 2135, 2177, 2182, 2189, 2224, 2237,\n",
      "       2282, 2292, 2293, 2298, 2299, 2371, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2454, 2457, 2462, 2574, 2597, 2607, 2648, 2654, 2721, 2730, 2771, 2810, 2853, 2863, 2896, 2927, 2939, 2945, 2953,\n",
      "       2998, 3060, 3062, 3073, 3115, 3117, 3160, 3206, 3262, 3289, 3333, 3405, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3604, 3629, 3686, 3702, 3726, 3742, 3767, 3780, 3808, 3811, 3838, 3853, 3893,\n",
      "       3902, 3926, 3941, 3968, 4065, 4072, 4075, 4078, 4116, 4140, 4163, 4176, 4224, 4238, 4269, 4284, 4289, 4294, 4297, 4306, 4355, 4360, 4483, 4497, 4500, 4551, 4639, 4671, 4731, 4737, 4761, 4785,\n",
      "       4807, 4823, 4837, 4860, 4874, 4879, 4886, 4890, 4911, 4943, 4966, 4978, 4990, 5001, 5068, 5138, 5176, 5278, 5600, 5634, 5734, 5769, 5835, 5858, 5866, 5867, 5887, 5906, 5937, 5955, 5973, 5982,\n",
      "       5997, 6011, 6023, 6035, 6059, 6071, 6081, 6091, 6157, 6160, 6166, 6172, 6173, 6505, 6555, 6560, 6597, 6651, 6755, 6813, 7216, 7333, 7432, 7434, 7492, 7545, 7595, 7797, 8094, 8112, 8277, 8279,\n",
      "       8325, 8408, 8410, 8520, 8527, 9009, 9024, 9211, 9280, 9382, 9422, 9423, 9587, 9613, 9634, 9642, 9664, 9719, 9729, 9733, 9745, 9751, 9768, 9770, 9779, 9792, 9811, 9839, 9883, 9893, 9904, 9905,\n",
      "       9943, 9944, 9982], dtype=int64),)\n",
      "num correct is  9708  an accuracy of  0.9708970897089709\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 7 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 6 7 0 6 8 6 3 9 9 8 8 7 7\n",
      " 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 8 5 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "ndx_errs (array([  73,  115,  151,  241,  247,  320,  321,  338,  362,  376,  381,  444,  445,  448,  464,  478,  479,  495,  519,  582,  628,  659,  716,  740,  791,  810,  839,  924,  938,  939,  947,  951,\n",
      "        956,  957, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1156, 1173, 1181, 1192, 1226, 1232, 1242, 1247, 1270, 1283, 1289, 1299, 1319, 1326, 1328, 1393, 1414, 1500, 1523, 1530, 1549,\n",
      "       1553, 1559, 1637, 1681, 1695, 1709, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2044, 2052, 2093, 2098, 2109, 2118, 2129, 2130, 2135, 2177, 2182, 2189, 2224, 2237,\n",
      "       2282, 2292, 2293, 2298, 2299, 2371, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2454, 2457, 2462, 2574, 2597, 2607, 2648, 2654, 2721, 2730, 2771, 2810, 2853, 2863, 2896, 2927, 2939, 2945, 2953,\n",
      "       2998, 3060, 3062, 3073, 3115, 3117, 3160, 3206, 3262, 3289, 3333, 3405, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3604, 3629, 3686, 3702, 3726, 3742, 3767, 3780, 3808, 3811, 3838, 3853, 3893,\n",
      "       3902, 3926, 3941, 3968, 4065, 4072, 4075, 4078, 4116, 4140, 4163, 4176, 4224, 4238, 4269, 4284, 4289, 4294, 4297, 4306, 4355, 4360, 4483, 4497, 4500, 4551, 4639, 4671, 4731, 4737, 4761, 4785,\n",
      "       4807, 4823, 4837, 4860, 4874, 4879, 4886, 4890, 4911, 4943, 4966, 4978, 4990, 5001, 5068, 5138, 5176, 5278, 5600, 5634, 5734, 5769, 5835, 5858, 5866, 5867, 5887, 5906, 5937, 5955, 5973, 5982,\n",
      "       5997, 6011, 6023, 6035, 6059, 6071, 6081, 6091, 6157, 6160, 6166, 6172, 6173, 6505, 6555, 6560, 6597, 6651, 6755, 6813, 7216, 7333, 7432, 7434, 7492, 7545, 7595, 7797, 8094, 8112, 8277, 8279,\n",
      "       8325, 8408, 8410, 8520, 8527, 9009, 9024, 9211, 9280, 9382, 9422, 9423, 9587, 9613, 9634, 9642, 9664, 9719, 9729, 9733, 9745, 9751, 9768, 9770, 9779, 9792, 9811, 9839, 9883, 9893, 9904, 9905,\n",
      "       9943, 9944, 9982], dtype=int64),)\n",
      "num correct is  9709  an accuracy of  0.9709\n",
      "2020-06-01 15:47:41.587834 end\n"
     ]
    }
   ],
   "source": [
    "Config.OVERLAP_QUADS_RATIO=0.0625\n",
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "Config.OVERLAP_QUADS_RATIO=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-01 07:34:34.450129 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7 7\n",
      " 1 0 1 7 8 9 0 1 2 3 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "<class 'numpy.ndarray'> (0, 128)\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "****************************** 6000 ******************************\n",
      "****************************** 8000 ******************************\n",
      "****************************** 10000 ******************************\n",
      "****************************** 12000 ******************************\n",
      "****************************** 14000 ******************************\n",
      "****************************** 16000 ******************************\n",
      "****************************** 18000 ******************************\n",
      "****************************** 20000 ******************************\n",
      "****************************** 22000 ******************************\n",
      "****************************** 24000 ******************************\n",
      "****************************** 26000 ******************************\n",
      "****************************** 28000 ******************************\n",
      "****************************** 30000 ******************************\n",
      "****************************** 32000 ******************************\n",
      "****************************** 34000 ******************************\n",
      "****************************** 36000 ******************************\n",
      "****************************** 38000 ******************************\n",
      "****************************** 40000 ******************************\n",
      "****************************** 42000 ******************************\n",
      "****************************** 44000 ******************************\n",
      "****************************** 46000 ******************************\n",
      "****************************** 48000 ******************************\n",
      "****************************** 50000 ******************************\n",
      "****************************** 52000 ******************************\n",
      "****************************** 54000 ******************************\n",
      "****************************** 56000 ******************************\n",
      "****************************** 58000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "****************************** 1999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 4 8 9 6 9 6 8 3 6 6 8 5 1 4 2 4 4 5 1 1 9 0 2 4 9 5 7 1 8 3 5 6 9 8 7 1 1 6 7 6 3 2 2 0 8 9\n",
      " 2 5 1 0 8 1 4 5 7 9 6 9 0 6 1 5 5 8 3 8 2 6 5 0 7 4 6 1 3 4 7 3 2 3 4 2 5 2 7 1 7 2 6 4 1 5 7 8 6 0 1 8 2 5 7 7 6 9 3 5 2 4 2 4 0 8 8 3 4 9 2 7 5 8 6 3 6 0 8 6 7 3 6 4 9 4 6 6 3 0 4 1 0 1 4 6 2 9 1\n",
      " 1 0 6 3 9]\n",
      "ndx_errs (array([ 151,  241,  247,  320,  321,  338,  340,  362,  376,  381,  444,  445,  448,  464,  478,  479,  495,  519,  571,  578,  582,  628,  659,  689,  691,  716,  740,  791,  810,  839,  844,  938,\n",
      "        939,  947,  951,  957, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1192, 1212, 1226, 1228, 1232, 1242, 1247, 1270, 1289, 1299, 1319, 1326, 1328, 1331, 1364, 1393, 1414, 1466,\n",
      "       1500, 1522, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1878, 1901, 1955, 1970, 1984], dtype=int64),)\n",
      "num correct is  1910  an accuracy of  0.9554777388694348\n",
      "****************************** 3999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 9 1 1 0 7 5 9 9 1 9 5 9 2 5 0 4 1 0 8 9 0 8 9 8 9 4 2 5 7 9 8 9 8 0 9 9 6 8 9 9 5 9 8 5 1\n",
      " 0 3 3 5 2 1 6 3 0 2 8 1 5 6 2 3 0 2 2 6 4 3 5 5 1 7 2 1 6 9 1 3 9 5 5 1 6 2 2 8 6 7 1 4 6 0 6 0 3 3 2 2 3 6 8 9 8 5 3 8 5 4 5 2 0 5 6 3 2 8 3 9 9 3 7 9 4 6 7 1 3 7 3 6 6 0 9 0 1 9 9 2 8 8 0 1 6 9 7\n",
      " 5 3 4 7 4]\n",
      "ndx_errs (array([ 151,  241,  247,  320,  321,  338,  340,  362,  376,  381,  444,  445,  448,  464,  478,  479,  495,  519,  571,  578,  582,  628,  659,  689,  691,  716,  740,  791,  810,  839,  844,  938,\n",
      "        939,  947,  951,  957, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1192, 1212, 1226, 1228, 1232, 1242, 1247, 1270, 1289, 1299, 1319, 1326, 1328, 1331, 1364, 1393, 1414, 1466,\n",
      "       1500, 1522, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2044, 2052, 2070, 2093, 2098, 2109, 2118,\n",
      "       2129, 2130, 2135, 2168, 2177, 2182, 2189, 2224, 2237, 2282, 2293, 2298, 2371, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2462, 2574, 2582, 2607, 2648, 2654, 2730, 2771, 2810, 2853, 2877, 2896,\n",
      "       2927, 2939, 2953, 2998, 3060, 3062, 3073, 3117, 3206, 3261, 3289, 3333, 3369, 3405, 3429, 3475, 3503, 3542, 3558, 3559, 3597, 3629, 3702, 3718, 3726, 3767, 3780, 3808, 3811, 3838, 3853, 3902,\n",
      "       3926, 3941, 3968], dtype=int64),)\n",
      "num correct is  3836  an accuracy of  0.9592398099524881\n",
      "****************************** 5999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 2 3 4 5 6 7 8 9 8 7 1 3 7 5 2 8 0 7 3 9 9 0 9 1 1 5 8 8 6 3 2 1 8 3 2 6 5 6 7 6 1 0 5 3 1 9\n",
      " 2 1 9 6 0 4 6 1 7 3 8 9 2 9 6 5 8 3 5 7 1 6 1 0 9 6 2 5 4 2 3 4 4 6 0 0 2 0 1 2 3 4 3 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 8 4 5 6 7 8 9 8 6 5 0 6 8 9 4 1 9 5 8 0 4 8 9 1 4 0 5 3 2 1 5 4 0 7 6 0 1 7 0\n",
      " 6 8 9 3 1]\n",
      "ndx_errs (array([ 151,  241,  247,  320,  321,  338,  340,  362,  376,  381,  444,  445,  448,  464,  478,  479,  495,  519,  571,  578,  582,  628,  659,  689,  691,  716,  740,  791,  810,  839,  844,  938,\n",
      "        939,  947,  951,  957, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1192, 1212, 1226, 1228, 1232, 1242, 1247, 1270, 1289, 1299, 1319, 1326, 1328, 1331, 1364, 1393, 1414, 1466,\n",
      "       1500, 1522, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2044, 2052, 2070, 2093, 2098, 2109, 2118,\n",
      "       2129, 2130, 2135, 2168, 2177, 2182, 2189, 2224, 2237, 2282, 2293, 2298, 2371, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2462, 2574, 2582, 2607, 2648, 2654, 2730, 2771, 2810, 2853, 2877, 2896,\n",
      "       2927, 2939, 2953, 2998, 3060, 3062, 3073, 3117, 3206, 3261, 3289, 3333, 3369, 3405, 3429, 3475, 3503, 3542, 3558, 3559, 3597, 3629, 3702, 3718, 3726, 3767, 3780, 3808, 3811, 3838, 3853, 3902,\n",
      "       3926, 3941, 3968, 4007, 4053, 4065, 4075, 4078, 4116, 4163, 4176, 4224, 4238, 4271, 4284, 4289, 4294, 4297, 4306, 4317, 4355, 4483, 4497, 4500, 4598, 4639, 4671, 4690, 4724, 4761, 4785, 4807,\n",
      "       4823, 4837, 4860, 4879, 4886, 4890, 4893, 4943, 4966, 4978, 4990, 5001, 5138, 5176, 5288, 5532, 5600, 5634, 5714, 5734, 5769, 5835, 5867, 5888, 5906, 5937, 5955, 5973, 5982, 5997], dtype=int64),)\n",
      "num correct is  5777  an accuracy of  0.9629938323053843\n",
      "****************************** 7999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 3 5 6 7 8 9 0 1 2 3 5 6 7 8 9 9 7 0 9 0 1 5 8 8 0 9 3 2 7 8 4 6 1 0 4 9 4 2 0 5 0 1 6 9 3 2\n",
      " 9 1 6 0 1 1 8 7 7 6 3 6 0 7 2 4 1 7 0 6 7 1 2 5 8 1 1 2 8 7 6 8 7 1 6 2 9 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 8 9 5 7 0 3 1 6 8 4 1 5 6 4 2 7 8 1 3 4 3 4 7 2 0 5 0 1 9 2 3\n",
      " 2 3 5 5 7]\n",
      "ndx_errs (array([ 151,  241,  247,  320,  321,  338,  340,  362,  376,  381,  444,  445,  448,  464,  478,  479,  495,  519,  571,  578,  582,  628,  659,  689,  691,  716,  740,  791,  810,  839,  844,  938,\n",
      "        939,  947,  951,  957, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1192, 1212, 1226, 1228, 1232, 1242, 1247, 1270, 1289, 1299, 1319, 1326, 1328, 1331, 1364, 1393, 1414, 1466,\n",
      "       1500, 1522, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2044, 2052, 2070, 2093, 2098, 2109, 2118,\n",
      "       2129, 2130, 2135, 2168, 2177, 2182, 2189, 2224, 2237, 2282, 2293, 2298, 2371, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2462, 2574, 2582, 2607, 2648, 2654, 2730, 2771, 2810, 2853, 2877, 2896,\n",
      "       2927, 2939, 2953, 2998, 3060, 3062, 3073, 3117, 3206, 3261, 3289, 3333, 3369, 3405, 3429, 3475, 3503, 3542, 3558, 3559, 3597, 3629, 3702, 3718, 3726, 3767, 3780, 3808, 3811, 3838, 3853, 3902,\n",
      "       3926, 3941, 3968, 4007, 4053, 4065, 4075, 4078, 4116, 4163, 4176, 4224, 4238, 4271, 4284, 4289, 4294, 4297, 4306, 4317, 4355, 4483, 4497, 4500, 4598, 4639, 4671, 4690, 4724, 4761, 4785, 4807,\n",
      "       4823, 4837, 4860, 4879, 4886, 4890, 4893, 4943, 4966, 4978, 4990, 5001, 5138, 5176, 5288, 5532, 5600, 5634, 5714, 5734, 5769, 5835, 5867, 5888, 5906, 5937, 5955, 5973, 5982, 5997, 6011, 6023,\n",
      "       6035, 6059, 6071, 6081, 6091, 6157, 6160, 6166, 6172, 6173, 6505, 6555, 6560, 6597, 6651, 6755, 6783, 6813, 7094, 7216, 7233, 7333, 7432, 7434, 7498, 7545, 7637, 7821, 7921], dtype=int64),)\n",
      "num correct is  7746  an accuracy of  0.9683710463807976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 9999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 2 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 8 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 5 7 0 6 8 6 3 9 9 8 8 7\n",
      " 7 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 8 8 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0\n",
      " 1 2 3 4 5]\n",
      "ndx_errs (array([ 151,  241,  247,  320,  321,  338,  340,  362,  376,  381,  444,  445,  448,  464,  478,  479,  495,  519,  571,  578,  582,  628,  659,  689,  691,  716,  740,  791,  810,  839,  844,  938,\n",
      "        939,  947,  951,  957, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1192, 1212, 1226, 1228, 1232, 1242, 1247, 1270, 1289, 1299, 1319, 1326, 1328, 1331, 1364, 1393, 1414, 1466,\n",
      "       1500, 1522, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2044, 2052, 2070, 2093, 2098, 2109, 2118,\n",
      "       2129, 2130, 2135, 2168, 2177, 2182, 2189, 2224, 2237, 2282, 2293, 2298, 2371, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2462, 2574, 2582, 2607, 2648, 2654, 2730, 2771, 2810, 2853, 2877, 2896,\n",
      "       2927, 2939, 2953, 2998, 3060, 3062, 3073, 3117, 3206, 3261, 3289, 3333, 3369, 3405, 3429, 3475, 3503, 3542, 3558, 3559, 3597, 3629, 3702, 3718, 3726, 3767, 3780, 3808, 3811, 3838, 3853, 3902,\n",
      "       3926, 3941, 3968, 4007, 4053, 4065, 4075, 4078, 4116, 4163, 4176, 4224, 4238, 4271, 4284, 4289, 4294, 4297, 4306, 4317, 4355, 4483, 4497, 4500, 4598, 4639, 4671, 4690, 4724, 4761, 4785, 4807,\n",
      "       4823, 4837, 4860, 4879, 4886, 4890, 4893, 4943, 4966, 4978, 4990, 5001, 5138, 5176, 5288, 5532, 5600, 5634, 5714, 5734, 5769, 5835, 5867, 5888, 5906, 5937, 5955, 5973, 5982, 5997, 6011, 6023,\n",
      "       6035, 6059, 6071, 6081, 6091, 6157, 6160, 6166, 6172, 6173, 6505, 6555, 6560, 6597, 6651, 6755, 6783, 6813, 7094, 7216, 7233, 7333, 7432, 7434, 7498, 7545, 7637, 7821, 7921, 8279, 8325, 8406,\n",
      "       8408, 8410, 8520, 8527, 9009, 9024, 9280, 9382, 9422, 9534, 9587, 9634, 9642, 9664, 9719, 9729, 9733, 9745, 9751, 9768, 9770, 9779, 9808, 9811, 9839, 9867, 9893, 9904, 9905, 9943, 9944, 9982],\n",
      "      dtype=int64),)\n",
      "num correct is  9711  an accuracy of  0.9711971197119712\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 8 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 5 7 0 6 8 6 3 9 9 8 8 7 7\n",
      " 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 8 8 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "ndx_errs (array([ 151,  241,  247,  320,  321,  338,  340,  362,  376,  381,  444,  445,  448,  464,  478,  479,  495,  519,  571,  578,  582,  628,  659,  689,  691,  716,  740,  791,  810,  839,  844,  938,\n",
      "        939,  947,  951,  957, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1192, 1212, 1226, 1228, 1232, 1242, 1247, 1270, 1289, 1299, 1319, 1326, 1328, 1331, 1364, 1393, 1414, 1466,\n",
      "       1500, 1522, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2044, 2052, 2070, 2093, 2098, 2109, 2118,\n",
      "       2129, 2130, 2135, 2168, 2177, 2182, 2189, 2224, 2237, 2282, 2293, 2298, 2371, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2462, 2574, 2582, 2607, 2648, 2654, 2730, 2771, 2810, 2853, 2877, 2896,\n",
      "       2927, 2939, 2953, 2998, 3060, 3062, 3073, 3117, 3206, 3261, 3289, 3333, 3369, 3405, 3429, 3475, 3503, 3542, 3558, 3559, 3597, 3629, 3702, 3718, 3726, 3767, 3780, 3808, 3811, 3838, 3853, 3902,\n",
      "       3926, 3941, 3968, 4007, 4053, 4065, 4075, 4078, 4116, 4163, 4176, 4224, 4238, 4271, 4284, 4289, 4294, 4297, 4306, 4317, 4355, 4483, 4497, 4500, 4598, 4639, 4671, 4690, 4724, 4761, 4785, 4807,\n",
      "       4823, 4837, 4860, 4879, 4886, 4890, 4893, 4943, 4966, 4978, 4990, 5001, 5138, 5176, 5288, 5532, 5600, 5634, 5714, 5734, 5769, 5835, 5867, 5888, 5906, 5937, 5955, 5973, 5982, 5997, 6011, 6023,\n",
      "       6035, 6059, 6071, 6081, 6091, 6157, 6160, 6166, 6172, 6173, 6505, 6555, 6560, 6597, 6651, 6755, 6783, 6813, 7094, 7216, 7233, 7333, 7432, 7434, 7498, 7545, 7637, 7821, 7921, 8279, 8325, 8406,\n",
      "       8408, 8410, 8520, 8527, 9009, 9024, 9280, 9382, 9422, 9534, 9587, 9634, 9642, 9664, 9719, 9729, 9733, 9745, 9751, 9768, 9770, 9779, 9808, 9811, 9839, 9867, 9893, 9904, 9905, 9943, 9944, 9982],\n",
      "      dtype=int64),)\n",
      "num correct is  9712  an accuracy of  0.9712\n",
      "2020-06-01 10:35:13.237609 end\n"
     ]
    }
   ],
   "source": [
    "Config.OVERLAP_QUADS_RATIO=0.125\n",
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "Config.OVERLAP_QUADS_RATIO=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s2noappendimage'></a>\n",
    "<a href='#toc'>Goto Table of Contents</a>\n",
    "\n",
    "## Try just the centroid info without the image.\n",
    "## Do this with option parent centroids with overlap\n",
    "\n",
    "- kNN acc (6,000        ; 60,000 89.91%)\n",
    "- kNN acc (6,000        ; 60,000 89.62%)\n",
    "\n",
    "## whereas the baseline is\n",
    "\n",
    "## kNN acc (6,000 91.6% 60,000 96.88%)\n",
    "## CNN acc (6,000 96.06% (+/- 1.42%); 60,000 99.00% (+/- 0.21%))\n",
    "\n",
    "## This shows that we need the image in addition to centroid info for the best results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-01 10:35:13.470001 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7 7\n",
      " 1 0 1 7 8 9 0 1 2 3 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "<class 'numpy.ndarray'> (0, 128)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "****************************** 6000 ******************************\n",
      "****************************** 8000 ******************************\n",
      "****************************** 10000 ******************************\n",
      "****************************** 12000 ******************************\n",
      "****************************** 14000 ******************************\n",
      "****************************** 16000 ******************************\n",
      "****************************** 18000 ******************************\n",
      "****************************** 20000 ******************************\n",
      "****************************** 22000 ******************************\n",
      "****************************** 24000 ******************************\n",
      "****************************** 26000 ******************************\n",
      "****************************** 28000 ******************************\n",
      "****************************** 30000 ******************************\n",
      "****************************** 32000 ******************************\n",
      "****************************** 34000 ******************************\n",
      "****************************** 36000 ******************************\n",
      "****************************** 38000 ******************************\n",
      "****************************** 40000 ******************************\n",
      "****************************** 42000 ******************************\n",
      "****************************** 44000 ******************************\n",
      "****************************** 46000 ******************************\n",
      "****************************** 48000 ******************************\n",
      "****************************** 50000 ******************************\n",
      "****************************** 52000 ******************************\n",
      "****************************** 54000 ******************************\n",
      "****************************** 56000 ******************************\n",
      "****************************** 58000 ******************************\n",
      "****************************** 1999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 7 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 9 4 6 3 5 5 6 0 4 1 9 5 7 8 9 2 7 4 6 4 3 0 7 0 2 7 1 7 3 2 8 7 7 6 2 7 8 4 7 7 6 1 3 6 4 3 1 9 1 4 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 4 1 8 2 0 2 ... 4 8 9 6 9 6 8 3 6 6 8 5 1 4 2 4 4 5 1 4 9 0 2 4 9 5 7 1 8 3 5 6 9 8 7 1 1 6 7 6 3 2 2 0 8 9\n",
      " 2 3 1 0 8 1 4 5 7 9 6 9 0 6 1 5 5 8 3 8 2 6 5 0 7 9 6 1 3 2 7 3 2 3 4 2 5 2 7 1 7 2 6 4 1 5 9 8 6 0 1 8 2 5 7 7 6 3 3 5 2 4 2 4 0 8 8 3 4 9 1 7 5 8 6 3 6 0 3 6 7 3 6 4 4 4 6 5 3 0 4 1 0 2 4 6 2 9 1\n",
      " 1 0 6 3 9]\n",
      "ndx_errs (array([   9,   48,   63,   73,   78,   87,   92,   95,   97,  144,  151,  165,  184,  206,  207,  217,  232,  241,  247,  250,  259,  266,  282,  301,  307,  316,  318,  320,  338,  340,  359,  362,\n",
      "        376,  386,  391,  405,  406,  436,  444,  445,  447,  448,  457,  464,  468,  478,  479,  493,  495,  497,  502,  505,  507,  511,  519,  543,  551,  565,  571,  578,  583,  591,  593,  605,\n",
      "        610,  619,  628,  645,  654,  659,  684,  689,  691,  694,  714,  716,  717,  720,  740,  751,  752,  781,  785,  786,  791,  810,  813,  823,  827,  829,  844,  877,  881,  894,  898,  899,\n",
      "        916,  924,  938,  943,  947,  951,  955,  956,  958,  960,  965,  966,  976,  987,  999, 1003, 1014, 1033, 1039, 1052, 1069, 1072, 1074, 1077, 1089, 1107, 1108, 1112, 1125, 1147, 1152, 1153,\n",
      "       1156, 1164, 1173, 1178, 1181, 1182, 1194, 1198, 1212, 1217, 1219, 1226, 1228, 1233, 1240, 1247, 1248, 1263, 1288, 1289, 1299, 1314, 1319, 1326, 1328, 1331, 1334, 1339, 1352, 1363, 1364, 1391,\n",
      "       1393, 1398, 1414, 1436, 1440, 1453, 1458, 1464, 1465, 1466, 1467, 1476, 1480, 1488, 1492, 1494, 1499, 1500, 1510, 1522, 1525, 1527, 1530, 1543, 1549, 1553, 1562, 1581, 1626, 1631, 1634, 1637,\n",
      "       1648, 1670, 1681, 1686, 1695, 1702, 1709, 1718, 1721, 1732, 1735, 1737, 1754, 1760, 1769, 1770, 1779, 1790, 1811, 1816, 1847, 1868, 1878, 1896, 1901, 1920, 1924, 1941, 1952, 1955, 1965, 1970,\n",
      "       1973, 1979, 1982, 1984, 1988], dtype=int64),)\n",
      "num correct is  1770  an accuracy of  0.8854427213606804\n",
      "****************************** 3999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 7 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 9 4 6 3 5 5 6 0 4 1 9 5 7 8 9 2 7 4 6 4 3 0 7 0 2 7 1 7 3 2 8 7 7 6 2 7 8 4 7 7 6 1 3 6 4 3 1 9 1 4 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 4 1 8 2 0 2 ... 0 9 1 1 6 7 8 9 9 1 9 5 9 2 5 0 4 1 0 8 9 0 5 9 8 9 4 2 5 7 9 8 9 8 0 4 9 6 8 9 9 5 9 8 3 1\n",
      " 0 3 8 5 2 1 6 3 0 2 8 1 5 6 2 3 0 2 2 6 4 8 5 5 1 7 2 1 6 9 1 3 9 5 5 1 6 2 2 8 6 7 1 4 6 0 6 0 3 3 2 2 3 6 8 9 8 5 2 8 5 4 5 2 0 5 6 8 2 8 3 9 9 5 7 9 4 6 7 1 3 7 3 6 6 0 9 0 1 9 9 2 8 8 0 1 6 9 7\n",
      " 5 3 4 7 4]\n",
      "ndx_errs (array([   9,   48,   63,   73,   78,   87,   92,   95,   97,  144,  151,  165,  184,  206,  207,  217,  232,  241,  247,  250,  259,  266,  282,  301,  307,  316,  318,  320,  338,  340,  359,  362,\n",
      "        376,  386,  391,  405,  406,  436,  444,  445,  447,  448,  457,  464,  468,  478,  479,  493,  495,  497,  502,  505,  507,  511,  519,  543,  551,  565,  571,  578,  583,  591,  593,  605,\n",
      "        610,  619,  628,  645,  654,  659,  684,  689,  691,  694,  714,  716,  717,  720,  740,  751,  752,  781,  785,  786,  791,  810,  813,  823,  827,  829,  844,  877,  881,  894,  898,  899,\n",
      "        916,  924,  938,  943,  947,  951,  955,  956,  958,  960,  965,  966,  976,  987,  999, 1003, 1014, 1033, 1039, 1052, 1069, 1072, 1074, 1077, 1089, 1107, 1108, 1112, 1125, 1147, 1152, 1153,\n",
      "       1156, 1164, 1173, 1178, 1181, 1182, 1194, 1198, 1212, 1217, 1219, 1226, 1228, 1233, 1240, 1247, 1248, 1263, 1288, 1289, 1299, 1314, 1319, 1326, 1328, 1331, 1334, 1339, 1352, 1363, 1364, 1391,\n",
      "       1393, 1398, 1414, 1436, 1440, 1453, 1458, 1464, 1465, 1466, 1467, 1476, 1480, 1488, 1492, 1494, 1499, 1500, 1510, 1522, 1525, 1527, 1530, 1543, 1549, 1553, 1562, 1581, 1626, 1631, 1634, 1637,\n",
      "       1648, 1670, 1681, 1686, 1695, 1702, 1709, 1718, 1721, 1732, 1735, 1737, 1754, 1760, 1769, 1770, 1779, 1790, 1811, 1816, 1847, 1868, 1878, 1896, 1901, 1920, 1924, 1941, 1952, 1955, 1965, 1970,\n",
      "       1973, 1979, 1982, 1984, 1988, 1999, 2016, 2018, 2028, 2043, 2052, 2053, 2056, 2070, 2073, 2080, 2093, 2094, 2098, 2099, 2101, 2107, 2109, 2118, 2129, 2130, 2135, 2148, 2168, 2177, 2182, 2186,\n",
      "       2189, 2199, 2224, 2229, 2237, 2247, 2266, 2272, 2281, 2282, 2291, 2293, 2298, 2300, 2325, 2334, 2343, 2358, 2363, 2371, 2381, 2386, 2387, 2393, 2395, 2400, 2404, 2414, 2422, 2423, 2438, 2447,\n",
      "       2462, 2464, 2498, 2512, 2515, 2526, 2539, 2540, 2556, 2559, 2560, 2574, 2604, 2607, 2628, 2648, 2651, 2653, 2654, 2659, 2668, 2670, 2683, 2705, 2713, 2730, 2745, 2750, 2758, 2771, 2773, 2775,\n",
      "       2780, 2803, 2810, 2823, 2832, 2834, 2847, 2848, 2850, 2851, 2852, 2853, 2882, 2888, 2896, 2914, 2921, 2927, 2934, 2938, 2939, 2945, 2953, 2956, 2970, 2972, 2986, 2990, 2995, 2998, 3023, 3029,\n",
      "       3038, 3051, 3056, 3062, 3073, 3091, 3100, 3102, 3107, 3115, 3117, 3129, 3132, 3136, 3138, 3145, 3153, 3186, 3202, 3208, 3240, 3246, 3254, 3260, 3261, 3262, 3300, 3303, 3316, 3319, 3329, 3330,\n",
      "       3333, 3336, 3341, 3369, 3376, 3410, 3427, 3429, 3437, 3440, 3457, 3467, 3469, 3473, 3475, 3499, 3503, 3534, 3542, 3549, 3550, 3558, 3559, 3563, 3580, 3591, 3597, 3604, 3627, 3629, 3670, 3674,\n",
      "       3686, 3691, 3702, 3716, 3718, 3726, 3755, 3763, 3767, 3778, 3780, 3789, 3808, 3811, 3821, 3838, 3855, 3871, 3884, 3893, 3897, 3902, 3916, 3926, 3941, 3953, 3962], dtype=int64),)\n",
      "num correct is  3556  an accuracy of  0.8892223055763941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 5999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 7 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 9 4 6 3 5 5 6 0 4 1 9 5 7 8 9 2 7 4 6 4 3 0 7 0 2 7 1 7 3 2 8 7 7 6 2 7 8 4 7 7 6 1 3 6 4 3 1 9 1 4 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 4 1 8 2 0 2 ... 2 3 4 5 6 4 8 9 3 3 1 3 7 3 2 8 0 9 3 9 9 0 9 1 1 5 8 3 6 3 2 1 8 3 2 6 3 6 2 2 1 0 3 3 1 9\n",
      " 2 1 9 6 0 4 6 1 9 3 8 9 8 9 6 5 8 3 3 7 1 6 1 0 2 6 2 3 4 2 3 4 4 6 0 0 2 0 1 2 3 4 3 6 7 2 9 0 1 2 3 4 8 6 7 8 9 0 1 2 8 4 5 6 7 8 7 6 6 5 0 6 0 9 9 1 9 3 8 0 4 3 9 1 4 0 5 3 2 1 3 4 0 7 6 0 1 7 0\n",
      " 6 8 9 5 1]\n",
      "ndx_errs (array([   9,   48,   63,   73,   78,   87,   92,   95,   97,  144,  151,  165,  184,  206,  207,  217,  232,  241,  247,  250,  259,  266,  282,  301,  307,  316,  318,  320,  338,  340,  359,  362,\n",
      "        376,  386,  391,  405,  406,  436,  444,  445,  447,  448,  457,  464,  468,  478,  479,  493,  495,  497,  502,  505,  507,  511,  519,  543,  551,  565,  571,  578,  583,  591,  593,  605,\n",
      "        610,  619,  628,  645,  654,  659,  684,  689,  691,  694,  714,  716,  717,  720,  740,  751,  752,  781,  785,  786,  791,  810,  813,  823,  827,  829,  844,  877,  881,  894,  898,  899,\n",
      "        916,  924,  938,  943,  947,  951,  955,  956,  958,  960,  965,  966,  976,  987,  999, 1003, 1014, 1033, 1039, 1052, 1069, 1072, 1074, 1077, 1089, 1107, 1108, 1112, 1125, 1147, 1152, 1153,\n",
      "       1156, 1164, 1173, 1178, 1181, 1182, 1194, 1198, 1212, 1217, 1219, 1226, 1228, 1233, 1240, 1247, 1248, 1263, 1288, 1289, 1299, 1314, 1319, 1326, 1328, 1331, 1334, 1339, 1352, 1363, 1364, 1391,\n",
      "       1393, 1398, 1414, 1436, 1440, 1453, 1458, 1464, 1465, 1466, 1467, 1476, 1480, 1488, 1492, 1494, 1499, 1500, 1510, 1522, 1525, 1527, 1530, 1543, 1549, 1553, 1562, 1581, 1626, 1631, 1634, 1637,\n",
      "       1648, 1670, 1681, 1686, 1695, 1702, 1709, 1718, 1721, 1732, 1735, 1737, 1754, 1760, 1769, 1770, 1779, 1790, 1811, 1816, 1847, 1868, 1878, 1896, 1901, 1920, 1924, 1941, 1952, 1955, 1965, 1970,\n",
      "       1973, 1979, 1982, 1984, 1988, 1999, 2016, 2018, 2028, 2043, 2052, 2053, 2056, 2070, 2073, 2080, 2093, 2094, 2098, 2099, 2101, 2107, 2109, 2118, 2129, 2130, 2135, 2148, 2168, 2177, 2182, 2186,\n",
      "       2189, 2199, 2224, 2229, 2237, 2247, 2266, 2272, 2281, 2282, 2291, 2293, 2298, 2300, 2325, 2334, 2343, 2358, 2363, 2371, 2381, 2386, 2387, 2393, 2395, 2400, 2404, 2414, 2422, 2423, 2438, 2447,\n",
      "       2462, 2464, 2498, 2512, 2515, 2526, 2539, 2540, 2556, 2559, 2560, 2574, 2604, 2607, 2628, 2648, 2651, 2653, 2654, 2659, 2668, 2670, 2683, 2705, 2713, 2730, 2745, 2750, 2758, 2771, 2773, 2775,\n",
      "       2780, 2803, 2810, 2823, 2832, 2834, 2847, 2848, 2850, 2851, 2852, 2853, 2882, 2888, 2896, 2914, 2921, 2927, 2934, 2938, 2939, 2945, 2953, 2956, 2970, 2972, 2986, 2990, 2995, 2998, 3023, 3029,\n",
      "       3038, 3051, 3056, 3062, 3073, 3091, 3100, 3102, 3107, 3115, 3117, 3129, 3132, 3136, 3138, 3145, 3153, 3186, 3202, 3208, 3240, 3246, 3254, 3260, 3261, 3262, 3300, 3303, 3316, 3319, 3329, 3330,\n",
      "       3333, 3336, 3341, 3369, 3376, 3410, 3427, 3429, 3437, 3440, 3457, 3467, 3469, 3473, 3475, 3499, 3503, 3534, 3542, 3549, 3550, 3558, 3559, 3563, 3580, 3591, 3597, 3604, 3627, 3629, 3670, 3674,\n",
      "       3686, 3691, 3702, 3716, 3718, 3726, 3755, 3763, 3767, 3778, 3780, 3789, 3808, 3811, 3821, 3838, 3855, 3871, 3884, 3893, 3897, 3902, 3916, 3926, 3941, 3953, 3962, 4001, 4007, 4015, 4031, 4053,\n",
      "       4063, 4068, 4072, 4075, 4078, 4086, 4094, 4097, 4111, 4118, 4123, 4140, 4145, 4157, 4159, 4176, 4194, 4201, 4207, 4211, 4224, 4228, 4238, 4253, 4255, 4266, 4269, 4271, 4284, 4289, 4294, 4300,\n",
      "       4302, 4306, 4313, 4315, 4321, 4325, 4334, 4350, 4355, 4360, 4364, 4379, 4384, 4411, 4415, 4433, 4437, 4443, 4487, 4489, 4494, 4497, 4500, 4514, 4534, 4536, 4540, 4548, 4567, 4569, 4575, 4578,\n",
      "       4598, 4639, 4643, 4657, 4660, 4671, 4690, 4695, 4696, 4702, 4723, 4724, 4731, 4736, 4737, 4743, 4746, 4759, 4761, 4769, 4772, 4783, 4785, 4794, 4807, 4814, 4823, 4827, 4828, 4841, 4855, 4860,\n",
      "       4874, 4879, 4880, 4890, 4894, 4895, 4911, 4916, 4924, 4942, 4943, 4950, 4956, 4963, 4966, 4971, 4976, 4978, 4990, 5011, 5061, 5062, 5084, 5104, 5121, 5127, 5129, 5159, 5167, 5173, 5194, 5207,\n",
      "       5242, 5260, 5269, 5299, 5311, 5409, 5429, 5504, 5522, 5528, 5530, 5532, 5533, 5560, 5569, 5586, 5601, 5608, 5616, 5623, 5634, 5635, 5638, 5649, 5654, 5661, 5662, 5705, 5709, 5718, 5728, 5745,\n",
      "       5747, 5749, 5754, 5769, 5784, 5802, 5835, 5840, 5841, 5845, 5854, 5857, 5858, 5862, 5866, 5867, 5876, 5885, 5887, 5888, 5891, 5903, 5906, 5907, 5913, 5919, 5922, 5937, 5940, 5947, 5955, 5961,\n",
      "       5962, 5967, 5969, 5972, 5973, 5976, 5982, 5985], dtype=int64),)\n",
      "num correct is  5351  an accuracy of  0.8919819969994999\n",
      "****************************** 7999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 7 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 9 4 6 3 5 5 6 0 4 1 9 5 7 8 9 2 7 4 6 4 3 0 7 0 2 7 1 7 3 2 8 7 7 6 2 7 8 4 7 7 6 1 3 6 4 3 1 9 1 4 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 4 1 8 2 0 2 ... 3 8 6 7 8 9 0 8 3 3 8 2 7 8 9 9 7 0 9 0 1 3 8 8 0 9 3 2 7 8 4 6 1 0 4 9 4 2 0 8 0 1 6 9 3 2\n",
      " 9 1 6 0 1 8 8 8 8 8 3 6 0 7 2 4 1 7 0 3 8 8 2 5 8 1 8 2 8 9 6 8 7 8 5 2 9 3 0 1 2 3 4 5 6 7 8 7 0 1 2 2 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 8 9 5 7 0 3 1 6 0 4 1 5 6 4 2 7 8 1 3 6 3 4 7 2 0 5 0 8 9 2 3\n",
      " 2 3 5 5 7]\n",
      "ndx_errs (array([   9,   48,   63,   73,   78,   87,   92,   95,   97,  144,  151,  165,  184,  206,  207,  217,  232,  241,  247,  250,  259,  266,  282,  301,  307,  316,  318,  320,  338,  340,  359,  362,\n",
      "        376,  386,  391,  405,  406,  436,  444,  445,  447,  448,  457,  464,  468,  478,  479,  493,  495,  497,  502,  505,  507,  511,  519,  543,  551,  565,  571,  578,  583,  591,  593,  605,\n",
      "        610,  619,  628,  645,  654,  659,  684,  689,  691,  694,  714,  716,  717,  720,  740,  751,  752,  781,  785,  786,  791,  810,  813,  823,  827,  829,  844,  877,  881,  894,  898,  899,\n",
      "        916,  924,  938,  943,  947,  951,  955,  956,  958,  960,  965,  966,  976,  987,  999, 1003, 1014, 1033, 1039, 1052, 1069, 1072, 1074, 1077, 1089, 1107, 1108, 1112, 1125, 1147, 1152, 1153,\n",
      "       1156, 1164, 1173, 1178, 1181, 1182, 1194, 1198, 1212, 1217, 1219, 1226, 1228, 1233, 1240, 1247, 1248, 1263, 1288, 1289, 1299, 1314, 1319, 1326, 1328, 1331, 1334, 1339, 1352, 1363, 1364, 1391,\n",
      "       1393, 1398, 1414, 1436, 1440, 1453, 1458, 1464, 1465, 1466, 1467, 1476, 1480, 1488, 1492, 1494, 1499, 1500, 1510, 1522, 1525, 1527, 1530, 1543, 1549, 1553, 1562, 1581, 1626, 1631, 1634, 1637,\n",
      "       1648, 1670, 1681, 1686, 1695, 1702, 1709, 1718, 1721, 1732, 1735, 1737, 1754, 1760, 1769, 1770, 1779, 1790, 1811, 1816, 1847, 1868, 1878, 1896, 1901, 1920, 1924, 1941, 1952, 1955, 1965, 1970,\n",
      "       1973, 1979, 1982, 1984, 1988, 1999, 2016, 2018, 2028, 2043, 2052, 2053, 2056, 2070, 2073, 2080, 2093, 2094, 2098, 2099, 2101, 2107, 2109, 2118, 2129, 2130, 2135, 2148, 2168, 2177, 2182, 2186,\n",
      "       2189, 2199, 2224, 2229, 2237, 2247, 2266, 2272, 2281, 2282, 2291, 2293, 2298, 2300, 2325, 2334, 2343, 2358, 2363, 2371, 2381, 2386, 2387, 2393, 2395, 2400, 2404, 2414, 2422, 2423, 2438, 2447,\n",
      "       2462, 2464, 2498, 2512, 2515, 2526, 2539, 2540, 2556, 2559, 2560, 2574, 2604, 2607, 2628, 2648, 2651, 2653, 2654, 2659, 2668, 2670, 2683, 2705, 2713, 2730, 2745, 2750, 2758, 2771, 2773, 2775,\n",
      "       2780, 2803, 2810, 2823, 2832, 2834, 2847, 2848, 2850, 2851, 2852, 2853, 2882, 2888, 2896, 2914, 2921, 2927, 2934, 2938, 2939, 2945, 2953, 2956, 2970, 2972, 2986, 2990, 2995, 2998, 3023, 3029,\n",
      "       3038, 3051, 3056, 3062, 3073, 3091, 3100, 3102, 3107, 3115, 3117, 3129, 3132, 3136, 3138, 3145, 3153, 3186, 3202, 3208, 3240, 3246, 3254, 3260, 3261, 3262, 3300, 3303, 3316, 3319, 3329, 3330,\n",
      "       3333, 3336, 3341, 3369, 3376, 3410, 3427, 3429, 3437, 3440, 3457, 3467, 3469, 3473, 3475, 3499, 3503, 3534, 3542, 3549, 3550, 3558, 3559, 3563, 3580, 3591, 3597, 3604, 3627, 3629, 3670, 3674,\n",
      "       3686, 3691, 3702, 3716, 3718, 3726, 3755, 3763, 3767, 3778, 3780, 3789, 3808, 3811, 3821, 3838, 3855, 3871, 3884, 3893, 3897, 3902, 3916, 3926, 3941, 3953, 3962, 4001, 4007, 4015, 4031, 4053,\n",
      "       4063, 4068, 4072, 4075, 4078, 4086, 4094, 4097, 4111, 4118, 4123, 4140, 4145, 4157, 4159, 4176, 4194, 4201, 4207, 4211, 4224, 4228, 4238, 4253, 4255, 4266, 4269, 4271, 4284, 4289, 4294, 4300,\n",
      "       4302, 4306, 4313, 4315, 4321, 4325, 4334, 4350, 4355, 4360, 4364, 4379, 4384, 4411, 4415, 4433, 4437, 4443, 4487, 4489, 4494, 4497, 4500, 4514, 4534, 4536, 4540, 4548, 4567, 4569, 4575, 4578,\n",
      "       4598, 4639, 4643, 4657, 4660, 4671, 4690, 4695, 4696, 4702, 4723, 4724, 4731, 4736, 4737, 4743, 4746, 4759, 4761, 4769, 4772, 4783, 4785, 4794, 4807, 4814, 4823, 4827, 4828, 4841, 4855, 4860,\n",
      "       4874, 4879, 4880, 4890, 4894, 4895, 4911, 4916, 4924, 4942, 4943, 4950, 4956, 4963, 4966, 4971, 4976, 4978, 4990, 5011, 5061, 5062, 5084, 5104, 5121, 5127, 5129, 5159, 5167, 5173, 5194, 5207,\n",
      "       5242, 5260, 5269, 5299, 5311, 5409, 5429, 5504, 5522, 5528, 5530, 5532, 5533, 5560, 5569, 5586, 5601, 5608, 5616, 5623, 5634, 5635, 5638, 5649, 5654, 5661, 5662, 5705, 5709, 5718, 5728, 5745,\n",
      "       5747, 5749, 5754, 5769, 5784, 5802, 5835, 5840, 5841, 5845, 5854, 5857, 5858, 5862, 5866, 5867, 5876, 5885, 5887, 5888, 5891, 5903, 5906, 5907, 5913, 5919, 5922, 5937, 5940, 5947, 5955, 5961,\n",
      "       5962, 5967, 5969, 5972, 5973, 5976, 5982, 5985, 6006, 6011, 6013, 6026, 6028, 6035, 6037, 6043, 6046, 6053, 6065, 6071, 6077, 6080, 6081, 6083, 6084, 6085, 6091, 6093, 6101, 6113, 6120, 6126,\n",
      "       6142, 6155, 6157, 6160, 6165, 6166, 6168, 6173, 6174, 6223, 6348, 6356, 6379, 6385, 6386, 6390, 6395, 6405, 6410, 6434, 6453, 6458, 6460, 6471, 6481, 6490, 6501, 6504, 6505, 6544, 6553, 6555,\n",
      "       6560, 6568, 6625, 6636, 6641, 6642, 6643, 6651, 6658, 6706, 6708, 6721, 6740, 6744, 6747, 6755, 6759, 6761, 6783, 6788, 6796, 6806, 6813, 6834, 6864, 6866, 6883, 6894, 6941, 6962, 6964, 6977,\n",
      "       6988, 7032, 7040, 7066, 7094, 7102, 7104, 7130, 7153, 7177, 7206, 7216, 7233, 7238, 7260, 7268, 7277, 7287, 7293, 7297, 7301, 7302, 7309, 7315, 7338, 7339, 7361, 7366, 7370, 7376, 7397, 7434,\n",
      "       7437, 7448, 7459, 7461, 7471, 7478, 7482, 7491, 7498, 7499, 7509, 7514, 7524, 7534, 7538, 7545, 7569, 7584, 7595, 7605, 7606, 7619, 7637, 7656, 7659, 7672, 7689, 7718, 7732, 7736, 7756, 7757,\n",
      "       7764, 7777, 7788, 7797, 7807, 7808, 7812, 7822, 7823, 7842, 7844, 7847, 7850, 7856, 7857, 7859, 7860, 7870, 7888, 7900, 7902, 7903, 7904, 7914, 7915, 7916, 7924, 7928, 7929, 7942, 7946, 7971,\n",
      "       7982, 7990], dtype=int64),)\n",
      "num correct is  7165  an accuracy of  0.8957369671208901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 9999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 7 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 9 4 6 3 5 5 6 0 4 1 9 5 7 8 9 2 7 4 6 4 3 0 7 0 2 7 1 7 3 2 8 7 7 6 2 7 8 4 7 7 6 1 3 6 4 3 1 9 1 4 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 4 1 8 2 0 2 ... 2 0 7 7 5 6 2 9 8 0 7 3 4 6 8 7 0 4 8 7 7 5 4 3 0 2 8 1 5 1 0 8 3 3 6 7 0 6 8 6 3 9 9 5 8 7\n",
      " 7 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 9 1 4 8 8 4 4 7 0 1 9 2 8 7 5 2 6 0 6 5 3 8 3 9 1 2 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 3 2 4 4 4 3 4 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0\n",
      " 1 2 3 4 5]\n",
      "ndx_errs (array([   9,   48,   63,   73,   78,   87,   92,   95,   97,  144,  151,  165,  184,  206,  207,  217,  232,  241,  247,  250,  259,  266,  282,  301,  307,  316,  318,  320,  338,  340,  359,  362,\n",
      "        376,  386,  391,  405,  406,  436,  444,  445,  447,  448,  457,  464,  468,  478,  479,  493,  495,  497,  502,  505,  507,  511,  519,  543,  551,  565,  571,  578,  583,  591,  593,  605,\n",
      "        610,  619,  628,  645,  654,  659,  684,  689,  691,  694,  714,  716,  717,  720,  740,  751,  752,  781,  785,  786,  791,  810,  813,  823,  827,  829,  844,  877,  881,  894,  898,  899,\n",
      "        916,  924,  938,  943,  947,  951,  955,  956,  958,  960,  965,  966,  976,  987,  999, 1003, 1014, 1033, 1039, 1052, 1069, 1072, 1074, 1077, 1089, 1107, 1108, 1112, 1125, 1147, 1152, 1153,\n",
      "       1156, 1164, 1173, 1178, 1181, 1182, 1194, 1198, 1212, 1217, 1219, 1226, 1228, 1233, 1240, 1247, 1248, 1263, 1288, 1289, 1299, 1314, ..., 8316, 8322, 8325, 8332, 8346, 8375, 8377, 8379, 8393,\n",
      "       8406, 8407, 8408, 8410, 8413, 8422, 8447, 8453, 8469, 8486, 8487, 8493, 8502, 8507, 8509, 8520, 8522, 8529, 8545, 8547, 8553, 8582, 8597, 8601, 8603, 8613, 8676, 8684, 8711, 8713, 8757, 8759,\n",
      "       8777, 8821, 8866, 8954, 8998, 9007, 9009, 9010, 9015, 9019, 9022, 9024, 9033, 9036, 9045, 9067, 9069, 9071, 9075, 9110, 9115, 9169, 9171, 9183, 9202, 9203, 9210, 9211, 9214, 9224, 9225, 9231,\n",
      "       9248, 9257, 9280, 9316, 9354, 9382, 9391, 9400, 9422, 9427, 9450, 9465, 9478, 9482, 9505, 9508, 9530, 9534, 9537, 9538, 9539, 9542, 9546, 9548, 9554, 9580, 9587, 9610, 9636, 9662, 9664, 9669,\n",
      "       9692, 9700, 9711, 9713, 9716, 9719, 9726, 9733, 9734, 9737, 9738, 9740, 9741, 9745, 9746, 9749, 9767, 9768, 9770, 9771, 9773, 9779, 9811, 9832, 9839, 9854, 9858, 9867, 9873, 9880, 9883, 9892,\n",
      "       9893, 9904, 9905, 9922, 9924, 9925, 9936, 9943, 9947, 9970, 9973, 9976, 9982], dtype=int64),)\n",
      "num correct is  8990  an accuracy of  0.8990899089908991\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 7 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 9 4 6 3 5 5 6 0 4 1 9 5 7 8 9 2 7 4 6 4 3 0 7 0 2 7 1 7 3 2 8 7 7 6 2 7 8 4 7 7 6 1 3 6 4 3 1 9 1 4 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 4 1 8 2 0 2 ... 0 7 7 5 6 2 9 8 0 7 3 4 6 8 7 0 4 8 7 7 5 4 3 0 2 8 1 5 1 0 8 3 3 6 7 0 6 8 6 3 9 9 5 8 7 7\n",
      " 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 9 1 4 8 8 4 4 7 0 1 9 2 8 7 5 2 6 0 6 5 3 8 3 9 1 2 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 3 2 4 4 4 3 4 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "ndx_errs (array([   9,   48,   63,   73,   78,   87,   92,   95,   97,  144,  151,  165,  184,  206,  207,  217,  232,  241,  247,  250,  259,  266,  282,  301,  307,  316,  318,  320,  338,  340,  359,  362,\n",
      "        376,  386,  391,  405,  406,  436,  444,  445,  447,  448,  457,  464,  468,  478,  479,  493,  495,  497,  502,  505,  507,  511,  519,  543,  551,  565,  571,  578,  583,  591,  593,  605,\n",
      "        610,  619,  628,  645,  654,  659,  684,  689,  691,  694,  714,  716,  717,  720,  740,  751,  752,  781,  785,  786,  791,  810,  813,  823,  827,  829,  844,  877,  881,  894,  898,  899,\n",
      "        916,  924,  938,  943,  947,  951,  955,  956,  958,  960,  965,  966,  976,  987,  999, 1003, 1014, 1033, 1039, 1052, 1069, 1072, 1074, 1077, 1089, 1107, 1108, 1112, 1125, 1147, 1152, 1153,\n",
      "       1156, 1164, 1173, 1178, 1181, 1182, 1194, 1198, 1212, 1217, 1219, 1226, 1228, 1233, 1240, 1247, 1248, 1263, 1288, 1289, 1299, 1314, ..., 8316, 8322, 8325, 8332, 8346, 8375, 8377, 8379, 8393,\n",
      "       8406, 8407, 8408, 8410, 8413, 8422, 8447, 8453, 8469, 8486, 8487, 8493, 8502, 8507, 8509, 8520, 8522, 8529, 8545, 8547, 8553, 8582, 8597, 8601, 8603, 8613, 8676, 8684, 8711, 8713, 8757, 8759,\n",
      "       8777, 8821, 8866, 8954, 8998, 9007, 9009, 9010, 9015, 9019, 9022, 9024, 9033, 9036, 9045, 9067, 9069, 9071, 9075, 9110, 9115, 9169, 9171, 9183, 9202, 9203, 9210, 9211, 9214, 9224, 9225, 9231,\n",
      "       9248, 9257, 9280, 9316, 9354, 9382, 9391, 9400, 9422, 9427, 9450, 9465, 9478, 9482, 9505, 9508, 9530, 9534, 9537, 9538, 9539, 9542, 9546, 9548, 9554, 9580, 9587, 9610, 9636, 9662, 9664, 9669,\n",
      "       9692, 9700, 9711, 9713, 9716, 9719, 9726, 9733, 9734, 9737, 9738, 9740, 9741, 9745, 9746, 9749, 9767, 9768, 9770, 9771, 9773, 9779, 9811, 9832, 9839, 9854, 9858, 9867, 9873, 9880, 9883, 9892,\n",
      "       9893, 9904, 9905, 9922, 9924, 9925, 9936, 9943, 9947, 9970, 9973, 9976, 9982], dtype=int64),)\n",
      "num correct is  8991  an accuracy of  0.8991\n",
      "2020-06-01 11:04:46.466135 end\n"
     ]
    }
   ],
   "source": [
    "Config.OVERLAP_QUADS_RATIO=0.125\n",
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "Config.OVERLAP_QUADS_RATIO=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-01 11:04:46.494003 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7 7\n",
      " 1 0 1 7 8 9 0 1 2 3 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "<class 'numpy.ndarray'> (0, 170)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "****************************** 6000 ******************************\n",
      "****************************** 8000 ******************************\n",
      "****************************** 10000 ******************************\n",
      "****************************** 12000 ******************************\n",
      "****************************** 14000 ******************************\n",
      "****************************** 16000 ******************************\n",
      "****************************** 18000 ******************************\n",
      "****************************** 20000 ******************************\n",
      "****************************** 22000 ******************************\n",
      "****************************** 24000 ******************************\n",
      "****************************** 26000 ******************************\n",
      "****************************** 28000 ******************************\n",
      "****************************** 30000 ******************************\n",
      "****************************** 32000 ******************************\n",
      "****************************** 34000 ******************************\n",
      "****************************** 36000 ******************************\n",
      "****************************** 38000 ******************************\n",
      "****************************** 40000 ******************************\n",
      "****************************** 42000 ******************************\n",
      "****************************** 44000 ******************************\n",
      "****************************** 46000 ******************************\n",
      "****************************** 48000 ******************************\n",
      "****************************** 50000 ******************************\n",
      "****************************** 52000 ******************************\n",
      "****************************** 54000 ******************************\n",
      "****************************** 56000 ******************************\n",
      "****************************** 58000 ******************************\n",
      "****************************** 1999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 7 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 9 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 7 1 7 3 2 8 7 7 6 2 7 8 4 7 3 6 1 3 6 4 3 1 9 1 4 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 9 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 4 1 8 2 0 2 ... 4 3 9 6 9 6 8 3 6 6 8 5 1 4 2 4 4 5 1 4 9 0 2 4 9 5 7 1 8 3 5 6 9 8 7 1 1 6 7 6 3 2 2 0 8 9\n",
      " 2 3 1 0 8 1 4 5 7 9 6 9 0 6 1 5 5 8 3 8 2 6 5 0 7 4 6 1 3 2 7 3 2 3 4 2 5 2 7 1 7 2 6 4 1 5 9 8 6 0 1 8 2 5 7 7 6 3 3 5 2 4 2 4 0 8 8 3 4 9 1 7 5 8 6 3 6 0 3 6 7 3 6 4 4 4 6 5 3 0 4 1 0 4 4 6 2 9 1\n",
      " 1 0 6 3 9]\n",
      "ndx_errs (array([   9,   48,   73,   78,   92,   95,   97,  115,  121,  144,  151,  158,  165,  173,  184,  206,  207,  217,  232,  241,  247,  250,  259,  266,  282,  307,  316,  318,  320,  338,  340,  359,\n",
      "        362,  369,  376,  386,  391,  405,  406,  436,  444,  445,  447,  448,  457,  464,  468,  479,  486,  493,  495,  497,  498,  502,  505,  507,  510,  519,  542,  543,  551,  565,  571,  578,\n",
      "        582,  583,  591,  605,  610,  619,  627,  628,  645,  654,  659,  684,  691,  694,  708,  716,  717,  720,  726,  740,  751,  752,  760,  781,  785,  786,  791,  810,  813,  823,  829,  841,\n",
      "        844,  846,  877,  881,  898,  899,  902,  916,  924,  938,  951,  955,  956,  958,  960,  965,  966,  987,  999, 1003, 1010, 1014, 1033, 1039, 1052, 1063, 1069, 1072, 1074, 1077, 1089, 1107,\n",
      "       1108, 1112, 1125, 1156, 1164, 1169, 1173, 1178, 1181, 1182, 1194, 1198, 1204, 1212, 1217, 1219, 1226, 1228, 1247, 1248, 1263, 1270, 1288, 1289, 1299, 1314, 1319, 1326, 1328, 1331, 1334, 1339,\n",
      "       1352, 1363, 1364, 1391, 1393, 1398, 1414, 1444, 1458, 1464, 1465, 1466, 1467, 1476, 1480, 1488, 1492, 1494, 1500, 1510, 1522, 1523, 1525, 1527, 1530, 1543, 1549, 1553, 1559, 1562, 1581, 1626,\n",
      "       1631, 1634, 1637, 1641, 1648, 1670, 1681, 1686, 1695, 1697, 1702, 1709, 1718, 1721, 1732, 1735, 1737, 1754, 1760, 1769, 1779, 1790, 1811, 1847, 1850, 1868, 1878, 1896, 1901, 1924, 1941, 1952,\n",
      "       1955, 1965, 1970, 1973, 1979, 1982, 1984, 1988], dtype=int64),)\n",
      "num correct is  1767  an accuracy of  0.8839419709854928\n",
      "****************************** 3999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 7 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 9 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 7 1 7 3 2 8 7 7 6 2 7 8 4 7 3 6 1 3 6 4 3 1 9 1 4 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 9 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 4 1 8 2 0 2 ... 0 9 1 1 6 7 8 9 9 1 9 5 9 2 5 0 4 1 0 8 4 0 5 9 8 9 4 2 5 7 9 8 9 8 0 4 9 6 8 9 9 5 9 8 6 1\n",
      " 0 3 8 5 2 1 6 3 0 2 8 1 5 8 2 3 0 2 2 6 4 8 5 5 1 7 2 1 6 9 1 3 9 5 5 1 6 2 2 8 6 7 1 4 6 0 6 0 3 3 2 2 3 6 8 9 8 5 2 8 5 4 5 2 0 5 6 8 2 8 3 9 9 3 7 9 4 6 7 1 3 7 3 6 6 0 9 0 1 9 9 2 8 3 0 1 6 9 7\n",
      " 5 3 4 7 4]\n",
      "ndx_errs (array([   9,   48,   73,   78,   92,   95,   97,  115,  121,  144,  151,  158,  165,  173,  184,  206,  207,  217,  232,  241,  247,  250,  259,  266,  282,  307,  316,  318,  320,  338,  340,  359,\n",
      "        362,  369,  376,  386,  391,  405,  406,  436,  444,  445,  447,  448,  457,  464,  468,  479,  486,  493,  495,  497,  498,  502,  505,  507,  510,  519,  542,  543,  551,  565,  571,  578,\n",
      "        582,  583,  591,  605,  610,  619,  627,  628,  645,  654,  659,  684,  691,  694,  708,  716,  717,  720,  726,  740,  751,  752,  760,  781,  785,  786,  791,  810,  813,  823,  829,  841,\n",
      "        844,  846,  877,  881,  898,  899,  902,  916,  924,  938,  951,  955,  956,  958,  960,  965,  966,  987,  999, 1003, 1010, 1014, 1033, 1039, 1052, 1063, 1069, 1072, 1074, 1077, 1089, 1107,\n",
      "       1108, 1112, 1125, 1156, 1164, 1169, 1173, 1178, 1181, 1182, 1194, 1198, 1204, 1212, 1217, 1219, 1226, 1228, 1247, 1248, 1263, 1270, 1288, 1289, 1299, 1314, 1319, 1326, 1328, 1331, 1334, 1339,\n",
      "       1352, 1363, 1364, 1391, 1393, 1398, 1414, 1444, 1458, 1464, 1465, 1466, 1467, 1476, 1480, 1488, 1492, 1494, 1500, 1510, 1522, 1523, 1525, 1527, 1530, 1543, 1549, 1553, 1559, 1562, 1581, 1626,\n",
      "       1631, 1634, 1637, 1641, 1648, 1670, 1681, 1686, 1695, 1697, 1702, 1709, 1718, 1721, 1732, 1735, 1737, 1754, 1760, 1769, 1779, 1790, 1811, 1847, 1850, 1868, 1878, 1896, 1901, 1924, 1941, 1952,\n",
      "       1955, 1965, 1970, 1973, 1979, 1982, 1984, 1988, 1999, 2018, 2028, 2040, 2043, 2052, 2053, 2056, 2070, 2073, 2080, 2093, 2094, 2098, 2099, 2101, 2107, 2109, 2118, 2130, 2135, 2148, 2168, 2177,\n",
      "       2182, 2186, 2189, 2197, 2199, 2218, 2224, 2229, 2237, 2247, 2266, 2272, 2282, 2291, 2292, 2293, 2298, 2300, 2308, 2322, 2325, 2334, 2343, 2358, 2363, 2365, 2371, 2386, 2387, 2393, 2395, 2400,\n",
      "       2406, 2414, 2422, 2423, 2440, 2447, 2450, 2454, 2456, 2462, 2464, 2495, 2498, 2512, 2515, 2516, 2526, 2539, 2540, 2556, 2559, 2560, 2574, 2604, 2607, 2628, 2648, 2651, 2653, 2654, 2659, 2668,\n",
      "       2683, 2686, 2705, 2713, 2730, 2745, 2750, 2758, 2760, 2771, 2773, 2775, 2780, 2802, 2803, 2810, 2823, 2832, 2834, 2847, 2848, 2850, 2851, 2852, 2853, 2862, 2882, 2896, 2914, 2927, 2934, 2938,\n",
      "       2939, 2945, 2951, 2953, 2956, 2970, 2976, 2986, 2990, 2995, 2998, 3023, 3029, 3030, 3038, 3056, 3062, 3073, 3091, 3100, 3102, 3107, 3115, 3117, 3129, 3132, 3136, 3138, 3145, 3153, 3171, 3172,\n",
      "       3186, 3202, 3208, 3235, 3240, 3246, 3254, 3260, 3261, 3262, 3264, 3291, 3300, 3303, 3319, 3329, 3330, 3333, 3336, 3341, 3369, 3373, 3376, 3404, 3410, 3414, 3427, 3429, 3437, 3440, 3457, 3467,\n",
      "       3469, 3473, 3475, 3499, 3503, 3511, 3542, 3549, 3550, 3558, 3559, 3563, 3573, 3591, 3597, 3604, 3618, 3629, 3670, 3674, 3686, 3691, 3702, 3709, 3716, 3718, 3722, 3723, 3726, 3728, 3763, 3767,\n",
      "       3771, 3778, 3780, 3789, 3806, 3808, 3811, 3821, 3834, 3838, 3855, 3869, 3871, 3884, 3893, 3897, 3902, 3908, 3916, 3926, 3941, 3953, 3962, 3968, 3988], dtype=int64),)\n",
      "num correct is  3526  an accuracy of  0.8817204301075269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 5999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 7 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 9 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 7 1 7 3 2 8 7 7 6 2 7 8 4 7 3 6 1 3 6 4 3 1 9 1 4 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 9 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 4 1 8 2 0 2 ... 2 3 4 5 6 4 8 4 3 3 1 3 7 3 2 8 0 9 3 9 9 0 9 1 1 5 8 2 6 3 2 1 8 3 2 6 3 6 2 2 1 0 3 3 1 9\n",
      " 2 1 9 6 0 4 6 1 9 3 8 7 8 9 6 5 8 3 3 7 1 6 1 0 2 6 2 3 4 2 3 4 4 6 0 0 2 0 1 2 2 4 3 6 7 0 9 0 1 2 3 4 8 6 7 8 9 0 1 2 8 4 5 6 7 8 9 8 6 5 0 6 0 9 9 1 9 3 3 0 4 3 9 1 4 0 5 3 2 1 3 4 0 7 6 0 1 7 0\n",
      " 6 8 9 3 1]\n",
      "ndx_errs (array([   9,   48,   73,   78,   92,   95,   97,  115,  121,  144,  151,  158,  165,  173,  184,  206,  207,  217,  232,  241,  247,  250,  259,  266,  282,  307,  316,  318,  320,  338,  340,  359,\n",
      "        362,  369,  376,  386,  391,  405,  406,  436,  444,  445,  447,  448,  457,  464,  468,  479,  486,  493,  495,  497,  498,  502,  505,  507,  510,  519,  542,  543,  551,  565,  571,  578,\n",
      "        582,  583,  591,  605,  610,  619,  627,  628,  645,  654,  659,  684,  691,  694,  708,  716,  717,  720,  726,  740,  751,  752,  760,  781,  785,  786,  791,  810,  813,  823,  829,  841,\n",
      "        844,  846,  877,  881,  898,  899,  902,  916,  924,  938,  951,  955,  956,  958,  960,  965,  966,  987,  999, 1003, 1010, 1014, 1033, 1039, 1052, 1063, 1069, 1072, 1074, 1077, 1089, 1107,\n",
      "       1108, 1112, 1125, 1156, 1164, 1169, 1173, 1178, 1181, 1182, 1194, 1198, 1204, 1212, 1217, 1219, 1226, 1228, 1247, 1248, 1263, 1270, 1288, 1289, 1299, 1314, 1319, 1326, 1328, 1331, 1334, 1339,\n",
      "       1352, 1363, 1364, 1391, 1393, 1398, 1414, 1444, 1458, 1464, 1465, 1466, 1467, 1476, 1480, 1488, 1492, 1494, 1500, 1510, 1522, 1523, 1525, 1527, 1530, 1543, 1549, 1553, 1559, 1562, 1581, 1626,\n",
      "       1631, 1634, 1637, 1641, 1648, 1670, 1681, 1686, 1695, 1697, 1702, 1709, 1718, 1721, 1732, 1735, 1737, 1754, 1760, 1769, 1779, 1790, 1811, 1847, 1850, 1868, 1878, 1896, 1901, 1924, 1941, 1952,\n",
      "       1955, 1965, 1970, 1973, 1979, 1982, 1984, 1988, 1999, 2018, 2028, 2040, 2043, 2052, 2053, 2056, 2070, 2073, 2080, 2093, 2094, 2098, 2099, 2101, 2107, 2109, 2118, 2130, 2135, 2148, 2168, 2177,\n",
      "       2182, 2186, 2189, 2197, 2199, 2218, 2224, 2229, 2237, 2247, 2266, 2272, 2282, 2291, 2292, 2293, 2298, 2300, 2308, 2322, 2325, 2334, 2343, 2358, 2363, 2365, 2371, 2386, 2387, 2393, 2395, 2400,\n",
      "       2406, 2414, 2422, 2423, 2440, 2447, 2450, 2454, 2456, 2462, 2464, 2495, 2498, 2512, 2515, 2516, 2526, 2539, 2540, 2556, 2559, 2560, 2574, 2604, 2607, 2628, 2648, 2651, 2653, 2654, 2659, 2668,\n",
      "       2683, 2686, 2705, 2713, 2730, 2745, 2750, 2758, 2760, 2771, 2773, 2775, 2780, 2802, 2803, 2810, 2823, 2832, 2834, 2847, 2848, 2850, 2851, 2852, 2853, 2862, 2882, 2896, 2914, 2927, 2934, 2938,\n",
      "       2939, 2945, 2951, 2953, 2956, 2970, 2976, 2986, 2990, 2995, 2998, 3023, 3029, 3030, 3038, 3056, 3062, 3073, 3091, 3100, 3102, 3107, 3115, 3117, 3129, 3132, 3136, 3138, 3145, 3153, 3171, 3172,\n",
      "       3186, 3202, 3208, 3235, 3240, 3246, 3254, 3260, 3261, 3262, 3264, 3291, 3300, 3303, 3319, 3329, 3330, 3333, 3336, 3341, 3369, 3373, 3376, 3404, 3410, 3414, 3427, 3429, 3437, 3440, 3457, 3467,\n",
      "       3469, 3473, 3475, 3499, 3503, 3511, 3542, 3549, 3550, 3558, 3559, 3563, 3573, 3591, 3597, 3604, 3618, 3629, 3670, 3674, 3686, 3691, 3702, 3709, 3716, 3718, 3722, 3723, 3726, 3728, 3763, 3767,\n",
      "       3771, 3778, 3780, 3789, 3806, 3808, 3811, 3821, 3834, 3838, 3855, 3869, 3871, 3884, 3893, 3897, 3902, 3908, 3916, 3926, 3941, 3953, 3962, 3968, 3988, 4001, 4007, 4015, 4031, 4053, 4063, 4068,\n",
      "       4072, 4075, 4078, 4086, 4094, 4097, 4111, 4116, 4118, 4123, 4145, 4157, 4159, 4176, 4194, 4196, 4201, 4207, 4211, 4224, 4228, 4238, 4253, 4266, 4269, 4271, 4283, 4284, 4289, 4294, 4300, 4302,\n",
      "       4313, 4315, 4321, 4325, 4338, 4350, 4355, 4360, 4364, 4379, 4384, 4411, 4415, 4433, 4437, 4443, 4489, 4494, 4497, 4500, 4514, 4534, 4536, 4540, 4548, 4567, 4569, 4575, 4578, 4598, 4639, 4643,\n",
      "       4660, 4690, 4695, 4696, 4702, 4723, 4724, 4731, 4736, 4743, 4746, 4759, 4761, 4772, 4777, 4783, 4785, 4789, 4794, 4807, 4814, 4827, 4828, 4841, 4855, 4860, 4866, 4874, 4879, 4880, 4890, 4893,\n",
      "       4894, 4895, 4911, 4924, 4942, 4943, 4950, 4956, 4963, 4966, 4971, 4976, 4978, 4990, 5011, 5038, 5061, 5062, 5084, 5104, 5121, 5127, 5129, 5143, 5159, 5173, 5194, 5207, 5239, 5242, 5269, 5299,\n",
      "       5311, 5409, 5429, 5464, 5504, 5518, 5522, 5528, 5530, 5532, 5533, 5560, 5569, 5579, 5586, 5601, 5608, 5616, 5623, 5634, 5635, 5642, 5649, 5654, 5661, 5662, 5687, 5705, 5709, 5718, 5745, 5747,\n",
      "       5749, 5754, 5769, 5802, 5804, 5835, 5841, 5845, 5854, 5856, 5857, 5858, 5862, 5866, 5867, 5876, 5885, 5887, 5888, 5891, 5903, 5907, 5913, 5919, 5922, 5935, 5937, 5940, 5947, 5955, 5967, 5969,\n",
      "       5972, 5976, 5982, 5985, 5997], dtype=int64),)\n",
      "num correct is  5322  an accuracy of  0.8871478579763294\n",
      "****************************** 7999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 7 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 9 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 7 1 7 3 2 8 7 7 6 2 7 8 4 7 3 6 1 3 6 4 3 1 9 1 4 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 9 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 4 1 8 2 0 2 ... 3 8 6 7 8 9 0 8 2 3 5 2 7 8 9 9 7 0 9 0 1 3 8 8 0 9 3 2 7 8 4 6 1 0 4 9 4 2 0 8 0 1 6 9 3 2\n",
      " 9 1 6 0 1 8 8 8 7 8 3 6 0 7 2 4 1 7 0 2 8 8 2 5 8 8 7 2 8 9 6 8 7 8 5 2 9 3 0 1 2 3 4 5 6 7 8 7 0 1 2 2 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 8 9 5 7 0 3 1 6 0 4 1 5 6 4 2 7 8 1 3 6 3 4 7 2 0 5 0 8 9 2 5\n",
      " 2 3 5 5 7]\n",
      "ndx_errs (array([   9,   48,   73,   78,   92,   95,   97,  115,  121,  144,  151,  158,  165,  173,  184,  206,  207,  217,  232,  241,  247,  250,  259,  266,  282,  307,  316,  318,  320,  338,  340,  359,\n",
      "        362,  369,  376,  386,  391,  405,  406,  436,  444,  445,  447,  448,  457,  464,  468,  479,  486,  493,  495,  497,  498,  502,  505,  507,  510,  519,  542,  543,  551,  565,  571,  578,\n",
      "        582,  583,  591,  605,  610,  619,  627,  628,  645,  654,  659,  684,  691,  694,  708,  716,  717,  720,  726,  740,  751,  752,  760,  781,  785,  786,  791,  810,  813,  823,  829,  841,\n",
      "        844,  846,  877,  881,  898,  899,  902,  916,  924,  938,  951,  955,  956,  958,  960,  965,  966,  987,  999, 1003, 1010, 1014, 1033, 1039, 1052, 1063, 1069, 1072, 1074, 1077, 1089, 1107,\n",
      "       1108, 1112, 1125, 1156, 1164, 1169, 1173, 1178, 1181, 1182, 1194, 1198, 1204, 1212, 1217, 1219, 1226, 1228, 1247, 1248, 1263, 1270, 1288, 1289, 1299, 1314, 1319, 1326, 1328, 1331, 1334, 1339,\n",
      "       1352, 1363, 1364, 1391, 1393, 1398, 1414, 1444, 1458, 1464, 1465, 1466, 1467, 1476, 1480, 1488, 1492, 1494, 1500, 1510, 1522, 1523, 1525, 1527, 1530, 1543, 1549, 1553, 1559, 1562, 1581, 1626,\n",
      "       1631, 1634, 1637, 1641, 1648, 1670, 1681, 1686, 1695, 1697, 1702, 1709, 1718, 1721, 1732, 1735, 1737, 1754, 1760, 1769, 1779, 1790, 1811, 1847, 1850, 1868, 1878, 1896, 1901, 1924, 1941, 1952,\n",
      "       1955, 1965, 1970, 1973, 1979, 1982, 1984, 1988, 1999, 2018, 2028, 2040, 2043, 2052, 2053, 2056, 2070, 2073, 2080, 2093, 2094, 2098, 2099, 2101, 2107, 2109, 2118, 2130, 2135, 2148, 2168, 2177,\n",
      "       2182, 2186, 2189, 2197, 2199, 2218, 2224, 2229, 2237, 2247, 2266, 2272, 2282, 2291, 2292, 2293, 2298, 2300, 2308, 2322, 2325, 2334, 2343, 2358, 2363, 2365, 2371, 2386, 2387, 2393, 2395, 2400,\n",
      "       2406, 2414, 2422, 2423, 2440, 2447, 2450, 2454, 2456, 2462, 2464, 2495, 2498, 2512, 2515, 2516, 2526, 2539, 2540, 2556, 2559, 2560, 2574, 2604, 2607, 2628, 2648, 2651, 2653, 2654, 2659, 2668,\n",
      "       2683, 2686, 2705, 2713, 2730, 2745, 2750, 2758, 2760, 2771, 2773, 2775, 2780, 2802, 2803, 2810, 2823, 2832, 2834, 2847, 2848, 2850, 2851, 2852, 2853, 2862, 2882, 2896, 2914, 2927, 2934, 2938,\n",
      "       2939, 2945, 2951, 2953, 2956, 2970, 2976, 2986, 2990, 2995, 2998, 3023, 3029, 3030, 3038, 3056, 3062, 3073, 3091, 3100, 3102, 3107, 3115, 3117, 3129, 3132, 3136, 3138, 3145, 3153, 3171, 3172,\n",
      "       3186, 3202, 3208, 3235, 3240, 3246, 3254, 3260, 3261, 3262, 3264, 3291, 3300, 3303, 3319, 3329, 3330, 3333, 3336, 3341, 3369, 3373, 3376, 3404, 3410, 3414, 3427, 3429, 3437, 3440, 3457, 3467,\n",
      "       3469, 3473, 3475, 3499, 3503, 3511, 3542, 3549, 3550, 3558, 3559, 3563, 3573, 3591, 3597, 3604, 3618, 3629, 3670, 3674, 3686, 3691, 3702, 3709, 3716, 3718, 3722, 3723, 3726, 3728, 3763, 3767,\n",
      "       3771, 3778, 3780, 3789, 3806, 3808, 3811, 3821, 3834, 3838, 3855, 3869, 3871, 3884, 3893, 3897, 3902, 3908, 3916, 3926, 3941, 3953, 3962, 3968, 3988, 4001, 4007, 4015, 4031, 4053, 4063, 4068,\n",
      "       4072, 4075, 4078, 4086, 4094, 4097, 4111, 4116, 4118, 4123, 4145, 4157, 4159, 4176, 4194, 4196, 4201, 4207, 4211, 4224, 4228, 4238, 4253, 4266, 4269, 4271, 4283, 4284, 4289, 4294, 4300, 4302,\n",
      "       4313, 4315, 4321, 4325, 4338, 4350, 4355, 4360, 4364, 4379, 4384, 4411, 4415, 4433, 4437, 4443, 4489, 4494, 4497, 4500, 4514, 4534, 4536, 4540, 4548, 4567, 4569, 4575, 4578, 4598, 4639, 4643,\n",
      "       4660, 4690, 4695, 4696, 4702, 4723, 4724, 4731, 4736, 4743, 4746, 4759, 4761, 4772, 4777, 4783, 4785, 4789, 4794, 4807, 4814, 4827, 4828, 4841, 4855, 4860, 4866, 4874, 4879, 4880, 4890, 4893,\n",
      "       4894, 4895, 4911, 4924, 4942, 4943, 4950, 4956, 4963, 4966, 4971, 4976, 4978, 4990, 5011, 5038, 5061, 5062, 5084, 5104, 5121, 5127, 5129, 5143, 5159, 5173, 5194, 5207, 5239, 5242, 5269, 5299,\n",
      "       5311, 5409, 5429, 5464, 5504, 5518, 5522, 5528, 5530, 5532, 5533, 5560, 5569, 5579, 5586, 5601, 5608, 5616, 5623, 5634, 5635, 5642, 5649, 5654, 5661, 5662, 5687, 5705, 5709, 5718, 5745, 5747,\n",
      "       5749, 5754, 5769, 5802, 5804, 5835, 5841, 5845, 5854, 5856, 5857, 5858, 5862, 5866, 5867, 5876, 5885, 5887, 5888, 5891, 5903, 5907, 5913, 5919, 5922, 5935, 5937, 5940, 5947, 5955, 5967, 5969,\n",
      "       5972, 5976, 5982, 5985, 5997, 6006, 6024, 6026, 6028, 6035, 6037, 6043, 6046, 6049, 6053, 6056, 6065, 6071, 6077, 6080, 6081, 6083, 6084, 6085, 6091, 6093, 6101, 6113, 6120, 6126, 6142, 6155,\n",
      "       6157, 6160, 6165, 6166, 6168, 6173, 6174, 6223, 6302, 6303, 6304, 6348, 6349, 6356, 6379, 6386, 6390, 6395, 6425, 6434, 6458, 6460, 6471, 6481, 6490, 6501, 6504, 6505, 6544, 6553, 6555, 6560,\n",
      "       6568, 6625, 6636, 6641, 6642, 6643, 6646, 6651, 6658, 6706, 6708, 6721, 6740, 6744, 6747, 6755, 6761, 6783, 6788, 6796, 6806, 6813, 6834, 6850, 6864, 6866, 6886, 6894, 6941, 6962, 6964, 6977,\n",
      "       6988, 7032, 7040, 7066, 7094, 7102, 7104, 7128, 7130, 7153, 7177, 7206, 7216, 7233, 7238, 7260, 7268, 7277, 7287, 7293, 7297, 7302, 7309, 7315, 7333, 7338, 7361, 7366, 7370, 7376, 7397, 7434,\n",
      "       7448, 7459, 7471, 7478, 7491, 7498, 7509, 7524, 7534, 7538, 7545, 7569, 7584, 7595, 7605, 7619, 7637, 7656, 7659, 7672, 7718, 7732, 7736, 7746, 7756, 7757, 7764, 7777, 7788, 7797, 7807, 7808,\n",
      "       7812, 7822, 7842, 7847, 7850, 7856, 7860, 7870, 7888, 7900, 7902, 7904, 7914, 7915, 7916, 7920, 7921, 7924, 7928, 7929, 7942, 7946, 7971, 7982, 7990, 7993], dtype=int64),)\n",
      "num correct is  7141  an accuracy of  0.8927365920740092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 9999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 7 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 9 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 7 1 7 3 2 8 7 7 6 2 7 8 4 7 3 6 1 3 6 4 3 1 9 1 4 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 9 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 4 1 8 2 0 2 ... 2 0 7 7 5 6 2 9 8 0 7 3 4 6 8 7 0 4 8 7 7 5 4 3 0 2 8 1 5 1 0 8 3 3 6 7 0 6 8 6 3 9 9 5 8 7\n",
      " 7 1 0 1 7 8 9 0 1 0 9 0 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 9 1 9 8 8 4 4 7 0 1 9 2 8 7 5 2 6 0 6 5 3 8 5 9 1 2 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 3 2 4 4 4 3 4 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0\n",
      " 1 2 5 4 5]\n",
      "ndx_errs (array([   9,   48,   73,   78,   92,   95,   97,  115,  121,  144,  151,  158,  165,  173,  184,  206,  207,  217,  232,  241,  247,  250,  259,  266,  282,  307,  316,  318,  320,  338,  340,  359,\n",
      "        362,  369,  376,  386,  391,  405,  406,  436,  444,  445,  447,  448,  457,  464,  468,  479,  486,  493,  495,  497,  498,  502,  505,  507,  510,  519,  542,  543,  551,  565,  571,  578,\n",
      "        582,  583,  591,  605,  610,  619,  627,  628,  645,  654,  659,  684,  691,  694,  708,  716,  717,  720,  726,  740,  751,  752,  760,  781,  785,  786,  791,  810,  813,  823,  829,  841,\n",
      "        844,  846,  877,  881,  898,  899,  902,  916,  924,  938,  951,  955,  956,  958,  960,  965,  966,  987,  999, 1003, 1010, 1014, 1033, 1039, 1052, 1063, 1069, 1072, 1074, 1077, 1089, 1107,\n",
      "       1108, 1112, 1125, 1156, 1164, 1169, 1173, 1178, 1181, 1182, 1194, 1198, 1204, 1212, 1217, 1219, 1226, 1228, 1247, 1248, 1263, 1270, ..., 8325, 8332, 8375, 8376, 8379, 8393, 8406, 8408, 8410,\n",
      "       8413, 8422, 8447, 8453, 8457, 8469, 8486, 8487, 8493, 8502, 8507, 8509, 8511, 8520, 8522, 8529, 8553, 8582, 8597, 8601, 8603, 8613, 8676, 8684, 8702, 8708, 8713, 8757, 8759, 8777, 8821, 8866,\n",
      "       8954, 8984, 8998, 9007, 9009, 9010, 9015, 9019, 9022, 9024, 9033, 9036, 9045, 9067, 9071, 9075, 9099, 9110, 9115, 9169, 9172, 9183, 9202, 9203, 9210, 9211, 9214, 9224, 9225, 9231, 9248, 9257,\n",
      "       9280, 9316, 9354, 9382, 9391, 9398, 9400, 9422, 9427, 9450, 9465, 9478, 9482, 9505, 9534, 9536, 9537, 9538, 9539, 9541, 9542, 9548, 9580, 9587, 9610, 9624, 9625, 9662, 9664, 9669, 9692, 9700,\n",
      "       9711, 9713, 9716, 9719, 9733, 9734, 9737, 9738, 9740, 9741, 9745, 9746, 9749, 9767, 9768, 9770, 9771, 9773, 9779, 9811, 9817, 9832, 9839, 9854, 9858, 9867, 9873, 9880, 9883, 9892, 9893, 9904,\n",
      "       9905, 9906, 9922, 9925, 9936, 9943, 9944, 9947, 9970, 9973, 9976, 9982, 9996], dtype=int64),)\n",
      "num correct is  8961  an accuracy of  0.8961896189618962\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 7 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 9 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 7 1 7 3 2 8 7 7 6 2 7 8 4 7 3 6 1 3 6 4 3 1 9 1 4 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 9 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 4 1 8 2 0 2 ... 0 7 7 5 6 2 9 8 0 7 3 4 6 8 7 0 4 8 7 7 5 4 3 0 2 8 1 5 1 0 8 3 3 6 7 0 6 8 6 3 9 9 5 8 7 7\n",
      " 1 0 1 7 8 9 0 1 0 9 0 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 9 1 9 8 8 4 4 7 0 1 9 2 8 7 5 2 6 0 6 5 3 8 5 9 1 2 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 3 2 4 4 4 3 4 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 5 4 5 6]\n",
      "ndx_errs (array([   9,   48,   73,   78,   92,   95,   97,  115,  121,  144,  151,  158,  165,  173,  184,  206,  207,  217,  232,  241,  247,  250,  259,  266,  282,  307,  316,  318,  320,  338,  340,  359,\n",
      "        362,  369,  376,  386,  391,  405,  406,  436,  444,  445,  447,  448,  457,  464,  468,  479,  486,  493,  495,  497,  498,  502,  505,  507,  510,  519,  542,  543,  551,  565,  571,  578,\n",
      "        582,  583,  591,  605,  610,  619,  627,  628,  645,  654,  659,  684,  691,  694,  708,  716,  717,  720,  726,  740,  751,  752,  760,  781,  785,  786,  791,  810,  813,  823,  829,  841,\n",
      "        844,  846,  877,  881,  898,  899,  902,  916,  924,  938,  951,  955,  956,  958,  960,  965,  966,  987,  999, 1003, 1010, 1014, 1033, 1039, 1052, 1063, 1069, 1072, 1074, 1077, 1089, 1107,\n",
      "       1108, 1112, 1125, 1156, 1164, 1169, 1173, 1178, 1181, 1182, 1194, 1198, 1204, 1212, 1217, 1219, 1226, 1228, 1247, 1248, 1263, 1270, ..., 8325, 8332, 8375, 8376, 8379, 8393, 8406, 8408, 8410,\n",
      "       8413, 8422, 8447, 8453, 8457, 8469, 8486, 8487, 8493, 8502, 8507, 8509, 8511, 8520, 8522, 8529, 8553, 8582, 8597, 8601, 8603, 8613, 8676, 8684, 8702, 8708, 8713, 8757, 8759, 8777, 8821, 8866,\n",
      "       8954, 8984, 8998, 9007, 9009, 9010, 9015, 9019, 9022, 9024, 9033, 9036, 9045, 9067, 9071, 9075, 9099, 9110, 9115, 9169, 9172, 9183, 9202, 9203, 9210, 9211, 9214, 9224, 9225, 9231, 9248, 9257,\n",
      "       9280, 9316, 9354, 9382, 9391, 9398, 9400, 9422, 9427, 9450, 9465, 9478, 9482, 9505, 9534, 9536, 9537, 9538, 9539, 9541, 9542, 9548, 9580, 9587, 9610, 9624, 9625, 9662, 9664, 9669, 9692, 9700,\n",
      "       9711, 9713, 9716, 9719, 9733, 9734, 9737, 9738, 9740, 9741, 9745, 9746, 9749, 9767, 9768, 9770, 9771, 9773, 9779, 9811, 9817, 9832, 9839, 9854, 9858, 9867, 9873, 9880, 9883, 9892, 9893, 9904,\n",
      "       9905, 9906, 9922, 9925, 9936, 9943, 9944, 9947, 9970, 9973, 9976, 9982, 9996], dtype=int64),)\n",
      "num correct is  8962  an accuracy of  0.8962\n",
      "2020-06-01 11:42:38.589618 end\n"
     ]
    }
   ],
   "source": [
    "Config.USE_PARENT_CENTROIDS=True\n",
    "Config.OVERLAP_QUADS_RATIO=0.125\n",
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.USE_PARENT_CENTROIDS=False\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "Config.OVERLAP_QUADS_RATIO=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s2weightcentroids'></a>\n",
    "<a href='#toc'>Goto Table of Contents</a>\n",
    "\n",
    "## Try weighted centroids (no overlap) with image\n",
    "\n",
    "- kNN acc (6,000      ; 60,000 93.6%)\n",
    "\n",
    "## whereas the baseline is\n",
    "\n",
    "## kNN acc (6,000 91.6% 60,000 96.88%)\n",
    "## CNN acc (6,000 96.06% (+/- 1.42%); 60,000 99.00% (+/- 0.21%))\n",
    "\n",
    "## This is no improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-01 06:33:49.154334 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 9 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 9 8 7 2 3 0 4 4 2 4 1 9 5 7 7 2 8 2 6 8 5 7 7 9 1 8 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 9 2 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 8 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 2 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 3 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 6 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 3 8 8 2 7 5 8 9 6 1 8 4 1 2 5 9 1 9 7 5 4 0 8 9 9 1 0 5 2 3 7\n",
      " 8 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 8 4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 2 1 7 0 6 5 4 3 8 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 2 3 1 9 7 5 1 0 8 4 6 2 6 7 9 3 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 5 8 0 3 7 2 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 7 8 3 3 6 7 2 8 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 8 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5 4 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 5\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 8 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 8 8 8 7 4 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 2 3 2 3 9 1 7 4 0 3 5 5 8 6 3 2 6 7 6 6 3 2 7 8 1 1 7 5 6 4 9 5 1 3 3 4 7 8 9 1 1 6 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "<class 'numpy.ndarray'> (0, 128)\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 9 9 8 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 3 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 7 7 9 2 2 4 1 5 8 8 4 2 3 0 6 4 2 9 1 9 5 7 7 2 6 2 6 8 5 7 7 4 1 0 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 7 7 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 5 6 5 4 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 7 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 7 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 8 0 6 4 8 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 7 8 8 2 7 5 8 9 6 1 8 4 1 2 5 8 1 9 7 5 4 0 8 9 7 1 0 5 8 3 7\n",
      " 0 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 7 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 3 4 0 0 8 3 2 9 4 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 7 1 7 0 6 5 4 3 3 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 8 3 1 9 7 5 1 0 8 4 6 2 6 7 9 9 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 0 8 0 3 7 8 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 9 8 3 3 6 7 2 9 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 3 2 7 6 8 4 5 0 4 0 6 1 4 3 2 6 7 2 6 9 3 1 4 6 3 5 9 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 9 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 3 6 8 9 4 1 9\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 9 0 1 7 7 4 7 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 2 8 8 7 9 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 7 3 0 3 9 1 4 4 0 3 5 5 8 6 3 0 6 7 6 6 3 2 7 9 1 1 7 9 6 4 9 6 1 5 3 4 7 8 7 1 1 0 9 1 4 4 5 4 0 6 2 2 8 1 5 1 2 0 8 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "ndx_errs (array([149, 151, 187, 233, 241, 243, 247, 250, 257, 264, 266, 320, 321, 338, 341, 362, 381, 444, 445, 448, 464, 479, 488, 492, 495, 511, 543, 547, 550, 551, 583, 591, 613, 628, 654, 659, 684, 691,\n",
      "       714, 716, 717, 726, 738, 740, 760, 785, 791, 838, 839, 844, 877, 881, 924, 926, 930, 939, 947, 951, 955, 957, 962, 965, 976, 982], dtype=int64),)\n",
      "num correct is  936  an accuracy of  0.9359999999999999\n",
      "2020-06-01 06:35:55.392347 end\n"
     ]
    }
   ],
   "source": [
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=6_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=1_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s2treesizesweighted'></a>\n",
    "<a href='#toc'>Goto Table of Contents</a>\n",
    "\n",
    "## Try different sizes for the tree of weighted centroids\n",
    "\n",
    "\n",
    "## whereas the baseline is\n",
    "\n",
    "## kNN acc (6,000 91.6% 60,000 96.88%)\n",
    "## CNN acc (6,000 96.06% (+/- 1.42%); 60,000 99.00% (+/- 0.21%))\n",
    "\n",
    "### A tree size of 3 seems to be best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-31 15:22:21.258761 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 9 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 9 8 7 2 3 0 4 4 2 4 1 9 5 7 7 2 8 2 6 8 5 7 7 9 1 8 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 9 2 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 8 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 2 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 3 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 6 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 3 8 8 2 7 5 8 9 6 1 8 4 1 2 5 9 1 9 7 5 4 0 8 9 9 1 0 5 2 3 7\n",
      " 8 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 8 4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 2 1 7 0 6 5 4 3 8 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 2 3 1 9 7 5 1 0 8 4 6 2 6 7 9 3 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 5 8 0 3 7 2 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 7 8 3 3 6 7 2 8 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 8 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5 4 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 5\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 8 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 8 8 8 7 4 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 2 3 2 3 9 1 7 4 0 3 5 5 8 6 3 2 6 7 6 6 3 2 7 8 1 1 7 5 6 4 9 5 1 3 3 4 7 8 9 1 1 6 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "<class 'numpy.ndarray'> (0, 32)\n",
      "<class 'numpy.ndarray'> (0, 816)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 816)\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 9 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 7 1 7 3 2 9 7 9 6 2 7 8 4 7 3 6 1 3 6 4 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 9 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 3 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 7 7 9 2 2 4 1 5 8 8 7 2 6 0 6 4 2 9 1 9 5 7 7 2 6 2 6 8 5 7 7 4 1 0 1 3 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 9 2 9 2 0 4 0\n",
      " 0 2 8 1 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 1 7 9 3 6 4 6 0 7 1 1 2 1 5 3 3 9 7 5 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 4 9 4 6 7 2 5 0 6 8 6 3 7 2 0 8 8 5 4 1 1 4 0 7 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 0 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 7 8 8 2 7 5 8 9 6 1 8 4 1 2 5 8 1 9 7 5 4 0 8 9 9 1 0 5 8 3 7\n",
      " 0 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 4 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 3 4 0 0 8 3 2 4 1 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 9 8 3 3 9 3 3 3 7 8 0 8 7 1 7 0 6 5 4 3 3 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 8 3 1 9 7 5 1 0 8 4 6 2 6 7 9 9 2 9 8 2 2 9 1 7 3 5 9 1 8 0 2 0 5 6 1 3 7 6 7 1 2 0 8 0 3 7 7 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 1 8 3 3 6 9 2 4 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 5 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5 9 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 3 3 1 4 5 6 8 9 9 1 9\n",
      " 3 8 0 6 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 4 1 7 9 6 1 1 2 4 0 1 7 7 4 3 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 8 8 8 7 9 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 7 3 0 3 9 1 7 4 0 3 5 5 6 6 5 0 6 7 6 6 3 2 7 9 1 1 7 4 6 4 9 5 1 5 3 4 7 8 4 1 1 0 9 1 4 4 5 4 0 6 2 2 8 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "ndx_errs (array([ 24,  73,  80,  92, 115, 207, 233, 241, 245, 247, 250, 257, 264, 266, 268, 290, 300, 320, 321, 324, 326, 338, 358, 362, 367, 381, 445, 464, 479, 492, 495, 521, 543, 547, 550, 551, 571, 583,\n",
      "       591, 613, 628, 635, 646, 654, 659, 684, 689, 691, 714, 740, 781, 789, 791, 795, 830, 839, 844, 881, 924, 926, 936, 938, 939, 947, 951, 957, 962, 965, 976], dtype=int64),)\n",
      "num correct is  931  an accuracy of  0.931\n",
      "2020-05-31 15:23:45.278830 end\n"
     ]
    }
   ],
   "source": [
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=6_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=1_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=2\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-31 15:05:36.526985 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 9 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 9 8 7 2 3 0 4 4 2 4 1 9 5 7 7 2 8 2 6 8 5 7 7 9 1 8 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 9 2 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 8 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 2 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 3 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 6 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 3 8 8 2 7 5 8 9 6 1 8 4 1 2 5 9 1 9 7 5 4 0 8 9 9 1 0 5 2 3 7\n",
      " 8 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 8 4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 2 1 7 0 6 5 4 3 8 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 2 3 1 9 7 5 1 0 8 4 6 2 6 7 9 3 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 5 8 0 3 7 2 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 7 8 3 3 6 7 2 8 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 8 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5 4 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 5\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 8 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 8 8 8 7 4 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 2 3 2 3 9 1 7 4 0 3 5 5 8 6 3 2 6 7 6 6 3 2 7 8 1 1 7 5 6 4 9 5 1 3 3 4 7 8 9 1 1 6 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "<class 'numpy.ndarray'> (0, 512)\n",
      "<class 'numpy.ndarray'> (0, 1296)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 1296)\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 4 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 6 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 4 3 7 1 6 4 3 0 7 0 2 8 1 7 3 2 1 7 9 6 2 7 8 4 7 5 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 1 3 9 4 9 9 4 9 7 5 4 7 6 7 4 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 4 4 8 5 5 1 5 6 0 3 9 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 1 1 8 1 8 1 8 5 0 3 4 2 3 0 1 1 1 0 4 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 7 7 9 2 2 4 1 5 8 8 7 1 3 0 6 4 2 4 1 9 5 7 7 2 6 2 6 8 5 7 7 4 1 0 1 3 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 4 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 7 7 9 3 6 4 2 0 7 1 1 2 1 5 3 3 9 7 5 6 5 6 1 3 8 1 0 5 1 3 1 5 0 6 1 8 5 1 7 9 4 6 7 2 5 0 6 5 6 3 7 2 0 8 8 5 9 1 1 4 0 7 3 7 6 1 6 2 1 9 2 8 6 1 4 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 3 7 9 7 1 9 2 1 4 2 4 2 0 4 9 1 4 8 1 8 4 5 9 9 8 3 7 6 0 0 3 0 8 0 6 4 8 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 7 8 8 2 7 5 8 9 6 1 8 4 1 2 6 3 1 9 7 5 4 0 8 9 7 1 0 5 8 3 7\n",
      " 2 9 4 0 6 3 9 5 2 1 3 1 3 6 3 7 1 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 1 3 4 0 0 2 3 2 4 4 0 8 7 4 4 7 9 6 9 0 4 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 2 2 1 7 0 6 5 4 3 3 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 1 1 1 9 7 5 8 0 8 4 6 1 6 7 4 9 2 9 8 2 2 9 2 7 3 5 4 1 8 0 2 0 5 2 1 3 7 6 7 1 2 0 8 0 3 7 2 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 1 8 3 3 6 9 2 7 5\n",
      " 8 5 1 1 4 4 3 1 0 1 7 0 7 9 4 4 8 5 5 4 0 3 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5 9 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 7 9 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 3 6 8 9 9 1 9\n",
      " 3 8 0 6 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 6 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 3 1 7 7 4 2 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 4 2 8 3 5 2 6 5 6 0 8 2 9 2 8 2 8 8 7 4 4 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 7 1 4 7 4 7 3 9 8 6 4 7 1 2 1 2 2 3 7 3 0 3 9 1 4 9 0 3 5 5 5 6 3 2 6 7 6 6 3 2 7 8 1 1 7 4 6 4 9 5 6 3 0 4 7 8 9 1 1 0 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 8 8 1 2 6 7 1 6\n",
      " 2 3 4 0 1 2 2 0 8 4]\n",
      "ndx_errs (array([ 16,  33,  62,  65,  73,  78,  80,  87, 111, 114, 115, 116, 119, 125, 149, 150, 151, 159, 175, 184, 185, 187, 193, 233, 241, 244, 247, 257, 264, 266, 268, 290, 320, 321, 324, 338, 352, 362,\n",
      "       376, 381, 394, 412, 422, 435, 444, 445, 448, 464, 478, 479, 488, 492, 495, 509, 511, 542, 543, 550, 551, 562, 582, 591, 613, 614, 619, 624, 627, 628, 639, 654, 684, 689, 691, 702, 714, 740,\n",
      "       759, 760, 785, 789, 791, 795, 818, 839, 844, 862, 868, 877, 882, 906, 915, 924, 926, 930, 931, 936, 951, 956, 958, 965, 982, 992, 999], dtype=int64),)\n",
      "num correct is  897  an accuracy of  0.897\n",
      "2020-05-31 15:10:19.766338 end\n"
     ]
    }
   ],
   "source": [
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=6_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=1_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=4\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s2weightedparents2'></a>\n",
    "<a href='#toc'>Goto Table of Contents</a>\n",
    "\n",
    "## Compare weighted parent centroids to just the image\n",
    "\n",
    "## whereas the baseline is\n",
    "\n",
    "## kNN acc (6,000 91.6% 60,000 96.88%)\n",
    "## CNN acc (6,000 96.06% (+/- 1.42%); 60,000 99.00% (+/- 0.21%))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-31 15:00:51.343737 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 9 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 9 8 7 2 3 0 4 4 2 4 1 9 5 7 7 2 8 2 6 8 5 7 7 9 1 8 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 9 2 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 8 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 2 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 3 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 6 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 3 8 8 2 7 5 8 9 6 1 8 4 1 2 5 9 1 9 7 5 4 0 8 9 9 1 0 5 2 3 7\n",
      " 8 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 8 4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 2 1 7 0 6 5 4 3 8 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 2 3 1 9 7 5 1 0 8 4 6 2 6 7 9 3 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 5 8 0 3 7 2 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 7 8 3 3 6 7 2 8 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 8 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5 4 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 5\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 8 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 8 8 8 7 4 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 2 3 2 3 9 1 7 4 0 3 5 5 8 6 3 2 6 7 6 6 3 2 7 8 1 1 7 5 6 4 9 5 1 3 3 4 7 8 9 1 1 6 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "<class 'numpy.ndarray'> (0, 170)\n",
      "<class 'numpy.ndarray'> (0, 954)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 954)\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 4 3 7 4 6 4 3 0 7 0 2 7 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 4 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 1 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 8 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 3 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 7 7 9 2 2 4 1 5 8 8 4 2 3 0 6 4 2 9 1 9 5 7 7 2 6 2 6 8 5 7 7 4 1 0 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 3 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 8 7 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 5 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 7 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 7 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 8 0 6 4 8 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 7 8 8 2 7 5 8 9 6 1 8 4 1 2 6 8 1 9 7 5 4 0 8 9 7 1 0 5 8 3 7\n",
      " 0 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 1 2 2 6 8 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 3 4 0 0 8 3 2 9 9 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 7 1 7 0 6 5 4 3 3 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 9 8 6 0 2 4 0 2 1 3 1 9 7 5 1 0 8 4 6 2 6 7 9 9 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 6 1 3 7 6 7 1 2 0 8 0 3 7 8 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 9 8 3 3 6 7 2 4 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 3 2 1 0 8 4 5 0 4 0 6 1 4 3 2 6 7 2 6 9 3 1 4 6 8 5 9 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 9\n",
      " 3 8 0 5 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 9 0 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 6 2 2 5 6 0 8 2 9 2 8 2 8 8 7 9 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 7 3 0 3 9 1 7 4 0 3 5 5 8 6 3 0 6 7 6 6 3 2 7 9 1 1 7 4 6 4 9 6 2 5 3 4 7 8 9 1 1 0 9 1 4 4 5 4 0 6 2 2 8 1 5 1 2 0 8 8 1 2 6 7 1 6\n",
      " 2 3 4 0 1 2 2 0 8 9]\n",
      "ndx_errs (array([ 62,  73,  92, 111, 151, 187, 233, 241, 243, 247, 250, 257, 264, 266, 282, 320, 321, 338, 362, 381, 444, 445, 448, 464, 478, 479, 488, 492, 495, 511, 515, 543, 547, 550, 551, 583, 591, 605,\n",
      "       613, 628, 646, 654, 659, 684, 691, 714, 726, 738, 740, 791, 795, 838, 839, 866, 877, 881, 924, 926, 939, 947, 951, 955, 956, 957, 965, 976, 982, 992], dtype=int64),)\n",
      "num correct is  932  an accuracy of  0.9319999999999999\n",
      "2020-05-31 15:03:12.971295 end\n"
     ]
    }
   ],
   "source": [
    "Config.USE_PARENT_CENTROIDS=True\n",
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=6_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=1_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.USE_PARENT_CENTROIDS=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-30 12:36:15.479827 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7 7\n",
      " 1 0 1 7 8 9 0 1 2 3 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "<class 'numpy.ndarray'> (0, 128)\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "****************************** 0 ******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "****************************** 6000 ******************************\n",
      "****************************** 8000 ******************************\n",
      "****************************** 10000 ******************************\n",
      "****************************** 12000 ******************************\n",
      "****************************** 14000 ******************************\n",
      "****************************** 16000 ******************************\n",
      "****************************** 18000 ******************************\n",
      "****************************** 20000 ******************************\n",
      "****************************** 22000 ******************************\n",
      "****************************** 24000 ******************************\n",
      "****************************** 26000 ******************************\n",
      "****************************** 28000 ******************************\n",
      "****************************** 30000 ******************************\n",
      "****************************** 32000 ******************************\n",
      "****************************** 34000 ******************************\n",
      "****************************** 36000 ******************************\n",
      "****************************** 38000 ******************************\n",
      "****************************** 40000 ******************************\n",
      "****************************** 42000 ******************************\n",
      "****************************** 44000 ******************************\n",
      "****************************** 46000 ******************************\n",
      "****************************** 48000 ******************************\n",
      "****************************** 50000 ******************************\n",
      "****************************** 52000 ******************************\n",
      "****************************** 54000 ******************************\n",
      "****************************** 56000 ******************************\n",
      "****************************** 58000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "****************************** 1999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 0 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 4 7 9 6 9 6 5 3 6 6 8 5 1 4 2 4 9 5 1 1 9 0 2 4 9 5 7 1 8 3 5 6 9 8 7 1 1 6 7 6 3 2 2 0 8 9\n",
      " 2 5 1 0 8 1 4 5 7 9 6 9 0 6 1 5 5 8 3 8 2 6 5 0 7 4 6 1 3 4 7 3 2 3 4 2 5 2 7 1 7 2 6 4 1 5 7 8 6 0 1 8 2 5 7 7 6 9 3 5 2 4 2 4 0 8 8 3 4 9 2 7 5 8 6 3 6 0 8 6 7 3 6 4 9 4 6 6 3 0 4 1 0 1 4 6 2 9 1\n",
      " 1 0 6 3 9]\n",
      "ndx_errs (array([  33,  115,  195,  241,  247,  300,  318,  320,  321,  341,  358,  381,  444,  445,  464,  479,  495,  542,  551,  565,  582,  583,  628,  646,  659,  691,  707,  740,  791,  839,  844,  877,\n",
      "        881,  924,  938,  939,  947,  951,  957, 1014, 1039, 1062, 1068, 1082, 1089, 1107, 1112, 1192, 1202, 1226, 1242, 1247, 1260, 1289, 1299, 1319, 1325, 1326, 1364, 1394, 1465, 1466, 1500, 1522,\n",
      "       1523, 1530, 1553, 1559, 1681, 1709, 1717, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1823, 1850, 1855, 1865, 1878, 1901, 1955, 1970, 1984], dtype=int64),)\n",
      "num correct is  1912  an accuracy of  0.9564782391195598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 3999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 0 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 9 1 1 0 7 5 9 9 1 9 5 9 2 5 0 4 1 0 8 9 0 8 9 8 9 4 2 5 7 9 8 9 8 0 9 9 6 8 9 9 5 9 8 0 1\n",
      " 0 3 3 5 2 1 6 3 0 2 8 1 5 6 2 3 0 2 2 6 4 3 5 5 1 7 2 1 6 9 1 3 9 5 5 1 6 2 2 8 6 7 1 4 6 0 6 0 3 3 2 2 3 6 8 9 8 5 3 8 5 4 5 2 0 5 6 3 2 8 3 9 9 5 7 9 4 6 7 1 3 1 3 6 6 0 9 0 1 9 9 2 8 8 0 1 6 9 7\n",
      " 5 3 4 7 4]\n",
      "ndx_errs (array([  33,  115,  195,  241,  247,  300,  318,  320,  321,  341,  358,  381,  444,  445,  464,  479,  495,  542,  551,  565,  582,  583,  628,  646,  659,  691,  707,  740,  791,  839,  844,  877,\n",
      "        881,  924,  938,  939,  947,  951,  957, 1014, 1039, 1062, 1068, 1082, 1089, 1107, 1112, 1192, 1202, 1226, 1242, 1247, 1260, 1289, 1299, 1319, 1325, 1326, 1364, 1394, 1465, 1466, 1500, 1522,\n",
      "       1523, 1530, 1553, 1559, 1681, 1709, 1717, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1823, 1850, 1855, 1865, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2063, 2082, 2093, 2098, 2109, 2118,\n",
      "       2129, 2130, 2135, 2168, 2177, 2182, 2189, 2197, 2224, 2237, 2293, 2298, 2299, 2325, 2339, 2371, 2387, 2393, 2406, 2422, 2426, 2437, 2447, 2454, 2462, 2488, 2533, 2582, 2597, 2607, 2648, 2654,\n",
      "       2730, 2758, 2771, 2810, 2863, 2896, 2901, 2927, 2939, 2952, 2953, 3005, 3060, 3062, 3073, 3117, 3160, 3206, 3225, 3262, 3269, 3333, 3369, 3384, 3405, 3456, 3475, 3503, 3520, 3558, 3559, 3597,\n",
      "       3599, 3629, 3654, 3662, 3702, 3727, 3751, 3757, 3767, 3780, 3796, 3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3976], dtype=int64),)\n",
      "num correct is  3819  an accuracy of  0.9549887471867967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 5999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 0 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 2 3 4 5 6 7 8 9 8 7 1 3 7 5 2 8 0 7 5 9 9 0 9 1 1 5 8 8 6 3 2 1 8 3 2 6 5 6 9 0 1 0 3 3 1 9\n",
      " 2 1 9 6 0 4 6 1 7 3 8 9 2 9 6 5 8 3 5 7 1 6 1 0 9 6 2 5 4 2 3 4 4 6 0 0 2 0 1 2 3 9 3 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 8 4 5 6 7 8 9 8 6 5 0 6 8 9 4 1 9 5 3 0 4 8 9 1 4 0 5 5 2 1 5 4 0 7 6 0 1 7 0\n",
      " 6 8 9 3 1]\n",
      "ndx_errs (array([  33,  115,  195,  241,  247,  300,  318,  320,  321,  341,  358,  381,  444,  445,  464,  479,  495,  542,  551,  565,  582,  583,  628,  646,  659,  691,  707,  740,  791,  839,  844,  877,\n",
      "        881,  924,  938,  939,  947,  951,  957, 1014, 1039, 1062, 1068, 1082, 1089, 1107, 1112, 1192, 1202, 1226, 1242, 1247, 1260, 1289, 1299, 1319, 1325, 1326, 1364, 1394, 1465, 1466, 1500, 1522,\n",
      "       1523, 1530, 1553, 1559, 1681, 1709, 1717, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1823, 1850, 1855, 1865, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2063, 2082, 2093, 2098, 2109, 2118,\n",
      "       2129, 2130, 2135, 2168, 2177, 2182, 2189, 2197, 2224, 2237, 2293, 2298, 2299, 2325, 2339, 2371, 2387, 2393, 2406, 2422, 2426, 2437, 2447, 2454, 2462, 2488, 2533, 2582, 2597, 2607, 2648, 2654,\n",
      "       2730, 2758, 2771, 2810, 2863, 2896, 2901, 2927, 2939, 2952, 2953, 3005, 3060, 3062, 3073, 3117, 3160, 3206, 3225, 3262, 3269, 3333, 3369, 3384, 3405, 3456, 3475, 3503, 3520, 3558, 3559, 3597,\n",
      "       3599, 3629, 3654, 3662, 3702, 3727, 3751, 3757, 3767, 3780, 3796, 3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3976, 4017, 4027, 4056, 4065, 4075, 4078, 4116, 4140, 4163, 4176, 4194, 4199,\n",
      "       4224, 4289, 4294, 4306, 4317, 4330, 4341, 4344, 4374, 4435, 4451, 4483, 4497, 4500, 4504, 4521, 4575, 4578, 4635, 4639, 4671, 4690, 4699, 4731, 4737, 4761, 4785, 4807, 4814, 4823, 4837, 4860,\n",
      "       4879, 4886, 4890, 4966, 5068, 5176, 5209, 5586, 5600, 5634, 5676, 5678, 5691, 5714, 5734, 5757, 5835, 5841, 5887, 5888, 5891, 5906, 5936, 5937, 5955, 5997], dtype=int64),)\n",
      "num correct is  5749  an accuracy of  0.9583263877312885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 7999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 0 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 3 5 6 7 8 9 0 1 2 3 5 6 7 8 9 9 7 0 9 0 1 5 8 8 0 9 3 2 7 8 4 6 1 0 4 9 4 2 0 5 0 1 6 9 3 2\n",
      " 9 1 6 0 1 1 8 7 7 6 3 6 0 7 2 4 1 7 0 6 7 1 2 5 8 1 8 2 8 7 6 8 7 1 6 2 9 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 8 9 5 7 0 3 1 6 8 4 1 5 6 4 2 7 8 1 3 4 3 4 7 2 0 5 0 1 9 2 3\n",
      " 2 3 5 5 7]\n",
      "ndx_errs (array([  33,  115,  195,  241,  247,  300,  318,  320,  321,  341,  358,  381,  444,  445,  464,  479,  495,  542,  551,  565,  582,  583,  628,  646,  659,  691,  707,  740,  791,  839,  844,  877,\n",
      "        881,  924,  938,  939,  947,  951,  957, 1014, 1039, 1062, 1068, 1082, 1089, 1107, 1112, 1192, 1202, 1226, 1242, 1247, 1260, 1289, 1299, 1319, 1325, 1326, 1364, 1394, 1465, 1466, 1500, 1522,\n",
      "       1523, 1530, 1553, 1559, 1681, 1709, 1717, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1823, 1850, 1855, 1865, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2063, 2082, 2093, 2098, 2109, 2118,\n",
      "       2129, 2130, 2135, 2168, 2177, 2182, 2189, 2197, 2224, 2237, 2293, 2298, 2299, 2325, 2339, 2371, 2387, 2393, 2406, 2422, 2426, 2437, 2447, 2454, 2462, 2488, 2533, 2582, 2597, 2607, 2648, 2654,\n",
      "       2730, 2758, 2771, 2810, 2863, 2896, 2901, 2927, 2939, 2952, 2953, 3005, 3060, 3062, 3073, 3117, 3160, 3206, 3225, 3262, 3269, 3333, 3369, 3384, 3405, 3456, 3475, 3503, 3520, 3558, 3559, 3597,\n",
      "       3599, 3629, 3654, 3662, 3702, 3727, 3751, 3757, 3767, 3780, 3796, 3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3976, 4017, 4027, 4056, 4065, 4075, 4078, 4116, 4140, 4163, 4176, 4194, 4199,\n",
      "       4224, 4289, 4294, 4306, 4317, 4330, 4341, 4344, 4374, 4435, 4451, 4483, 4497, 4500, 4504, 4521, 4575, 4578, 4635, 4639, 4671, 4690, 4699, 4731, 4737, 4761, 4785, 4807, 4814, 4823, 4837, 4860,\n",
      "       4879, 4886, 4890, 4966, 5068, 5176, 5209, 5586, 5600, 5634, 5676, 5678, 5691, 5714, 5734, 5757, 5835, 5841, 5887, 5888, 5891, 5906, 5936, 5937, 5955, 5997, 6011, 6023, 6035, 6059, 6071, 6081,\n",
      "       6091, 6166, 6172, 6173, 6505, 6555, 6569, 6571, 6577, 6597, 6625, 6651, 6755, 7121, 7432, 7434, 7492, 7545, 7637, 7797, 7821], dtype=int64),)\n",
      "num correct is  7722  an accuracy of  0.9653706713339167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 9999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 0 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 2 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 6 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7\n",
      " 7 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 5 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0\n",
      " 1 2 3 4 5]\n",
      "ndx_errs (array([  33,  115,  195,  241,  247,  300,  318,  320,  321,  341,  358,  381,  444,  445,  464,  479,  495,  542,  551,  565,  582,  583,  628,  646,  659,  691,  707,  740,  791,  839,  844,  877,\n",
      "        881,  924,  938,  939,  947,  951,  957, 1014, 1039, 1062, 1068, 1082, 1089, 1107, 1112, 1192, 1202, 1226, 1242, 1247, 1260, 1289, 1299, 1319, 1325, 1326, 1364, 1394, 1465, 1466, 1500, 1522,\n",
      "       1523, 1530, 1553, 1559, 1681, 1709, 1717, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1823, 1850, 1855, 1865, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2063, 2082, 2093, 2098, 2109, 2118,\n",
      "       2129, 2130, 2135, 2168, 2177, 2182, 2189, 2197, 2224, 2237, 2293, 2298, 2299, 2325, 2339, 2371, 2387, 2393, 2406, 2422, 2426, 2437, 2447, 2454, 2462, 2488, 2533, 2582, 2597, 2607, 2648, 2654,\n",
      "       2730, 2758, 2771, 2810, 2863, 2896, 2901, 2927, 2939, 2952, 2953, 3005, 3060, 3062, 3073, 3117, 3160, 3206, 3225, 3262, 3269, 3333, 3369, 3384, 3405, 3456, 3475, 3503, 3520, 3558, 3559, 3597,\n",
      "       3599, 3629, 3654, 3662, 3702, 3727, 3751, 3757, 3767, 3780, 3796, 3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3976, 4017, 4027, 4056, 4065, 4075, 4078, 4116, 4140, 4163, 4176, 4194, 4199,\n",
      "       4224, 4289, 4294, 4306, 4317, 4330, 4341, 4344, 4374, 4435, 4451, 4483, 4497, 4500, 4504, 4521, 4575, 4578, 4635, 4639, 4671, 4690, 4699, 4731, 4737, 4761, 4785, 4807, 4814, 4823, 4837, 4860,\n",
      "       4879, 4886, 4890, 4966, 5068, 5176, 5209, 5586, 5600, 5634, 5676, 5678, 5691, 5714, 5734, 5757, 5835, 5841, 5887, 5888, 5891, 5906, 5936, 5937, 5955, 5997, 6011, 6023, 6035, 6059, 6071, 6081,\n",
      "       6091, 6166, 6172, 6173, 6505, 6555, 6569, 6571, 6577, 6597, 6625, 6651, 6755, 7121, 7432, 7434, 7492, 7545, 7637, 7797, 7821, 8059, 8094, 8095, 8277, 8279, 8290, 8325, 8408, 8416, 8520, 8527,\n",
      "       9009, 9015, 9024, 9280, 9544, 9613, 9624, 9634, 9642, 9655, 9664, 9686, 9719, 9729, 9741, 9745, 9751, 9768, 9770, 9779, 9808, 9811, 9839, 9879, 9904, 9905, 9944], dtype=int64),)\n",
      "num correct is  9684  an accuracy of  0.9684968496849685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 0 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 6 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7 7\n",
      " 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 5 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "ndx_errs (array([  33,  115,  195,  241,  247,  300,  318,  320,  321,  341,  358,  381,  444,  445,  464,  479,  495,  542,  551,  565,  582,  583,  628,  646,  659,  691,  707,  740,  791,  839,  844,  877,\n",
      "        881,  924,  938,  939,  947,  951,  957, 1014, 1039, 1062, 1068, 1082, 1089, 1107, 1112, 1192, 1202, 1226, 1242, 1247, 1260, 1289, 1299, 1319, 1325, 1326, 1364, 1394, 1465, 1466, 1500, 1522,\n",
      "       1523, 1530, 1553, 1559, 1681, 1709, 1717, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1823, 1850, 1855, 1865, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2063, 2082, 2093, 2098, 2109, 2118,\n",
      "       2129, 2130, 2135, 2168, 2177, 2182, 2189, 2197, 2224, 2237, 2293, 2298, 2299, 2325, 2339, 2371, 2387, 2393, 2406, 2422, 2426, 2437, 2447, 2454, 2462, 2488, 2533, 2582, 2597, 2607, 2648, 2654,\n",
      "       2730, 2758, 2771, 2810, 2863, 2896, 2901, 2927, 2939, 2952, 2953, 3005, 3060, 3062, 3073, 3117, 3160, 3206, 3225, 3262, 3269, 3333, 3369, 3384, 3405, 3456, 3475, 3503, 3520, 3558, 3559, 3597,\n",
      "       3599, 3629, 3654, 3662, 3702, 3727, 3751, 3757, 3767, 3780, 3796, 3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3976, 4017, 4027, 4056, 4065, 4075, 4078, 4116, 4140, 4163, 4176, 4194, 4199,\n",
      "       4224, 4289, 4294, 4306, 4317, 4330, 4341, 4344, 4374, 4435, 4451, 4483, 4497, 4500, 4504, 4521, 4575, 4578, 4635, 4639, 4671, 4690, 4699, 4731, 4737, 4761, 4785, 4807, 4814, 4823, 4837, 4860,\n",
      "       4879, 4886, 4890, 4966, 5068, 5176, 5209, 5586, 5600, 5634, 5676, 5678, 5691, 5714, 5734, 5757, 5835, 5841, 5887, 5888, 5891, 5906, 5936, 5937, 5955, 5997, 6011, 6023, 6035, 6059, 6071, 6081,\n",
      "       6091, 6166, 6172, 6173, 6505, 6555, 6569, 6571, 6577, 6597, 6625, 6651, 6755, 7121, 7432, 7434, 7492, 7545, 7637, 7797, 7821, 8059, 8094, 8095, 8277, 8279, 8290, 8325, 8408, 8416, 8520, 8527,\n",
      "       9009, 9015, 9024, 9280, 9544, 9613, 9624, 9634, 9642, 9655, 9664, 9686, 9719, 9729, 9741, 9745, 9751, 9768, 9770, 9779, 9808, 9811, 9839, 9879, 9904, 9905, 9944], dtype=int64),)\n",
      "num correct is  9685  an accuracy of  0.9685\n",
      "2020-05-30 15:42:06.909133 end\n"
     ]
    }
   ],
   "source": [
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s2relativebdy'></a>\n",
    "<a href='#toc'>Goto Table of Contents</a>\n",
    "\n",
    "## Try using relation of image to boundary\n",
    "\n",
    "## whereas the baseline is\n",
    "\n",
    "## kNN acc (6,000 91.6% 60,000 96.88%)\n",
    "## CNN acc (6,000 96.06% (+/- 1.42%); 60,000 99.00% (+/- 0.21%))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-30 15:53:35.022865 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7 7\n",
      " 1 0 1 7 8 9 0 1 2 3 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "<class 'numpy.ndarray'> (0, 170)\n",
      "<class 'numpy.ndarray'> (0, 954)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "****************************** 6000 ******************************\n",
      "****************************** 8000 ******************************\n",
      "****************************** 10000 ******************************\n",
      "****************************** 12000 ******************************\n",
      "****************************** 14000 ******************************\n",
      "****************************** 16000 ******************************\n",
      "****************************** 18000 ******************************\n",
      "****************************** 20000 ******************************\n",
      "****************************** 22000 ******************************\n",
      "****************************** 24000 ******************************\n",
      "****************************** 26000 ******************************\n",
      "****************************** 28000 ******************************\n",
      "****************************** 30000 ******************************\n",
      "****************************** 32000 ******************************\n",
      "****************************** 34000 ******************************\n",
      "****************************** 36000 ******************************\n",
      "****************************** 38000 ******************************\n",
      "****************************** 40000 ******************************\n",
      "****************************** 42000 ******************************\n",
      "****************************** 44000 ******************************\n",
      "****************************** 46000 ******************************\n",
      "****************************** 48000 ******************************\n",
      "****************************** 50000 ******************************\n",
      "****************************** 52000 ******************************\n",
      "****************************** 54000 ******************************\n",
      "****************************** 56000 ******************************\n",
      "****************************** 58000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 954)\n",
      "****************************** 1999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 0 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 4 7 9 6 9 6 5 3 6 6 8 5 1 4 2 4 9 5 1 1 9 0 2 4 9 5 7 1 8 3 5 6 9 8 7 1 1 6 7 6 3 2 2 0 8 9\n",
      " 2 5 1 0 8 1 4 5 7 9 6 9 0 6 1 5 5 8 3 8 2 6 5 0 7 4 6 1 3 4 7 3 2 3 4 2 5 2 7 1 7 2 6 4 1 5 7 8 6 0 1 8 2 5 7 7 6 9 3 5 2 4 2 4 0 8 8 3 4 9 2 7 5 8 6 3 6 0 8 6 7 3 6 4 9 4 6 6 3 0 4 1 0 1 4 6 2 9 1\n",
      " 1 0 6 3 9]\n",
      "ndx_errs (array([  33,  115,  195,  241,  247,  300,  318,  320,  321,  341,  358,  381,  444,  445,  464,  479,  495,  542,  551,  565,  582,  583,  628,  646,  659,  691,  707,  740,  791,  839,  844,  877,\n",
      "        881,  924,  938,  939,  947,  951,  957, 1014, 1039, 1062, 1068, 1082, 1089, 1107, 1112, 1192, 1202, 1226, 1242, 1247, 1260, 1289, 1299, 1319, 1325, 1326, 1364, 1394, 1465, 1466, 1500, 1522,\n",
      "       1523, 1530, 1553, 1559, 1681, 1709, 1717, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1823, 1850, 1855, 1865, 1878, 1901, 1955, 1970, 1984], dtype=int64),)\n",
      "num correct is  1912  an accuracy of  0.9564782391195598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 3999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 0 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 9 1 1 0 7 5 9 9 1 9 5 9 2 5 0 4 1 0 8 9 0 8 9 8 9 4 2 5 7 9 8 9 8 0 9 9 6 8 9 9 5 9 8 0 1\n",
      " 0 3 3 5 2 1 6 3 0 2 8 1 5 6 2 3 0 2 2 6 4 3 5 5 1 7 2 1 6 9 1 3 9 5 5 1 6 2 2 8 6 7 1 4 6 0 6 0 3 3 2 2 3 6 8 9 8 5 3 8 5 4 5 2 0 5 6 3 2 8 3 9 9 5 7 9 4 6 7 1 3 1 3 6 6 0 9 0 1 9 9 2 8 8 0 1 6 9 7\n",
      " 5 3 4 7 4]\n",
      "ndx_errs (array([  33,  115,  195,  241,  247,  300,  318,  320,  321,  341,  358,  381,  444,  445,  464,  479,  495,  542,  551,  565,  582,  583,  628,  646,  659,  691,  707,  740,  791,  839,  844,  877,\n",
      "        881,  924,  938,  939,  947,  951,  957, 1014, 1039, 1062, 1068, 1082, 1089, 1107, 1112, 1192, 1202, 1226, 1242, 1247, 1260, 1289, 1299, 1319, 1325, 1326, 1364, 1394, 1465, 1466, 1500, 1522,\n",
      "       1523, 1530, 1553, 1559, 1681, 1709, 1717, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1823, 1850, 1855, 1865, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2053, 2063, 2082, 2093, 2098, 2109,\n",
      "       2118, 2129, 2130, 2135, 2168, 2177, 2182, 2189, 2197, 2224, 2237, 2293, 2298, 2299, 2325, 2339, 2371, 2387, 2393, 2406, 2422, 2426, 2437, 2454, 2462, 2488, 2533, 2582, 2597, 2607, 2648, 2654,\n",
      "       2730, 2758, 2771, 2810, 2863, 2896, 2901, 2927, 2939, 2952, 2953, 3005, 3060, 3062, 3073, 3117, 3160, 3206, 3225, 3262, 3269, 3333, 3369, 3384, 3405, 3456, 3475, 3503, 3520, 3558, 3559, 3597,\n",
      "       3599, 3629, 3654, 3662, 3702, 3727, 3751, 3757, 3767, 3780, 3796, 3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3976], dtype=int64),)\n",
      "num correct is  3819  an accuracy of  0.9549887471867967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 5999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 0 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 2 3 4 5 6 7 8 9 8 7 1 3 7 5 2 8 0 7 5 9 9 0 9 1 1 5 8 8 6 3 2 1 8 3 2 6 5 6 9 0 1 0 3 3 1 9\n",
      " 2 1 9 6 0 4 6 1 7 3 8 9 2 9 6 5 8 3 5 7 1 6 1 0 9 6 2 5 4 2 3 4 4 6 0 0 2 0 1 2 3 9 3 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 8 4 5 6 7 8 9 8 6 5 0 6 8 9 4 1 9 5 3 0 4 8 9 1 4 0 5 5 2 1 5 4 0 7 6 0 1 7 0\n",
      " 6 8 9 3 1]\n",
      "ndx_errs (array([  33,  115,  195,  241,  247,  300,  318,  320,  321,  341,  358,  381,  444,  445,  464,  479,  495,  542,  551,  565,  582,  583,  628,  646,  659,  691,  707,  740,  791,  839,  844,  877,\n",
      "        881,  924,  938,  939,  947,  951,  957, 1014, 1039, 1062, 1068, 1082, 1089, 1107, 1112, 1192, 1202, 1226, 1242, 1247, 1260, 1289, 1299, 1319, 1325, 1326, 1364, 1394, 1465, 1466, 1500, 1522,\n",
      "       1523, 1530, 1553, 1559, 1681, 1709, 1717, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1823, 1850, 1855, 1865, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2053, 2063, 2082, 2093, 2098, 2109,\n",
      "       2118, 2129, 2130, 2135, 2168, 2177, 2182, 2189, 2197, 2224, 2237, 2293, 2298, 2299, 2325, 2339, 2371, 2387, 2393, 2406, 2422, 2426, 2437, 2454, 2462, 2488, 2533, 2582, 2597, 2607, 2648, 2654,\n",
      "       2730, 2758, 2771, 2810, 2863, 2896, 2901, 2927, 2939, 2952, 2953, 3005, 3060, 3062, 3073, 3117, 3160, 3206, 3225, 3262, 3269, 3333, 3369, 3384, 3405, 3456, 3475, 3503, 3520, 3558, 3559, 3597,\n",
      "       3599, 3629, 3654, 3662, 3702, 3727, 3751, 3757, 3767, 3780, 3796, 3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3976, 4017, 4027, 4056, 4065, 4075, 4078, 4116, 4140, 4163, 4176, 4194, 4199,\n",
      "       4224, 4289, 4306, 4317, 4330, 4341, 4344, 4374, 4435, 4451, 4483, 4497, 4500, 4504, 4521, 4575, 4578, 4635, 4639, 4671, 4690, 4699, 4731, 4737, 4761, 4785, 4807, 4814, 4823, 4837, 4860, 4879,\n",
      "       4886, 4890, 4966, 5068, 5176, 5209, 5586, 5600, 5676, 5678, 5691, 5714, 5734, 5757, 5835, 5841, 5887, 5888, 5891, 5906, 5936, 5937, 5955, 5997], dtype=int64),)\n",
      "num correct is  5751  an accuracy of  0.9586597766294382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 7999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 0 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 3 5 6 7 8 9 0 1 2 3 5 6 7 8 9 9 7 0 9 0 1 5 8 8 0 9 3 2 7 8 4 6 1 0 4 9 4 2 0 5 0 1 6 9 3 2\n",
      " 9 1 6 0 1 1 8 7 7 6 3 6 0 7 2 4 1 7 0 6 7 1 2 5 8 1 8 2 8 7 6 8 7 1 6 2 9 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 8 9 5 7 0 3 1 6 8 4 1 5 6 4 2 7 8 1 3 4 3 4 7 2 0 5 0 1 9 2 3\n",
      " 2 3 5 5 7]\n",
      "ndx_errs (array([  33,  115,  195,  241,  247,  300,  318,  320,  321,  341,  358,  381,  444,  445,  464,  479,  495,  542,  551,  565,  582,  583,  628,  646,  659,  691,  707,  740,  791,  839,  844,  877,\n",
      "        881,  924,  938,  939,  947,  951,  957, 1014, 1039, 1062, 1068, 1082, 1089, 1107, 1112, 1192, 1202, 1226, 1242, 1247, 1260, 1289, 1299, 1319, 1325, 1326, 1364, 1394, 1465, 1466, 1500, 1522,\n",
      "       1523, 1530, 1553, 1559, 1681, 1709, 1717, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1823, 1850, 1855, 1865, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2053, 2063, 2082, 2093, 2098, 2109,\n",
      "       2118, 2129, 2130, 2135, 2168, 2177, 2182, 2189, 2197, 2224, 2237, 2293, 2298, 2299, 2325, 2339, 2371, 2387, 2393, 2406, 2422, 2426, 2437, 2454, 2462, 2488, 2533, 2582, 2597, 2607, 2648, 2654,\n",
      "       2730, 2758, 2771, 2810, 2863, 2896, 2901, 2927, 2939, 2952, 2953, 3005, 3060, 3062, 3073, 3117, 3160, 3206, 3225, 3262, 3269, 3333, 3369, 3384, 3405, 3456, 3475, 3503, 3520, 3558, 3559, 3597,\n",
      "       3599, 3629, 3654, 3662, 3702, 3727, 3751, 3757, 3767, 3780, 3796, 3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3976, 4017, 4027, 4056, 4065, 4075, 4078, 4116, 4140, 4163, 4176, 4194, 4199,\n",
      "       4224, 4289, 4306, 4317, 4330, 4341, 4344, 4374, 4435, 4451, 4483, 4497, 4500, 4504, 4521, 4575, 4578, 4635, 4639, 4671, 4690, 4699, 4731, 4737, 4761, 4785, 4807, 4814, 4823, 4837, 4860, 4879,\n",
      "       4886, 4890, 4966, 5068, 5176, 5209, 5586, 5600, 5676, 5678, 5691, 5714, 5734, 5757, 5835, 5841, 5887, 5888, 5891, 5906, 5936, 5937, 5955, 5997, 6011, 6023, 6035, 6059, 6071, 6081, 6091, 6166,\n",
      "       6172, 6173, 6505, 6555, 6569, 6571, 6577, 6597, 6625, 6651, 7121, 7432, 7434, 7492, 7545, 7637, 7797, 7821], dtype=int64),)\n",
      "num correct is  7725  an accuracy of  0.9657457182147768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 9999 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 0 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 2 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 6 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7\n",
      " 7 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 5 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0\n",
      " 1 2 3 4 5]\n",
      "ndx_errs (array([  33,  115,  195,  241,  247,  300,  318,  320,  321,  341,  358,  381,  444,  445,  464,  479,  495,  542,  551,  565,  582,  583,  628,  646,  659,  691,  707,  740,  791,  839,  844,  877,\n",
      "        881,  924,  938,  939,  947,  951,  957, 1014, 1039, 1062, 1068, 1082, 1089, 1107, 1112, 1192, 1202, 1226, 1242, 1247, 1260, 1289, 1299, 1319, 1325, 1326, 1364, 1394, 1465, 1466, 1500, 1522,\n",
      "       1523, 1530, 1553, 1559, 1681, 1709, 1717, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1823, 1850, 1855, 1865, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2053, 2063, 2082, 2093, 2098, 2109,\n",
      "       2118, 2129, 2130, 2135, 2168, 2177, 2182, 2189, 2197, 2224, 2237, 2293, 2298, 2299, 2325, 2339, 2371, 2387, 2393, 2406, 2422, 2426, 2437, 2454, 2462, 2488, 2533, 2582, 2597, 2607, 2648, 2654,\n",
      "       2730, 2758, 2771, 2810, 2863, 2896, 2901, 2927, 2939, 2952, 2953, 3005, 3060, 3062, 3073, 3117, 3160, 3206, 3225, 3262, 3269, 3333, 3369, 3384, 3405, 3456, 3475, 3503, 3520, 3558, 3559, 3597,\n",
      "       3599, 3629, 3654, 3662, 3702, 3727, 3751, 3757, 3767, 3780, 3796, 3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3976, 4017, 4027, 4056, 4065, 4075, 4078, 4116, 4140, 4163, 4176, 4194, 4199,\n",
      "       4224, 4289, 4306, 4317, 4330, 4341, 4344, 4374, 4435, 4451, 4483, 4497, 4500, 4504, 4521, 4575, 4578, 4635, 4639, 4671, 4690, 4699, 4731, 4737, 4761, 4785, 4807, 4814, 4823, 4837, 4860, 4879,\n",
      "       4886, 4890, 4966, 5068, 5176, 5209, 5586, 5600, 5676, 5678, 5691, 5714, 5734, 5757, 5835, 5841, 5887, 5888, 5891, 5906, 5936, 5937, 5955, 5997, 6011, 6023, 6035, 6059, 6071, 6081, 6091, 6166,\n",
      "       6172, 6173, 6505, 6555, 6569, 6571, 6577, 6597, 6625, 6651, 7121, 7432, 7434, 7492, 7545, 7637, 7797, 7821, 8059, 8094, 8095, 8277, 8279, 8290, 8325, 8408, 8416, 8520, 8527, 9009, 9015, 9024,\n",
      "       9280, 9544, 9613, 9624, 9634, 9642, 9655, 9664, 9686, 9719, 9729, 9741, 9745, 9751, 9768, 9770, 9779, 9808, 9811, 9839, 9879, 9904, 9905, 9944], dtype=int64),)\n",
      "num correct is  9687  an accuracy of  0.9687968796879688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 0 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 6 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7 7\n",
      " 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 5 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "ndx_errs (array([  33,  115,  195,  241,  247,  300,  318,  320,  321,  341,  358,  381,  444,  445,  464,  479,  495,  542,  551,  565,  582,  583,  628,  646,  659,  691,  707,  740,  791,  839,  844,  877,\n",
      "        881,  924,  938,  939,  947,  951,  957, 1014, 1039, 1062, 1068, 1082, 1089, 1107, 1112, 1192, 1202, 1226, 1242, 1247, 1260, 1289, 1299, 1319, 1325, 1326, 1364, 1394, 1465, 1466, 1500, 1522,\n",
      "       1523, 1530, 1553, 1559, 1681, 1709, 1717, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1823, 1850, 1855, 1865, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2053, 2063, 2082, 2093, 2098, 2109,\n",
      "       2118, 2129, 2130, 2135, 2168, 2177, 2182, 2189, 2197, 2224, 2237, 2293, 2298, 2299, 2325, 2339, 2371, 2387, 2393, 2406, 2422, 2426, 2437, 2454, 2462, 2488, 2533, 2582, 2597, 2607, 2648, 2654,\n",
      "       2730, 2758, 2771, 2810, 2863, 2896, 2901, 2927, 2939, 2952, 2953, 3005, 3060, 3062, 3073, 3117, 3160, 3206, 3225, 3262, 3269, 3333, 3369, 3384, 3405, 3456, 3475, 3503, 3520, 3558, 3559, 3597,\n",
      "       3599, 3629, 3654, 3662, 3702, 3727, 3751, 3757, 3767, 3780, 3796, 3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3976, 4017, 4027, 4056, 4065, 4075, 4078, 4116, 4140, 4163, 4176, 4194, 4199,\n",
      "       4224, 4289, 4306, 4317, 4330, 4341, 4344, 4374, 4435, 4451, 4483, 4497, 4500, 4504, 4521, 4575, 4578, 4635, 4639, 4671, 4690, 4699, 4731, 4737, 4761, 4785, 4807, 4814, 4823, 4837, 4860, 4879,\n",
      "       4886, 4890, 4966, 5068, 5176, 5209, 5586, 5600, 5676, 5678, 5691, 5714, 5734, 5757, 5835, 5841, 5887, 5888, 5891, 5906, 5936, 5937, 5955, 5997, 6011, 6023, 6035, 6059, 6071, 6081, 6091, 6166,\n",
      "       6172, 6173, 6505, 6555, 6569, 6571, 6577, 6597, 6625, 6651, 7121, 7432, 7434, 7492, 7545, 7637, 7797, 7821, 8059, 8094, 8095, 8277, 8279, 8290, 8325, 8408, 8416, 8520, 8527, 9009, 9015, 9024,\n",
      "       9280, 9544, 9613, 9624, 9634, 9642, 9655, 9664, 9686, 9719, 9729, 9741, 9745, 9751, 9768, 9770, 9779, 9808, 9811, 9839, 9879, 9904, 9905, 9944], dtype=int64),)\n",
      "num correct is  9688  an accuracy of  0.9688\n",
      "2020-05-30 19:09:57.988484 end\n"
     ]
    }
   ],
   "source": [
    "Config.APPEND_IMAGE=True\n",
    "Config.USE_PARENT_CENTROIDS=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "USE_REL_BDY=True\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.USE_PARENT_CENTROIDS=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-30 20:59:52.515593 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7 7\n",
      " 1 0 1 7 8 9 0 1 2 3 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "<class 'numpy.ndarray'> (0, 682)\n",
      "<class 'numpy.ndarray'> (0, 1466)\n",
      "****************************** 0 ******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-701510192991>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mUSE_REL_BDY\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mrun_tests\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAPPEND_IMAGE\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-68-32dbbcf1c41c>\u001b[0m in \u001b[0;36mrun_tests\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m             centroids_relative=np.hstack((centroids_relative,\\\n\u001b[0;32m     39\u001b[0m                                        np.reshape(X[ndx],(Config.NUM_PIXELS_PER_IMAGE))))\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0mcentroids_array\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcentroids_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcentroids_relative\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;31m#             np.reshape(centroids_array,((1,len(centroids_array))))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \"\"\"\n\u001b[0;32m    282\u001b[0m     \u001b[0m_warn_for_nonsequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Config.APPEND_IMAGE=True\n",
    "Config.USE_PARENT_CENTROIDS=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=4\n",
    "USE_REL_BDY=True\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.USE_PARENT_CENTROIDS=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s2onlyleaves'></a>\n",
    "<a href='#toc'>Goto Table of Contents</a>\n",
    "\n",
    "## try without image (just the centroid info); Use only the leaves of the tree of centroids\n",
    "\n",
    "## Try more kNN neighbors and a bigger tree\n",
    "\n",
    "- kNN acc (6,000    ; 60,000 93.95%)\n",
    "- kNN acc (6,000    ; 60,000 92.20%)\n",
    "\n",
    "## whereas the baseline is\n",
    "\n",
    "## kNN acc (6,000 91.6% 60,000 96.88%)\n",
    "## CNN acc (6,000 96.06% (+/- 1.42%); 60,000 99.00% (+/- 0.21%))\n",
    "\n",
    "## Without the image, centroid info is not enough for best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-28 19:25:11.832647 start\n",
      "<class 'numpy.ndarray'> (0, 512)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "****************************** 6000 ******************************\n",
      "****************************** 8000 ******************************\n",
      "****************************** 10000 ******************************\n",
      "****************************** 12000 ******************************\n",
      "****************************** 14000 ******************************\n",
      "****************************** 16000 ******************************\n",
      "****************************** 18000 ******************************\n",
      "****************************** 20000 ******************************\n",
      "****************************** 22000 ******************************\n",
      "****************************** 24000 ******************************\n",
      "****************************** 26000 ******************************\n",
      "****************************** 28000 ******************************\n",
      "****************************** 30000 ******************************\n",
      "****************************** 32000 ******************************\n",
      "****************************** 34000 ******************************\n",
      "****************************** 36000 ******************************\n",
      "****************************** 38000 ******************************\n",
      "****************************** 40000 ******************************\n",
      "****************************** 42000 ******************************\n",
      "****************************** 44000 ******************************\n",
      "****************************** 46000 ******************************\n",
      "****************************** 48000 ******************************\n",
      "****************************** 50000 ******************************\n",
      "****************************** 52000 ******************************\n",
      "****************************** 54000 ******************************\n",
      "****************************** 56000 ******************************\n",
      "****************************** 58000 ******************************\n",
      "****************************** 1999 ******************************\n",
      "num correct is  1833  an accuracy of  0.9169584792396198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 3999 ******************************\n",
      "num correct is  3664  an accuracy of  0.9162290572643161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 5999 ******************************\n",
      "num correct is  5541  an accuracy of  0.9236539423237207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 7999 ******************************\n",
      "num correct is  7474  an accuracy of  0.9343667958494812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 9999 ******************************\n",
      "num correct is  9394  an accuracy of  0.9394939493949395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num correct is  9395  an accuracy of  0.9395\n",
      "2020-05-28 21:37:22.176638 end\n"
     ]
    }
   ],
   "source": [
    "USE_REL_BDY=True\n",
    "Config.N_NEIGHBORS=5\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=4\n",
    "\n",
    "run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-29 10:15:41.947293 start\n",
      "<class 'numpy.ndarray'> (0, 512)\n",
      "****************************** 0 ******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "****************************** 6000 ******************************\n",
      "****************************** 8000 ******************************\n",
      "****************************** 10000 ******************************\n",
      "****************************** 12000 ******************************\n",
      "****************************** 14000 ******************************\n",
      "****************************** 16000 ******************************\n",
      "****************************** 18000 ******************************\n",
      "****************************** 20000 ******************************\n",
      "****************************** 22000 ******************************\n",
      "****************************** 24000 ******************************\n",
      "****************************** 26000 ******************************\n",
      "****************************** 28000 ******************************\n",
      "****************************** 30000 ******************************\n",
      "****************************** 32000 ******************************\n",
      "****************************** 34000 ******************************\n",
      "****************************** 36000 ******************************\n",
      "****************************** 38000 ******************************\n",
      "****************************** 40000 ******************************\n",
      "****************************** 42000 ******************************\n",
      "****************************** 44000 ******************************\n",
      "****************************** 46000 ******************************\n",
      "****************************** 48000 ******************************\n",
      "****************************** 50000 ******************************\n",
      "****************************** 52000 ******************************\n",
      "****************************** 54000 ******************************\n",
      "****************************** 56000 ******************************\n",
      "****************************** 58000 ******************************\n",
      "****************************** 1999 ******************************\n",
      "num correct is  1783  an accuracy of  0.8919459729864933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 3999 ******************************\n",
      "num correct is  3585  an accuracy of  0.8964741185296324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 5999 ******************************\n",
      "num correct is  5426  an accuracy of  0.9044840806801133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 7999 ******************************\n",
      "num correct is  7336  an accuracy of  0.9171146393299162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 9999 ******************************\n",
      "num correct is  9219  an accuracy of  0.921992199219922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num correct is  9220  an accuracy of  0.922\n",
      "2020-05-29 12:30:32.921778 end\n"
     ]
    }
   ],
   "source": [
    "USE_REL_BDY=True\n",
    "Config.N_NEIGHBORS=5\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=4\n",
    "\n",
    "run_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s2onlybigtree'></a>\n",
    "<a href='#toc'>Goto Table of Contents</a>\n",
    "\n",
    "## try without image (just the centroid info) and more neighbors, larger tree\n",
    "\n",
    "- kNN acc (6,000 83.9%; 60,000 ) Try weighted centroid without image\n",
    "- kNN acc (6,000 ; 60,000 91.22%)\n",
    "- kNN acc (6,000 ; 60,000 88.47%)\n",
    "\n",
    "## whereas the baseline is\n",
    "\n",
    "## kNN acc (6,000 91.6% 60,000 96.88%)\n",
    "## CNN acc (6,000 96.06% (+/- 1.42%); 60,000 99.00% (+/- 0.21%))\n",
    "\n",
    "## This shows that we need the image for best results. The centroids by themselves is not enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-31 15:13:11.757654 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 9 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 9 8 7 2 3 0 4 4 2 4 1 9 5 7 7 2 8 2 6 8 5 7 7 9 1 8 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 9 2 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 8 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 2 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 3 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 6 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 3 8 8 2 7 5 8 9 6 1 8 4 1 2 5 9 1 9 7 5 4 0 8 9 9 1 0 5 2 3 7\n",
      " 8 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 8 4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 2 1 7 0 6 5 4 3 8 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 2 3 1 9 7 5 1 0 8 4 6 2 6 7 9 3 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 5 8 0 3 7 2 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 7 8 3 3 6 7 2 8 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 8 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5 4 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 5\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 8 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 8 8 8 7 4 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 2 3 2 3 9 1 7 4 0 3 5 5 8 6 3 2 6 7 6 6 3 2 7 8 1 1 7 5 6 4 9 5 1 3 3 4 7 8 9 1 1 6 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "<class 'numpy.ndarray'> (0, 128)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "predicted_labels [7 2 1 0 4 1 4 4 5 9 0 6 4 0 1 3 4 7 8 4 9 6 6 5 4 0 7 4 0 1 3 1 3 2 7 2 7 1 2 1 1 7 4 2 3 5 1 2 9 4 6 3 5 5 6 0 4 1 9 5 7 8 4 3 9 4 6 4 3 0 7 0 2 1 1 7 3 2 8 7 7 6 2 7 8 4 7 7 6 1 3 6 4 3 1 4 1 4 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 1 3 9 4 4 4 4 9 2 5 4 7 6 7 4 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 4 9 8 5 3 1 5 6 0 3 4 4 6 5 4 6 3 4 5 1 4 4 8 2 0 2 7 1 8 1 8 1 8 5 0 3 4 2 3 0 1 1 1 0 9 0 1 1 6\n",
      " 9 2 3 6 1 1 1 3 9 0 2 9 4 5 9 3 4 0 3 5 5 5 7 2 2 7 1 2 8 4 1 7 3 3 6 4 7 9 2 2 4 1 5 8 8 4 2 3 0 6 4 2 9 1 9 5 7 7 2 6 2 0 8 5 7 7 4 1 6 1 8 0 3 0 1 4 9 4 1 8 2 1 2 9 2 5 4 2 6 9 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 4 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 0 5 8 2 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 0 6 3 6 1 3 8 1 0 5 1 3 1 5 0 6 1 8 5 1 7 8 4 6 7 2 5 0 6 5 6 0 7 2 0 8 8 5 9 1 1 4 0 7 3 7 6 1 6 2 1 4 0 0 6 1 4 5\n",
      " 2 5 4 4 2 3 3 8 2 4 3 0 3 1 7 7 3 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 8 0 6 4 8 3 3 0 2 3 9 1 2 5 8 0 5 6 6 6 5 8 8 2 4 3 8 7 6 1 8 4 1 2 5 8 1 9 7 5 4 0 8 4 4 1 0 5 2 3 7\n",
      " 6 9 4 0 6 3 4 5 2 1 2 1 3 6 5 7 1 2 2 6 5 2 6 5 4 8 9 7 1 3 0 3 5 3 1 4 3 4 4 6 4 2 1 8 2 5 4 4 3 4 0 0 8 3 2 4 4 0 6 7 4 4 7 9 6 9 0 4 8 0 7 6 0 6 3 5 4 8 3 3 9 3 3 8 7 8 0 8 8 1 7 0 6 5 4 3 6 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 4 8 6 0 2 6 0 2 2 3 1 7 4 5 8 0 8 4 6 2 6 7 4 9 2 9 8 2 2 4 2 7 3 5 9 1 8 0 2 0 6 2 1 5 7 6 7 1 2 0 8 0 5 9 2 4 0 9 1 8 6 7 7 4 3 4 4 1 4 5 1 7 3 9 7 6 9 1 3 9 8 3 3 6 7 2 8 5\n",
      " 3 8 1 1 4 4 3 1 0 1 7 0 7 9 4 4 8 5 5 4 0 8 2 7 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 0 0 9 2 0 6 2 1 7 2 4 1 0 5 4 3 1 1 7 4 4 9 4 8 4 0 2 4 3 1 1 6 4 7 1 9 4 2 4 1 3 5 3 8 3 1 4 3 6 8 9 4 1 9\n",
      " 3 8 0 3 2 5 1 2 8 6 4 4 0 8 8 3 3 1 7 3 5 4 6 3 2 6 1 3 6 0 7 3 1 7 1 9 2 9 2 1 7 9 6 1 1 2 9 3 1 7 7 4 7 0 7 2 1 3 1 0 7 1 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 3 2 9 2 3 6 8 8 7 9 4 5 0 6 6 3 2 1 3\n",
      " 2 2 9 8 0 0 5 4 3 1 4 9 6 0 2 7 1 4 7 9 7 3 9 8 8 0 7 1 2 1 2 2 3 7 3 2 3 9 1 4 4 0 5 5 5 6 6 3 8 6 7 6 6 3 2 7 9 1 1 1 4 6 4 9 6 2 3 0 4 4 8 4 1 1 0 7 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 2 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "ndx_errs (array([  7,  12,  15,  16,  18,  33,  48,  62,  64,  73,  78,  87,  92,  97, 111, 114, 125, 149, 151, 153, 165, 171, 173, 184, 185, 187, 195, 198, 207, 214, 217, 232, 233, 241, 243, 247, 250, 257,\n",
      "       259, 264, 266, 273, 282, 284, 287, 301, 318, 320, 338, 340, 352, 359, 362, 369, 376, 381, 389, 390, 391, 394, 401, 406, 412, 444, 445, 448, 451, 457, 464, 468, 469, 471, 479, 487, 488, 495,\n",
      "       501, 505, 511, 515, 527, 530, 542, 543, 547, 550, 551, 553, 562, 565, 578, 583, 591, 605, 610, 616, 617, 619, 627, 628, 634, 645, 648, 654, 657, 658, 671, 673, 684, 693, 694, 702, 716, 738,\n",
      "       739, 740, 747, 758, 766, 778, 785, 791, 801, 813, 823, 827, 829, 838, 839, 844, 847, 853, 872, 876, 877, 881, 882, 883, 894, 898, 899, 902, 906, 910, 916, 924, 930, 933, 936, 939, 947, 950,\n",
      "       951, 955, 956, 958, 960, 962, 965, 966, 982], dtype=int64),)\n",
      "num correct is  839  an accuracy of  0.839\n",
      "2020-05-31 15:14:06.364350 end\n"
     ]
    }
   ],
   "source": [
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=6_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=1_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-29 12:33:19.023909 start\n",
      "<class 'numpy.ndarray'> (0, 2048)\n",
      "****************************** 0 ******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "****************************** 6000 ******************************\n",
      "****************************** 8000 ******************************\n",
      "****************************** 10000 ******************************\n",
      "****************************** 12000 ******************************\n",
      "****************************** 14000 ******************************\n",
      "****************************** 16000 ******************************\n",
      "****************************** 18000 ******************************\n",
      "****************************** 20000 ******************************\n",
      "****************************** 22000 ******************************\n",
      "****************************** 24000 ******************************\n",
      "****************************** 26000 ******************************\n",
      "****************************** 28000 ******************************\n",
      "****************************** 30000 ******************************\n",
      "****************************** 32000 ******************************\n",
      "****************************** 34000 ******************************\n",
      "****************************** 36000 ******************************\n",
      "****************************** 38000 ******************************\n",
      "****************************** 40000 ******************************\n",
      "****************************** 42000 ******************************\n",
      "****************************** 44000 ******************************\n",
      "****************************** 46000 ******************************\n",
      "****************************** 48000 ******************************\n",
      "****************************** 50000 ******************************\n",
      "****************************** 52000 ******************************\n",
      "****************************** 54000 ******************************\n",
      "****************************** 56000 ******************************\n",
      "****************************** 58000 ******************************\n",
      "****************************** 1999 ******************************\n",
      "num correct is  1763  an accuracy of  0.8819409704852426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 3999 ******************************\n",
      "num correct is  3545  an accuracy of  0.8864716179044762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 5999 ******************************\n",
      "num correct is  5363  an accuracy of  0.893982330388398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 7999 ******************************\n",
      "num correct is  7246  an accuracy of  0.905863232904113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 9999 ******************************\n",
      "num correct is  9121  an accuracy of  0.9121912191219121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num correct is  9122  an accuracy of  0.9122\n",
      "2020-05-29 21:22:15.245199 end\n"
     ]
    }
   ],
   "source": [
    "USE_REL_BDY=True\n",
    "Config.N_NEIGHBORS=5\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=5\n",
    "\n",
    "run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-29 21:22:15.480034 start\n",
      "<class 'numpy.ndarray'> (0, 128)\n",
      "****************************** 0 ******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "****************************** 6000 ******************************\n",
      "****************************** 8000 ******************************\n",
      "****************************** 10000 ******************************\n",
      "****************************** 12000 ******************************\n",
      "****************************** 14000 ******************************\n",
      "****************************** 16000 ******************************\n",
      "****************************** 18000 ******************************\n",
      "****************************** 20000 ******************************\n",
      "****************************** 22000 ******************************\n",
      "****************************** 24000 ******************************\n",
      "****************************** 26000 ******************************\n",
      "****************************** 28000 ******************************\n",
      "****************************** 30000 ******************************\n",
      "****************************** 32000 ******************************\n",
      "****************************** 34000 ******************************\n",
      "****************************** 36000 ******************************\n",
      "****************************** 38000 ******************************\n",
      "****************************** 40000 ******************************\n",
      "****************************** 42000 ******************************\n",
      "****************************** 44000 ******************************\n",
      "****************************** 46000 ******************************\n",
      "****************************** 48000 ******************************\n",
      "****************************** 50000 ******************************\n",
      "****************************** 52000 ******************************\n",
      "****************************** 54000 ******************************\n",
      "****************************** 56000 ******************************\n",
      "****************************** 58000 ******************************\n",
      "****************************** 1999 ******************************\n",
      "num correct is  1718  an accuracy of  0.8594297148574287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 3999 ******************************\n",
      "num correct is  3459  an accuracy of  0.86496624156039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 5999 ******************************\n",
      "num correct is  5233  an accuracy of  0.8723120520086681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 7999 ******************************\n",
      "num correct is  7040  an accuracy of  0.8801100137517189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 9999 ******************************\n",
      "num correct is  8846  an accuracy of  0.8846884688468847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num correct is  8847  an accuracy of  0.8847\n",
      "2020-05-29 21:52:31.007097 end\n"
     ]
    }
   ],
   "source": [
    "USE_REL_BDY=True\n",
    "Config.N_NEIGHBORS=5\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s2norelativebdy'></a>\n",
    "<a href='#toc'>Goto Table of Contents</a>\n",
    "## Try not getting points relative to the bounding rectangle. \n",
    "\n",
    "## Try several configurations\n",
    "\n",
    "- kNN acc (6,000 ; 60,000 94.17%)\n",
    "- kNN acc (6,000 ; 60,000 90.85%)\n",
    "- kNN acc (6,000 ; 60,000 91.15%)\n",
    "\n",
    "## whereas the baseline is\n",
    "\n",
    "## kNN acc (6,000 91.6% 60,000 96.88%)\n",
    "## CNN acc (6,000 96.06% (+/- 1.42%); 60,000 99.00% (+/- 0.21%))\n",
    "\n",
    "## This shows that we must look at points relative to the bounding rectangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-28 14:05:28.133736 start\n",
      "<class 'numpy.ndarray'> (0, 512)\n",
      "****************************** 0 ******************************\n",
      "main():centroids_array [[        nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan\n",
      "          nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan\n",
      "          nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan\n",
      "          nan         nan         nan         nan 15.         19.         16.         19.                 nan         nan 17.         20.         17.5        19.         19.         19.\n",
      "  19.         18.         17.5        18.         17.66666667 16.66666667 19.         16.5        16.         18.         15.         18.         15.         16.5        16.         16.5\n",
      "  16.         15.         15.         15.         15.         14.                 nan         nan 19.         15.         18.         15.         18.         14.         19.         14.\n",
      "          nan         nan         nan         nan         nan         nan         nan         nan         nan         nan 20.         18.         20.         16.5        21.         16.\n",
      "  21.         15.         20.         15.         20.         14.         21.         14.                 nan         nan 22.         15.         22.         14.                 nan         nan\n",
      "          nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan\n",
      "          nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan\n",
      "          nan         nan         nan         nan         nan         nan         nan         nan  7.         22.          5.5        22.5         5.5        21.          7.         21.\n",
      "   7.         20.          5.5        20.          5.5        19.          7.         19.                 nan         nan         nan         nan         nan         nan         nan         nan\n",
      "          nan         nan         nan         nan  8.         16.5         9.         16.5         7.         18.          5.5        18.          5.5        16.5         7.         16.5\n",
      "   7.         15.          5.5        15.          5.5        14.          7.         14.                 nan         nan  8.         15.          8.         14.          9.         14.\n",
      "  14.         18.                 nan         nan 13.         16.         14.         16.5                nan         nan         nan         nan         nan         nan         nan         nan\n",
      "          nan         nan         nan         nan         nan         nan 12.         14.         14.         15.         13.         15.         13.         14.         14.         14.\n",
      "  14.         13.         13.         13.         13.         12.                 nan         nan 11.5        13.         10.         13.         10.         12.         11.5        12.\n",
      "  11.5        11.         10.         11.         10.          9.                 nan         nan         nan         nan         nan         nan         nan         nan         nan         nan\n",
      "   9.         13.          8.         13.          8.         12.          9.         12.          7.         13.          5.5        13.          6.         12.          7.         12.\n",
      "   7.         10.5         6.         10.5         6.          9.          7.          9.          9.         10.5         8.         10.5         8.          9.          9.          9.\n",
      "   9.          8.          8.          8.          8.          7.                 nan         nan  7.          8.          6.          8.                 nan         nan  7.          7.\n",
      "          nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan\n",
      "          nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan\n",
      "          nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan\n",
      "  23.         13.         22.         13.         22.         12.         23.         12.         21.         13.         20.         13.         20.         12.         21.         12.\n",
      "  21.         10.5        20.         10.5                nan         nan 21.          9.         23.5        10.5        22.         10.5        22.          9.         23.5         9.\n",
      "  19.         13.                 nan         nan         nan         nan 19.         12.                 nan         nan         nan         nan         nan         nan         nan         nan\n",
      "          nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan\n",
      "          nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan\n",
      "          nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan         nan\n",
      "  23.5         8.         22.          8.         22.          7.         23.5         7.         21.          8.                 nan         nan         nan         nan         nan         nan\n",
      "          nan         nan         nan         nan         nan         nan         nan         nan 23.5         6.         22.          6.                 nan         nan 23.5         4.5       ]]\n",
      "y[ndx] 5\n",
      "one_image [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253 253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201  78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 1000 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 3000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "****************************** 5000 ******************************\n",
      "****************************** 6000 ******************************\n",
      "****************************** 7000 ******************************\n",
      "****************************** 8000 ******************************\n",
      "****************************** 9000 ******************************\n",
      "****************************** 10000 ******************************\n",
      "****************************** 11000 ******************************\n",
      "****************************** 12000 ******************************\n",
      "****************************** 13000 ******************************\n",
      "****************************** 14000 ******************************\n",
      "****************************** 15000 ******************************\n",
      "****************************** 16000 ******************************\n",
      "****************************** 17000 ******************************\n",
      "****************************** 18000 ******************************\n",
      "****************************** 19000 ******************************\n",
      "****************************** 20000 ******************************\n",
      "****************************** 21000 ******************************\n",
      "****************************** 22000 ******************************\n",
      "****************************** 23000 ******************************\n",
      "****************************** 24000 ******************************\n",
      "****************************** 25000 ******************************\n",
      "****************************** 26000 ******************************\n",
      "****************************** 27000 ******************************\n",
      "****************************** 28000 ******************************\n",
      "****************************** 29000 ******************************\n",
      "****************************** 30000 ******************************\n",
      "****************************** 31000 ******************************\n",
      "****************************** 32000 ******************************\n",
      "****************************** 33000 ******************************\n",
      "****************************** 34000 ******************************\n",
      "****************************** 35000 ******************************\n",
      "****************************** 36000 ******************************\n",
      "****************************** 37000 ******************************\n",
      "****************************** 38000 ******************************\n",
      "****************************** 39000 ******************************\n",
      "****************************** 40000 ******************************\n",
      "****************************** 41000 ******************************\n",
      "****************************** 42000 ******************************\n",
      "****************************** 43000 ******************************\n",
      "****************************** 44000 ******************************\n",
      "****************************** 45000 ******************************\n",
      "****************************** 46000 ******************************\n",
      "****************************** 47000 ******************************\n",
      "****************************** 48000 ******************************\n",
      "****************************** 49000 ******************************\n",
      "****************************** 50000 ******************************\n",
      "****************************** 51000 ******************************\n",
      "****************************** 52000 ******************************\n",
      "****************************** 53000 ******************************\n",
      "****************************** 54000 ******************************\n",
      "****************************** 55000 ******************************\n",
      "****************************** 56000 ******************************\n",
      "****************************** 57000 ******************************\n",
      "****************************** 58000 ******************************\n",
      "****************************** 59000 ******************************\n",
      "<class 'numpy.ndarray'> (1, 512)\n",
      "main():test_centroids_array [[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "   nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan 19.5 16.   nan  nan 18.  17.  17.  17.  17.  16.\n",
      "  18.  16.  18.  15.  17.  15.   nan  nan 18.  14.  21.  15.  19.5 15.  19.5 14.  21.  14.   nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan 22.\n",
      "  14.  23.  14.   nan  nan  nan  nan 24.  14.  25.  14.   nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan 12.  20.  13.  20.  13.5 19.  12.  19.  12.  18.  13.5 18.   nan  nan  nan  nan\n",
      "  15.  18.  16.  18.  11.  21.  10.  21.  10.  20.  11.  20.   9.  21.   8.  21.   8.  20.   9.  20.   9.  19.   8.  19.   8.  18.   9.  18.  11.  19.  10.  19.  10.  18.  11.  18.   nan  nan 10.\n",
      "  17.  10.  16.   nan  nan  9.  17.   8.  17.   8.  16.   9.  16.   9.  15.   8.  15.   8.  14.   9.  14.   nan  nan 10.  15.  10.  14.   nan  nan 16.  17.  15.  17.  15.  16.  16.  16.  13.5 17.\n",
      "  12.  17.   nan  nan 14.  16.   nan  nan  nan  nan  nan  nan  nan  nan 16.  15.   nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "   nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan 10.  13.  10.  12.   nan  nan  9.  13.   8.  13.   8.  12.   9.  12.   9.  11.   7.5 11.   7.5 10.   9.  10.\n",
      "   nan  nan 10.  11.   nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  9.   9.   7.5  9.   7.5  8.   9.   8.   9.   7.   7.5  7.   7.5  6.   9.   6.   nan  nan  nan  nan  nan  nan  nan\n",
      "   nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan 25.5 13.  24.  13.  24.  12.\n",
      "  25.5 12.  23.  13.  22.  13.  22.  12.  23.  12.  23.  11.  22.  11.   nan  nan  nan  nan 25.5 11.  24.  11.  24.  10.  25.5 10.  21.  13.  19.5 13.   nan  nan 21.  12.   nan  nan  nan  nan  nan\n",
      "   nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "   nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "   nan  nan  nan  nan  nan]]\n",
      "****************************** 999 ******************************\n",
      "num correct is  922  an accuracy of  0.9229229229229229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 1999 ******************************\n",
      "num correct is  1839  an accuracy of  0.919959979989995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 2999 ******************************\n",
      "num correct is  2754  an accuracy of  0.9183061020340113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 3999 ******************************\n",
      "num correct is  3679  an accuracy of  0.9199799949987497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 4999 ******************************\n",
      "num correct is  4598  an accuracy of  0.9197839567913583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 5999 ******************************\n",
      "num correct is  5552  an accuracy of  0.9254875812635439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 6999 ******************************\n",
      "num correct is  6515  an accuracy of  0.9308472638948422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 7999 ******************************\n",
      "num correct is  7488  an accuracy of  0.9361170146268284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 8999 ******************************\n",
      "num correct is  8461  an accuracy of  0.9402155795088343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 9999 ******************************\n",
      "num correct is  9416  an accuracy of  0.9416941694169417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num correct is  9417  an accuracy of  0.9417\n",
      "2020-05-28 16:41:40.285282 end\n"
     ]
    }
   ],
   "source": [
    "USE_REL_BDY=False\n",
    "Config.N_NEIGHBORS=5\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=4\n",
    "\n",
    "run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-30 06:00:58.422655 start\n",
      "<class 'numpy.ndarray'> (0, 128)\n",
      "****************************** 0 ******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "****************************** 6000 ******************************\n",
      "****************************** 8000 ******************************\n",
      "****************************** 10000 ******************************\n",
      "****************************** 12000 ******************************\n",
      "****************************** 14000 ******************************\n",
      "****************************** 16000 ******************************\n",
      "****************************** 18000 ******************************\n",
      "****************************** 20000 ******************************\n",
      "****************************** 22000 ******************************\n",
      "****************************** 24000 ******************************\n",
      "****************************** 26000 ******************************\n",
      "****************************** 28000 ******************************\n",
      "****************************** 30000 ******************************\n",
      "****************************** 32000 ******************************\n",
      "****************************** 34000 ******************************\n",
      "****************************** 36000 ******************************\n",
      "****************************** 38000 ******************************\n",
      "****************************** 40000 ******************************\n",
      "****************************** 42000 ******************************\n",
      "****************************** 44000 ******************************\n",
      "****************************** 46000 ******************************\n",
      "****************************** 48000 ******************************\n",
      "****************************** 50000 ******************************\n",
      "****************************** 52000 ******************************\n",
      "****************************** 54000 ******************************\n",
      "****************************** 56000 ******************************\n",
      "****************************** 58000 ******************************\n",
      "****************************** 1999 ******************************\n",
      "num correct is  1793  an accuracy of  0.8969484742371185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 3999 ******************************\n",
      "num correct is  3595  an accuracy of  0.8989747436859215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 5999 ******************************\n",
      "num correct is  5411  an accuracy of  0.9019836639439907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 7999 ******************************\n",
      "num correct is  7261  an accuracy of  0.9077384673084136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 9999 ******************************\n",
      "num correct is  9114  an accuracy of  0.9114911491149115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num correct is  9115  an accuracy of  0.9115\n",
      "2020-05-30 06:32:46.927915 end\n"
     ]
    }
   ],
   "source": [
    "USE_REL_BDY=False\n",
    "Config.N_NEIGHBORS=5\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.USE_PARENT_CENTROIDS=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-30 05:20:55.465422 start\n",
      "<class 'numpy.ndarray'> (0, 170)\n",
      "****************************** 0 ******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "****************************** 6000 ******************************\n",
      "****************************** 8000 ******************************\n",
      "****************************** 10000 ******************************\n",
      "****************************** 12000 ******************************\n",
      "****************************** 14000 ******************************\n",
      "****************************** 16000 ******************************\n",
      "****************************** 18000 ******************************\n",
      "****************************** 20000 ******************************\n",
      "****************************** 22000 ******************************\n",
      "****************************** 24000 ******************************\n",
      "****************************** 26000 ******************************\n",
      "****************************** 28000 ******************************\n",
      "****************************** 30000 ******************************\n",
      "****************************** 32000 ******************************\n",
      "****************************** 34000 ******************************\n",
      "****************************** 36000 ******************************\n",
      "****************************** 38000 ******************************\n",
      "****************************** 40000 ******************************\n",
      "****************************** 42000 ******************************\n",
      "****************************** 44000 ******************************\n",
      "****************************** 46000 ******************************\n",
      "****************************** 48000 ******************************\n",
      "****************************** 50000 ******************************\n",
      "****************************** 52000 ******************************\n",
      "****************************** 54000 ******************************\n",
      "****************************** 56000 ******************************\n",
      "****************************** 58000 ******************************\n",
      "****************************** 1999 ******************************\n",
      "num correct is  1786  an accuracy of  0.8934467233616809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 3999 ******************************\n",
      "num correct is  3577  an accuracy of  0.8944736184046012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 5999 ******************************\n",
      "num correct is  5392  an accuracy of  0.8988164694115686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 7999 ******************************\n",
      "num correct is  7228  an accuracy of  0.9036129516189524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** 9999 ******************************\n",
      "num correct is  9084  an accuracy of  0.9084908490849085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num correct is  9085  an accuracy of  0.9085\n",
      "2020-05-30 06:00:58.404735 end\n"
     ]
    }
   ],
   "source": [
    "USE_REL_BDY=False\n",
    "Config.USE_PARENT_CENTROIDS=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.USE_PARENT_CENTROIDS=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s2weightcentroids'></a>\n",
    "<a href='#toc'>Goto Table of Contents</a>\n",
    "\n",
    "## append the image to the weighted centroids\n",
    "\n",
    "- kNN acc (6,000 93.6%; 60,000 )\n",
    "- CNN acc (6,000 94.39% (+/- 1.10%); 60,000 )\n",
    "\n",
    "## whereas the baseline is\n",
    "\n",
    "## kNN acc (6,000 91.6% 60,000 96.88%)\n",
    "## CNN acc (6,000 96.06% (+/- 1.42%); 60,000 99.00% (+/- 0.21%))\n",
    "\n",
    "- kNN acc (6,000 91.6%; 60,000 )\n",
    "- CNN acc (6,000 94.61% (+/- 1.72%); 60,000 )\n",
    "\n",
    "## The results are not the best in any situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-02 10:58:59.086326 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 9 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 9 8 7 2 3 0 4 4 2 4 1 9 5 7 7 2 8 2 6 8 5 7 7 9 1 8 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 9 2 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 8 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 2 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 3 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 6 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 3 8 8 2 7 5 8 9 6 1 8 4 1 2 5 9 1 9 7 5 4 0 8 9 9 1 0 5 2 3 7\n",
      " 8 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 8 4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 2 1 7 0 6 5 4 3 8 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 2 3 1 9 7 5 1 0 8 4 6 2 6 7 9 3 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 5 8 0 3 7 2 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 7 8 3 3 6 7 2 8 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 8 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5 4 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 5\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 8 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 8 8 8 7 4 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 2 3 2 3 9 1 7 4 0 3 5 5 8 6 3 2 6 7 6 6 3 2 7 8 1 1 7 5 6 4 9 5 1 3 3 4 7 8 9 1 1 6 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "<class 'numpy.ndarray'> (0, 128)\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "fill_up_last_row.shape (7000, 12)\n",
      "X_num_images 7000 X_image_num_pixels 912\n",
      "num_extra_rows 5\n",
      "2020-06-02 11:00:56.229705 Start of fit\n",
      "Epoch 1/5\n",
      "6296/6296 [==============================] - 3s 471us/sample - loss: 0.8638 - acc: 0.7147\n",
      "Epoch 2/5\n",
      "6296/6296 [==============================] - 3s 428us/sample - loss: 0.3069 - acc: 0.9003s - loss: 0.3075 - acc: 0\n",
      "Epoch 3/5\n",
      "6296/6296 [==============================] - 3s 418us/sample - loss: 0.2032 - acc: 0.9368s -\n",
      "Epoch 4/5\n",
      "6296/6296 [==============================] - 3s 410us/sample - loss: 0.1534 - acc: 0.9517s - loss: 0.1473 - acc: - ETA: 0s - loss: 0.15\n",
      "Epoch 5/5\n",
      "6296/6296 [==============================] - 3s 413us/sample - loss: 0.1198 - acc: 0.9620\n",
      "2020-06-02 11:01:10.913127 End of fit\n",
      "acc: 94.60%\n",
      "2020-06-02 11:01:11.589686 Start of fit\n",
      "Epoch 1/5\n",
      "6297/6297 [==============================] - 3s 489us/sample - loss: 0.8626 - acc: 0.7162s - loss: 0.9858 - \n",
      "Epoch 2/5\n",
      "6297/6297 [==============================] - 3s 434us/sample - loss: 0.3010 - acc: 0.9001s - loss: 0.3033 - acc: 0.899\n",
      "Epoch 3/5\n",
      "6297/6297 [==============================] - 3s 428us/sample - loss: 0.2107 - acc: 0.9336s - loss: 0.\n",
      "Epoch 4/5\n",
      "6297/6297 [==============================] - 3s 433us/sample - loss: 0.1574 - acc: 0.9493\n",
      "Epoch 5/5\n",
      "6297/6297 [==============================] - 3s 435us/sample - loss: 0.1216 - acc: 0.9600\n",
      "2020-06-02 11:01:26.714278 End of fit\n",
      "acc: 93.60%\n",
      "2020-06-02 11:01:27.396468 Start of fit\n",
      "Epoch 1/5\n",
      "6297/6297 [==============================] - 3s 495us/sample - loss: 0.8434 - acc: 0.7213\n",
      "Epoch 2/5\n",
      "6297/6297 [==============================] - 3s 420us/sample - loss: 0.3070 - acc: 0.8993\n",
      "Epoch 3/5\n",
      "6297/6297 [==============================] - 3s 424us/sample - loss: 0.2038 - acc: 0.9317\n",
      "Epoch 4/5\n",
      "6297/6297 [==============================] - 3s 430us/sample - loss: 0.1592 - acc: 0.9468\n",
      "Epoch 5/5\n",
      "6297/6297 [==============================] - 3s 415us/sample - loss: 0.1240 - acc: 0.9593\n",
      "2020-06-02 11:01:42.273659 End of fit\n",
      "acc: 94.31%\n",
      "2020-06-02 11:01:42.973264 Start of fit\n",
      "Epoch 1/5\n",
      "6298/6298 [==============================] - 3s 478us/sample - loss: 0.8500 - acc: 0.7315s - l\n",
      "Epoch 2/5\n",
      "6298/6298 [==============================] - 3s 411us/sample - loss: 0.2914 - acc: 0.9089s -\n",
      "Epoch 3/5\n",
      "6298/6298 [==============================] - 3s 411us/sample - loss: 0.1884 - acc: 0.9408s - loss: \n",
      "Epoch 4/5\n",
      "6298/6298 [==============================] - 3s 423us/sample - loss: 0.1406 - acc: 0.9559\n",
      "Epoch 5/5\n",
      "6298/6298 [==============================] - 3s 427us/sample - loss: 0.1098 - acc: 0.9654s - loss: 0.1117 - acc:\n",
      "2020-06-02 11:01:57.681183 End of fit\n",
      "acc: 97.01%\n",
      "2020-06-02 11:01:58.389072 Start of fit\n",
      "Epoch 1/5\n",
      "6298/6298 [==============================] - 3s 483us/sample - loss: 0.7848 - acc: 0.7409\n",
      "Epoch 2/5\n",
      "6298/6298 [==============================] - 3s 434us/sample - loss: 0.2810 - acc: 0.9046s - loss: 0.3343 - acc:  - ETA: 2s - loss: 0.3129  - ETA: 1s - lo\n",
      "Epoch 3/5\n",
      "6298/6298 [==============================] - 3s 431us/sample - loss: 0.1931 - acc: 0.9335TA: 0s - loss: 0.1935 - acc: 0\n",
      "Epoch 4/5\n",
      "6298/6298 [==============================] - 3s 447us/sample - loss: 0.1482 - acc: 0.9517\n",
      "Epoch 5/5\n",
      "6298/6298 [==============================] - 3s 434us/sample - loss: 0.1106 - acc: 0.9613s - loss: 0.1065 - acc: 0.962 - ETA: 1\n",
      "2020-06-02 11:02:13.644109 End of fit\n",
      "acc: 93.73%\n",
      "2020-06-02 11:02:14.376260 Start of fit\n",
      "Epoch 1/5\n",
      "6301/6301 [==============================] - 3s 488us/sample - loss: 0.8749 - acc: 0.7061s - loss: 0.9445 - acc:\n",
      "Epoch 2/5\n",
      "6301/6301 [==============================] - 3s 442us/sample - loss: 0.3188 - acc: 0.8937\n",
      "Epoch 3/5\n",
      "6301/6301 [==============================] - 3s 451us/sample - loss: 0.2065 - acc: 0.9354s - loss: 0.\n",
      "Epoch 4/5\n",
      "6301/6301 [==============================] - 3s 443us/sample - loss: 0.1566 - acc: 0.9491s - loss: 0.1588 - acc: 0.94\n",
      "Epoch 5/5\n",
      "6301/6301 [==============================] - 3s 468us/sample - loss: 0.1248 - acc: 0.9606\n",
      "2020-06-02 11:02:30.278190 End of fit\n",
      "acc: 92.99%\n",
      "2020-06-02 11:02:31.069032 Start of fit\n",
      "Epoch 1/5\n",
      "6301/6301 [==============================] - 3s 473us/sample - loss: 0.8866 - acc: 0.7058\n",
      "Epoch 2/5\n",
      "6301/6301 [==============================] - 3s 413us/sample - loss: 0.3034 - acc: 0.8999\n",
      "Epoch 3/5\n",
      "6301/6301 [==============================] - 3s 429us/sample - loss: 0.2101 - acc: 0.9343s - loss: 0.2195 - - ETA: 0s - loss: 0.2\n",
      "Epoch 4/5\n",
      "6301/6301 [==============================] - 3s 434us/sample - loss: 0.1591 - acc: 0.9486\n",
      "Epoch 5/5\n",
      "6301/6301 [==============================] - 3s 449us/sample - loss: 0.1265 - acc: 0.9562\n",
      "2020-06-02 11:02:46.274604 End of fit\n",
      "acc: 94.56%\n",
      "2020-06-02 11:02:47.048000 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 3s 479us/sample - loss: 0.8312 - acc: 0.7218s - lo\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 3s 417us/sample - loss: 0.2962 - acc: 0.9058s - loss: 0.3131 \n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 3s 438us/sample - loss: 0.2054 - acc: 0.9345\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 3s 434us/sample - loss: 0.1546 - acc: 0.9488s - loss: 0.1515 - acc: 0.951 - ETA: 1s - l\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 437us/sample - loss: 0.1210 - acc: 0.9610\n",
      "2020-06-02 11:03:02.274607 End of fit\n",
      "acc: 94.25%\n",
      "2020-06-02 11:03:03.052725 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 3s 484us/sample - loss: 0.8506 - acc: 0.7200\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 3s 424us/sample - loss: 0.2989 - acc: 0.8985\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 3s 504us/sample - loss: 0.1977 - acc: 0.9370\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 4s 556us/sample - loss: 0.1457 - acc: 0.9557\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 502us/sample - loss: 0.1175 - acc: 0.9630\n",
      "2020-06-02 11:03:19.977199 End of fit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 95.40%\n",
      "2020-06-02 11:03:20.839472 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 3s 543us/sample - loss: 0.8289 - acc: 0.7281ETA: 0s - loss: 0.9509 \n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 3s 439us/sample - loss: 0.2895 - acc: 0.9094\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 3s 418us/sample - loss: 0.1959 - acc: 0.9378s - loss: 0.1937\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 3s 414us/sample - loss: 0.1506 - acc: 0.9521s - loss\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 413us/sample - loss: 0.1177 - acc: 0.9629\n",
      "2020-06-02 11:03:36.383244 End of fit\n",
      "acc: 93.39%\n",
      "94.39% (+/- 1.10%)\n",
      "2020-06-02 11:03:37.021901 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 9 9 8 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 3 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 7 7 9 2 2 4 1 5 8 8 4 2 3 0 6 4 2 9 1 9 5 7 7 2 6 2 6 8 5 7 7 4 1 0 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 7 7 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 5 6 5 4 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 7 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 7 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 8 0 6 4 8 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 7 8 8 2 7 5 8 9 6 1 8 4 1 2 5 8 1 9 7 5 4 0 8 9 7 1 0 5 8 3 7\n",
      " 0 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 7 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 3 4 0 0 8 3 2 9 4 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 7 1 7 0 6 5 4 3 3 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 8 3 1 9 7 5 1 0 8 4 6 2 6 7 9 9 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 0 8 0 3 7 8 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 9 8 3 3 6 7 2 9 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 3 2 7 6 8 4 5 0 4 0 6 1 4 3 2 6 7 2 6 9 3 1 4 6 3 5 9 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 9 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 3 6 8 9 4 1 9\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 9 0 1 7 7 4 7 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 2 8 8 7 9 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 7 3 0 3 9 1 4 4 0 3 5 5 8 6 3 0 6 7 6 6 3 2 7 9 1 1 7 9 6 4 9 6 1 5 3 4 7 8 7 1 1 0 9 1 4 4 5 4 0 6 2 2 8 1 5 1 2 0 8 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "ndx_errs (array([149, 151, 187, 233, 241, 243, 247, 250, 257, 264, 266, 320, 321, 338, 341, 362, 381, 444, 445, 448, 464, 479, 488, 492, 495, 511, 543, 547, 550, 551, 583, 591, 613, 628, 654, 659, 684, 691,\n",
      "       714, 716, 717, 726, 738, 740, 760, 785, 791, 838, 839, 844, 877, 881, 924, 926, 930, 939, 947, 951, 955, 957, 962, 965, 976, 982], dtype=int64),)\n",
      "num correct is  936  an accuracy of  0.9359999999999999\n",
      "2020-06-02 11:03:46.311690 end\n"
     ]
    }
   ],
   "source": [
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=6_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=1_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-02 11:34:23.991176 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 9 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 9 8 7 2 3 0 4 4 2 4 1 9 5 7 7 2 8 2 6 8 5 7 7 9 1 8 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 9 2 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 8 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 2 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 3 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 6 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 3 8 8 2 7 5 8 9 6 1 8 4 1 2 5 9 1 9 7 5 4 0 8 9 9 1 0 5 2 3 7\n",
      " 8 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 8 4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 2 1 7 0 6 5 4 3 8 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 2 3 1 9 7 5 1 0 8 4 6 2 6 7 9 3 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 5 8 0 3 7 2 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 7 8 3 3 6 7 2 8 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 8 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5 4 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 5\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 8 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 8 8 8 7 4 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 2 3 2 3 9 1 7 4 0 3 5 5 8 6 3 2 6 7 6 6 3 2 7 8 1 1 7 5 6 4 9 5 1 3 3 4 7 8 9 1 1 6 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "<class 'numpy.ndarray'> (0, 128)\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "fill_up_last_row.shape (7000, 12)\n",
      "X_num_images 7000 X_image_num_pixels 912\n",
      "num_extra_rows 5\n",
      "2020-06-02 11:36:20.837003 Start of fit\n",
      "Epoch 1/5\n",
      "6296/6296 [==============================] - 3s 494us/sample - loss: 0.8348 - acc: 0.7260\n",
      "Epoch 2/5\n",
      "6296/6296 [==============================] - 3s 435us/sample - loss: 0.3036 - acc: 0.9009\n",
      "Epoch 3/5\n",
      "6296/6296 [==============================] - 3s 438us/sample - loss: 0.2040 - acc: 0.9322\n",
      "Epoch 4/5\n",
      "6296/6296 [==============================] - 3s 432us/sample - loss: 0.1575 - acc: 0.9501s - loss: 0.1577 - acc: 0.95\n",
      "Epoch 5/5\n",
      "6296/6296 [==============================] - 3s 420us/sample - loss: 0.1251 - acc: 0.9584\n",
      "2020-06-02 11:36:36.594744 End of fit\n",
      "acc: 96.02%\n",
      "2020-06-02 11:36:37.570912 Start of fit\n",
      "Epoch 1/5\n",
      "6297/6297 [==============================] - 3s 502us/sample - loss: 0.8670 - acc: 0.7167\n",
      "Epoch 2/5\n",
      "6297/6297 [==============================] - 3s 430us/sample - loss: 0.3185 - acc: 0.9011\n",
      "Epoch 3/5\n",
      "6297/6297 [==============================] - 3s 443us/sample - loss: 0.2188 - acc: 0.9323\n",
      "Epoch 4/5\n",
      "6297/6297 [==============================] - 3s 430us/sample - loss: 0.1671 - acc: 0.9473\n",
      "Epoch 5/5\n",
      "6297/6297 [==============================] - ETA: 0s - loss: 0.1288 - acc: 0.961 - 3s 428us/sample - loss: 0.1281 - acc: 0.9617\n",
      "2020-06-02 11:36:53.472034 End of fit\n",
      "acc: 95.16%\n",
      "2020-06-02 11:36:54.466715 Start of fit\n",
      "Epoch 1/5\n",
      "6297/6297 [==============================] - 3s 505us/sample - loss: 0.9194 - acc: 0.7040\n",
      "Epoch 2/5\n",
      "6297/6297 [==============================] - 3s 439us/sample - loss: 0.3264 - acc: 0.8952\n",
      "Epoch 3/5\n",
      "6297/6297 [==============================] - 3s 426us/sample - loss: 0.2229 - acc: 0.9292s - loss: 0.2413 - - ETA: 0s - loss: 0.2375 - acc: 0.923 - ETA: 0s - loss: 0.2365 \n",
      "Epoch 4/5\n",
      "6297/6297 [==============================] - 3s 433us/sample - loss: 0.1651 - acc: 0.9482\n",
      "Epoch 5/5\n",
      "6297/6297 [==============================] - 3s 423us/sample - loss: 0.1352 - acc: 0.9570: 0s - loss: 0.1399 - acc\n",
      "2020-06-02 11:37:10.380559 End of fit\n",
      "acc: 96.16%\n",
      "2020-06-02 11:37:11.390431 Start of fit\n",
      "Epoch 1/5\n",
      "6298/6298 [==============================] - 3s 505us/sample - loss: 0.8178 - acc: 0.7350\n",
      "Epoch 2/5\n",
      "6298/6298 [==============================] - 3s 440us/sample - loss: 0.2876 - acc: 0.9073\n",
      "Epoch 3/5\n",
      "6298/6298 [==============================] - 3s 432us/sample - loss: 0.1973 - acc: 0.9311\n",
      "Epoch 4/5\n",
      "6298/6298 [==============================] - 3s 435us/sample - loss: 0.1497 - acc: 0.9557\n",
      "Epoch 5/5\n",
      "6298/6298 [==============================] - 3s 429us/sample - loss: 0.1188 - acc: 0.9616\n",
      "2020-06-02 11:37:27.623943 End of fit\n",
      "acc: 94.30%\n",
      "2020-06-02 11:37:28.632146 Start of fit\n",
      "Epoch 1/5\n",
      "6298/6298 [==============================] - 3s 517us/sample - loss: 0.8703 - acc: 0.7147\n",
      "Epoch 2/5\n",
      "6298/6298 [==============================] - 3s 434us/sample - loss: 0.3010 - acc: 0.9006\n",
      "Epoch 3/5\n",
      "6298/6298 [==============================] - 3s 434us/sample - loss: 0.2020 - acc: 0.9352\n",
      "Epoch 4/5\n",
      "6298/6298 [==============================] - 3s 431us/sample - loss: 0.1497 - acc: 0.9509\n",
      "Epoch 5/5\n",
      "6298/6298 [==============================] - 3s 435us/sample - loss: 0.1199 - acc: 0.9608\n",
      "2020-06-02 11:37:44.787292 End of fit\n",
      "acc: 94.87%\n",
      "2020-06-02 11:37:45.827595 Start of fit\n",
      "Epoch 1/5\n",
      "6301/6301 [==============================] - 3s 504us/sample - loss: 0.8379 - acc: 0.7210\n",
      "Epoch 2/5\n",
      "6301/6301 [==============================] - 3s 442us/sample - loss: 0.3074 - acc: 0.8995\n",
      "Epoch 3/5\n",
      "6301/6301 [==============================] - 3s 430us/sample - loss: 0.2066 - acc: 0.9352\n",
      "Epoch 4/5\n",
      "6301/6301 [==============================] - 3s 441us/sample - loss: 0.1603 - acc: 0.9486\n",
      "Epoch 5/5\n",
      "6301/6301 [==============================] - 3s 449us/sample - loss: 0.1260 - acc: 0.9589s - loss: 0.1268 - acc: 0.9\n",
      "2020-06-02 11:38:02.094704 End of fit\n",
      "acc: 96.42%\n",
      "2020-06-02 11:38:03.149258 Start of fit\n",
      "Epoch 1/5\n",
      "6301/6301 [==============================] - 3s 510us/sample - loss: 0.8555 - acc: 0.7162\n",
      "Epoch 2/5\n",
      "6301/6301 [==============================] - 3s 436us/sample - loss: 0.2992 - acc: 0.9051s - loss: 0.\n",
      "Epoch 3/5\n",
      "6301/6301 [==============================] - 3s 457us/sample - loss: 0.2104 - acc: 0.9297\n",
      "Epoch 4/5\n",
      "6301/6301 [==============================] - 3s 450us/sample - loss: 0.1590 - acc: 0.9486\n",
      "Epoch 5/5\n",
      "6301/6301 [==============================] - 3s 448us/sample - loss: 0.1202 - acc: 0.9614s\n",
      "2020-06-02 11:38:19.695850 End of fit\n",
      "acc: 95.42%\n",
      "2020-06-02 11:38:20.802347 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 3s 529us/sample - loss: 0.8529 - acc: 0.7278\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 3s 459us/sample - loss: 0.3141 - acc: 0.9042\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 3s 506us/sample - loss: 0.2071 - acc: 0.9332s - loss: 0.2051 -\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 3s 486us/sample - loss: 0.1666 - acc: 0.9480\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 501us/sample - loss: 0.1282 - acc: 0.9591\n",
      "2020-06-02 11:38:38.489466 End of fit\n",
      "acc: 92.10%\n",
      "2020-06-02 11:38:39.666585 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 3s 501us/sample - loss: 0.8455 - acc: 0.7262s - loss - ETA: 0s - loss: 1.0152 \n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 3s 409us/sample - loss: 0.3086 - acc: 0.9012\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - ETA: 0s - loss: 0.2130 - acc: 0.9314- ETA: 0s - loss: 0.2134 - acc: 0 - 3s 426us/sample - loss: 0.2118 - acc: 0.9315\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 3s 424us/sample - loss: 0.1579 - acc: 0.9488\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 454us/sample - loss: 0.1193 - acc: 0.9608\n",
      "2020-06-02 11:38:55.726859 End of fit\n",
      "acc: 94.83%\n",
      "2020-06-02 11:38:56.869898 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 3s 499us/sample - loss: 0.8934 - acc: 0.7107\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 3s 416us/sample - loss: 0.3114 - acc: 0.9032\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 3s 415us/sample - loss: 0.2157 - acc: 0.9312\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 3s 419us/sample - loss: 0.1653 - acc: 0.9470\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 426us/sample - loss: 0.1327 - acc: 0.9564\n",
      "2020-06-02 11:39:12.701557 End of fit\n",
      "acc: 90.80%\n",
      "94.61% (+/- 1.72%)\n",
      "2020-06-02 11:39:13.649198 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 9 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 1 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 3 9 7 9 6 2 7 8 4 7 3 6 1 3 6 4 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 1 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 1 9 9 5 5 1 5 6 0 3 1 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 1 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 1 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 8 8 7 2 6 0 6 4 2 9 1 9 5 7 7 2 6 2 6 8 5 7 7 4 1 0 1 3 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 9 2 9 2 0 4 0\n",
      " 0 2 8 1 7 1 7 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 7 7 9 3 6 4 6 0 7 1 1 2 1 5 3 3 9 7 5 6 5 4 1 3 8 1 0 5 1 9 1 5 5 6 1 8 5 1 4 9 4 6 7 2 5 0 6 8 6 3 7 2 0 8 8 5 4 1 1 4 0 7 3 7 6 1 6 2 1 4 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 5 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 0 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 7 8 8 2 7 5 8 9 6 1 8 4 1 2 5 8 1 9 7 5 4 0 8 9 9 1 0 5 8 3 7\n",
      " 0 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 7 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 1 9 4 0 0 8 3 2 7 1 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 9 8 3 3 9 3 3 3 7 8 0 2 7 1 7 0 6 5 4 3 3 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 1 3 1 9 7 5 1 0 8 4 6 2 6 7 9 9 2 9 8 2 2 9 1 7 3 5 9 1 8 0 2 0 5 6 1 3 7 6 7 1 2 0 8 0 3 7 7 4 0 9 1 8 6 7 1 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 1 8 3 3 6 9 2 4 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 9 4 8 5 5 4 0 5 2 1 6 8 4 5 0 4 0 6 1 5 3 2 6 7 2 6 9 3 1 4 6 2 5 9 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 3 3 1 4 5 6 8 9 4 1 9\n",
      " 3 8 0 6 2 1 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 4 1 7 9 6 1 1 2 4 0 1 7 7 4 3 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 6 2 2 5 6 0 8 2 9 2 8 8 8 8 7 9 4 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 7 3 0 3 9 1 1 4 0 3 5 5 6 6 5 0 6 7 6 6 3 2 7 9 1 1 7 4 6 4 9 5 1 5 3 4 7 8 9 1 1 0 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "ndx_errs (array([ 24,  43,  77,  80,  92, 111, 115, 149, 159, 175, 195, 241, 245, 247, 250, 257, 264, 266, 268, 290, 300, 303, 320, 321, 324, 326, 338, 341, 349, 358, 362, 367, 381, 389, 403, 445, 464, 479,\n",
      "       492, 495, 511, 542, 543, 547, 551, 571, 582, 583, 591, 613, 628, 635, 646, 654, 659, 667, 684, 689, 691, 707, 714, 717, 726, 740, 781, 791, 795, 797, 830, 839, 844, 866, 881, 882, 924, 926,\n",
      "       930, 936, 938, 939, 947, 951, 957, 965], dtype=int64),)\n",
      "num correct is  916  an accuracy of  0.916\n",
      "2020-06-02 11:39:22.911981 end\n"
     ]
    }
   ],
   "source": [
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=6_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=1_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s2onlyleaves2'></a>\n",
    "<a href='#toc'>Goto Table of Contents</a>\n",
    "\n",
    "## Try weighted centroids with parents\n",
    "\n",
    "- kNN acc (6,000 93.4%; 60,000 )\n",
    "- CNN acc (6,000 97.01% (+/- 0.80%); 60,000 )\n",
    "\n",
    "## whereas the baseline is\n",
    "\n",
    "## kNN acc (6,000 91.6% 60,000 96.88%)\n",
    "## CNN acc (6,000 96.06% (+/- 1.42%); 60,000 99.00% (+/- 0.21%))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-02 11:42:05.852666 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 9 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 9 8 7 2 3 0 4 4 2 4 1 9 5 7 7 2 8 2 6 8 5 7 7 9 1 8 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 9 2 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 8 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 2 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 3 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 6 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 3 8 8 2 7 5 8 9 6 1 8 4 1 2 5 9 1 9 7 5 4 0 8 9 9 1 0 5 2 3 7\n",
      " 8 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 8 4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 2 1 7 0 6 5 4 3 8 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 2 3 1 9 7 5 1 0 8 4 6 2 6 7 9 3 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 5 8 0 3 7 2 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 7 8 3 3 6 7 2 8 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 8 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5 4 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 5\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 8 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 8 8 8 7 4 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 2 3 2 3 9 1 7 4 0 3 5 5 8 6 3 2 6 7 6 6 3 2 7 8 1 1 7 5 6 4 9 5 1 3 3 4 7 8 9 1 1 6 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "<class 'numpy.ndarray'> (0, 170)\n",
      "<class 'numpy.ndarray'> (0, 954)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 954)\n",
      "fill_up_last_row.shape (7000, 26)\n",
      "X_num_images 7000 X_image_num_pixels 954\n",
      "num_extra_rows 7\n",
      "2020-06-02 11:44:18.936276 Start of fit\n",
      "Epoch 1/5\n",
      "6296/6296 [==============================] - 3s 540us/sample - loss: 0.7278 - acc: 0.7660\n",
      "Epoch 2/5\n",
      "6296/6296 [==============================] - 3s 445us/sample - loss: 0.2020 - acc: 0.9408s - loss: 0\n",
      "Epoch 3/5\n",
      "6296/6296 [==============================] - 3s 450us/sample - loss: 0.1205 - acc: 0.9646\n",
      "Epoch 4/5\n",
      "6296/6296 [==============================] - 3s 448us/sample - loss: 0.0822 - acc: 0.9746\n",
      "Epoch 5/5\n",
      "6296/6296 [==============================] - 3s 453us/sample - loss: 0.0585 - acc: 0.9827\n",
      "2020-06-02 11:44:35.838929 End of fit\n",
      "acc: 97.30%\n",
      "2020-06-02 11:44:36.998960 Start of fit\n",
      "Epoch 1/5\n",
      "6297/6297 [==============================] - 3s 545us/sample - loss: 0.6786 - acc: 0.7829s - loss: 1.1248 - acc: - ETA: 1s - loss\n",
      "Epoch 2/5\n",
      "6297/6297 [==============================] - 3s 453us/sample - loss: 0.1936 - acc: 0.9403\n",
      "Epoch 3/5\n",
      "6297/6297 [==============================] - 3s 462us/sample - loss: 0.1117 - acc: 0.9655\n",
      "Epoch 4/5\n",
      "6297/6297 [==============================] - 3s 463us/sample - loss: 0.0802 - acc: 0.9760\n",
      "Epoch 5/5\n",
      "6297/6297 [==============================] - 3s 451us/sample - loss: 0.0553 - acc: 0.9832\n",
      "2020-06-02 11:44:54.155309 End of fit\n",
      "acc: 97.72%\n",
      "2020-06-02 11:44:55.330930 Start of fit\n",
      "Epoch 1/5\n",
      "6297/6297 [==============================] - 3s 539us/sample - loss: 0.7300 - acc: 0.7734\n",
      "Epoch 2/5\n",
      "6297/6297 [==============================] - 3s 457us/sample - loss: 0.2075 - acc: 0.9368\n",
      "Epoch 3/5\n",
      "6297/6297 [==============================] - 3s 455us/sample - loss: 0.1228 - acc: 0.9624\n",
      "Epoch 4/5\n",
      "6297/6297 [==============================] - 3s 447us/sample - loss: 0.0814 - acc: 0.9713\n",
      "Epoch 5/5\n",
      "6297/6297 [==============================] - 3s 465us/sample - loss: 0.0532 - acc: 0.9840s - loss: 0.0561 - acc\n",
      "2020-06-02 11:45:12.563039 End of fit\n",
      "acc: 96.73%\n",
      "2020-06-02 11:45:13.747711 Start of fit\n",
      "Epoch 1/5\n",
      "6298/6298 [==============================] - 3s 547us/sample - loss: 0.6912 - acc: 0.7793\n",
      "Epoch 2/5\n",
      "6298/6298 [==============================] - 3s 455us/sample - loss: 0.1910 - acc: 0.9411\n",
      "Epoch 3/5\n",
      "6298/6298 [==============================] - 3s 492us/sample - loss: 0.1149 - acc: 0.9651s -\n",
      "Epoch 4/5\n",
      "6298/6298 [==============================] - 3s 475us/sample - loss: 0.0792 - acc: 0.9771s - loss:\n",
      "Epoch 5/5\n",
      "6298/6298 [==============================] - 3s 465us/sample - loss: 0.0574 - acc: 0.9825\n",
      "2020-06-02 11:45:31.438098 End of fit\n",
      "acc: 97.29%\n",
      "2020-06-02 11:45:32.653561 Start of fit\n",
      "Epoch 1/5\n",
      "6298/6298 [==============================] - 3s 534us/sample - loss: 0.6436 - acc: 0.7930s - loss: 0.6914 - acc: \n",
      "Epoch 2/5\n",
      "6298/6298 [==============================] - 3s 452us/sample - loss: 0.1882 - acc: 0.9389s - loss: 0.1889 - acc: 0.938\n",
      "Epoch 3/5\n",
      "6298/6298 [==============================] - 3s 453us/sample - loss: 0.1027 - acc: 0.9679\n",
      "Epoch 4/5\n",
      "6298/6298 [==============================] - 3s 468us/sample - loss: 0.0728 - acc: 0.9786s - loss: 0\n",
      "Epoch 5/5\n",
      "6298/6298 [==============================] - 3s 468us/sample - loss: 0.0560 - acc: 0.9833s - loss: 0.0\n",
      "2020-06-02 11:45:49.943697 End of fit\n",
      "acc: 97.01%\n",
      "2020-06-02 11:45:51.178144 Start of fit\n",
      "Epoch 1/5\n",
      "6301/6301 [==============================] - 3s 541us/sample - loss: 0.6899 - acc: 0.7773\n",
      "Epoch 2/5\n",
      "6301/6301 [==============================] - 3s 450us/sample - loss: 0.1919 - acc: 0.9414\n",
      "Epoch 3/5\n",
      "6301/6301 [==============================] - 3s 458us/sample - loss: 0.1188 - acc: 0.9637\n",
      "Epoch 4/5\n",
      "6301/6301 [==============================] - 3s 472us/sample - loss: 0.0783 - acc: 0.9740s - loss: 0.0823 - acc: 0.97 - ETA: 0s - loss: 0.0808 - acc: 0.97 - ETA: 0s - loss: 0.0792 - acc: 0.97\n",
      "Epoch 5/5\n",
      "6301/6301 [==============================] - 3s 472us/sample - loss: 0.0562 - acc: 0.9813s - loss: 0.0572 - acc: 0.\n",
      "2020-06-02 11:46:08.591225 End of fit\n",
      "acc: 97.71%\n",
      "2020-06-02 11:46:10.148025 Start of fit\n",
      "Epoch 1/5\n",
      "6301/6301 [==============================] - 3s 541us/sample - loss: 0.7474 - acc: 0.7727s - loss: 0.8049 - acc: \n",
      "Epoch 2/5\n",
      "6301/6301 [==============================] - 3s 458us/sample - loss: 0.2073 - acc: 0.9365\n",
      "Epoch 3/5\n",
      "6301/6301 [==============================] - 3s 453us/sample - loss: 0.1239 - acc: 0.9627\n",
      "Epoch 4/5\n",
      "6301/6301 [==============================] - 3s 470us/sample - loss: 0.0890 - acc: 0.9732s - loss: 0.0893 - acc: 0.973\n",
      "Epoch 5/5\n",
      "6301/6301 [==============================] - 3s 479us/sample - loss: 0.0640 - acc: 0.9806\n",
      "2020-06-02 11:46:27.655515 End of fit\n",
      "acc: 97.71%\n",
      "2020-06-02 11:46:28.921515 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 3s 548us/sample - loss: 0.7103 - acc: 0.7789\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 3s 456us/sample - loss: 0.2156 - acc: 0.9343\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 3s 459us/sample - loss: 0.1294 - acc: 0.9603s - loss: 0.1313 - acc: 0.9\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 3s 469us/sample - loss: 0.0958 - acc: 0.9721\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 480us/sample - loss: 0.0635 - acc: 0.9792s - loss: 0.0629 - acc: 0.979\n",
      "2020-06-02 11:46:46.542866 End of fit\n",
      "acc: 94.97%\n",
      "2020-06-02 11:46:47.826250 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 4s 561us/sample - loss: 0.7143 - acc: 0.7786TA: 0s - loss: 0.7269 - acc: 0.77\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 3s 471us/sample - loss: 0.2025 - acc: 0.9385\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 3s 465us/sample - loss: 0.1175 - acc: 0.9618\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - ETA: 0s - loss: 0.0767 - acc: 0.9778- ETA: 1s - loss: 0.0825 - acc: 0.9 - ETA: 0s - loss: 0.0844 - acc: 0. - ETA: 0s - loss: 0.0831 -  - 3s 487us/sample - loss: 0.0775 - acc: 0.9773\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 470us/sample - loss: 0.0594 - acc: 0.9797s - loss: 0.0 - ETA: 0s - loss: 0.0622 - acc - ETA: 0s - loss: 0.0623 - acc\n",
      "2020-06-02 11:47:05.743434 End of fit\n",
      "acc: 96.41%\n",
      "2020-06-02 11:47:07.044920 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 3s 538us/sample - loss: 0.6893 - acc: 0.7776\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 3s 463us/sample - loss: 0.1860 - acc: 0.9464\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 3s 455us/sample - loss: 0.1164 - acc: 0.9654\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 3s 456us/sample - loss: 0.0821 - acc: 0.9749\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 455us/sample - loss: 0.0604 - acc: 0.9822\n",
      "2020-06-02 11:47:24.452851 End of fit\n",
      "acc: 97.27%\n",
      "97.01% (+/- 0.80%)\n",
      "2020-06-02 11:47:25.569218 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 7 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 8 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 3 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 7 7 9 2 2 4 1 5 8 8 4 2 6 0 6 4 2 9 1 9 5 7 7 2 6 2 6 8 5 7 7 9 1 0 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 7 7 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 5 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 7 2 5 0 6 5 6 3 7 2 0 8 8 5 9 1 1 4 0 7 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 8 0 6 4 8 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 7 8 8 2 7 5 8 9 6 1 8 4 1 2 6 8 1 9 7 5 4 0 8 9 9 1 0 5 8 3 7\n",
      " 0 9 9 0 6 3 9 5 2 1 3 1 3 6 5 7 7 2 2 6 8 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 9 4 6 4 2 1 8 2 5 4 8 3 4 0 0 8 3 2 9 4 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 7 1 7 0 6 5 4 3 3 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 9 8 6 0 2 4 0 2 8 3 1 9 7 5 1 0 8 4 6 2 6 7 9 9 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 0 8 0 3 7 8 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 9 8 3 3 6 7 2 3 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 3 2 7 6 8 4 5 0 4 0 6 1 4 3 2 6 7 2 6 9 3 1 4 6 8 5 9 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 9 8 4 0 2 4 8 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 9\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 9 0 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 2 8 8 7 9 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 7 3 0 3 9 1 4 4 0 3 5 5 8 6 3 0 6 7 6 6 3 2 7 9 1 1 7 9 6 4 9 5 1 5 3 4 7 8 7 1 1 0 9 1 4 4 5 4 0 6 2 2 8 1 5 1 2 0 8 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "ndx_errs (array([ 73, 151, 187, 233, 241, 243, 245, 247, 250, 257, 266, 320, 321, 338, 362, 376, 381, 444, 445, 448, 464, 478, 479, 492, 495, 497, 511, 515, 532, 543, 547, 550, 551, 583, 591, 605, 613, 628,\n",
      "       654, 659, 684, 691, 714, 716, 717, 726, 738, 740, 760, 766, 791, 838, 839, 877, 881, 924, 926, 930, 939, 947, 951, 957, 962, 965, 976, 982], dtype=int64),)\n",
      "num correct is  934  an accuracy of  0.9339999999999999\n",
      "2020-06-02 11:47:35.277320 end\n"
     ]
    }
   ],
   "source": [
    "Config.USE_PARENT_CENTROIDS=True\n",
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=6_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=1_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.USE_PARENT_CENTROIDS=False\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s2overlapparentweight'></a>\n",
    "<a href='#toc'>Goto Table of Contents</a>\n",
    "\n",
    "\n",
    "## ...and now overlap the weighted centroids with parents improved CNN and kNN for small set of images\n",
    "\n",
    "- weighted overlap 1/16 \n",
    "- CNN (6,000 96.69% (+/- 1.29%))\n",
    "- kNN (6,000 94.2%)\n",
    "\n",
    "## whereas the baseline is\n",
    "\n",
    "## kNN acc (6,000 91.6% 60,000 96.88%)\n",
    "## CNN acc (6,000 96.06% (+/- 1.42%); 60,000 99.00% (+/- 0.21%))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-02 12:04:11.394332 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 9 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 9 8 7 2 3 0 4 4 2 4 1 9 5 7 7 2 8 2 6 8 5 7 7 9 1 8 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 9 2 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 8 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 2 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 3 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 6 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 3 8 8 2 7 5 8 9 6 1 8 4 1 2 5 9 1 9 7 5 4 0 8 9 9 1 0 5 2 3 7\n",
      " 8 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 8 4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 2 1 7 0 6 5 4 3 8 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 2 3 1 9 7 5 1 0 8 4 6 2 6 7 9 3 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 5 8 0 3 7 2 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 7 8 3 3 6 7 2 8 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 8 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5 4 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 5\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 8 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 8 8 8 7 4 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 2 3 2 3 9 1 7 4 0 3 5 5 8 6 3 2 6 7 6 6 3 2 7 8 1 1 7 5 6 4 9 5 1 3 3 4 7 8 9 1 1 6 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "<class 'numpy.ndarray'> (0, 170)\n",
      "<class 'numpy.ndarray'> (0, 954)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 954)\n",
      "fill_up_last_row.shape (7000, 26)\n",
      "X_num_images 7000 X_image_num_pixels 954\n",
      "num_extra_rows 7\n",
      "2020-06-02 12:06:27.369920 Start of fit\n",
      "Epoch 1/5\n",
      "6296/6296 [==============================] - 4s 560us/sample - loss: 0.6704 - acc: 0.7868s - loss: 0.8218\n",
      "Epoch 2/5\n",
      "6296/6296 [==============================] - 3s 469us/sample - loss: 0.1895 - acc: 0.9423s - loss: 0.2217 - - ETA: 0s - loss: 0.2099 - acc: 0.93 - ETA: 0s - loss: 0.2072\n",
      "Epoch 3/5\n",
      "6296/6296 [==============================] - 3s 461us/sample - loss: 0.1137 - acc: 0.9673\n",
      "Epoch 4/5\n",
      "6296/6296 [==============================] - 3s 468us/sample - loss: 0.0764 - acc: 0.9770\n",
      "Epoch 5/5\n",
      "6296/6296 [==============================] - 3s 457us/sample - loss: 0.0540 - acc: 0.9832\n",
      "2020-06-02 12:06:45.146201 End of fit\n",
      "acc: 97.87%\n",
      "2020-06-02 12:06:46.478354 Start of fit\n",
      "Epoch 1/5\n",
      "6297/6297 [==============================] - 4s 556us/sample - loss: 0.7055 - acc: 0.7775\n",
      "Epoch 2/5\n",
      "6297/6297 [==============================] - 3s 455us/sample - loss: 0.1979 - acc: 0.9409s - loss: 0.2058 \n",
      "Epoch 3/5\n",
      "6297/6297 [==============================] - 3s 465us/sample - loss: 0.1216 - acc: 0.9651\n",
      "Epoch 4/5\n",
      "6297/6297 [==============================] - 3s 475us/sample - loss: 0.0796 - acc: 0.9762s - loss: 0.0840 - acc: 0.97 - ETA: 1s - \n",
      "Epoch 5/5\n",
      "6297/6297 [==============================] - 3s 464us/sample - loss: 0.0587 - acc: 0.9814s - loss: 0.0596 - acc: \n",
      "2020-06-02 12:07:04.240608 End of fit\n",
      "acc: 97.44%\n",
      "2020-06-02 12:07:05.569406 Start of fit\n",
      "Epoch 1/5\n",
      "6297/6297 [==============================] - 4s 572us/sample - loss: 0.7350 - acc: 0.7688s - loss: 1.0200 - ETA: 0s - loss: 0.8074 - acc\n",
      "Epoch 2/5\n",
      "6297/6297 [==============================] - 3s 475us/sample - loss: 0.2188 - acc: 0.9331\n",
      "Epoch 3/5\n",
      "6297/6297 [==============================] - 3s 488us/sample - loss: 0.1296 - acc: 0.9598s - loss: 0.13 - ETA: 1s - loss: 0\n",
      "Epoch 4/5\n",
      "6297/6297 [==============================] - 3s 478us/sample - loss: 0.0891 - acc: 0.9732s - loss: 0 - ETA: 1s - loss: 0.09 - ETA: 0s - loss: 0.0938 - acc: 0\n",
      "Epoch 5/5\n",
      "6297/6297 [==============================] - 3s 492us/sample - loss: 0.0678 - acc: 0.9795\n",
      "2020-06-02 12:07:23.987765 End of fit\n",
      "acc: 93.31%\n",
      "2020-06-02 12:07:25.376498 Start of fit\n",
      "Epoch 1/5\n",
      "6298/6298 [==============================] - 4s 579us/sample - loss: 0.6690 - acc: 0.7898\n",
      "Epoch 2/5\n",
      "6298/6298 [==============================] - 3s 470us/sample - loss: 0.1951 - acc: 0.9403s - loss: 0.2221 - ac - ETA: 1s - loss: 0.2060 - acc - ETA: 0s - loss: 0.1984 - ac - ETA: 0s - loss: 0.1922 - acc: 0.9\n",
      "Epoch 3/5\n",
      "6298/6298 [==============================] - 3s 477us/sample - loss: 0.1158 - acc: 0.9624\n",
      "Epoch 4/5\n",
      "6298/6298 [==============================] - 3s 479us/sample - loss: 0.0835 - acc: 0.9741s - loss: 0.0819 - ac - ETA: 0s - loss: 0.0812 - acc: 0. - ETA: 0s - loss: 0.0814 - \n",
      "Epoch 5/5\n",
      "6298/6298 [==============================] - 3s 491us/sample - loss: 0.0621 - acc: 0.9832 ETA: 0s - loss: 0.0600 - acc:\n",
      "2020-06-02 12:07:43.779603 End of fit\n",
      "acc: 96.87%\n",
      "2020-06-02 12:07:45.164304 Start of fit\n",
      "Epoch 1/5\n",
      "6298/6298 [==============================] - 4s 575us/sample - loss: 0.7159 - acc: 0.7723s - loss: 2. - ETA: 2s - loss: 1.0732 - ETA: 0s - loss: 0.8302 - acc: 0.736 - ETA: 0s - loss: 0.8193 - \n",
      "Epoch 2/5\n",
      "6298/6298 [==============================] - 3s 469us/sample - loss: 0.2193 - acc: 0.9320s - \n",
      "Epoch 3/5\n",
      "6298/6298 [==============================] - 3s 475us/sample - loss: 0.1298 - acc: 0.9592s - los - ETA: 0s - loss: 0.1363 - acc: 0.957 - ETA: 0s - loss: 0.1355 - acc: 0. - ETA: 0s - loss: 0.1303 - a\n",
      "Epoch 4/5\n",
      "6298/6298 [==============================] - 3s 509us/sample - loss: 0.0908 - acc: 0.9705s - loss: 0.0809 - acc:  - ETA: 1s - \n",
      "Epoch 5/5\n",
      "6298/6298 [==============================] - 3s 499us/sample - loss: 0.0659 - acc: 0.9784s - loss: 0.0655 - acc\n",
      "2020-06-02 12:08:03.739524 End of fit\n",
      "acc: 95.58%\n",
      "2020-06-02 12:08:05.171595 Start of fit\n",
      "Epoch 1/5\n",
      "6301/6301 [==============================] - 4s 572us/sample - loss: 0.6708 - acc: 0.7883s - loss: 1.0781 - ETA: 1s - loss: 0.8205\n",
      "Epoch 2/5\n",
      "6301/6301 [==============================] - 3s 475us/sample - loss: 0.1910 - acc: 0.9413s - loss: 0.2 - ETA: 0s - loss: 0.1929 - acc: 0.9\n",
      "Epoch 3/5\n",
      "6301/6301 [==============================] - 3s 489us/sample - loss: 0.1162 - acc: 0.9633s - loss: - ETA: 1s - loss: 0.1295 - acc - ETA: 0s - loss: 0.1252\n",
      "Epoch 4/5\n",
      "6301/6301 [==============================] - 3s 506us/sample - loss: 0.0815 - acc: 0.9737s - loss: 0.0662 - acc\n",
      "Epoch 5/5\n",
      "6301/6301 [==============================] - 3s 487us/sample - loss: 0.0593 - acc: 0.9824s - loss: 0.05 - ETA: 0s - loss: 0.0636 - acc: 0. - ETA: 0s - loss: 0.0605 - acc: 0.98 - ETA: 0s - loss: 0.0587 - acc: - ETA: 0s - loss: 0.0607 - acc: 0.9\n",
      "2020-06-02 12:08:23.855034 End of fit\n",
      "acc: 97.00%\n",
      "2020-06-02 12:08:25.272689 Start of fit\n",
      "Epoch 1/5\n",
      "6301/6301 [==============================] - 4s 589us/sample - loss: 0.6788 - acc: 0.7892ETA: 0s - loss: 0.6921 - acc: 0.78\n",
      "Epoch 2/5\n",
      "6301/6301 [==============================] - 3s 473us/sample - loss: 0.1818 - acc: 0.9449s - loss: 0.2205 - a - ETA: 1s - loss: 0.2046 - acc: 0.9 - ETA: 1s - loss: 0.1 - ETA: 0s - loss: 0.1879 - acc: 0\n",
      "Epoch 3/5\n",
      "6301/6301 [==============================] - 3s 493us/sample - loss: 0.1086 - acc: 0.9667s -\n",
      "Epoch 4/5\n",
      "6301/6301 [==============================] - 3s 491us/sample - loss: 0.0776 - acc: 0.9764s - loss: 0.0955 - acc: 0.9\n",
      "Epoch 5/5\n",
      "6301/6301 [==============================] - 3s 493us/sample - loss: 0.0542 - acc: 0.9825s - loss: 0.0581 - acc: - ETA: 1s -\n",
      "2020-06-02 12:08:44.030045 End of fit\n",
      "acc: 96.57%\n",
      "2020-06-02 12:08:45.558352 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 4s 568us/sample - loss: 0.7474 - acc: 0.7614\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 3s 484us/sample - loss: 0.2045 - acc: 0.9410s - loss: 0\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 3s 491us/sample - loss: 0.1202 - acc: 0.9630s - loss: 0.13\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 3s 479us/sample - loss: 0.0838 - acc: 0.9738\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 482us/sample - loss: 0.0595 - acc: 0.9802s - loss: 0.0586 - - ETA: 0s - loss: 0.0573 \n",
      "2020-06-02 12:09:04.170392 End of fit\n",
      "acc: 97.13%\n",
      "2020-06-02 12:09:05.663417 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 4s 567us/sample - loss: 0.7320 - acc: 0.7649s - loss: \n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 3s 474us/sample - loss: 0.1967 - acc: 0.9385s - lo\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 3s 467us/sample - loss: 0.1165 - acc: 0.9645\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 3s 474us/sample - loss: 0.0786 - acc: 0.9743\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 472us/sample - loss: 0.0610 - acc: 0.9810\n",
      "2020-06-02 12:09:23.971823 End of fit\n",
      "acc: 97.27%\n",
      "2020-06-02 12:09:25.441084 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 4s 571us/sample - loss: 0.6648 - acc: 0.7854\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 3s 473us/sample - loss: 0.1831 - acc: 0.9462\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 3s 478us/sample - loss: 0.1175 - acc: 0.9646\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 3s 488us/sample - loss: 0.0815 - acc: 0.9745s - loss: 0. - ETA: 1s - \n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 485us/sample - loss: 0.0603 - acc: 0.9814s - loss: 0.0617 - acc - ETA: 0s - loss: 0.065\n",
      "2020-06-02 12:09:44.034611 End of fit\n",
      "acc: 97.84%\n",
      "96.69% (+/- 1.29%)\n",
      "2020-06-02 12:09:45.347973 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 8 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 3 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 8 8 4 2 6 0 6 4 2 9 1 9 5 7 7 2 8 2 6 8 5 7 7 9 1 0 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 7 7 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 5 6 5 6 1 3 8 1 0 5 1 3 1 5 0 6 1 8 5 1 4 9 4 6 7 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 7 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 6 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 8 0 6 4 8 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 7 8 8 2 7 5 8 9 6 1 8 4 1 2 6 8 1 9 7 5 4 0 8 9 9 1 0 5 2 3 7\n",
      " 0 9 9 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 9 4 6 4 2 1 8 2 5 4 8 3 4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 9 8 3 3 9 3 3 3 7 8 0 8 7 1 7 0 6 5 4 3 3 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 9 8 6 0 2 4 0 2 8 3 1 9 7 5 1 0 8 4 6 2 6 7 9 9 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 0 8 0 3 7 8 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 2 8 3 3 6 7 2 7 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 3 2 7 6 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 3 5 9 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 9 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 3 6 8 9 4 1 5\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 2 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 0 1 7 7 4 7 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 6 2 2 5 6 0 8 2 9 2 8 8 8 8 7 9 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 7 3 0 3 9 1 7 4 0 3 5 5 8 6 3 0 6 7 6 6 3 2 7 9 1 1 7 4 6 4 9 6 1 3 3 4 9 8 9 1 1 0 9 1 4 4 5 4 0 6 2 2 8 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "ndx_errs (array([151, 187, 241, 243, 245, 247, 250, 266, 320, 321, 338, 352, 358, 362, 381, 409, 444, 445, 448, 464, 478, 479, 495, 497, 532, 543, 571, 583, 591, 605, 613, 628, 654, 659, 684, 691, 714, 716,\n",
      "       717, 738, 740, 760, 785, 810, 839, 844, 866, 881, 924, 926, 939, 947, 951, 955, 960, 965, 976], dtype=int64),)\n",
      "num correct is  943  an accuracy of  0.943\n",
      "2020-06-02 12:09:55.085445 end\n"
     ]
    }
   ],
   "source": [
    "Config.OVERLAP_QUADS_RATIO=0.0625\n",
    "Config.USE_PARENT_CENTROIDS=True\n",
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=6_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=1_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.OVERLAP_QUADS_RATIO=1\n",
    "Config.USE_PARENT_CENTROIDS=False\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s2overlaponlyleaves'></a>\n",
    "<a href='#toc'>Goto Table of Contents</a>\n",
    "\n",
    "## ...and now do without the parents; CNN did worse than baseline for small set of images\n",
    "\n",
    "- weighted overlap 1/16 \n",
    "- CNN (6,000 95.26% (+/- 1.11%))\n",
    "- kNN (6,000 94.2%)\n",
    "\n",
    "## whereas the baseline is\n",
    "\n",
    "## kNN acc (6,000 91.6% 60,000 96.88%)\n",
    "## CNN acc (6,000 96.06% (+/- 1.42%); 60,000 99.00% (+/- 0.21%))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-02 12:10:47.621524 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 9 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 9 8 7 2 3 0 4 4 2 4 1 9 5 7 7 2 8 2 6 8 5 7 7 9 1 8 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 9 2 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 8 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 2 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 3 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 6 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 3 8 8 2 7 5 8 9 6 1 8 4 1 2 5 9 1 9 7 5 4 0 8 9 9 1 0 5 2 3 7\n",
      " 8 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 8 4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 2 1 7 0 6 5 4 3 8 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 2 3 1 9 7 5 1 0 8 4 6 2 6 7 9 3 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 5 8 0 3 7 2 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 7 8 3 3 6 7 2 8 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 8 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5 4 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 5\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 8 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 8 8 8 7 4 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 2 3 2 3 9 1 7 4 0 3 5 5 8 6 3 2 6 7 6 6 3 2 7 8 1 1 7 5 6 4 9 5 1 3 3 4 7 8 9 1 1 6 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "<class 'numpy.ndarray'> (0, 128)\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "fill_up_last_row.shape (7000, 12)\n",
      "X_num_images 7000 X_image_num_pixels 912\n",
      "num_extra_rows 5\n",
      "2020-06-02 12:12:47.595349 Start of fit\n",
      "Epoch 1/5\n",
      "6296/6296 [==============================] - 3s 550us/sample - loss: 0.8467 - acc: 0.7189\n",
      "Epoch 2/5\n",
      "6296/6296 [==============================] - 3s 444us/sample - loss: 0.3015 - acc: 0.9031\n",
      "Epoch 3/5\n",
      "6296/6296 [==============================] - 3s 452us/sample - loss: 0.2066 - acc: 0.9354s - loss: 0.\n",
      "Epoch 4/5\n",
      "6296/6296 [==============================] - 3s 456us/sample - loss: 0.1598 - acc: 0.9493s - loss: 0.1627 - acc:  - ETA: 0s - loss: 0.1597 - acc: 0.949\n",
      "Epoch 5/5\n",
      "6296/6296 [==============================] - 3s 449us/sample - loss: 0.1320 - acc: 0.9563\n",
      "2020-06-02 12:13:05.317807 End of fit\n",
      "acc: 96.02%\n",
      "2020-06-02 12:13:06.783432 Start of fit\n",
      "Epoch 1/5\n",
      "6297/6297 [==============================] - 3s 542us/sample - loss: 0.8508 - acc: 0.7269\n",
      "Epoch 2/5\n",
      "6297/6297 [==============================] - 3s 449us/sample - loss: 0.2975 - acc: 0.9042\n",
      "Epoch 3/5\n",
      "6297/6297 [==============================] - 3s 447us/sample - loss: 0.2022 - acc: 0.9333\n",
      "Epoch 4/5\n",
      "6297/6297 [==============================] - 3s 442us/sample - loss: 0.1509 - acc: 0.9525\n",
      "Epoch 5/5\n",
      "6297/6297 [==============================] - 3s 441us/sample - loss: 0.1148 - acc: 0.9617\n",
      "2020-06-02 12:13:24.679721 End of fit\n",
      "acc: 95.59%\n",
      "2020-06-02 12:13:26.170506 Start of fit\n",
      "Epoch 1/5\n",
      "6297/6297 [==============================] - 4s 571us/sample - loss: 0.8159 - acc: 0.7259s -\n",
      "Epoch 2/5\n",
      "6297/6297 [==============================] - 3s 441us/sample - loss: 0.3017 - acc: 0.8984\n",
      "Epoch 3/5\n",
      "6297/6297 [==============================] - 3s 442us/sample - loss: 0.2082 - acc: 0.9346\n",
      "Epoch 4/5\n",
      "6297/6297 [==============================] - 3s 442us/sample - loss: 0.1545 - acc: 0.9497\n",
      "Epoch 5/5\n",
      "6297/6297 [==============================] - 3s 452us/sample - loss: 0.1173 - acc: 0.9616s - loss: 0.1146 -\n",
      "2020-06-02 12:13:43.971548 End of fit\n",
      "acc: 95.16%\n",
      "2020-06-02 12:13:45.469004 Start of fit\n",
      "Epoch 1/5\n",
      "6298/6298 [==============================] - 4s 583us/sample - loss: 0.9327 - acc: 0.6994\n",
      "Epoch 2/5\n",
      "6298/6298 [==============================] - 3s 465us/sample - loss: 0.3157 - acc: 0.9020\n",
      "Epoch 3/5\n",
      "6298/6298 [==============================] - 3s 463us/sample - loss: 0.2137 - acc: 0.9324\n",
      "Epoch 4/5\n",
      "6298/6298 [==============================] - 3s 467us/sample - loss: 0.1559 - acc: 0.9522\n",
      "Epoch 5/5\n",
      "6298/6298 [==============================] - 3s 449us/sample - loss: 0.1272 - acc: 0.9595\n",
      "2020-06-02 12:14:03.802151 End of fit\n",
      "acc: 95.73%\n",
      "2020-06-02 12:14:05.356433 Start of fit\n",
      "Epoch 1/5\n",
      "6298/6298 [==============================] - 4s 567us/sample - loss: 0.8424 - acc: 0.7229\n",
      "Epoch 2/5\n",
      "6298/6298 [==============================] - 3s 447us/sample - loss: 0.2951 - acc: 0.9074\n",
      "Epoch 3/5\n",
      "6298/6298 [==============================] - 3s 451us/sample - loss: 0.1932 - acc: 0.9381\n",
      "Epoch 4/5\n",
      "6298/6298 [==============================] - 3s 457us/sample - loss: 0.1530 - acc: 0.9514\n",
      "Epoch 5/5\n",
      "6298/6298 [==============================] - 3s 452us/sample - loss: 0.1181 - acc: 0.9609\n",
      "2020-06-02 12:14:23.393686 End of fit\n",
      "acc: 94.30%\n",
      "2020-06-02 12:14:24.955103 Start of fit\n",
      "Epoch 1/5\n",
      "6301/6301 [==============================] - 4s 560us/sample - loss: 0.8848 - acc: 0.7137\n",
      "Epoch 2/5\n",
      "6301/6301 [==============================] - 3s 459us/sample - loss: 0.2959 - acc: 0.9016\n",
      "Epoch 3/5\n",
      "6301/6301 [==============================] - 3s 453us/sample - loss: 0.2022 - acc: 0.9345s - loss: 0.2026 - acc: 0.93\n",
      "Epoch 4/5\n",
      "6301/6301 [==============================] - 3s 458us/sample - loss: 0.1498 - acc: 0.9478\n",
      "Epoch 5/5\n",
      "6301/6301 [==============================] - 3s 453us/sample - loss: 0.1178 - acc: 0.9654\n",
      "2020-06-02 12:14:43.060640 End of fit\n",
      "acc: 96.57%\n",
      "2020-06-02 12:14:44.625414 Start of fit\n",
      "Epoch 1/5\n",
      "6301/6301 [==============================] - 4s 581us/sample - loss: 0.8917 - acc: 0.7054\n",
      "Epoch 2/5\n",
      "6301/6301 [==============================] - 3s 454us/sample - loss: 0.3161 - acc: 0.9003\n",
      "Epoch 3/5\n",
      "6301/6301 [==============================] - 3s 454us/sample - loss: 0.2103 - acc: 0.9314s - loss: 0.2497 - ac\n",
      "Epoch 4/5\n",
      "6301/6301 [==============================] - 3s 478us/sample - loss: 0.1564 - acc: 0.9492s - loss: 0.1549 - acc: 0.9\n",
      "Epoch 5/5\n",
      "6301/6301 [==============================] - 3s 471us/sample - loss: 0.1246 - acc: 0.9586\n",
      "2020-06-02 12:15:03.200660 End of fit\n",
      "acc: 96.42%\n",
      "2020-06-02 12:15:04.803525 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 4s 573us/sample - loss: 0.8849 - acc: 0.7153\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 3s 457us/sample - loss: 0.3149 - acc: 0.9002s - los\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 3s 464us/sample - loss: 0.2051 - acc: 0.9324\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 3s 461us/sample - loss: 0.1528 - acc: 0.9524\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 465us/sample - loss: 0.1179 - acc: 0.9624\n",
      "2020-06-02 12:15:23.284678 End of fit\n",
      "acc: 93.39%\n",
      "2020-06-02 12:15:24.886607 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 4s 571us/sample - loss: 0.9304 - acc: 0.6943\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 3s 447us/sample - loss: 0.3193 - acc: 0.8977\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 3s 456us/sample - loss: 0.2113 - acc: 0.9327s - loss: 0.237 - ETA: 1s - loss: 0\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - ETA: 0s - loss: 0.1583 - acc: 0.948 - 3s 457us/sample - loss: 0.1580 - acc: 0.9480\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 457us/sample - loss: 0.1258 - acc: 0.9580\n",
      "2020-06-02 12:15:43.153493 End of fit\n",
      "acc: 95.98%\n",
      "2020-06-02 12:15:44.789629 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 4s 592us/sample - loss: 0.8556 - acc: 0.7249\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 3s 453us/sample - loss: 0.3032 - acc: 0.9056s - l\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 3s 450us/sample - loss: 0.2054 - acc: 0.9348\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 3s 451us/sample - loss: 0.1494 - acc: 0.9532\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 452us/sample - loss: 0.1210 - acc: 0.9591s - loss: 0.1265 - acc\n",
      "2020-06-02 12:16:03.273836 End of fit\n",
      "acc: 93.39%\n",
      "95.26% (+/- 1.11%)\n",
      "2020-06-02 12:16:04.751448 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 8 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 3 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 8 8 4 2 6 0 6 4 2 9 1 9 5 7 7 2 8 2 6 8 5 7 7 4 1 0 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 7 7 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 5 6 5 4 1 3 8 1 0 5 1 3 1 5 0 6 1 8 5 1 7 9 4 6 7 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 7 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 8 0 6 4 8 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 7 8 8 2 7 5 8 9 6 1 8 4 1 2 6 8 1 9 7 5 4 0 8 9 9 1 0 5 8 3 7\n",
      " 0 9 9 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 9 4 6 4 2 1 8 2 5 4 8 3 4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 9 8 3 3 9 3 3 3 7 8 0 8 7 1 7 0 6 5 4 3 3 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 8 3 1 9 7 5 1 0 8 4 6 2 6 7 9 9 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 0 8 0 3 7 8 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 9 8 3 3 6 7 2 7 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 3 2 7 6 8 4 5 0 4 0 6 1 5 3 2 6 7 2 6 9 3 1 4 6 3 5 9 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 9 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 3 6 8 9 4 1 5\n",
      " 3 8 0 1 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 0 1 7 7 4 7 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 6 2 2 5 6 0 8 2 9 2 8 8 8 8 7 9 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 7 3 0 3 9 1 7 4 0 3 5 5 8 6 3 0 6 7 6 6 3 2 7 9 1 1 7 4 6 4 9 6 1 3 3 4 7 8 4 1 1 0 9 1 4 4 5 4 0 6 2 2 8 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "ndx_errs (array([151, 187, 241, 243, 245, 247, 250, 264, 266, 320, 321, 338, 341, 352, 362, 381, 444, 445, 448, 464, 478, 479, 492, 495, 497, 532, 543, 571, 583, 591, 613, 628, 654, 659, 684, 691, 714, 716,\n",
      "       717, 726, 738, 740, 760, 785, 795, 839, 844, 866, 881, 924, 926, 939, 947, 951, 955, 962, 965, 976], dtype=int64),)\n",
      "num correct is  942  an accuracy of  0.942\n",
      "2020-06-02 12:16:14.151597 end\n"
     ]
    }
   ],
   "source": [
    "Config.OVERLAP_QUADS_RATIO=0.0625\n",
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=6_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=1_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.OVERLAP_QUADS_RATIO=1\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s2reprokNNimprove'></a>\n",
    "<a href='#toc'>Goto Table of Contents</a>\n",
    "\n",
    "## Reproduce the improvement for kNN with options weighted centroid but no overlap, nor parents, \n",
    "\n",
    "- kNN acc (6,000 93.6%; 60,000 96.98%)\n",
    "\n",
    "## whereas the baseline is\n",
    "\n",
    "- kNN acc (6,000 91.6% 60,000 96.88%)\n",
    "\n",
    "## The error rate reduction for kNN is (2/8.4)=23.8% for 6,000 and (0.1/3.12)=3.2% for 60,000\n",
    "\n",
    "- kNN error rate reduction (6,000 ; 60,000)\n",
    "\n",
    "## Although kNN improved, CNN improved only for the small sample size (6,000)\n",
    "\n",
    "- CNN acc (6,000 94.80% (+/- 1.28%); 60,000 98.29% (+/- 0.22%))\n",
    "\n",
    "## whereas the baseline is\n",
    "- CNN acc (6,000 96.06% (+/- 1.42%); 60,000 99.00% (+/- 0.21%))\n",
    "\n",
    "## In general, small sample size (6,000) always seems to benefit more than large (60,000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-05 09:09:19.155800 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7 7\n",
      " 1 0 1 7 8 9 0 1 2 3 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "<class 'numpy.ndarray'> (0, 128)\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "****************************** 6000 ******************************\n",
      "****************************** 8000 ******************************\n",
      "****************************** 10000 ******************************\n",
      "****************************** 12000 ******************************\n",
      "****************************** 14000 ******************************\n",
      "****************************** 16000 ******************************\n",
      "****************************** 18000 ******************************\n",
      "****************************** 20000 ******************************\n",
      "****************************** 22000 ******************************\n",
      "****************************** 24000 ******************************\n",
      "****************************** 26000 ******************************\n",
      "****************************** 28000 ******************************\n",
      "****************************** 30000 ******************************\n",
      "****************************** 32000 ******************************\n",
      "****************************** 34000 ******************************\n",
      "****************************** 36000 ******************************\n",
      "****************************** 38000 ******************************\n",
      "****************************** 40000 ******************************\n",
      "****************************** 42000 ******************************\n",
      "****************************** 44000 ******************************\n",
      "****************************** 46000 ******************************\n",
      "****************************** 48000 ******************************\n",
      "****************************** 50000 ******************************\n",
      "****************************** 52000 ******************************\n",
      "****************************** 54000 ******************************\n",
      "****************************** 56000 ******************************\n",
      "****************************** 58000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "****************************** 1999 ******************************\n",
      "fill_up_last_row.shape (61999, 12)\n",
      "X_num_images 61999 X_image_num_pixels 912\n",
      "num_extra_rows 5\n",
      "2020-06-05 11:13:33.822514 Start of fit\n",
      "Epoch 1/5\n",
      "55796/55796 [==============================] - 38s 677us/sample - loss: 0.2531 - acc: 0.9189A: 2s - lo\n",
      "Epoch 2/5\n",
      "55796/55796 [==============================] - 32s 567us/sample - loss: 0.0845 - acc: 0.9733: 0s - loss: 0.085\n",
      "Epoch 3/5\n",
      "55796/55796 [==============================] - 32s 577us/sample - loss: 0.0592 - acc: 0.9812 - loss: 0 - ETA: 6s - loss: 0.0587 - ac - ETA: 5s - loss: 0.0586 - acc: 0 - ETA: 5s - loss: 0.0587 - a - ETA: 4s - loss: 0.0596 - acc: 0.9 - ETA: 4s - loss: 0 - ETA: 0s - loss: 0.0591 - acc: 0.\n",
      "Epoch 4/5\n",
      "55796/55796 [==============================] - 32s 567us/sample - loss: 0.0463 - acc: 0.9853\n",
      "Epoch 5/5\n",
      "55796/55796 [==============================] - 31s 564us/sample - loss: 0.0381 - acc: 0.9883\n",
      "2020-06-05 11:16:47.651794 End of fit\n",
      "acc: 98.19%\n",
      "2020-06-05 11:16:57.572857 Start of fit\n",
      "Epoch 1/5\n",
      "55796/55796 [==============================] - 34s 609us/sample - loss: 0.2713 - acc: 0.9121 - loss: 0.2913 -  - ETA: 2s - loss: 0.2867 - ac - ETA: \n",
      "Epoch 2/5\n",
      "55796/55796 [==============================] - 31s 559us/sample - loss: 0.0885 - acc: 0.9730s - los\n",
      "Epoch 3/5\n",
      "55796/55796 [==============================] - 31s 548us/sample - loss: 0.0613 - acc: 0.9808\n",
      "Epoch 4/5\n",
      "55796/55796 [==============================] - 31s 560us/sample - loss: 0.0468 - acc: 0.9856 - loss: \n",
      "Epoch 5/5\n",
      "55796/55796 [==============================] - 33s 589us/sample - loss: 0.0372 - acc: 0.9879\n",
      "2020-06-05 11:19:55.080339 End of fit\n",
      "acc: 98.68%\n",
      "2020-06-05 11:20:05.252969 Start of fit\n",
      "Epoch 1/5\n",
      "55796/55796 [==============================] - 34s 616us/sample - loss: 0.2835 - acc: 0.9090 5s\n",
      "Epoch 2/5\n",
      "55796/55796 [==============================] - 33s 592us/sample - loss: 0.0895 - acc: 0.9724\n",
      "Epoch 3/5\n",
      "55796/55796 [==============================] - 32s 567us/sample - loss: 0.0626 - acc: 0.9803 - loss - ET - ETA: 1s - loss: 0.06\n",
      "Epoch 4/5\n",
      "55796/55796 [==============================] - 33s 590us/sample - loss: 0.0471 - acc: 0.9852 \n",
      "Epoch 5/5\n",
      "55796/55796 [==============================] - 32s 565us/sample - loss: 0.0377 - acc: 0.9880 - loss: 0.0381 - a\n",
      "2020-06-05 11:23:05.423043 End of fit\n",
      "acc: 97.69%\n",
      "2020-06-05 11:23:16.233670 Start of fit\n",
      "Epoch 1/5\n",
      "55798/55798 [==============================] - 34s 613us/sample - loss: 0.2502 - acc: 0.9204\n",
      "Epoch 2/5\n",
      "55798/55798 [==============================] - 31s 562us/sample - loss: 0.0809 - acc: 0.9749\n",
      "Epoch 3/5\n",
      "55798/55798 [==============================] - 30s 542us/sample - loss: 0.0568 - acc: 0.9823 - loss: 0.0575 - acc: 0.981 - ETA: 8s - loss: 0.0574 - acc: - ETA: 8s - loss: 0.0572 - acc - E\n",
      "Epoch 4/5\n",
      "55798/55798 [==============================] - 31s 559us/sample - loss: 0.0435 - acc: 0.9862 -\n",
      "Epoch 5/5\n",
      "55798/55798 [==============================] - 31s 560us/sample - loss: 0.0350 - acc: 0.9889\n",
      "2020-06-05 11:26:09.731329 End of fit\n",
      "acc: 98.24%\n",
      "2020-06-05 11:26:19.132678 Start of fit\n",
      "Epoch 1/5\n",
      "55798/55798 [==============================] - 35s 622us/sample - loss: 0.2543 - acc: 0.9186 - loss: 0.2721  - ETA: 2s - loss: 0 - ETA: 1s - loss: 0.\n",
      "Epoch 2/5\n",
      "55798/55798 [==============================] - 33s 588us/sample - loss: 0.0841 - acc: 0.9731 - los\n",
      "Epoch 3/5\n",
      "55798/55798 [==============================] - 31s 562us/sample - loss: 0.0578 - acc: 0.9819\n",
      "Epoch 4/5\n",
      "55798/55798 [==============================] - 31s 562us/sample - loss: 0.0449 - acc: 0.9855\n",
      "Epoch 5/5\n",
      "55798/55798 [==============================] - 32s 568us/sample - loss: 0.0349 - acc: 0.9891  - ETA: 0s - loss: 0.0351 - acc: 0.989 - ETA: 0s - loss: 0.0350 - acc: 0.98\n",
      "2020-06-05 11:29:16.638471 End of fit\n",
      "acc: 98.03%\n",
      "2020-06-05 11:29:24.525846 Start of fit\n",
      "Epoch 1/5\n",
      "55798/55798 [==============================] - 34s 608us/sample - loss: 0.2517 - acc: 0.9194\n",
      "Epoch 2/5\n",
      "55798/55798 [==============================] - 32s 567us/sample - loss: 0.0847 - acc: 0.9734\n",
      "Epoch 3/5\n",
      "55798/55798 [==============================] - 33s 583us/sample - loss: 0.0566 - acc: 0.9816\n",
      "Epoch 4/5\n",
      "55798/55798 [==============================] - 32s 571us/sample - loss: 0.0436 - acc: 0.9861 - loss: 0.0441 - ETA: 1s - loss\n",
      "Epoch 5/5\n",
      "55798/55798 [==============================] - 32s 569us/sample - loss: 0.0349 - acc: 0.9895\n",
      "2020-06-05 11:32:18.138769 End of fit\n",
      "acc: 98.27%\n",
      "2020-06-05 11:32:25.333944 Start of fit\n",
      "Epoch 1/5\n",
      "55800/55800 [==============================] - 34s 607us/sample - loss: 0.2686 - acc: 0.9148\n",
      "Epoch 2/5\n",
      "55800/55800 [==============================] - 32s 573us/sample - loss: 0.0888 - acc: 0.9717 - - ET\n",
      "Epoch 3/5\n",
      "55800/55800 [==============================] - 31s 564us/sample - loss: 0.0593 - acc: 0.9813 -\n",
      "Epoch 4/5\n",
      "55800/55800 [==============================] - ETA: 0s - loss: 0.0460 - acc: 0.985 - 31s 554us/sample - loss: 0.0462 - acc: 0.9853\n",
      "Epoch 5/5\n",
      "55800/55800 [==============================] - 31s 556us/sample - loss: 0.0361 - acc: 0.9889\n",
      "2020-06-05 11:35:15.738988 End of fit\n",
      "acc: 98.16%\n",
      "2020-06-05 11:35:23.269375 Start of fit\n",
      "Epoch 1/5\n",
      "55801/55801 [==============================] - 35s 620us/sample - loss: 0.2562 - acc: 0.9179 -\n",
      "Epoch 2/5\n",
      "55801/55801 [==============================] - 33s 585us/sample - loss: 0.0844 - acc: 0.9736\n",
      "Epoch 3/5\n",
      "55801/55801 [==============================] - 32s 572us/sample - loss: 0.0577 - acc: 0.9813 - loss: - ETA: 2s - loss: 0.0579 -  - ETA: 1s - los\n",
      "Epoch 4/5\n",
      "55801/55801 [==============================] - 31s 560us/sample - loss: 0.0447 - acc: 0.9859 - lo - ET\n",
      "Epoch 5/5\n",
      "55801/55801 [==============================] - 31s 557us/sample - loss: 0.0344 - acc: 0.9888s -  - ETA: 10s - loss: 0.0 - ETA: 9 - ETA: 2s - loss: 0.0343 - acc:  - ETA: \n",
      "2020-06-05 11:38:15.335700 End of fit\n",
      "acc: 98.42%\n",
      "2020-06-05 11:38:21.911374 Start of fit\n",
      "Epoch 1/5\n",
      "55803/55803 [==============================] - 34s 601us/sample - loss: 0.2574 - acc: 0.9181s - loss: 0.2718  - ETA: \n",
      "Epoch 2/5\n",
      "55803/55803 [==============================] - 31s 563us/sample - loss: 0.0821 - acc: 0.9740\n",
      "Epoch 3/5\n",
      "55803/55803 [==============================] - 31s 560us/sample - loss: 0.0583 - acc: 0.9818 - loss: 0.0596\n",
      "Epoch 4/5\n",
      "55803/55803 [==============================] - 30s 536us/sample - loss: 0.0448 - acc: 0.9860 - ETA: 3s - loss: 0.0454 - a - ETA: 3s - loss: 0.0454 - acc:\n",
      "Epoch 5/5\n",
      "55803/55803 [==============================] - 31s 558us/sample - loss: 0.0361 - acc: 0.9890 - loss: 0.0360 - acc: - E\n",
      "2020-06-05 11:41:09.103823 End of fit\n",
      "acc: 98.01%\n",
      "2020-06-05 11:41:15.769148 Start of fit\n",
      "Epoch 1/5\n",
      "55805/55805 [==============================] - 35s 620us/sample - loss: 0.2598 - acc: 0.9180 - loss: 0.3089 - - ETA: 7s - lo - ETA: 6s - ETA: 3s - ETA: 1s - loss: \n",
      "Epoch 2/5\n",
      "55805/55805 [==============================] - 33s 586us/sample - loss: 0.0813 - acc: 0.9745\n",
      "Epoch 3/5\n",
      "55805/55805 [==============================] - 32s 568us/sample - loss: 0.0559 - acc: 0.9830 - loss: 0.0559 - acc: 0.983\n",
      "Epoch 4/5\n",
      "55805/55805 [==============================] - 32s 569us/sample - loss: 0.0438 - acc: 0.9863\n",
      "Epoch 5/5\n",
      "55805/55805 [==============================] - 31s 557us/sample - loss: 0.0348 - acc: 0.9888 - loss: 0.0344 - acc: 0.989 - ETA: 9s - loss: 0.0344 - acc: 0.98 - ETA: 8s  - ETA:  - ETA:  \n",
      "2020-06-05 11:44:09.092494 End of fit\n",
      "acc: 97.80%\n",
      "98.15% (+/- 0.27%)\n",
      "2020-06-05 11:44:14.479915 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 4 8 9 6 9 6 8 3 6 6 8 5 1 4 2 4 4 5 1 1 9 0 2 4 9 5 7 1 8 3 5 6 9 8 7 1 1 6 7 6 3 2 2 0 8 9\n",
      " 2 5 1 0 8 1 4 5 7 9 6 9 0 6 1 5 5 8 3 8 2 6 5 0 7 4 6 1 3 4 7 3 2 3 4 2 5 2 7 1 7 2 6 4 1 5 7 8 6 0 1 8 2 5 7 7 6 9 3 5 2 4 2 4 0 8 8 3 4 9 2 7 5 8 6 3 6 0 8 6 7 3 6 4 9 4 6 6 3 0 4 1 0 1 4 6 2 9 1\n",
      " 1 0 6 3 9]\n",
      "ndx_errs (array([ 151,  241,  247,  320,  321,  338,  362,  376,  381,  444,  445,  448,  464,  479,  495,  519,  582,  628,  646,  659,  689,  691,  707,  716,  726,  740,  760,  839,  844,  881,  924,  938,\n",
      "        939,  947,  951,  956,  966, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1192, 1226, 1232, 1242, 1247, 1283, 1289, 1299, 1319, 1325, 1326, 1331, 1364, 1393, 1414, 1500, 1523,\n",
      "       1530, 1549, 1553, 1559, 1637, 1681, 1695, 1709, 1718, 1721, 1737, 1782, 1790, 1813, 1878, 1901, 1955, 1970, 1984], dtype=int64),)\n",
      "num correct is  1916  an accuracy of  0.9584792396198099\n",
      "****************************** 3999 ******************************\n",
      "fill_up_last_row.shape (63999, 12)\n",
      "X_num_images 63999 X_image_num_pixels 912\n",
      "num_extra_rows 5\n",
      "2020-06-05 11:47:37.502559 Start of fit\n",
      "Epoch 1/5\n",
      "57595/57595 [==============================] - 35s 608us/sample - loss: 0.2551 - acc: 0.9189\n",
      "Epoch 2/5\n",
      "57595/57595 [==============================] - 33s 567us/sample - loss: 0.0880 - acc: 0.9727\n",
      "Epoch 3/5\n",
      "57595/57595 [==============================] - 33s 577us/sample - loss: 0.0610 - acc: 0.9807 - loss: 0.0618 - acc: 0.98 - ETA: 8s - loss: 0.0616 - acc: 0.980  - ETA: 5s - l - ETA: 1s - loss: 0.0612 - acc: 0.9 - ETA: 1s - loss: 0.\n",
      "Epoch 4/5\n",
      "57595/57595 [==============================] - 34s 582us/sample - loss: 0.0461 - acc: 0.9852 - loss: 0.0453 - acc: 0 - ETA: 1s - loss: 0.045\n",
      "Epoch 5/5\n",
      "57595/57595 [==============================] - 32s 559us/sample - loss: 0.0371 - acc: 0.9881 - loss:  - ETA: 7s - loss: 0.0372 - acc: 0.987 -\n",
      "2020-06-05 11:50:37.773089 End of fit\n",
      "acc: 98.55%\n",
      "2020-06-05 11:50:44.924971 Start of fit\n",
      "Epoch 1/5\n",
      "57595/57595 [==============================] - 35s 600us/sample - loss: 0.2593 - acc: 0.9177 0s - loss: 0.2596 - acc: 0.91\n",
      "Epoch 2/5\n",
      "57595/57595 [==============================] - 34s 593us/sample - loss: 0.0834 - acc: 0.9740 - loss:  - ETA: 1s - loss: 0.0\n",
      "Epoch 3/5\n",
      "57595/57595 [==============================] - 33s 566us/sample - loss: 0.0576 - acc: 0.9817\n",
      "Epoch 4/5\n",
      "57595/57595 [==============================] - 32s 552us/sample - loss: 0.0449 - acc: 0.9860\n",
      "Epoch 5/5\n",
      "57595/57595 [==============================] - 32s 553us/sample - loss: 0.0360 - acc: 0.9887 - loss: 0.03\n",
      "2020-06-05 11:53:41.345712 End of fit\n",
      "acc: 97.94%\n",
      "2020-06-05 11:53:49.039948 Start of fit\n",
      "Epoch 1/5\n",
      "57596/57596 [==============================] - 35s 605us/sample - loss: 0.2471 - acc: 0.9209\n",
      "Epoch 2/5\n",
      "57596/57596 [==============================] - 33s 568us/sample - loss: 0.0840 - acc: 0.9736\n",
      "Epoch 3/5\n",
      "57596/57596 [==============================] - 37s 640us/sample - loss: 0.0572 - acc: 0.9819\n",
      "Epoch 4/5\n",
      "57596/57596 [==============================] - 34s 598us/sample - loss: 0.0435 - acc: 0.9865\n",
      "Epoch 5/5\n",
      "57596/57596 [==============================] - 32s 550us/sample - loss: 0.0359 - acc: 0.9889 - - ETA: \n",
      "2020-06-05 11:56:50.692471 End of fit\n",
      "acc: 98.25%\n",
      "2020-06-05 11:56:58.276801 Start of fit\n",
      "Epoch 1/5\n",
      "57598/57598 [==============================] - 36s 619us/sample - loss: 0.2595 - acc: 0.9175\n",
      "Epoch 2/5\n",
      "57598/57598 [==============================] - 33s 576us/sample - loss: 0.0814 - acc: 0.9744\n",
      "Epoch 3/5\n",
      "57598/57598 [==============================] - 33s 566us/sample - loss: 0.0566 - acc: 0.9819\n",
      "Epoch 4/5\n",
      "57598/57598 [==============================] - 33s 572us/sample - loss: 0.0449 - acc: 0.9861 - loss: - ETA: 1s - loss: 0.\n",
      "Epoch 5/5\n",
      "57598/57598 [==============================] - 31s 543us/sample - loss: 0.0355 - acc: 0.9886\n",
      "2020-06-05 11:59:55.264956 End of fit\n",
      "acc: 98.16%\n",
      "2020-06-05 12:00:03.205484 Start of fit\n",
      "Epoch 1/5\n",
      "57598/57598 [==============================] - 36s 619us/sample - loss: 0.2567 - acc: 0.9179\n",
      "Epoch 2/5\n",
      "57598/57598 [==============================] - 32s 563us/sample - loss: 0.0846 - acc: 0.9729\n",
      "Epoch 3/5\n",
      "57598/57598 [==============================] - 32s 562us/sample - loss: 0.0573 - acc: 0.9824\n",
      "Epoch 4/5\n",
      "57598/57598 [==============================] - 33s 578us/sample - loss: 0.0448 - acc: 0.9862 - loss: 0.0446 - acc:\n",
      "Epoch 5/5\n",
      "57598/57598 [==============================] - 34s 583us/sample - loss: 0.0358 - acc: 0.9888 - ETA: 4s - \n",
      "2020-06-05 12:03:02.281610 End of fit\n",
      "acc: 98.47%\n",
      "2020-06-05 12:03:09.543278 Start of fit\n",
      "Epoch 1/5\n",
      "57599/57599 [==============================] - 35s 605us/sample - loss: 0.2478 - acc: 0.9213\n",
      "Epoch 2/5\n",
      "57599/57599 [==============================] - 34s 584us/sample - loss: 0.0831 - acc: 0.9737\n",
      "Epoch 3/5\n",
      "57599/57599 [==============================] - 33s 577us/sample - loss: 0.0572 - acc: 0.9813\n",
      "Epoch 4/5\n",
      "57599/57599 [==============================] - ETA: 0s - loss: 0.0436 - acc: 0.9860- - 32s 552us/sample - loss: 0.0436 - acc: 0.9860\n",
      "Epoch 5/5\n",
      "57599/57599 [==============================] - 32s 560us/sample - loss: 0.0348 - acc: 0.9887s - loss: 0.0336 - acc - ETA: \n",
      "2020-06-05 12:06:06.987646 End of fit\n",
      "acc: 98.34%\n",
      "2020-06-05 12:06:14.407510 Start of fit\n",
      "Epoch 1/5\n",
      "57602/57602 [==============================] - 36s 627us/sample - loss: 0.2476 - acc: 0.9205 - loss: 0.2507 - acc:  - ETA: 0s - loss: 0.2489 - acc: 0.\n",
      "Epoch 2/5\n",
      "57602/57602 [==============================] - 34s 584us/sample - loss: 0.0801 - acc: 0.9748\n",
      "Epoch 3/5\n",
      "57602/57602 [==============================] - 34s 582us/sample - loss: 0.0559 - acc: 0.9824\n",
      "Epoch 4/5\n",
      "57602/57602 [==============================] - 33s 581us/sample - loss: 0.0425 - acc: 0.9862\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57602/57602 [==============================] - 32s 560us/sample - loss: 0.0349 - acc: 0.9890 - loss: 0.0349 - acc: \n",
      "2020-06-05 12:09:14.706813 End of fit\n",
      "acc: 98.53%\n",
      "2020-06-05 12:09:22.629495 Start of fit\n",
      "Epoch 1/5\n",
      "57602/57602 [==============================] - 35s 604us/sample - loss: 0.2534 - acc: 0.9186\n",
      "Epoch 2/5\n",
      "57602/57602 [==============================] - 33s 571us/sample - loss: 0.0855 - acc: 0.9728 - loss: 0.0867 - acc: 0. - ETA: 3s - loss: 0.\n",
      "Epoch 3/5\n",
      "57602/57602 [==============================] - 33s 571us/sample - loss: 0.0609 - acc: 0.9807 - loss: 0.0607 - acc\n",
      "Epoch 4/5\n",
      "57602/57602 [==============================] - 32s 553us/sample - loss: 0.0466 - acc: 0.9859\n",
      "Epoch 5/5\n",
      "57602/57602 [==============================] - 31s 544us/sample - loss: 0.0363 - acc: 0.9891\n",
      "2020-06-05 12:12:17.377481 End of fit\n",
      "acc: 98.44%\n",
      "2020-06-05 12:12:25.036148 Start of fit\n",
      "Epoch 1/5\n",
      "57602/57602 [==============================] - 35s 603us/sample - loss: 0.2521 - acc: 0.9198\n",
      "Epoch 2/5\n",
      "57602/57602 [==============================] - 33s 565us/sample - loss: 0.0864 - acc: 0.9733\n",
      "Epoch 3/5\n",
      "57602/57602 [==============================] - 33s 568us/sample - loss: 0.0607 - acc: 0.9816\n",
      "Epoch 4/5\n",
      "57602/57602 [==============================] - 33s 568us/sample - loss: 0.0462 - acc: 0.9854 - loss: 0.0462 - acc: 0.985\n",
      "Epoch 5/5\n",
      "57602/57602 [==============================] - 33s 575us/sample - loss: 0.0374 - acc: 0.9882 - loss: 0.03 - ETA: 3s - loss: 0.0374 - ETA:\n",
      "2020-06-05 12:15:22.229774 End of fit\n",
      "acc: 98.53%\n",
      "2020-06-05 12:15:29.574965 Start of fit\n",
      "Epoch 1/5\n",
      "57604/57604 [==============================] - 36s 628us/sample - loss: 0.2463 - acc: 0.9222\n",
      "Epoch 2/5\n",
      "57604/57604 [==============================] - 33s 567us/sample - loss: 0.0827 - acc: 0.9744\n",
      "Epoch 3/5\n",
      "57604/57604 [==============================] - 33s 572us/sample - loss: 0.0580 - acc: 0.9817\n",
      "Epoch 4/5\n",
      "57604/57604 [==============================] - 33s 575us/sample - loss: 0.0451 - acc: 0.9859\n",
      "Epoch 5/5\n",
      "57604/57604 [==============================] - 33s 579us/sample - loss: 0.0359 - acc: 0.9888\n",
      "2020-06-05 12:18:30.391221 End of fit\n",
      "acc: 98.30%\n",
      "98.35% (+/- 0.19%)\n",
      "2020-06-05 12:18:36.307681 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 9 1 1 5 7 5 9 9 1 9 5 9 2 5 0 4 1 0 8 9 0 8 9 8 9 4 2 5 7 9 8 9 8 0 9 9 6 8 9 9 5 9 8 0 1\n",
      " 0 3 3 5 2 1 6 3 0 2 8 1 5 6 2 3 0 2 2 6 4 3 5 5 1 7 2 1 6 9 1 3 9 5 5 1 6 2 2 8 6 7 1 4 6 0 6 0 3 3 2 2 3 6 8 9 8 5 3 8 5 4 5 2 0 5 6 3 2 8 3 9 9 3 7 9 4 6 7 1 3 7 3 6 6 0 9 0 1 9 9 2 8 8 0 1 6 9 7\n",
      " 5 3 4 7 4]\n",
      "ndx_errs (array([ 151,  241,  247,  320,  321,  338,  362,  376,  381,  444,  445,  448,  464,  479,  495,  519,  582,  628,  646,  659,  689,  691,  707,  716,  726,  740,  760,  839,  844,  881,  924,  938,\n",
      "        939,  947,  951,  956,  966, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1192, 1226, 1232, 1242, 1247, 1283, 1289, 1299, 1319, 1325, 1326, 1331, 1364, 1393, 1414, 1500, 1523,\n",
      "       1530, 1549, 1553, 1559, 1637, 1681, 1695, 1709, 1718, 1721, 1737, 1782, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2070, 2098, 2109, 2118, 2129, 2130, 2135, 2177, 2182, 2189,\n",
      "       2224, 2237, 2282, 2292, 2293, 2298, 2299, 2387, 2393, 2406, 2414, 2422, 2433, 2447, 2454, 2462, 2574, 2582, 2597, 2607, 2648, 2654, 2730, 2758, 2771, 2810, 2853, 2863, 2896, 2927, 2939, 2945,\n",
      "       2952, 2953, 2998, 3005, 3030, 3060, 3062, 3073, 3160, 3206, 3240, 3262, 3289, 3323, 3333, 3336, 3369, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3629, 3702, 3716, 3718, 3726, 3742, 3757, 3767,\n",
      "       3780, 3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3968], dtype=int64),)\n",
      "num correct is  3829  an accuracy of  0.9574893723430857\n",
      "****************************** 5999 ******************************\n",
      "fill_up_last_row.shape (65999, 12)\n",
      "X_num_images 65999 X_image_num_pixels 912\n",
      "num_extra_rows 5\n",
      "2020-06-05 12:24:52.494514 Start of fit\n",
      "Epoch 1/5\n",
      "59395/59395 [==============================] - 37s 617us/sample - loss: 0.2553 - acc: 0.9192\n",
      "Epoch 2/5\n",
      "59395/59395 [==============================] - 34s 569us/sample - loss: 0.0831 - acc: 0.9740 - loss: 0.0  - ETA: 0s - loss: 0.0833 - acc: 0.97\n",
      "Epoch 3/5\n",
      "59395/59395 [==============================] - 34s 570us/sample - loss: 0.0568 - acc: 0.9823\n",
      "Epoch 4/5\n",
      "59395/59395 [==============================] - 34s 568us/sample - loss: 0.0444 - acc: 0.9859\n",
      "Epoch 5/5\n",
      "59395/59395 [==============================] - 33s 561us/sample - loss: 0.0352 - acc: 0.9886 - loss: 0.0351 - acc: 0.988 - ETA: 0s - loss: 0.0351 - acc: 0.98\n",
      "2020-06-05 12:27:59.934281 End of fit\n",
      "acc: 97.71%\n",
      "2020-06-05 12:30:16.797370 Start of fit\n",
      "Epoch 1/5\n",
      "59397/59397 [==============================] - 46s 776us/sample - loss: 0.2464 - acc: 0.9213 - loss - ETA: 1s - loss:\n",
      "Epoch 2/5\n",
      "59397/59397 [==============================] - 35s 585us/sample - loss: 0.0800 - acc: 0.9750 - loss: 0.0804\n",
      "Epoch 3/5\n",
      "59397/59397 [==============================] - 35s 583us/sample - loss: 0.0557 - acc: 0.9824 - loss: 0.0563 - - ETA: 1s - loss: 0.0 - ETA: 0s - loss: 0.0558 - acc: 0.98\n",
      "Epoch 4/5\n",
      "59397/59397 [==============================] - 34s 569us/sample - loss: 0.0427 - acc: 0.9863\n",
      "Epoch 5/5\n",
      "59397/59397 [==============================] - 34s 574us/sample - loss: 0.0347 - acc: 0.9891\n",
      "2020-06-05 12:35:19.241462 End of fit\n",
      "acc: 98.23%\n",
      "2020-06-05 12:35:28.394801 Start of fit\n",
      "Epoch 1/5\n",
      "59397/59397 [==============================] - 38s 640us/sample - loss: 0.2490 - acc: 0.9220 - loss: 0.\n",
      "Epoch 2/5\n",
      "59397/59397 [==============================] - 35s 595us/sample - loss: 0.0826 - acc: 0.9750 - loss: 0.0\n",
      "Epoch 3/5\n",
      "59397/59397 [==============================] - 36s 601us/sample - loss: 0.0582 - acc: 0.9816\n",
      "Epoch 4/5\n",
      "59397/59397 [==============================] - 35s 595us/sample - loss: 0.0444 - acc: 0.9857\n",
      "Epoch 5/5\n",
      "59397/59397 [==============================] - 35s 596us/sample - loss: 0.0358 - acc: 0.9888\n",
      "2020-06-05 12:38:43.549771 End of fit\n",
      "acc: 98.42%\n",
      "2020-06-05 12:38:52.272285 Start of fit\n",
      "Epoch 1/5\n",
      "59399/59399 [==============================] - 37s 621us/sample - loss: 0.2498 - acc: 0.9204\n",
      "Epoch 2/5\n",
      "59399/59399 [==============================] - 34s 577us/sample - loss: 0.0818 - acc: 0.9746 - loss: 0.0818 - acc: 0\n",
      "Epoch 3/5\n",
      "59399/59399 [==============================] - 34s 572us/sample - loss: 0.0559 - acc: 0.9820\n",
      "Epoch 4/5\n",
      "59399/59399 [==============================] - 34s 567us/sample - loss: 0.0428 - acc: 0.9864\n",
      "Epoch 5/5\n",
      "59399/59399 [==============================] - 33s 556us/sample - loss: 0.0339 - acc: 0.9894\n",
      "2020-06-05 12:41:58.201633 End of fit\n",
      "acc: 98.41%\n",
      "2020-06-05 12:42:06.862263 Start of fit\n",
      "Epoch 1/5\n",
      "59399/59399 [==============================] - 37s 627us/sample - loss: 0.2377 - acc: 0.9238\n",
      "Epoch 2/5\n",
      "59399/59399 [==============================] - 35s 583us/sample - loss: 0.0812 - acc: 0.9746\n",
      "Epoch 3/5\n",
      "59399/59399 [==============================] - 35s 582us/sample - loss: 0.0570 - acc: 0.9822\n",
      "Epoch 4/5\n",
      "59399/59399 [==============================] - 34s 576us/sample - loss: 0.0448 - acc: 0.9860 \n",
      "Epoch 5/5\n",
      "59399/59399 [==============================] - 34s 575us/sample - loss: 0.0369 - acc: 0.9887\n",
      "2020-06-05 12:45:14.519650 End of fit\n",
      "acc: 98.00%\n",
      "2020-06-05 12:45:22.131583 Start of fit\n",
      "Epoch 1/5\n",
      "59399/59399 [==============================] - 38s 632us/sample - loss: 0.2372 - acc: 0.9238\n",
      "Epoch 2/5\n",
      "59399/59399 [==============================] - 34s 576us/sample - loss: 0.0821 - acc: 0.9740\n",
      "Epoch 3/5\n",
      "59399/59399 [==============================] - 34s 576us/sample - loss: 0.0565 - acc: 0.9816\n",
      "Epoch 4/5\n",
      "59399/59399 [==============================] - 35s 587us/sample - loss: 0.0437 - acc: 0.9856\n",
      "Epoch 5/5\n",
      "59399/59399 [==============================] - 35s 586us/sample - loss: 0.0344 - acc: 0.9890\n",
      "2020-06-05 12:48:29.963577 End of fit\n",
      "acc: 98.58%\n",
      "2020-06-05 12:48:37.347165 Start of fit\n",
      "Epoch 1/5\n",
      "59400/59400 [==============================] - 37s 625us/sample - loss: 0.2536 - acc: 0.9179s -  - ETA: 9s - loss: - ETA: 7s - loss: 0.2899 - ETA: 3s - loss: 0.2685 - a - \n",
      "Epoch 2/5\n",
      "59400/59400 [==============================] - 34s 580us/sample - loss: 0.0839 - acc: 0.9731\n",
      "Epoch 3/5\n",
      "59400/59400 [==============================] - 34s 575us/sample - loss: 0.0584 - acc: 0.9812\n",
      "Epoch 4/5\n",
      "59400/59400 [==============================] - 34s 576us/sample - loss: 0.0456 - acc: 0.9857 - loss: 0.045\n",
      "Epoch 5/5\n",
      "59400/59400 [==============================] - 35s 595us/sample - loss: 0.0368 - acc: 0.9881\n",
      "2020-06-05 12:51:44.469013 End of fit\n",
      "acc: 98.50%\n",
      "2020-06-05 12:51:52.065005 Start of fit\n",
      "Epoch 1/5\n",
      "59400/59400 [==============================] - 37s 618us/sample - loss: 0.2512 - acc: 0.9201\n",
      "Epoch 2/5\n",
      "59400/59400 [==============================] - 34s 575us/sample - loss: 0.0819 - acc: 0.9742 - loss: 0.0822 - acc: 0.9\n",
      "Epoch 3/5\n",
      "59400/59400 [==============================] - 34s 578us/sample - loss: 0.0571 - acc: 0.9819 - loss: 0.0570 - acc: 0.98 - ETA: 2\n",
      "Epoch 4/5\n",
      "59400/59400 [==============================] - 34s 579us/sample - loss: 0.0433 - acc: 0.9864\n",
      "Epoch 5/5\n",
      "59400/59400 [==============================] - 34s 579us/sample - loss: 0.0340 - acc: 0.9891 - loss: 0.0335 - acc: 0.989 - ETA: 1s \n",
      "2020-06-05 12:54:57.456291 End of fit\n",
      "acc: 98.42%\n",
      "2020-06-05 12:55:04.901131 Start of fit\n",
      "Epoch 1/5\n",
      "59402/59402 [==============================] - 37s 625us/sample - loss: 0.2448 - acc: 0.9239\n",
      "Epoch 2/5\n",
      "59402/59402 [==============================] - 35s 588us/sample - loss: 0.0785 - acc: 0.9753\n",
      "Epoch 3/5\n",
      "59402/59402 [==============================] - 35s 590us/sample - loss: 0.0545 - acc: 0.9828\n",
      "Epoch 4/5\n",
      "59402/59402 [==============================] - 34s 580us/sample - loss: 0.0422 - acc: 0.9870\n",
      "Epoch 5/5\n",
      "59402/59402 [==============================] - 35s 591us/sample - loss: 0.0332 - acc: 0.9895\n",
      "2020-06-05 12:58:12.648944 End of fit\n",
      "acc: 97.94%\n",
      "2020-06-05 12:58:19.979664 Start of fit\n",
      "Epoch 1/5\n",
      "59403/59403 [==============================] - 38s 634us/sample - loss: 0.2556 - acc: 0.9181\n",
      "Epoch 2/5\n",
      "59403/59403 [==============================] - 35s 593us/sample - loss: 0.0810 - acc: 0.9748\n",
      "Epoch 3/5\n",
      "59403/59403 [==============================] - 35s 588us/sample - loss: 0.0557 - acc: 0.9819\n",
      "Epoch 4/5\n",
      "59403/59403 [==============================] - 34s 579us/sample - loss: 0.0418 - acc: 0.9869\n",
      "Epoch 5/5\n",
      "59403/59403 [==============================] - 35s 586us/sample - loss: 0.0333 - acc: 0.9896\n",
      "2020-06-05 13:01:28.079499 End of fit\n",
      "acc: 98.50%\n",
      "98.27% (+/- 0.28%)\n",
      "2020-06-05 13:01:34.159879 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 2 3 4 5 6 7 8 9 8 4 1 3 7 5 2 8 0 7 3 9 9 0 9 1 1 5 8 8 6 3 2 1 8 3 2 6 5 6 9 6 1 0 5 3 1 9\n",
      " 2 1 9 6 0 4 6 1 7 3 8 9 2 9 6 5 8 3 5 7 1 6 1 0 9 6 2 5 4 2 3 4 4 6 0 0 2 0 1 2 3 4 3 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 8 4 5 6 7 8 9 8 6 5 0 6 8 9 4 1 9 5 8 0 9 8 9 1 4 0 5 3 2 1 5 4 0 7 6 0 1 7 0\n",
      " 6 8 9 3 1]\n",
      "ndx_errs (array([ 151,  241,  247,  320,  321,  338,  362,  376,  381,  444,  445,  448,  464,  479,  495,  519,  582,  628,  646,  659,  689,  691,  707,  716,  726,  740,  760,  839,  844,  881,  924,  938,\n",
      "        939,  947,  951,  956,  966, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1192, 1226, 1232, 1242, 1247, 1283, 1289, 1299, 1319, 1325, 1326, 1331, 1364, 1393, 1414, 1500, 1523,\n",
      "       1530, 1549, 1553, 1559, 1637, 1681, 1695, 1709, 1718, 1721, 1737, 1782, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2070, 2098, 2109, 2118, 2129, 2130, 2135, 2177, 2182, 2189,\n",
      "       2224, 2237, 2282, 2292, 2293, 2298, 2299, 2387, 2393, 2406, 2414, 2422, 2433, 2447, 2454, 2462, 2574, 2582, 2597, 2607, 2648, 2654, 2730, 2758, 2771, 2810, 2853, 2863, 2896, 2927, 2939, 2945,\n",
      "       2952, 2953, 2998, 3005, 3030, 3060, 3062, 3073, 3160, 3206, 3240, 3262, 3289, 3323, 3333, 3336, 3369, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3629, 3702, 3716, 3718, 3726, 3742, 3757, 3767,\n",
      "       3780, 3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3968, 4007, 4065, 4075, 4078, 4116, 4196, 4224, 4269, 4271, 4284, 4289, 4297, 4306, 4355, 4360, 4483, 4497, 4500, 4505, 4575, 4598, 4639,\n",
      "       4671, 4731, 4737, 4743, 4761, 4785, 4807, 4823, 4837, 4860, 4874, 4886, 4890, 4893, 4911, 4943, 4950, 4966, 4976, 4978, 4990, 5067, 5068, 5176, 5278, 5600, 5634, 5769, 5835, 5841, 5858, 5867,\n",
      "       5887, 5888, 5906, 5937, 5955, 5973, 5975, 5982, 5997], dtype=int64),)\n",
      "num correct is  5766  an accuracy of  0.9611601933655609\n",
      "****************************** 7999 ******************************\n",
      "fill_up_last_row.shape (67999, 12)\n",
      "X_num_images 67999 X_image_num_pixels 912\n",
      "num_extra_rows 5\n",
      "2020-06-05 13:10:39.628285 Start of fit\n",
      "Epoch 1/5\n",
      "61195/61195 [==============================] - 43s 700us/sample - loss: 0.2480 - acc: 0.9197\n",
      "Epoch 2/5\n",
      "61195/61195 [==============================] - 37s 607us/sample - loss: 0.0773 - acc: 0.9757 - loss: 0.0774 - acc: 0.97\n",
      "Epoch 3/5\n",
      "61195/61195 [==============================] - 38s 622us/sample - loss: 0.0542 - acc: 0.9830 - loss: 0.0536 - \n",
      "Epoch 4/5\n",
      "61195/61195 [==============================] - 37s 601us/sample - loss: 0.0405 - acc: 0.9873 - - ETA: 4s -\n",
      "Epoch 5/5\n",
      "61195/61195 [==============================] - 36s 591us/sample - loss: 0.0322 - acc: 0.9898\n",
      "2020-06-05 13:14:05.500589 End of fit\n",
      "acc: 98.75%\n",
      "2020-06-05 13:14:13.744324 Start of fit\n",
      "Epoch 1/5\n",
      "61195/61195 [==============================] - 39s 641us/sample - loss: 0.2318 - acc: 0.9242   - ETA:  - ETA: 0s - loss: 0.2348 - \n",
      "Epoch 2/5\n",
      "61195/61195 [==============================] - ETA: 0s - loss: 0.0796 - acc: 0.974 - 37s 602us/sample - loss: 0.0796 - acc: 0.9747\n",
      "Epoch 3/5\n",
      "61195/61195 [==============================] - 37s 601us/sample - loss: 0.0556 - acc: 0.9821\n",
      "Epoch 4/5\n",
      "61195/61195 [==============================] - 38s 622us/sample - loss: 0.0429 - acc: 0.9869 - loss: 0.0427 - acc\n",
      "Epoch 5/5\n",
      "61195/61195 [==============================] - 37s 598us/sample - loss: 0.0338 - acc: 0.9890\n",
      "2020-06-05 13:17:34.700373 End of fit\n",
      "acc: 98.59%\n",
      "2020-06-05 13:17:43.041485 Start of fit\n",
      "Epoch 1/5\n",
      "61196/61196 [==============================] - 41s 663us/sample - loss: 0.2491 - acc: 0.9210\n",
      "Epoch 2/5\n",
      "61196/61196 [==============================] - 37s 611us/sample - loss: 0.0822 - acc: 0.9741\n",
      "Epoch 3/5\n",
      "61196/61196 [==============================] - 38s 624us/sample - loss: 0.0570 - acc: 0.9823\n",
      "Epoch 4/5\n",
      "61196/61196 [==============================] - 39s 635us/sample - loss: 0.0433 - acc: 0.9865\n",
      "Epoch 5/5\n",
      "61196/61196 [==============================] - 39s 629us/sample - loss: 0.0349 - acc: 0.9886s - loss: 0.03 - ETA: 5s - loss: 0.0341 - acc: 0 -\n",
      "2020-06-05 13:21:09.902683 End of fit\n",
      "acc: 98.57%\n",
      "2020-06-05 13:21:18.720271 Start of fit\n",
      "Epoch 1/5\n",
      "61196/61196 [==============================] - 41s 669us/sample - loss: 0.2484 - acc: 0.9209\n",
      "Epoch 2/5\n",
      "61196/61196 [==============================] - 39s 629us/sample - loss: 0.0821 - acc: 0.9741\n",
      "Epoch 3/5\n",
      "61196/61196 [==============================] - 39s 634us/sample - loss: 0.0564 - acc: 0.9824 - lo - ETA: 1\n",
      "Epoch 4/5\n",
      "61196/61196 [==============================] - 37s 612us/sample - loss: 0.0447 - acc: 0.9858 - loss: 0.0\n",
      "Epoch 5/5\n",
      "61196/61196 [==============================] - 38s 618us/sample - loss: 0.0359 - acc: 0.9889 - l - ETA: 0s - loss: 0.0362 - a\n",
      "2020-06-05 13:24:45.909612 End of fit\n",
      "acc: 98.29%\n",
      "2020-06-05 13:24:54.223029 Start of fit\n",
      "Epoch 1/5\n",
      "61199/61199 [==============================] - 42s 682us/sample - loss: 0.2450 - acc: 0.9211\n",
      "Epoch 2/5\n",
      "61199/61199 [==============================] - 38s 627us/sample - loss: 0.0767 - acc: 0.9758ETA: 1s - loss\n",
      "Epoch 3/5\n",
      "61199/61199 [==============================] - 39s 631us/sample - loss: 0.0527 - acc: 0.9836\n",
      "Epoch 4/5\n",
      "61199/61199 [==============================] - 39s 631us/sample - loss: 0.0412 - acc: 0.9870 ETA\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61199/61199 [==============================] - 38s 627us/sample - loss: 0.0326 - acc: 0.9894 - loss: \n",
      "2020-06-05 13:28:21.868709 End of fit\n",
      "acc: 98.37%\n",
      "2020-06-05 13:28:30.733680 Start of fit\n",
      "Epoch 1/5\n",
      "61199/61199 [==============================] - 40s 651us/sample - loss: 0.2422 - acc: 0.9232\n",
      "Epoch 2/5\n",
      "61199/61199 [==============================] - 37s 597us/sample - loss: 0.0800 - acc: 0.9746 - los\n",
      "Epoch 3/5\n",
      "61199/61199 [==============================] - 36s 590us/sample - loss: 0.0552 - acc: 0.9827\n",
      "Epoch 4/5\n",
      "61199/61199 [==============================] - 36s 592us/sample - loss: 0.0417 - acc: 0.9870 - los\n",
      "Epoch 5/5\n",
      "61199/61199 [==============================] - 36s 596us/sample - loss: 0.0343 - acc: 0.9891\n",
      "2020-06-05 13:31:48.619913 End of fit\n",
      "acc: 98.41%\n",
      "2020-06-05 13:31:56.619786 Start of fit\n",
      "Epoch 1/5\n",
      "61200/61200 [==============================] - 41s 664us/sample - loss: 0.2459 - acc: 0.9210 - loss: 0.2472 - acc: 0.\n",
      "Epoch 2/5\n",
      "61200/61200 [==============================] - 37s 610us/sample - loss: 0.0804 - acc: 0.9749 -\n",
      "Epoch 3/5\n",
      "61200/61200 [==============================] - 37s 599us/sample - loss: 0.0558 - acc: 0.9823\n",
      "Epoch 4/5\n",
      "61200/61200 [==============================] - 37s 605us/sample - loss: 0.0429 - acc: 0.9862\n",
      "Epoch 5/5\n",
      "61200/61200 [==============================] - 38s 618us/sample - loss: 0.0352 - acc: 0.9888\n",
      "2020-06-05 13:35:18.426565 End of fit\n",
      "acc: 98.54%\n",
      "2020-06-05 13:35:26.873571 Start of fit\n",
      "Epoch 1/5\n",
      "61203/61203 [==============================] - 40s 658us/sample - loss: 0.2355 - acc: 0.9260\n",
      "Epoch 2/5\n",
      "61203/61203 [==============================] - 37s 607us/sample - loss: 0.0774 - acc: 0.9752\n",
      "Epoch 3/5\n",
      "61203/61203 [==============================] - 38s 617us/sample - loss: 0.0538 - acc: 0.9829TA: 7\n",
      "Epoch 4/5\n",
      "61203/61203 [==============================] - 38s 616us/sample - loss: 0.0415 - acc: 0.9867s - loss:  - E - ETA: 8s - loss: 0.0402 - a\n",
      "Epoch 5/5\n",
      "61203/61203 [==============================] - 38s 617us/sample - loss: 0.0331 - acc: 0.9895 - loss: 0.0332 - acc: 0.9\n",
      "2020-06-05 13:38:50.000644 End of fit\n",
      "acc: 98.66%\n",
      "2020-06-05 13:38:58.354689 Start of fit\n",
      "Epoch 1/5\n",
      "61204/61204 [==============================] - 41s 670us/sample - loss: 0.2521 - acc: 0.9194\n",
      "Epoch 2/5\n",
      "61204/61204 [==============================] - 38s 621us/sample - loss: 0.0801 - acc: 0.9749 - loss: 0.0807  - ETA: 1s - los\n",
      "Epoch 3/5\n",
      "61204/61204 [==============================] - 38s 617us/sample - loss: 0.0554 - acc: 0.9827ETA: 0s - loss: 0.0551\n",
      "Epoch 4/5\n",
      "61204/61204 [==============================] - 37s 606us/sample - loss: 0.0428 - acc: 0.9862s - loss: 0. - ETA: 0s - loss: 0.0427 - \n",
      "Epoch 5/5\n",
      "61204/61204 [==============================] - 37s 603us/sample - loss: 0.0352 - acc: 0.9891\n",
      "2020-06-05 13:42:21.207627 End of fit\n",
      "acc: 97.78%\n",
      "2020-06-05 13:42:29.263458 Start of fit\n",
      "Epoch 1/5\n",
      "61204/61204 [==============================] - 40s 652us/sample - loss: 0.2447 - acc: 0.9225\n",
      "Epoch 2/5\n",
      "61204/61204 [==============================] - 37s 610us/sample - loss: 0.0824 - acc: 0.9743 -\n",
      "Epoch 3/5\n",
      "61204/61204 [==============================] - 35s 576us/sample - loss: 0.0556 - acc: 0.9828\n",
      "Epoch 4/5\n",
      "61204/61204 [==============================] - 36s 592us/sample - loss: 0.0426 - acc: 0.9868 - loss: 0.0424 - \n",
      "Epoch 5/5\n",
      "61204/61204 [==============================] - 35s 579us/sample - loss: 0.0340 - acc: 0.9891\n",
      "2020-06-05 13:45:45.307709 End of fit\n",
      "acc: 98.65%\n",
      "98.46% (+/- 0.26%)\n",
      "2020-06-05 13:45:52.055119 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 3 5 6 7 8 9 0 1 2 3 5 6 7 8 9 9 7 0 9 0 1 5 8 8 0 9 3 2 7 8 4 6 1 0 4 9 4 2 0 5 0 1 6 9 3 2\n",
      " 9 1 6 0 1 1 8 7 7 6 3 6 0 7 2 4 1 7 0 6 7 1 2 5 8 1 8 2 8 7 6 8 7 1 6 2 9 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 8 9 5 7 0 3 1 6 8 4 1 5 6 4 2 7 8 1 3 4 3 4 7 2 0 5 0 1 9 2 3\n",
      " 2 3 5 5 7]\n",
      "ndx_errs (array([ 151,  241,  247,  320,  321,  338,  362,  376,  381,  444,  445,  448,  464,  479,  495,  519,  582,  628,  646,  659,  689,  691,  707,  716,  726,  740,  760,  839,  844,  881,  924,  938,\n",
      "        939,  947,  951,  956,  966, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1192, 1226, 1232, 1242, 1247, 1283, 1289, 1299, 1319, 1325, 1326, 1331, 1364, 1393, 1414, 1500, 1523,\n",
      "       1530, 1549, 1553, 1559, 1637, 1681, 1695, 1709, 1718, 1721, 1737, 1782, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2070, 2098, 2109, 2118, 2129, 2130, 2135, 2177, 2182, 2189,\n",
      "       2224, 2237, 2282, 2292, 2293, 2298, 2299, 2387, 2393, 2406, 2414, 2422, 2433, 2447, 2454, 2462, 2574, 2582, 2597, 2607, 2648, 2654, 2730, 2758, 2771, 2810, 2853, 2863, 2896, 2927, 2939, 2945,\n",
      "       2952, 2953, 2998, 3005, 3030, 3060, 3062, 3073, 3160, 3206, 3240, 3262, 3289, 3323, 3333, 3336, 3369, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3629, 3702, 3716, 3718, 3726, 3742, 3757, 3767,\n",
      "       3780, 3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3968, 4007, 4065, 4075, 4078, 4116, 4196, 4224, 4269, 4271, 4284, 4289, 4297, 4306, 4355, 4360, 4483, 4497, 4500, 4505, 4575, 4598, 4639,\n",
      "       4671, 4731, 4737, 4743, 4761, 4785, 4807, 4823, 4837, 4860, 4874, 4886, 4890, 4893, 4911, 4943, 4950, 4966, 4976, 4978, 4990, 5067, 5068, 5176, 5278, 5600, 5634, 5769, 5835, 5841, 5858, 5867,\n",
      "       5887, 5888, 5906, 5937, 5955, 5973, 5975, 5982, 5997, 6011, 6023, 6035, 6037, 6071, 6081, 6091, 6157, 6166, 6172, 6173, 6505, 6555, 6560, 6597, 6598, 6641, 6651, 6755, 6783, 6813, 7216, 7333,\n",
      "       7432, 7434, 7492, 7545, 7637, 7797], dtype=int64),)\n",
      "num correct is  7737  an accuracy of  0.9672459057382172\n",
      "****************************** 9999 ******************************\n",
      "fill_up_last_row.shape (69999, 12)\n",
      "X_num_images 69999 X_image_num_pixels 912\n",
      "num_extra_rows 5\n",
      "2020-06-05 13:57:57.797666 Start of fit\n",
      "Epoch 1/5\n",
      "62994/62994 [==============================] - 42s 659us/sample - loss: 0.2374 - acc: 0.9241 - loss: 0.2485 - acc: - ETA:\n",
      "Epoch 2/5\n",
      "62994/62994 [==============================] - 39s 624us/sample - loss: 0.0781 - acc: 0.9757: 1s - loss:\n",
      "Epoch 3/5\n",
      "62994/62994 [==============================] - 39s 622us/sample - loss: 0.0563 - acc: 0.9817\n",
      "Epoch 4/5\n",
      "62994/62994 [==============================] - 36s 577us/sample - loss: 0.0420 - acc: 0.9867\n",
      "Epoch 5/5\n",
      "62994/62994 [==============================] - 40s 628us/sample - loss: 0.0346 - acc: 0.9890 - los\n",
      "2020-06-05 14:01:28.823979 End of fit\n",
      "acc: 98.62%\n",
      "2020-06-05 14:01:38.129872 Start of fit\n",
      "Epoch 1/5\n",
      "62995/62995 [==============================] - 41s 646us/sample - loss: 0.2322 - acc: 0.9275 - loss: 0.23\n",
      "Epoch 2/5\n",
      "62995/62995 [==============================] - 39s 616us/sample - loss: 0.0768 - acc: 0.9758 - loss: 0.0772 - acc\n",
      "Epoch 3/5\n",
      "62995/62995 [==============================] - 38s 599us/sample - loss: 0.0530 - acc: 0.9835 - loss: 0.\n",
      "Epoch 4/5\n",
      "62995/62995 [==============================] - 36s 573us/sample - loss: 0.0410 - acc: 0.9869\n",
      "Epoch 5/5\n",
      "62995/62995 [==============================] - 39s 613us/sample - loss: 0.0326 - acc: 0.9899\n",
      "2020-06-05 14:05:04.922829 End of fit\n",
      "acc: 98.43%\n",
      "2020-06-05 14:05:14.707400 Start of fit\n",
      "Epoch 1/5\n",
      "62995/62995 [==============================] - 47s 740us/sample - loss: 0.2420 - acc: 0.9232 - loss: 0.2517 - acc: 0.920 \n",
      "Epoch 2/5\n",
      "62995/62995 [==============================] - 44s 703us/sample - loss: 0.0813 - acc: 0.9741\n",
      "Epoch 3/5\n",
      "62995/62995 [==============================] - 44s 696us/sample - loss: 0.0555 - acc: 0.9819TA: 12s -  - - ETA: 5s - loss: 0.05 - ETA: 4s - loss: 0.0563  - ETA: 0s - loss: 0.0554 - acc: 0.\n",
      "Epoch 4/5\n",
      "62995/62995 [==============================] - 42s 661us/sample - loss: 0.0436 - acc: 0.9863 - loss: 0.042 - E\n",
      "Epoch 5/5\n",
      "62995/62995 [==============================] - 41s 651us/sample - loss: 0.0347 - acc: 0.9891\n",
      "2020-06-05 14:09:06.308109 End of fit\n",
      "acc: 97.27%\n",
      "2020-06-05 14:09:15.353572 Start of fit\n",
      "Epoch 1/5\n",
      "62998/62998 [==============================] - 44s 697us/sample - loss: 0.2477 - acc: 0.9208s - loss: 0.2740 - - ETA: 5s - loss: 0.2693 - acc: 0.91 - \n",
      "Epoch 2/5\n",
      "62998/62998 [==============================] - 40s 633us/sample - loss: 0.0804 - acc: 0.9754  - ETA: 3s - loss: 0.081\n",
      "Epoch 3/5\n",
      "62998/62998 [==============================] - 39s 623us/sample - loss: 0.0554 - acc: 0.9829 - loss: 0.0566 -\n",
      "Epoch 4/5\n",
      "62998/62998 [==============================] - 38s 611us/sample - loss: 0.0428 - acc: 0.9865 - loss: 0.0429 - acc: 0.9\n",
      "Epoch 5/5\n",
      "62998/62998 [==============================] - 40s 629us/sample - loss: 0.0335 - acc: 0.9896 - loss: 0.0337 - acc:\n",
      "2020-06-05 14:12:50.371449 End of fit\n",
      "acc: 98.56%\n",
      "2020-06-05 14:12:59.654734 Start of fit\n",
      "Epoch 1/5\n",
      "62999/62999 [==============================] - 44s 705us/sample - loss: 0.2430 - acc: 0.9229\n",
      "Epoch 2/5\n",
      "62999/62999 [==============================] - 40s 639us/sample - loss: 0.0760 - acc: 0.9761 - loss: 0.0757  - ETA: 1s - loss: 0.07\n",
      "Epoch 3/5\n",
      "62999/62999 [==============================] - 39s 626us/sample - loss: 0.0523 - acc: 0.9831TA: 1s - loss: 0.0524 - - ETA: 0s - loss: 0.0523 - acc: 0.98 - ETA: 0s - loss: 0.0522 - acc: 0.\n",
      "Epoch 4/5\n",
      "62999/62999 [==============================] - 40s 634us/sample - loss: 0.0410 - acc: 0.9870 - los\n",
      "Epoch 5/5\n",
      "62999/62999 [==============================] - 41s 646us/sample - loss: 0.0329 - acc: 0.9895\n",
      "2020-06-05 14:16:37.525545 End of fit\n",
      "acc: 98.66%\n",
      "2020-06-05 14:16:47.007261 Start of fit\n",
      "Epoch 1/5\n",
      "63001/63001 [==============================] - 46s 723us/sample - loss: 0.2334 - acc: 0.9252\n",
      "Epoch 2/5\n",
      "63001/63001 [==============================] - 41s 657us/sample - loss: 0.0756 - acc: 0.9766\n",
      "Epoch 3/5\n",
      "63001/63001 [==============================] - 40s 638us/sample - loss: 0.0520 - acc: 0.9836\n",
      "Epoch 4/5\n",
      "63001/63001 [==============================] - 39s 612us/sample - loss: 0.0412 - acc: 0.9868\n",
      "Epoch 5/5\n",
      "63001/63001 [==============================] - 39s 617us/sample - loss: 0.0317 - acc: 0.9901\n",
      "2020-06-05 14:20:26.276344 End of fit\n",
      "acc: 98.69%\n",
      "2020-06-05 14:20:34.242778 Start of fit\n",
      "Epoch 1/5\n",
      "63001/63001 [==============================] - 42s 669us/sample - loss: 0.2297 - acc: 0.9265\n",
      "Epoch 2/5\n",
      "63001/63001 [==============================] - 39s 612us/sample - loss: 0.0799 - acc: 0.9745\n",
      "Epoch 3/5\n",
      "63001/63001 [==============================] - 39s 613us/sample - loss: 0.0556 - acc: 0.9832 - loss: 0.0560 - a\n",
      "Epoch 4/5\n",
      "63001/63001 [==============================] - 39s 612us/sample - loss: 0.0420 - acc: 0.9863\n",
      "Epoch 5/5\n",
      "63001/63001 [==============================] - 39s 621us/sample - loss: 0.0332 - acc: 0.9898\n",
      "2020-06-05 14:24:03.948298 End of fit\n",
      "acc: 98.31%\n",
      "2020-06-05 14:24:12.151502 Start of fit\n",
      "Epoch 1/5\n",
      "63002/63002 [==============================] - 43s 687us/sample - loss: 0.2429 - acc: 0.9217\n",
      "Epoch 2/5\n",
      "63002/63002 [==============================] - 40s 634us/sample - loss: 0.0805 - acc: 0.9739 - loss: 0.\n",
      "Epoch 3/5\n",
      "63002/63002 [==============================] - 40s 633us/sample - loss: 0.0561 - acc: 0.9820- ETA: 0s - loss: 0.0562 - acc:\n",
      "Epoch 4/5\n",
      "63002/63002 [==============================] - 40s 628us/sample - loss: 0.0430 - acc: 0.9865 - loss: 0.0430 - - ETA: 0s - loss: 0.0430 - acc: 0.98\n",
      "Epoch 5/5\n",
      "63002/63002 [==============================] - 40s 638us/sample - loss: 0.0338 - acc: 0.9895\n",
      "2020-06-05 14:27:47.672402 End of fit\n",
      "acc: 98.59%\n",
      "2020-06-05 14:27:56.432400 Start of fit\n",
      "Epoch 1/5\n",
      "63003/63003 [==============================] - 44s 691us/sample - loss: 0.2382 - acc: 0.9236 - loss: 0.2513 -\n",
      "Epoch 2/5\n",
      "63003/63003 [==============================] - 40s 641us/sample - loss: 0.0761 - acc: 0.9755\n",
      "Epoch 3/5\n",
      "63003/63003 [==============================] - 40s 637us/sample - loss: 0.0523 - acc: 0.9835 - loss: 0.0521 - acc:  - ETA: 2s - loss: 0.0521 - acc: - ETA:\n",
      "Epoch 4/5\n",
      "63003/63003 [==============================] - 40s 631us/sample - loss: 0.0420 - acc: 0.9865 - loss: 0.0421 - acc: 0 - ETA: 1s - loss: 0.\n",
      "Epoch 5/5\n",
      "63003/63003 [==============================] - 39s 626us/sample - loss: 0.0333 - acc: 0.9893 - loss: 0.0332 - acc: 0.\n",
      "2020-06-05 14:31:32.685806 End of fit\n",
      "acc: 98.63%\n",
      "2020-06-05 14:31:40.993374 Start of fit\n",
      "Epoch 1/5\n",
      "63003/63003 [==============================] - 43s 683us/sample - loss: 0.2442 - acc: 0.9222\n",
      "Epoch 2/5\n",
      "63003/63003 [==============================] - 40s 633us/sample - loss: 0.0791 - acc: 0.9754 - loss: 0.0792 - acc: 0.975 - ETA: 1s - loss: 0.079\n",
      "Epoch 3/5\n",
      "63003/63003 [==============================] - 39s 617us/sample - loss: 0.0545 - acc: 0.9833\n",
      "Epoch 4/5\n",
      "63003/63003 [==============================] - 39s 617us/sample - loss: 0.0423 - acc: 0.9869\n",
      "Epoch 5/5\n",
      "63003/63003 [==============================] - 39s 620us/sample - loss: 0.0331 - acc: 0.9896\n",
      "2020-06-05 14:35:14.040220 End of fit\n",
      "acc: 98.56%\n",
      "98.43% (+/- 0.40%)\n",
      "2020-06-05 14:35:21.455790 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 2 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 7 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 6 7 0 6 8 6 3 9 9 8 8 7\n",
      " 7 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 8 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0\n",
      " 1 2 3 4 5]\n",
      "ndx_errs (array([ 151,  241,  247,  320,  321,  338,  362,  376,  381,  444,  445,  448,  464,  479,  495,  519,  582,  628,  646,  659,  689,  691,  707,  716,  726,  740,  760,  839,  844,  881,  924,  938,\n",
      "        939,  947,  951,  956,  966, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1192, 1226, 1232, 1242, 1247, 1283, 1289, 1299, 1319, 1325, 1326, 1331, 1364, 1393, 1414, 1500, 1523,\n",
      "       1530, 1549, 1553, 1559, 1637, 1681, 1695, 1709, 1718, 1721, 1737, 1782, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2070, 2098, 2109, 2118, 2129, 2130, 2135, 2177, 2182, 2189,\n",
      "       2224, 2237, 2282, 2292, 2293, 2298, 2299, 2387, 2393, 2406, 2414, 2422, 2433, 2447, 2454, 2462, 2574, 2582, 2597, 2607, 2648, 2654, 2730, 2758, 2771, 2810, 2853, 2863, 2896, 2927, 2939, 2945,\n",
      "       2952, 2953, 2998, 3005, 3030, 3060, 3062, 3073, 3160, 3206, 3240, 3262, 3289, 3323, 3333, 3336, 3369, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3629, 3702, 3716, 3718, 3726, 3742, 3757, 3767,\n",
      "       3780, 3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3968, 4007, 4065, 4075, 4078, 4116, 4196, 4224, 4269, 4271, 4284, 4289, 4297, 4306, 4355, 4360, 4483, 4497, 4500, 4505, 4575, 4598, 4639,\n",
      "       4671, 4731, 4737, 4743, 4761, 4785, 4807, 4823, 4837, 4860, 4874, 4886, 4890, 4893, 4911, 4943, 4950, 4966, 4976, 4978, 4990, 5067, 5068, 5176, 5278, 5600, 5634, 5769, 5835, 5841, 5858, 5867,\n",
      "       5887, 5888, 5906, 5937, 5955, 5973, 5975, 5982, 5997, 6011, 6023, 6035, 6037, 6071, 6081, 6091, 6157, 6166, 6172, 6173, 6505, 6555, 6560, 6597, 6598, 6641, 6651, 6755, 6783, 6813, 7216, 7333,\n",
      "       7432, 7434, 7492, 7545, 7637, 7797, 8277, 8279, 8325, 8406, 8408, 8410, 8520, 8527, 9009, 9015, 9024, 9211, 9280, 9382, 9422, 9423, 9587, 9624, 9634, 9642, 9664, 9719, 9729, 9745, 9749, 9751,\n",
      "       9768, 9770, 9779, 9792, 9811, 9832, 9839, 9867, 9883, 9893, 9904, 9905, 9943, 9982], dtype=int64),)\n",
      "num correct is  9697  an accuracy of  0.9697969796979697\n",
      "fill_up_last_row.shape (70000, 12)\n",
      "X_num_images 70000 X_image_num_pixels 912\n",
      "num_extra_rows 5\n",
      "2020-06-05 14:48:28.950600 Start of fit\n",
      "Epoch 1/5\n",
      "62995/62995 [==============================] - 43s 684us/sample - loss: 0.2469 - acc: 0.9219\n",
      "Epoch 2/5\n",
      "62995/62995 [==============================] - 40s 631us/sample - loss: 0.0848 - acc: 0.9733\n",
      "Epoch 3/5\n",
      "62995/62995 [==============================] - 39s 626us/sample - loss: 0.0595 - acc: 0.9812\n",
      "Epoch 4/5\n",
      "62995/62995 [==============================] - 40s 635us/sample - loss: 0.0450 - acc: 0.9859\n",
      "Epoch 5/5\n",
      "62995/62995 [==============================] - 40s 631us/sample - loss: 0.0374 - acc: 0.9887\n",
      "2020-06-05 14:52:04.934889 End of fit\n",
      "acc: 98.37%\n",
      "2020-06-05 14:52:13.752385 Start of fit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "62996/62996 [==============================] - 43s 676us/sample - loss: 0.2396 - acc: 0.9234\n",
      "Epoch 2/5\n",
      "62996/62996 [==============================] - 39s 612us/sample - loss: 0.0757 - acc: 0.9763\n",
      "Epoch 3/5\n",
      "62996/62996 [==============================] - 39s 613us/sample - loss: 0.0545 - acc: 0.9828\n",
      "Epoch 4/5\n",
      "62996/62996 [==============================] - 39s 617us/sample - loss: 0.0409 - acc: 0.9872\n",
      "Epoch 5/5\n",
      "62996/62996 [==============================] - 39s 620us/sample - loss: 0.0332 - acc: 0.9900 - loss: 0 - ET\n",
      "2020-06-05 14:56:19.703204 End of fit\n",
      "acc: 97.72%\n",
      "2020-06-05 14:56:28.268772 Start of fit\n",
      "Epoch 1/5\n",
      "62996/62996 [==============================] - 43s 678us/sample - loss: 0.2447 - acc: 0.9222\n",
      "Epoch 2/5\n",
      "62996/62996 [==============================] - 39s 625us/sample - loss: 0.0799 - acc: 0.9748\n",
      "Epoch 3/5\n",
      "62996/62996 [==============================] - 39s 619us/sample - loss: 0.0560 - acc: 0.98230s - loss: 0.0560 - acc: 0.\n",
      "Epoch 4/5\n",
      "62996/62996 [==============================] - 39s 614us/sample - loss: 0.0426 - acc: 0.9867 - los\n",
      "Epoch 5/5\n",
      "62996/62996 [==============================] - 39s 613us/sample - loss: 0.0345 - acc: 0.9894\n",
      "2020-06-05 14:59:59.449074 End of fit\n",
      "acc: 98.19%\n",
      "2020-06-05 15:00:07.916907 Start of fit\n",
      "Epoch 1/5\n",
      "62999/62999 [==============================] - 43s 675us/sample - loss: 0.2314 - acc: 0.9264\n",
      "Epoch 2/5\n",
      "62999/62999 [==============================] - 41s 644us/sample - loss: 0.0773 - acc: 0.9759\n",
      "Epoch 3/5\n",
      "62999/62999 [==============================] - 39s 621us/sample - loss: 0.0540 - acc: 0.9832 - loss: 0.0 - ETA: 7s - loss:  - ETA: 3s - ETA: 1s - loss: 0.0\n",
      "Epoch 4/5\n",
      "62999/62999 [==============================] - 40s 629us/sample - loss: 0.0414 - acc: 0.9869\n",
      "Epoch 5/5\n",
      "62999/62999 [==============================] - 40s 632us/sample - loss: 0.0333 - acc: 0.9895ETA: 1s - loss:\n",
      "2020-06-05 15:03:41.954325 End of fit\n",
      "acc: 98.36%\n",
      "2020-06-05 15:03:50.198906 Start of fit\n",
      "Epoch 1/5\n",
      "63000/63000 [==============================] - 44s 695us/sample - loss: 0.2299 - acc: 0.9277\n",
      "Epoch 2/5\n",
      "63000/63000 [==============================] - 40s 629us/sample - loss: 0.0765 - acc: 0.9757 -\n",
      "Epoch 3/5\n",
      "63000/63000 [==============================] - 40s 634us/sample - loss: 0.0537 - acc: 0.9830\n",
      "Epoch 4/5\n",
      "63000/63000 [==============================] - 39s 623us/sample - loss: 0.0411 - acc: 0.9870 - loss: 0.0405 - acc: 0.987 - ETA: 1s - los\n",
      "Epoch 5/5\n",
      "63000/63000 [==============================] - 39s 624us/sample - loss: 0.0328 - acc: 0.9898\n",
      "2020-06-05 15:07:25.582635 End of fit\n",
      "acc: 98.57%\n",
      "2020-06-05 15:07:34.088005 Start of fit\n",
      "Epoch 1/5\n",
      "63001/63001 [==============================] - 43s 679us/sample - loss: 0.2374 - acc: 0.9236 - loss: 0.2402 \n",
      "Epoch 2/5\n",
      "63001/63001 [==============================] - 39s 620us/sample - loss: 0.0770 - acc: 0.9750\n",
      "Epoch 3/5\n",
      "63001/63001 [==============================] - ETA: 0s - loss: 0.0544 - acc: 0.9826- ETA: 0s - loss: 0.0542 - ac - 40s 627us/sample - loss: 0.0544 - acc: 0.9826\n",
      "Epoch 4/5\n",
      "63001/63001 [==============================] - 40s 640us/sample - loss: 0.0415 - acc: 0.9869\n",
      "Epoch 5/5\n",
      "63001/63001 [==============================] - 40s 632us/sample - loss: 0.0346 - acc: 0.9890\n",
      "2020-06-05 15:11:09.093726 End of fit\n",
      "acc: 98.31%\n",
      "2020-06-05 15:11:17.333997 Start of fit\n",
      "Epoch 1/5\n",
      "63002/63002 [==============================] - 43s 687us/sample - loss: 0.2335 - acc: 0.9246 - los\n",
      "Epoch 2/5\n",
      "63002/63002 [==============================] - 40s 636us/sample - loss: 0.0774 - acc: 0.9759 - loss: 0.0775 - acc: \n",
      "Epoch 3/5\n",
      "63002/63002 [==============================] - 40s 631us/sample - loss: 0.0527 - acc: 0.9831 - los - ETA: 1s -\n",
      "Epoch 4/5\n",
      "63002/63002 [==============================] - 40s 629us/sample - loss: 0.0416 - acc: 0.9870 - ET\n",
      "Epoch 5/5\n",
      "63002/63002 [==============================] - 40s 633us/sample - loss: 0.0329 - acc: 0.9896\n",
      "2020-06-05 15:14:52.747739 End of fit\n",
      "acc: 98.40%\n",
      "2020-06-05 15:15:01.306249 Start of fit\n",
      "Epoch 1/5\n",
      "63003/63003 [==============================] - 42s 673us/sample - loss: 0.2263 - acc: 0.9285\n",
      "Epoch 2/5\n",
      "63003/63003 [==============================] - 39s 612us/sample - loss: 0.0766 - acc: 0.9765 - loss: 0.0767 - acc: \n",
      "Epoch 3/5\n",
      "63003/63003 [==============================] - 39s 615us/sample - loss: 0.0539 - acc: 0.9829\n",
      "Epoch 4/5\n",
      "63003/63003 [==============================] - 39s 611us/sample - loss: 0.0425 - acc: 0.9861\n",
      "Epoch 5/5\n",
      "63003/63003 [==============================] - 39s 625us/sample - loss: 0.0324 - acc: 0.9897 - loss: 0.\n",
      "2020-06-05 15:18:32.377845 End of fit\n",
      "acc: 98.49%\n",
      "2020-06-05 15:18:41.280889 Start of fit\n",
      "Epoch 1/5\n",
      "63004/63004 [==============================] - 44s 702us/sample - loss: 0.2345 - acc: 0.9247\n",
      "Epoch 2/5\n",
      "63004/63004 [==============================] - 40s 639us/sample - loss: 0.0754 - acc: 0.9756\n",
      "Epoch 3/5\n",
      "63004/63004 [==============================] - 40s 635us/sample - loss: 0.0520 - acc: 0.9838 - loss: 0.\n",
      "Epoch 4/5\n",
      "63004/63004 [==============================] - 40s 640us/sample - loss: 0.0398 - acc: 0.9873 - loss: 0 - ETA: 3s - lo - ETA: 2s\n",
      "Epoch 5/5\n",
      "63004/63004 [==============================] - 40s 641us/sample - loss: 0.0314 - acc: 0.9897\n",
      "2020-06-05 15:22:19.844597 End of fit\n",
      "acc: 98.37%\n",
      "2020-06-05 15:22:28.518011 Start of fit\n",
      "Epoch 1/5\n",
      "63004/63004 [==============================] - 44s 697us/sample - loss: 0.2427 - acc: 0.9232\n",
      "Epoch 2/5\n",
      "63004/63004 [==============================] - 40s 633us/sample - loss: 0.0793 - acc: 0.9748\n",
      "Epoch 3/5\n",
      "63004/63004 [==============================] - 40s 629us/sample - loss: 0.0557 - acc: 0.9829\n",
      "Epoch 4/5\n",
      "63004/63004 [==============================] - 40s 638us/sample - loss: 0.0411 - acc: 0.9866 - loss: 0.0411 - acc: \n",
      "Epoch 5/5\n",
      "63004/63004 [==============================] - 39s 623us/sample - loss: 0.0333 - acc: 0.9899\n",
      "2020-06-05 15:26:04.652806 End of fit\n",
      "acc: 98.17%\n",
      "98.29% (+/- 0.22%)\n",
      "2020-06-05 15:26:12.275189 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 7 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 6 7 0 6 8 6 3 9 9 8 8 7 7\n",
      " 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 8 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "ndx_errs (array([ 151,  241,  247,  320,  321,  338,  362,  376,  381,  444,  445,  448,  464,  479,  495,  519,  582,  628,  646,  659,  689,  691,  707,  716,  726,  740,  760,  839,  844,  881,  924,  938,\n",
      "        939,  947,  951,  956,  966, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1192, 1226, 1232, 1242, 1247, 1283, 1289, 1299, 1319, 1325, 1326, 1331, 1364, 1393, 1414, 1500, 1523,\n",
      "       1530, 1549, 1553, 1559, 1637, 1681, 1695, 1709, 1718, 1721, 1737, 1782, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2070, 2098, 2109, 2118, 2129, 2130, 2135, 2177, 2182, 2189,\n",
      "       2224, 2237, 2282, 2292, 2293, 2298, 2299, 2387, 2393, 2406, 2414, 2422, 2433, 2447, 2454, 2462, 2574, 2582, 2597, 2607, 2648, 2654, 2730, 2758, 2771, 2810, 2853, 2863, 2896, 2927, 2939, 2945,\n",
      "       2952, 2953, 2998, 3005, 3030, 3060, 3062, 3073, 3160, 3206, 3240, 3262, 3289, 3323, 3333, 3336, 3369, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3629, 3702, 3716, 3718, 3726, 3742, 3757, 3767,\n",
      "       3780, 3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3968, 4007, 4065, 4075, 4078, 4116, 4196, 4224, 4269, 4271, 4284, 4289, 4297, 4306, 4355, 4360, 4483, 4497, 4500, 4505, 4575, 4598, 4639,\n",
      "       4671, 4731, 4737, 4743, 4761, 4785, 4807, 4823, 4837, 4860, 4874, 4886, 4890, 4893, 4911, 4943, 4950, 4966, 4976, 4978, 4990, 5067, 5068, 5176, 5278, 5600, 5634, 5769, 5835, 5841, 5858, 5867,\n",
      "       5887, 5888, 5906, 5937, 5955, 5973, 5975, 5982, 5997, 6011, 6023, 6035, 6037, 6071, 6081, 6091, 6157, 6166, 6172, 6173, 6505, 6555, 6560, 6597, 6598, 6641, 6651, 6755, 6783, 6813, 7216, 7333,\n",
      "       7432, 7434, 7492, 7545, 7637, 7797, 8277, 8279, 8325, 8406, 8408, 8410, 8520, 8527, 9009, 9015, 9024, 9211, 9280, 9382, 9422, 9423, 9587, 9624, 9634, 9642, 9664, 9719, 9729, 9745, 9749, 9751,\n",
      "       9768, 9770, 9779, 9792, 9811, 9832, 9839, 9867, 9883, 9893, 9904, 9905, 9943, 9982], dtype=int64),)\n",
      "num correct is  9698  an accuracy of  0.9698\n",
      "2020-06-05 15:39:15.860339 end\n"
     ]
    }
   ],
   "source": [
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-05 06:41:30.613845 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 9 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 9 8 7 2 3 0 4 4 2 4 1 9 5 7 7 2 8 2 6 8 5 7 7 9 1 8 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 9 2 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 8 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 2 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 3 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 6 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 3 8 8 2 7 5 8 9 6 1 8 4 1 2 5 9 1 9 7 5 4 0 8 9 9 1 0 5 2 3 7\n",
      " 8 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 8 4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 2 1 7 0 6 5 4 3 8 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 2 3 1 9 7 5 1 0 8 4 6 2 6 7 9 3 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 5 8 0 3 7 2 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 7 8 3 3 6 7 2 8 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 8 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5 4 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 5\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 8 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 8 8 8 7 4 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 2 3 2 3 9 1 7 4 0 3 5 5 8 6 3 2 6 7 6 6 3 2 7 8 1 1 7 5 6 4 9 5 1 3 3 4 7 8 9 1 1 6 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "<class 'numpy.ndarray'> (0, 128)\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "fill_up_last_row.shape (7000, 12)\n",
      "X_num_images 7000 X_image_num_pixels 912\n",
      "num_extra_rows 5\n",
      "2020-06-05 06:43:32.646821 Start of fit\n",
      "Epoch 1/5\n",
      "6296/6296 [==============================] - 8s 1ms/sample - loss: 0.8658 - acc: 0.7170\n",
      "Epoch 2/5\n",
      "6296/6296 [==============================] - 4s 622us/sample - loss: 0.3092 - acc: 0.8998s - loss: 0.3272 -\n",
      "Epoch 3/5\n",
      "6296/6296 [==============================] - 4s 603us/sample - loss: 0.2086 - acc: 0.9319\n",
      "Epoch 4/5\n",
      "6296/6296 [==============================] - 4s 613us/sample - loss: 0.1601 - acc: 0.9512s - loss: 0.1657 - acc: 0.950 - ETA: 1s - loss: 0.1667 - acc: 0. - ETA: 1s - loss:\n",
      "Epoch 5/5\n",
      "6296/6296 [==============================] - 4s 596us/sample - loss: 0.1281 - acc: 0.9587s - l\n",
      "2020-06-05 06:44:08.521219 End of fit\n",
      "acc: 95.60%\n",
      "2020-06-05 06:44:13.760824 Start of fit\n",
      "Epoch 1/5\n",
      "6297/6297 [==============================] - 6s 938us/sample - loss: 0.8457 - acc: 0.7289s - loss: 0.8651 - acc: 0.7\n",
      "Epoch 2/5\n",
      "6297/6297 [==============================] - 4s 653us/sample - loss: 0.2997 - acc: 0.9058s - loss: 0.3789 - acc:  - ETA: 2s - loss: 0.3472 - - ETA: 1s\n",
      "Epoch 3/5\n",
      "6297/6297 [==============================] - 4s 616us/sample - loss: 0.2028 - acc: 0.9354\n",
      "Epoch 4/5\n",
      "6297/6297 [==============================] - 4s 595us/sample - loss: 0.1489 - acc: 0.9514s - loss:  - ETA: 1s - lo\n",
      "Epoch 5/5\n",
      "6297/6297 [==============================] - 4s 575us/sample - loss: 0.1188 - acc: 0.9635\n",
      "2020-06-05 06:44:44.829842 End of fit\n",
      "acc: 94.31%\n",
      "2020-06-05 06:44:49.851717 Start of fit\n",
      "Epoch 1/5\n",
      "6297/6297 [==============================] - 5s 854us/sample - loss: 0.7869 - acc: 0.7391s  - ETA: 1s - loss: 0.8976 -  - ETA: 0s - loss: 0.7891 - acc: 0.738\n",
      "Epoch 2/5\n",
      "6297/6297 [==============================] - 4s 574us/sample - loss: 0.2935 - acc: 0.9074s - l\n",
      "Epoch 3/5\n",
      "6297/6297 [==============================] - 3s 546us/sample - loss: 0.2052 - acc: 0.9374\n",
      "Epoch 4/5\n",
      "6297/6297 [==============================] - 4s 597us/sample - loss: 0.1531 - acc: 0.9511s - lo - ETA: 1s - los\n",
      "Epoch 5/5\n",
      "6297/6297 [==============================] - 3s 550us/sample - loss: 0.1245 - acc: 0.9601\n",
      "2020-06-05 06:45:19.189186 End of fit\n",
      "acc: 95.73%\n",
      "2020-06-05 06:45:23.814518 Start of fit\n",
      "Epoch 1/5\n",
      "6298/6298 [==============================] - 6s 888us/sample - loss: 0.8894 - acc: 0.7140s - loss: 0.9000 - acc: 0.71\n",
      "Epoch 2/5\n",
      "6298/6298 [==============================] - 4s 623us/sample - loss: 0.3212 - acc: 0.8968\n",
      "Epoch 3/5\n",
      "6298/6298 [==============================] - 4s 578us/sample - loss: 0.2218 - acc: 0.9297s - loss: 0.2195 - ETA: 1s - \n",
      "Epoch 4/5\n",
      "6298/6298 [==============================] - 4s 592us/sample - loss: 0.1671 - acc: 0.9463s - loss: 0.1618 - a - ETA: 1s - loss: 0\n",
      "Epoch 5/5\n",
      "6298/6298 [==============================] - 4s 556us/sample - loss: 0.1282 - acc: 0.9562\n",
      "2020-06-05 06:45:54.077359 End of fit\n",
      "acc: 95.44%\n",
      "2020-06-05 06:45:59.609403 Start of fit\n",
      "Epoch 1/5\n",
      "6298/6298 [==============================] - 5s 816us/sample - loss: 0.8471 - acc: 0.7177s - loss: 1.2687 - ac - ETA: 2s - loss: \n",
      "Epoch 2/5\n",
      "6298/6298 [==============================] - 4s 592us/sample - loss: 0.2878 - acc: 0.9082s - loss\n",
      "Epoch 3/5\n",
      "6298/6298 [==============================] - 4s 562us/sample - loss: 0.1952 - acc: 0.9386\n",
      "Epoch 4/5\n",
      "6298/6298 [==============================] - 4s 560us/sample - loss: 0.1436 - acc: 0.9489s - loss: 0.1459 - - ETA: 0s - loss: 0.1443 - acc: 0\n",
      "Epoch 5/5\n",
      "6298/6298 [==============================] - 4s 577us/sample - loss: 0.1122 - acc: 0.9640s - loss: 0.1155 - acc: 0. - ETA: 0s - loss: 0.1144 \n",
      "2020-06-05 06:46:28.748300 End of fit\n",
      "acc: 96.15%\n",
      "2020-06-05 06:46:32.760244 Start of fit\n",
      "Epoch 1/5\n",
      "6301/6301 [==============================] - 6s 922us/sample - loss: 0.8206 - acc: 0.7310s -\n",
      "Epoch 2/5\n",
      "6301/6301 [==============================] - 4s 615us/sample - loss: 0.2784 - acc: 0.9092\n",
      "Epoch 3/5\n",
      "6301/6301 [==============================] - 4s 595us/sample - loss: 0.1887 - acc: 0.9386\n",
      "Epoch 4/5\n",
      "6301/6301 [==============================] - 4s 630us/sample - loss: 0.1493 - acc: 0.9532\n",
      "Epoch 5/5\n",
      "6301/6301 [==============================] - 4s 652us/sample - loss: 0.1108 - acc: 0.9656\n",
      "2020-06-05 06:47:03.502827 End of fit\n",
      "acc: 95.57%\n",
      "2020-06-05 06:47:08.833468 Start of fit\n",
      "Epoch 1/5\n",
      "6301/6301 [==============================] - 6s 900us/sample - loss: 0.8429 - acc: 0.7258s - loss: 0.9028 - acc:\n",
      "Epoch 2/5\n",
      "6301/6301 [==============================] - 4s 560us/sample - loss: 0.3042 - acc: 0.9013s - loss: 0.3494 - acc: 0. - ETA: 2s - loss: 0.3438 - a - ETA: 2s - loss - ETA: 0s - loss: 0.3196 - acc: 0. - ETA: 0s - loss: 0.3114 - acc: 0\n",
      "Epoch 3/5\n",
      "6301/6301 [==============================] - 4s 604us/sample - loss: 0.2011 - acc: 0.9372s - loss: 0.2 - ETA: 0s - loss: 0.2010 - acc\n",
      "Epoch 4/5\n",
      "6301/6301 [==============================] - 3s 536us/sample - loss: 0.1586 - acc: 0.9516s\n",
      "Epoch 5/5\n",
      "6301/6301 [==============================] - 3s 540us/sample - loss: 0.1200 - acc: 0.9635\n",
      "2020-06-05 06:47:38.666877 End of fit\n",
      "acc: 95.42%\n",
      "2020-06-05 06:47:43.196885 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 6s 888us/sample - loss: 0.8540 - acc: 0.7268\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 4s 571us/sample - loss: 0.3015 - acc: 0.9042s - loss: 0.3720 - acc:  - ETA: 2 - ETA: 0s - loss: 0.3017 - acc: 0\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 4s 575us/sample - loss: 0.1950 - acc: 0.9342s - loss: 0.1976 - acc: 0.9\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 4s 565us/sample - loss: 0.1472 - acc: 0.9529\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 550us/sample - loss: 0.1192 - acc: 0.9589\n",
      "2020-06-05 06:48:12.764883 End of fit\n",
      "acc: 94.54%\n",
      "2020-06-05 06:48:17.059706 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 6s 877us/sample - loss: 0.8885 - acc: 0.7073\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 4s 576us/sample - loss: 0.3156 - acc: 0.8997\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 4s 561us/sample - loss: 0.2096 - acc: 0.9340s - loss: 0.1907 - acc:  - ETA: 2s - loss: 0.2063 - a - ETA: 1s \n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 4s 582us/sample - loss: 0.1627 - acc: 0.9489\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 4s 577us/sample - loss: 0.1227 - acc: 0.9608s - loss: 0.1184 - acc: 0. - ETA: 0s - loss: 0.1250 \n",
      "2020-06-05 06:48:46.394173 End of fit\n",
      "acc: 91.67%\n",
      "2020-06-05 06:48:50.895716 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 6s 904us/sample - loss: 0.8996 - acc: 0.7076\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 3s 550us/sample - loss: 0.3194 - acc: 0.8969s - l\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 3s 553us/sample - loss: 0.2159 - acc: 0.9323s - loss: 0.2488 - ETA: 1s - loss: 0.2347 - acc - ETA: 1s - loss: 0.23\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 3s 542us/sample - loss: 0.1604 - acc: 0.9480s - loss: 0.2 - ETA:\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 533us/sample - loss: 0.1218 - acc: 0.9610s - lo\n",
      "2020-06-05 06:49:20.430081 End of fit\n",
      "acc: 93.53%\n",
      "94.80% (+/- 1.28%)\n",
      "2020-06-05 06:49:23.784255 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 9 9 8 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 3 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 7 7 9 2 2 4 1 5 8 8 4 2 3 0 6 4 2 9 1 9 5 7 7 2 6 2 6 8 5 7 7 4 1 0 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 7 7 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 5 6 5 4 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 7 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 7 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 8 0 6 4 8 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 7 8 8 2 7 5 8 9 6 1 8 4 1 2 5 8 1 9 7 5 4 0 8 9 7 1 0 5 8 3 7\n",
      " 0 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 7 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 3 4 0 0 8 3 2 9 4 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 7 1 7 0 6 5 4 3 3 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 8 3 1 9 7 5 1 0 8 4 6 2 6 7 9 9 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 0 8 0 3 7 8 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 9 8 3 3 6 7 2 9 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 3 2 7 6 8 4 5 0 4 0 6 1 4 3 2 6 7 2 6 9 3 1 4 6 3 5 9 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 9 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 3 6 8 9 4 1 9\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 9 0 1 7 7 4 7 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 2 8 8 7 9 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 7 3 0 3 9 1 4 4 0 3 5 5 8 6 3 0 6 7 6 6 3 2 7 9 1 1 7 9 6 4 9 6 1 5 3 4 7 8 7 1 1 0 9 1 4 4 5 4 0 6 2 2 8 1 5 1 2 0 8 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "ndx_errs (array([149, 151, 187, 233, 241, 243, 247, 250, 257, 264, 266, 320, 321, 338, 341, 362, 381, 444, 445, 448, 464, 479, 488, 492, 495, 511, 543, 547, 550, 551, 583, 591, 613, 628, 654, 659, 684, 691,\n",
      "       714, 716, 717, 726, 738, 740, 760, 785, 791, 838, 839, 844, 877, 881, 924, 926, 930, 939, 947, 951, 955, 957, 962, 965, 976, 982], dtype=int64),)\n",
      "num correct is  936  an accuracy of  0.9359999999999999\n",
      "2020-06-05 06:49:33.307811 end\n"
     ]
    }
   ],
   "source": [
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=6_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=1_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>\n",
    "<a href='#toc'>Goto Table of Contents</a>\n",
    "\n",
    "## Reproduce results before summary\n",
    "\n",
    "## Repeating baseline give the exact same result for kNN but CNN fluctuates significantly\n",
    "\n",
    "## The average of all baseline runs for 60,000 was 99.02%\n",
    "\n",
    "- CNN acc (6,000                   ; 60,000 99.06% (+/- 0.13%))\n",
    "- CNN acc (6,000                   ; 60,000 99.00% (+/- 0.20%))\n",
    "- CNN acc (6,000                   ; 60,000 99.08% (+/- 0.12%))\n",
    "- CNN acc (6,000                   ; 60,000 98.96% (+/- 0.16%))\n",
    "\n",
    "## whereas the first baseline for the large set of images was\n",
    "\n",
    "CNN acc (6,000 96.06% (+/- 1.42%); 60,000 99.00% (+/- 0.21%))\n",
    "\n",
    "## For small set of images, repeated baselines were\n",
    "\n",
    "- CNN acc (6,000 96.61% (+/- 1.20%); 60,000 )\n",
    "- CNN acc (6,000 96.20% (+/- 0.85%); 60,000 )\n",
    "\n",
    "## whereas the first baseline for the small set of images was\n",
    "\n",
    "- CNN acc (6,000 96.06% (+/- 1.42%); 60,000 )\n",
    "\n",
    "## The average of all CNN baseline runs for 6,000 was 96.29%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-06 07:28:59.377255 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7 7\n",
      " 1 0 1 7 8 9 0 1 2 3 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "X_num_images 70000 X_image_num_pixels 784\n",
      "num_extra_rows 0\n",
      "2020-06-06 07:29:00.072729 Start of fit\n",
      "Epoch 1/5\n",
      "62995/62995 [==============================] - 23s 359us/sample - loss: 0.1601 - acc: 0.9509\n",
      "Epoch 2/5\n",
      "62995/62995 [==============================] - 22s 354us/sample - loss: 0.0450 - acc: 0.9854\n",
      "Epoch 3/5\n",
      "62995/62995 [==============================] - 24s 384us/sample - loss: 0.0314 - acc: 0.9905 - loss: 0.0304 - - ETA: 3s - loss\n",
      "Epoch 4/5\n",
      "62995/62995 [==============================] - 23s 364us/sample - loss: 0.0238 - acc: 0.9927s - loss - ETA: 12s  -  - ETA: 7s - - ETA: 6s - ETA: 4s\n",
      "Epoch 5/5\n",
      "62995/62995 [==============================] - 23s 367us/sample - loss: 0.0188 - acc: 0.9940s - loss - ETA: 22s - loss: 0.0227 - acc:  - ETA: 22s - lo - ETA: 21s - loss: 0.01 - ETA: 13 - ETA:  - ETA: 9s - loss: 0.018 - ETA: 8s - loss: 0.0191 - a - ETA: 8s - lo - ETA: 6s - loss: 0.0193 - ETA: 0s - loss: 0.0190 - \n",
      "2020-06-06 07:30:55.653793 End of fit\n",
      "acc: 99.03%\n",
      "2020-06-06 07:30:57.007375 Start of fit\n",
      "Epoch 1/5\n",
      "62996/62996 [==============================] - 26s 419us/sample - loss: 0.1628 - acc: 0.9497 - loss: 0.2120 \n",
      "Epoch 2/5\n",
      "62996/62996 [==============================] - 23s 372us/sample - loss: 0.0465 - acc: 0.9851ETA: 3s - l - ETA: 2s - l - ETA: 0s - loss: 0.0466 - \n",
      "Epoch 3/5\n",
      "62996/62996 [==============================] - 26s 409us/sample - loss: 0.0326 - acc: 0.9901s - loss: 0.0318 - ETA: 9s - ETA\n",
      "Epoch 4/5\n",
      "62996/62996 [==============================] - 23s 372us/sample - loss: 0.0245 - acc: 0.9921 1s - loss: 0.0245 - acc: 0.992 - ETA: 1s - loss: 0.0245 - acc: 0.992 - ETA: 1s - loss: 0.0245 - acc: - ETA: 1s - loss: 0.0245 -  - ETA: 0s - loss: 0.0244 \n",
      "Epoch 5/5\n",
      "62996/62996 [==============================] - 24s 389us/sample - loss: 0.0193 - acc: 0.9943 - loss: 0.0190 - ac - ETA: 5s - l - ETA: 3s - lo - ETA: 0s - loss: 0.0190 - ac\n",
      "2020-06-06 07:33:00.936946 End of fit\n",
      "acc: 99.23%\n",
      "2020-06-06 07:33:02.261574 Start of fit\n",
      "Epoch 1/5\n",
      "62996/62996 [==============================] - 27s 425us/sample - loss: 0.1692 - acc: 0.9465\n",
      "Epoch 2/5\n",
      "62996/62996 [==============================] - 26s 405us/sample - loss: 0.0445 - acc: 0.9865 - loss: 0.0449 - ETA: 2s - loss: 0.0446 - acc: 0.986 - ETA: 2s - loss: 0.0445 - acc: 0.98 - ETA: 2s - loss: 0.0445 - acc: - ETA: 1s - loss: 0.0445 - acc: 0.9 - ETA: 1s - loss:  - ETA: 0s - loss: 0.0445 - acc: 0.98\n",
      "Epoch 3/5\n",
      "62996/62996 [==============================] - 25s 393us/sample - loss: 0.0316 - acc: 0.9906 -  - ETA: 1s - loss: 0.0317 - acc: 0.990 - ETA: 1\n",
      "Epoch 4/5\n",
      "62996/62996 [==============================] - 25s 395us/sample - loss: 0.0250 - acc: 0.9924 - loss: 0.0249 - acc: - ETA: 3s - loss: 0.0249  - ETA: 0s - loss: 0.0246 - acc: 0.992 - ETA: 0s - loss: 0.0246 - acc: 0.\n",
      "Epoch 5/5\n",
      "62996/62996 [==============================] - 25s 390us/sample - loss: 0.0193 - acc: 0.9943 - loss: 0.0185 - a - ETA: 6s - l - ETA: 4s - loss: 0.0191 - acc: 0.9 - - ETA: 2s - loss: 0.0187 - acc: 0.994 - ETA: 2s - l - ETA: 0s - loss: 0.0191 - acc: 0. - ETA: 0s - loss: 0.0193 - acc\n",
      "2020-06-06 07:35:09.225424 End of fit\n",
      "acc: 99.09%\n",
      "2020-06-06 07:35:10.539553 Start of fit\n",
      "Epoch 1/5\n",
      "62999/62999 [==============================] - 24s 376us/sample - loss: 0.1782 - acc: 0.9445TA: 1s - loss: 0.1 - ETA: 0s - loss: 0.1814 - acc: 0 - ETA: 0s - loss: 0.1798 - acc: 0 - ETA: 0s - loss: 0.1784 - acc: 0.944\n",
      "Epoch 2/5\n",
      "62999/62999 [==============================] - 24s 378us/sample - loss: 0.0465 - acc: 0.9856 - loss: 0 - ETA: 1s - loss: 0.047 - ETA: 0s - loss: 0.0466 - acc: 0\n",
      "Epoch 3/5\n",
      "62999/62999 [==============================] - 24s 381us/sample - loss: 0.0332 - acc: 0.9894s - loss: 0.03 - ETA: 27s - loss: 0.03 - - ETA: 10s - loss - ETA: 8s - l - ETA: 1s - loss:  - ETA: 0s - loss: 0.0330 - acc\n",
      "Epoch 4/5\n",
      "62999/62999 [==============================] - 23s 372us/sample - loss: 0.0246 - acc: 0.9927 - loss: 0.0237 - ac - ETA: 6s - los - ETA: 2s - loss: 0.0248 - acc:  - ETA: 1s - loss: 0.0244 - acc: 0.9 - ETA: 1s \n",
      "Epoch 5/5\n",
      "62999/62999 [==============================] - 25s 396us/sample - loss: 0.0197 - acc: 0.9937 - loss: 0.0197 - acc: 0. - ETA: 0s - loss: 0.0197 - acc: 0.993\n",
      "2020-06-06 07:37:10.844298 End of fit\n",
      "acc: 99.13%\n",
      "2020-06-06 07:37:12.193210 Start of fit\n",
      "Epoch 1/5\n",
      "63000/63000 [==============================] - 25s 390us/sample - loss: 0.1575 - acc: 0.9502TA: 13s -   - ETA: 3s - loss: 0.1727 - acc: 0.94 - ETA: 3s - loss: 0.1720 - ac\n",
      "Epoch 2/5\n",
      "63000/63000 [==============================] - 26s 405us/sample - loss: 0.0441 - acc: 0.9866\n",
      "Epoch 3/5\n",
      "63000/63000 [==============================] - 24s 384us/sample - loss: 0.0298 - acc: 0.9908 - loss: 0.0299 -  - ETA: 0s - loss: 0.0299 - acc: 0.990\n",
      "Epoch 4/5\n",
      "63000/63000 [==============================] - 24s 387us/sample - loss: 0.0245 - acc: 0.9921s - loss: 0.0239 - - ETA: 2s - loss: 0.0241 - acc:  - ETA: 2s - loss: 0.0243 - acc: 0. - ETA: 1s\n",
      "Epoch 5/5\n",
      "63000/63000 [==============================] - 25s 393us/sample - loss: 0.0185 - acc: 0.9943 - \n",
      "2020-06-06 07:39:16.265103 End of fit\n",
      "acc: 98.91%\n",
      "2020-06-06 07:39:17.614538 Start of fit\n",
      "Epoch 1/5\n",
      "63001/63001 [==============================] - 24s 388us/sample - loss: 0.1649 - acc: 0.9480 8s - loss: - ETA: 5s - loss: 0.1926  - ETA: 4s - loss: 0.1875 - ac - ETA: 3s - loss: 0.1836 - acc: 0.941 - ETA: 3s - loss: 0.1 - ETA: 2s - loss: 0 - ETA: 1s - \n",
      "Epoch 2/5\n",
      "63001/63001 [==============================] - 25s 391us/sample - loss: 0.0452 - acc: 0.9860s - lo - ETA: 12s - los - ETA: 6s - loss: 0.0455 - acc: 0.98 - ETA: 6s - loss: 0.0453 - acc: 0.98 - ETA: 6s - l - ETA: 4s - loss: 0.0452 - ac - ETA: 4s - loss: 0.045 - ETA: 3s - loss: 0.0450 - ac\n",
      "Epoch 3/5\n",
      "63001/63001 [==============================] - 24s 384us/sample - loss: 0.0317 - acc: 0.9905s - loss: 0.0323 - acc: 0. - ETA: 11s - loss: 0. - ETA: 10s -  - ETA: 8s - loss: 0.0325 - acc - ETA: 8 - ETA: 6s - loss: 0.0323 - acc: 0.990 - ETA: 6s - loss: 0.0323 - acc: 0.990 - ETA: 6s - loss: 0.0324 - acc: 0. - ETA: 5s - loss: 0.0323 - acc: - ETA: 5s - loss: 0.0324 -  - ETA: 4s - loss: 0.0320 - acc: 0. - ETA: 4s - loss:  - ETA: 3s - loss: 0.0317 - acc: 0. - ETA: 2s - loss: 0. - ETA: 1s - loss: 0.031 - ETA: 0s - loss: 0.03\n",
      "Epoch 4/5\n",
      "63001/63001 [==============================] - 24s 382us/sample - loss: 0.0243 - acc: 0.9926TA: 17s - loss: 0.0211 - acc: 0. - ETA: 17s - loss: 0.0215 - acc: 0. - ETA:  - ETA: 16s  - ETA: 1 - ETA: 9s - loss: 0.0246 - acc: 0.9 - ETA: 9s - loss - ETA: 5s - loss: 0 - ETA: 4\n",
      "Epoch 5/5\n",
      "63001/63001 [==============================] - 24s 386us/sample - loss: 0.0192 - acc: 0.9938s - loss: 0.0191 - acc: 0.99 - ETA: 19s - loss: 0.0189 - acc: 0.99 - ETA: 19s - loss: 0.0188 - acc:  - E - ETA: 18s - loss: 0.0186 - acc - ETA: 18s - loss: 0.0186 - acc - ETA: 17s - loss: 0.0182 - acc - ETA: 17s - loss: 0.0179 - - E - ETA: 10s - loss: 0.0185 - ETA: 10s -  - ETA: 8s - loss: 0.0187 - ac - ETA: 7s - loss: 0. - ETA: 6s - los - ETA: 5s - loss: 0.0195 - acc: 0 - ETA: 5s - loss: 0.0195 - acc:  - ETA: 4s - loss: 0.0194 - acc: - ETA: 4s - loss: 0.0192 - ac - ETA: 3s - loss: - ETA: 2s - loss:  - ETA: 1s - loss: 0\n",
      "2020-06-06 07:41:19.764945 End of fit\n",
      "acc: 99.07%\n",
      "2020-06-06 07:41:21.161582 Start of fit\n",
      "Epoch 1/5\n",
      "63002/63002 [==============================] - 24s 376us/sample - loss: 0.1612 - acc: 0.9488ETA: 2s - loss: 0. - ETA: 1s - loss: 0.1657 - acc: 0.9 - ETA: 0s - loss: 0.1646 - acc: 0.9 - ETA: 0s - loss: 0.1641 - \n",
      "Epoch 2/5\n",
      "63002/63002 [==============================] - 24s 376us/sample - loss: 0.0435 - acc: 0.9863 - loss: 0.0452 - acc: - ETA: 8s - loss: 0.0452 - acc - ETA: 8s - loss: 0.0452 - acc: 0.9 - ETA: 7s - loss: 0.04 - ETA: 6s - loss: 0.0447 - acc: 0.986 - ETA: 6s - loss: 0.0447  - ETA: 5s - loss: 0.044 - ETA: 2s - loss: 0.0436 - - ETA: 1s - loss: 0.0435 - - ETA: 0s - loss: 0.0431 - a\n",
      "Epoch 3/5\n",
      "63002/63002 [==============================] - 23s 357us/sample - loss: 0.0310 - acc: 0.9901 - loss: 0.0305 - acc: - ETA: 5s - loss: 0.0 - ETA: 2s - loss: 0.0307 - acc: 0.99 - ETA: 2s - loss - ETA: 0s - loss: 0.0309 - \n",
      "Epoch 4/5\n",
      "63002/63002 [==============================] - 23s 363us/sample - loss: 0.0240 - acc: 0.9926\n",
      "Epoch 5/5\n",
      "63002/63002 [==============================] - 23s 371us/sample - loss: 0.0176 - acc: 0.9947\n",
      "2020-06-06 07:43:17.866947 End of fit\n",
      "acc: 99.14%\n",
      "2020-06-06 07:43:19.378736 Start of fit\n",
      "Epoch 1/5\n",
      "63003/63003 [==============================] - 24s 375us/sample - loss: 0.1657 - acc: 0.9482s - loss: 0.2641 - acc: 0. - E - ETA: 4s - ETA: 2s - loss: 0.1778 - acc:  - ETA: 2s - loss: 0.1760 - acc: 0.94 - ETA: 2s - loss: 0.1753 - a - ETA: 1s - loss: 0. - ETA: 0s - loss: 0.1673 - acc: 0.947 - ETA: 0s - loss: 0.1670 - acc: 0.\n",
      "Epoch 2/5\n",
      "63003/63003 [==============================] - 24s 379us/sample - loss: 0.0449 - acc: 0.9857 - lo - ETA: 7s - loss: 0.0468 - ac - ETA: 6s - loss: 0.0466 - acc: 0.985 - ETA: 6s - l\n",
      "Epoch 3/5\n",
      "63003/63003 [==============================] - 23s 363us/sample - loss: 0.0323 - acc: 0.9902\n",
      "Epoch 4/5\n",
      "63003/63003 [==============================] - 23s 360us/sample - loss: 0.0231 - acc: 0.9928\n",
      "Epoch 5/5\n",
      "63003/63003 [==============================] - 23s 363us/sample - loss: 0.0183 - acc: 0.9940\n",
      "2020-06-06 07:45:16.004686 End of fit\n",
      "acc: 98.89%\n",
      "2020-06-06 07:45:17.397086 Start of fit\n",
      "Epoch 1/5\n",
      "63004/63004 [==============================] - 23s 369us/sample - loss: 0.1684 - acc: 0.9471 - loss: 0.185 - ETA: - ETA: 0s - loss: 0.1700 - acc: \n",
      "Epoch 2/5\n",
      "63004/63004 [==============================] - 23s 371us/sample - loss: 0.0444 - acc: 0.9861 - ETA: 0s - loss: 0.0448 - acc: 0.9 - ETA: 0s - loss: 0.0449 - acc\n",
      "Epoch 3/5\n",
      "63004/63004 [==============================] - 23s 364us/sample - loss: 0.0313 - acc: 0.9902\n",
      "Epoch 4/5\n",
      "63004/63004 [==============================] - 23s 367us/sample - loss: 0.0234 - acc: 0.9925 - loss: 0.0235 - acc: \n",
      "Epoch 5/5\n",
      "63004/63004 [==============================] - 23s 372us/sample - loss: 0.0182 - acc: 0.9941\n",
      "2020-06-06 07:47:14.080158 End of fit\n",
      "acc: 98.84%\n",
      "2020-06-06 07:47:15.525190 Start of fit\n",
      "Epoch 1/5\n",
      "63004/63004 [==============================] - 23s 365us/sample - loss: 0.1596 - acc: 0.9493s - loss: 0.2614 - acc:  - ETA: 12s - \n",
      "Epoch 2/5\n",
      "63004/63004 [==============================] - 23s 365us/sample - loss: 0.0450 - acc: 0.9862 - loss: 0.045 - E - ETA: 0s - loss: 0.0447 - acc: \n",
      "Epoch 3/5\n",
      "63004/63004 [==============================] - 23s 365us/sample - loss: 0.0317 - acc: 0.9903 - loss: 0.0326 - acc: 0.989 - ETA: 8s - loss: 0.0324 - acc: 0.9 - ETA: 8s  - ETA: 6s - loss - ETA: 4s - loss: 0.0314 - acc - ETA: 4s - loss:  - ETA: 2s - loss - ETA: 1s - los\n",
      "Epoch 4/5\n",
      "63004/63004 [==============================] - 23s 360us/sample - loss: 0.0239 - acc: 0.9925s -  - ETA: 8s - loss: 0.0238 - ETA: 7s - loss: 0.0236 - acc: 0.99 - ETA: 7s - - ETA: 3s - loss: 0 -\n",
      "Epoch 5/5\n",
      "63004/63004 [==============================] - 23s 361us/sample - loss: 0.0189 - acc: 0.9944 - los - ETA: 7s - los - ETA: 3s - loss: 0.0187 - acc: 0.99 - ETA: 3s - loss: 0.0192 - - ETA: 0s - loss: 0.0189 - acc\n",
      "2020-06-06 07:49:10.596242 End of fit\n",
      "acc: 99.24%\n",
      "99.06% (+/- 0.13%)\n",
      "2020-06-06 07:49:11.687045 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 0 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 6 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7 7\n",
      " 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 5 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "ndx_errs (array([  33,  115,  195,  241,  247,  300,  318,  320,  321,  341,  358,  381,  444,  445,  464,  479,  495,  542,  551,  565,  582,  583,  628,  646,  659,  691,  707,  740,  791,  839,  844,  877,\n",
      "        881,  924,  938,  939,  947,  951,  957, 1014, 1039, 1062, 1068, 1082, 1089, 1107, 1112, 1192, 1202, 1226, 1242, 1247, 1260, 1289, 1299, 1319, 1325, 1326, 1364, 1394, 1465, 1466, 1500, 1522,\n",
      "       1523, 1530, 1553, 1559, 1681, 1709, 1717, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1823, 1850, 1855, 1865, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2053, 2063, 2082, 2093, 2098, 2109,\n",
      "       2118, 2129, 2130, 2135, 2168, 2177, 2182, 2189, 2197, 2224, 2237, 2293, 2298, 2299, 2325, 2339, 2371, 2387, 2393, 2406, 2422, 2426, 2437, 2454, 2462, 2488, 2533, 2582, 2597, 2607, 2648, 2654,\n",
      "       2730, 2758, 2771, 2810, 2863, 2896, 2901, 2927, 2939, 2952, 2953, 3005, 3060, 3062, 3073, 3117, 3160, 3206, 3225, 3262, 3269, 3333, 3369, 3384, 3405, 3456, 3475, 3503, 3520, 3558, 3559, 3597,\n",
      "       3599, 3629, 3654, 3662, 3702, 3727, 3751, 3757, 3767, 3780, 3796, 3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3976, 4017, 4027, 4056, 4065, 4075, 4078, 4116, 4140, 4163, 4176, 4194, 4199,\n",
      "       4224, 4289, 4306, 4317, 4330, 4341, 4344, 4374, 4435, 4451, 4483, 4497, 4500, 4504, 4521, 4575, 4578, 4635, 4639, 4671, 4690, 4699, 4731, 4737, 4761, 4785, 4807, 4814, 4823, 4837, 4860, 4879,\n",
      "       4886, 4890, 4966, 5068, 5176, 5209, 5586, 5600, 5676, 5678, 5691, 5714, 5734, 5757, 5835, 5841, 5887, 5888, 5891, 5906, 5936, 5937, 5955, 5997, 6011, 6023, 6035, 6059, 6071, 6081, 6091, 6166,\n",
      "       6172, 6173, 6505, 6555, 6569, 6571, 6577, 6597, 6625, 6651, 7121, 7432, 7434, 7492, 7545, 7637, 7797, 7821, 8059, 8094, 8095, 8277, 8279, 8290, 8325, 8408, 8416, 8520, 8527, 9009, 9015, 9024,\n",
      "       9280, 9544, 9613, 9624, 9634, 9642, 9655, 9664, 9686, 9719, 9729, 9741, 9745, 9751, 9768, 9770, 9779, 9808, 9811, 9839, 9879, 9904, 9905, 9944], dtype=int64),)\n",
      "num correct is  9688  an accuracy of  0.9688\n"
     ]
    }
   ],
   "source": [
    "Config.JUST_DO_BASELINE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.JUST_DO_BASELINE=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-06 08:58:49.004025 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7 7\n",
      " 1 0 1 7 8 9 0 1 2 3 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "X_num_images 70000 X_image_num_pixels 784\n",
      "num_extra_rows 0\n",
      "2020-06-06 08:58:49.703194 Start of fit\n",
      "Epoch 1/5\n",
      "62995/62995 [==============================] - 24s 374us/sample - loss: 0.1586 - acc: 0.9511 - loss: 0.1602 - acc: 0\n",
      "Epoch 2/5\n",
      "62995/62995 [==============================] - 23s 369us/sample - loss: 0.0440 - acc: 0.9858\n",
      "Epoch 3/5\n",
      "62995/62995 [==============================] - 24s 382us/sample - loss: 0.0306 - acc: 0.9904\n",
      "Epoch 4/5\n",
      "62995/62995 [==============================] - 25s 389us/sample - loss: 0.0223 - acc: 0.9935\n",
      "Epoch 5/5\n",
      "62995/62995 [==============================] - 24s 382us/sample - loss: 0.0184 - acc: 0.9941\n",
      "2020-06-06 09:00:49.906982 End of fit\n",
      "acc: 99.14%\n",
      "2020-06-06 09:00:51.421512 Start of fit\n",
      "Epoch 1/5\n",
      "62996/62996 [==============================] - 26s 416us/sample - loss: 0.1597 - acc: 0.9499 - l - ETA: 4s - loss: 0.1 - ETA: 1s - loss: 0\n",
      "Epoch 2/5\n",
      "62996/62996 [==============================] - 25s 405us/sample - loss: 0.0446 - acc: 0.9861\n",
      "Epoch 3/5\n",
      "62996/62996 [==============================] - 26s 418us/sample - loss: 0.0306 - acc: 0.9903 - loss: 0 - ETA: 2s - loss: 0.0308 - acc:  - ETA: 2s - loss: 0.0307 - acc: 0.9\n",
      "Epoch 4/5\n",
      "62996/62996 [==============================] - 26s 410us/sample - loss: 0.0237 - acc: 0.9928\n",
      "Epoch 5/5\n",
      "62996/62996 [==============================] - 26s 410us/sample - loss: 0.0183 - acc: 0.9945 - loss: 0.0183 - acc: 0.99 - ETA: 2s - loss:  - ETA: 1s - lo\n",
      "2020-06-06 09:03:01.949640 End of fit\n",
      "acc: 98.46%\n",
      "2020-06-06 09:03:03.460387 Start of fit\n",
      "Epoch 1/5\n",
      "62996/62996 [==============================] - 25s 403us/sample - loss: 0.1650 - acc: 0.9486s - ETA: 5s - loss: 0.1947 - ETA: 4s - loss: 0.1883 - acc:  - ETA: 4s - los\n",
      "Epoch 2/5\n",
      "62996/62996 [==============================] - 24s 387us/sample - loss: 0.0428 - acc: 0.9866 - loss: 0.0434\n",
      "Epoch 3/5\n",
      "62996/62996 [==============================] - 24s 388us/sample - loss: 0.0299 - acc: 0.9907\n",
      "Epoch 4/5\n",
      "62996/62996 [==============================] - 25s 394us/sample - loss: 0.0229 - acc: 0.9931\n",
      "Epoch 5/5\n",
      "62996/62996 [==============================] - 25s 394us/sample - loss: 0.0178 - acc: 0.9943 - loss: 0\n",
      "2020-06-06 09:05:08.133039 End of fit\n",
      "acc: 99.00%\n",
      "2020-06-06 09:05:09.668502 Start of fit\n",
      "Epoch 1/5\n",
      "62999/62999 [==============================] - 25s 400us/sample - loss: 0.1660 - acc: 0.9484 - loss: 0.1691 -\n",
      "Epoch 2/5\n",
      "62999/62999 [==============================] - 26s 406us/sample - loss: 0.0452 - acc: 0.9861 - loss: 0.0450 - acc: 0\n",
      "Epoch 3/5\n",
      "62999/62999 [==============================] - 25s 392us/sample - loss: 0.0306 - acc: 0.9907\n",
      "Epoch 4/5\n",
      "62999/62999 [==============================] - 25s 394us/sample - loss: 0.0228 - acc: 0.9927\n",
      "Epoch 5/5\n",
      "62999/62999 [==============================] - 25s 394us/sample - loss: 0.0182 - acc: 0.9945\n",
      "2020-06-06 09:07:15.538171 End of fit\n",
      "acc: 99.16%\n",
      "2020-06-06 09:07:17.083130 Start of fit\n",
      "Epoch 1/5\n",
      "63000/63000 [==============================] - 25s 399us/sample - loss: 0.1647 - acc: 0.9477\n",
      "Epoch 2/5\n",
      "63000/63000 [==============================] - 25s 397us/sample - loss: 0.0461 - acc: 0.9859 - loss: 0.0464 - acc: 0.985 - ETA: 4s - loss: 0.0464 - ETA: 3s - loss: 0.0470 - acc: 0.9 - ETA: 2s - los - ETA: 1s - \n",
      "Epoch 3/5\n",
      "63000/63000 [==============================] - 25s 391us/sample - loss: 0.0306 - acc: 0.9902 - loss: 0.0307 - \n",
      "Epoch 4/5\n",
      "63000/63000 [==============================] - 25s 400us/sample - loss: 0.0236 - acc: 0.9927\n",
      "Epoch 5/5\n",
      "63000/63000 [==============================] - 26s 412us/sample - loss: 0.0186 - acc: 0.9944 - loss:  - ETA:  - ETA: 4s - l\n",
      "2020-06-06 09:09:23.835048 End of fit\n",
      "acc: 98.86%\n",
      "2020-06-06 09:09:25.461630 Start of fit\n",
      "Epoch 1/5\n",
      "63001/63001 [==============================] - 25s 398us/sample - loss: 0.1829 - acc: 0.9430 - loss: 0.1981 - acc: 0.  - ETA: 0s - loss: 0.1842 - acc: 0\n",
      "Epoch 2/5\n",
      "63001/63001 [==============================] - 25s 394us/sample - loss: 0.0468 - acc: 0.9854s -  - ETA: 16 - ETA: 15s - loss: 0. - - ETA: 14s - loss: 0.0483 - acc: 0.98 - ETA: 14s - loss: 0.04 - ETA: 13s - loss: 0.0485 - ETA - ETA: 6s - loss: 0.0477 - - ETA: 6s - loss: \n",
      "Epoch 3/5\n",
      "63001/63001 [==============================] - 25s 393us/sample - loss: 0.0317 - acc: 0.9902 - loss: 0 - ETA: 7s - loss: 0.0323 - acc: 0.9 - ETA: 7s - loss: 0. - ETA: 4\n",
      "Epoch 4/5\n",
      "63001/63001 [==============================] - 25s 395us/sample - loss: 0.0247 - acc: 0.9920s  - ETA: 10s - loss: 0. - ETA\n",
      "Epoch 5/5\n",
      "63001/63001 [==============================] - 24s 388us/sample - loss: 0.0201 - acc: 0.9938 - loss: 0.0193 - acc: 0. - ETA: 4s - loss: 0.0194 -   - ETA: 1s - loss: 0.0200 -  - ETA: 1s - loss: 0.0\n",
      "2020-06-06 09:11:30.255785 End of fit\n",
      "acc: 99.06%\n",
      "2020-06-06 09:11:31.967196 Start of fit\n",
      "Epoch 1/5\n",
      "63002/63002 [==============================] - 25s 403us/sample - loss: 0.1809 - acc: 0.9429\n",
      "Epoch 2/5\n",
      "63002/63002 [==============================] - 26s 406us/sample - loss: 0.0469 - acc: 0.9855s - loss: 0.0503 - acc - ETA: 5s - l - ETA: 3s - loss:\n",
      "Epoch 3/5\n",
      "63002/63002 [==============================] - 26s 409us/sample - loss: 0.0320 - acc: 0.9900  - ETA: 0s - loss: 0.0319 -\n",
      "Epoch 4/5\n",
      "63002/63002 [==============================] - 26s 407us/sample - loss: 0.0242 - acc: 0.9922 -\n",
      "Epoch 5/5\n",
      "63002/63002 [==============================] - 25s 394us/sample - loss: 0.0194 - acc: 0.9938s - loss: 0. - ETA - ETA: 18s - loss: 0. - ETA: 16s - loss: 0.0186 - - ETA: 16s - loss: 0.01 - ETA: 15s  - ETA: 4s - loss:  - ETA: 1s - loss\n",
      "2020-06-06 09:13:40.045757 End of fit\n",
      "acc: 99.07%\n",
      "2020-06-06 09:13:41.664712 Start of fit\n",
      "Epoch 1/5\n",
      "63003/63003 [==============================] - 25s 400us/sample - loss: 0.1750 - acc: 0.9443- ETA: 6s - - ETA: 5s -  - ETA: 3s - loss: 0.1912\n",
      "Epoch 2/5\n",
      "63003/63003 [==============================] - 25s 394us/sample - loss: 0.0472 - acc: 0.9847 ETA: 9s - loss: 0.0507  - ETA: 9s - loss - ETA: 2s - loss: 0.0478 - acc: \n",
      "Epoch 3/5\n",
      "63003/63003 [==============================] - 25s 393us/sample - loss: 0.0310 - acc: 0.9903 - loss: 0.0303 - acc: 0. - ETA: 4s - loss: 0.0303 - acc: 0.990 - ETA: 4s - ETA: 2s - loss: 0.0306 - a \n",
      "Epoch 4/5\n",
      "63003/63003 [==============================] - 25s 390us/sample - loss: 0.0226 - acc: 0.9926s  - ETA: 10s - lo - ETA: 9s - loss: 0.0230  - ETA: 4s - loss: 0.0216 - a - ETA: 3s - loss: 0.0216 - acc: 0.9 - ETA:  - ETA: 1s - loss: 0.0222 - acc: - ETA: 1s - loss: 0.0223 -  - ETA: 0s - loss: 0.0227 - acc: 0.992 - ETA: 0s - loss: 0.0226 -\n",
      "Epoch 5/5\n",
      "63003/63003 [==============================] - 24s 385us/sample - loss: 0.0183 - acc: 0.9945: 7s - loss: 0.0178 - acc:  - ETA: 0s - loss: 0.0183 - acc: 0.99 - ETA: 0s - loss: 0.0183 - acc: 0.994\n",
      "2020-06-06 09:15:46.254111 End of fit\n",
      "acc: 99.11%\n",
      "2020-06-06 09:15:47.869612 Start of fit\n",
      "Epoch 1/5\n",
      "63004/63004 [==============================] - 25s 405us/sample - loss: 0.1674 - acc: 0.9473TA: 2s - los - ETA: 1s - l\n",
      "Epoch 2/5\n",
      "63004/63004 [==============================] - 25s 400us/sample - loss: 0.0436 - acc: 0.9866: 5s - loss: 0.0444 -  - ETA: 4s - loss: 0.0446 - acc: 0. - ETA: 4s - loss: 0.0446 - acc: 0.986 - ETA: 4s - loss: 0.0445 - ac - ETA: 4s - loss: 0.0 -  - ETA: 0s - loss: 0.0438 \n",
      "Epoch 3/5\n",
      "63004/63004 [==============================] - 25s 399us/sample - loss: 0.0306 - acc: 0.9905s - loss:  - ETA: 9s - loss - ETA: 8s  - ETA: 6s - loss: 0.0309 - acc - ETA: - E - ETA: 2s - loss: 0.0303 - acc: 0 - ETA: 1s - l - ETA: 0s - loss: 0.0304 - acc: 0.\n",
      "Epoch 4/5\n",
      "63004/63004 [==============================] - 25s 397us/sample - loss: 0.0241 - acc: 0.9924s - loss: 0.0251 - acc: 0.99 - E\n",
      "Epoch 5/5\n",
      "63004/63004 [==============================] - 25s 399us/sample - loss: 0.0181 - acc: 0.9944\n",
      "2020-06-06 09:17:54.838901 End of fit\n",
      "acc: 99.04%\n",
      "2020-06-06 09:17:56.507442 Start of fit\n",
      "Epoch 1/5\n",
      "63004/63004 [==============================] - 25s 395us/sample - loss: 0.1643 - acc: 0.9484 - loss: 0.1852 - acc:  - ETA: 3s - loss: 0.1 - ETA: 2s  - ETA: 0s - loss: 0.\n",
      "Epoch 2/5\n",
      "63004/63004 [==============================] - 25s 395us/sample - loss: 0.0444 - acc: 0.9863 - loss: 0.0 - ETA: 7s - loss: 0.0475 - acc: 0.98 - ETA: 6 - ETA: 4s -  - ETA: 3s - - ETA: 1s - loss: 0.0449 - acc: 0.9 - ETA: 1s - loss: 0.0448 - acc: 0.9 - ETA: 1s - loss: 0.044 - ETA: 0s - loss: 0.0444 - acc:  - ETA: 0s - loss: 0.0444 - acc: 0.98\n",
      "Epoch 3/5\n",
      "63004/63004 [==============================] - 25s 390us/sample - loss: 0.0298 - acc: 0.9907\n",
      "Epoch 4/5\n",
      "63004/63004 [==============================] - 25s 390us/sample - loss: 0.0232 - acc: 0.9928 - ETA: 3s - loss: 0.0227 - acc: 0.992 - ETA: 3s - loss: 0.02 - ETA: 2s - loss: 0.0233 - - ETA: 1s - loss: 0.0235 - a - ETA: 0s - loss: 0.02\n",
      "Epoch 5/5\n",
      "63004/63004 [==============================] - 25s 393us/sample - loss: 0.0190 - acc: 0.9937s - loss: 0.0165 - ETA: 20s - loss: 0.0173 - ETA: 19s - loss: 0.0169 - a - E - - ETA: 10s - loss: 0. - ETA: 9s - loss: 0.0187 - ETA: 9s - loss: 0.0190 -  - ETA: 3s - loss: 0.0191 - ac - ETA: 3s - loss: 0.0190 - acc:  - ETA: 2s - loss: 0. - ETA: 1s -\n",
      "2020-06-06 09:20:01.245061 End of fit\n",
      "acc: 99.07%\n",
      "99.00% (+/- 0.20%)\n",
      "2020-06-06 09:20:02.535925 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 0 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 6 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7 7\n",
      " 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 5 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "ndx_errs (array([  33,  115,  195,  241,  247,  300,  318,  320,  321,  341,  358,  381,  444,  445,  464,  479,  495,  542,  551,  565,  582,  583,  628,  646,  659,  691,  707,  740,  791,  839,  844,  877,\n",
      "        881,  924,  938,  939,  947,  951,  957, 1014, 1039, 1062, 1068, 1082, 1089, 1107, 1112, 1192, 1202, 1226, 1242, 1247, 1260, 1289, 1299, 1319, 1325, 1326, 1364, 1394, 1465, 1466, 1500, 1522,\n",
      "       1523, 1530, 1553, 1559, 1681, 1709, 1717, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1823, 1850, 1855, 1865, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2053, 2063, 2082, 2093, 2098, 2109,\n",
      "       2118, 2129, 2130, 2135, 2168, 2177, 2182, 2189, 2197, 2224, 2237, 2293, 2298, 2299, 2325, 2339, 2371, 2387, 2393, 2406, 2422, 2426, 2437, 2454, 2462, 2488, 2533, 2582, 2597, 2607, 2648, 2654,\n",
      "       2730, 2758, 2771, 2810, 2863, 2896, 2901, 2927, 2939, 2952, 2953, 3005, 3060, 3062, 3073, 3117, 3160, 3206, 3225, 3262, 3269, 3333, 3369, 3384, 3405, 3456, 3475, 3503, 3520, 3558, 3559, 3597,\n",
      "       3599, 3629, 3654, 3662, 3702, 3727, 3751, 3757, 3767, 3780, 3796, 3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3976, 4017, 4027, 4056, 4065, 4075, 4078, 4116, 4140, 4163, 4176, 4194, 4199,\n",
      "       4224, 4289, 4306, 4317, 4330, 4341, 4344, 4374, 4435, 4451, 4483, 4497, 4500, 4504, 4521, 4575, 4578, 4635, 4639, 4671, 4690, 4699, 4731, 4737, 4761, 4785, 4807, 4814, 4823, 4837, 4860, 4879,\n",
      "       4886, 4890, 4966, 5068, 5176, 5209, 5586, 5600, 5676, 5678, 5691, 5714, 5734, 5757, 5835, 5841, 5887, 5888, 5891, 5906, 5936, 5937, 5955, 5997, 6011, 6023, 6035, 6059, 6071, 6081, 6091, 6166,\n",
      "       6172, 6173, 6505, 6555, 6569, 6571, 6577, 6597, 6625, 6651, 7121, 7432, 7434, 7492, 7545, 7637, 7797, 7821, 8059, 8094, 8095, 8277, 8279, 8290, 8325, 8408, 8416, 8520, 8527, 9009, 9015, 9024,\n",
      "       9280, 9544, 9613, 9624, 9634, 9642, 9655, 9664, 9686, 9719, 9729, 9741, 9745, 9751, 9768, 9770, 9779, 9808, 9811, 9839, 9879, 9904, 9905, 9944], dtype=int64),)\n",
      "num correct is  9688  an accuracy of  0.9688\n"
     ]
    }
   ],
   "source": [
    "Config.JUST_DO_BASELINE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.JUST_DO_BASELINE=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-06 09:32:29.252506 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7 7\n",
      " 1 0 1 7 8 9 0 1 2 3 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "X_num_images 70000 X_image_num_pixels 784\n",
      "num_extra_rows 0\n",
      "2020-06-06 09:32:29.957462 Start of fit\n",
      "Epoch 1/5\n",
      "62995/62995 [==============================] - 24s 376us/sample - loss: 0.1668 - acc: 0.9485\n",
      "Epoch 2/5\n",
      "62995/62995 [==============================] - 23s 371us/sample - loss: 0.0442 - acc: 0.9865 -\n",
      "Epoch 3/5\n",
      "62995/62995 [==============================] - 24s 382us/sample - loss: 0.0312 - acc: 0.9903TA: 10s - loss: 0.0306 - acc: 0. - ETA: 10s - l - ETA: 2s - loss: 0 - ETA: 0s - loss: 0.031\n",
      "Epoch 4/5\n",
      "62995/62995 [==============================] - 24s 386us/sample - loss: 0.0230 - acc: 0.9927 - loss: 0.0227 - acc: 0.992 - ETA: 2s - l - ETA: 1s - loss\n",
      "Epoch 5/5\n",
      "62995/62995 [==============================] - 24s 385us/sample - loss: 0.0186 - acc: 0.9941s - - ETA: 9s - loss: 0.0172 -  - ETA: 6s - loss: 0.0182  - ETA: 5s - loss: 0.0183 -  -\n",
      "2020-06-06 09:34:30.626460 End of fit\n",
      "acc: 99.17%\n",
      "2020-06-06 09:34:32.339282 Start of fit\n",
      "Epoch 1/5\n",
      "62996/62996 [==============================] - 25s 390us/sample - loss: 0.1596 - acc: 0.9506 - loss: - ETA: 7s - loss: 0.1997 - - ETA: 6s -  - ETA: 4s - loss: 0.1856 - acc: 0 - ETA - ETA: 2s - loss: 0.1708 - - ETA: 1s - loss: 0.1667 - acc:  - ETA: 1s - loss: 0.1650  - ETA: 0s - loss: 0.1622 - acc: - ETA: 0s - loss: 0.1606 - acc: 0\n",
      "Epoch 2/5\n",
      "62996/62996 [==============================] - 24s 386us/sample - loss: 0.0440 - acc: 0.9864\n",
      "Epoch 3/5\n",
      "62996/62996 [==============================] - 24s 386us/sample - loss: 0.0304 - acc: 0.9906s  - - ETA: 13s -  - ETA: 0s - loss: 0.0298 - \n",
      "Epoch 4/5\n",
      "62996/62996 [==============================] - 24s 379us/sample - loss: 0.0231 - acc: 0.9928s -  - ETA: 15s - loss - ETA: 15s - loss: 0.0216 - acc: 0. - ETA: 15s  - ETA: 14s - loss: 0.0209 - acc:  - ETA: 14s - loss: 0.0210 - ETA: 14s - loss: 0.0219 - acc: 0. - ETA - ETA: 11s - loss: 0.0218  - ETA: 4s - loss: 0.0225 - acc: 0.99 - ETA:  - ETA: 2s - loss: 0.0 - ETA: 1s - lo\n",
      "Epoch 5/5\n",
      "62996/62996 [==============================] - 24s 380us/sample - loss: 0.0179 - acc: 0.9945 - loss: 0.0173 - acc: - - ETA:\n",
      "2020-06-06 09:36:34.635808 End of fit\n",
      "acc: 99.07%\n",
      "2020-06-06 09:36:36.339848 Start of fit\n",
      "Epoch 1/5\n",
      "62996/62996 [==============================] - 25s 390us/sample - loss: 0.1688 - acc: 0.9472\n",
      "Epoch 2/5\n",
      "62996/62996 [==============================] - 25s 390us/sample - loss: 0.0469 - acc: 0.9853s - loss: 0.0491 - acc:  - ETA: 0s - loss: 0.0473 - acc: - ETA: 0s - loss: 0.0470 - acc: 0.985\n",
      "Epoch 3/5\n",
      "62996/62996 [==============================] - 25s 399us/sample - loss: 0.0324 - acc: 0.9901s - loss: 0.0322 - acc - ETA: 19s - loss: 0. - ETA: 18s - loss: 0.0332 - acc:  - ETA: 18s - loss: 0.0335 - - ETA: 17s - loss: 0.03 - ETA: 17s - loss: 0.0335 - ETA: 17s - loss: 0.0336 - a - ETA: 16s - loss: 0.03 - - ETA: 9s - loss: 0.0334 - acc: 0.990 - ETA: 9s - loss: 0.0333 - a - ETA: 8s - loss: 0 - ETA:  - ETA: 1s - loss: 0.0325 - acc:  - ETA: 0s - loss: 0.0325\n",
      "Epoch 4/5\n",
      "62996/62996 [==============================] - 25s 399us/sample - loss: 0.0237 - acc: 0.9931: 17s - loss: 0.0244 - ETA: 16s -  - - ET - ETA: 3s - loss\n",
      "Epoch 5/5\n",
      "62996/62996 [==============================] - 25s 392us/sample - loss: 0.0188 - acc: 0.9942 - loss: 0.0189 - acc: 0.994 - ETA: 7s - loss: 0.0189 - acc: 0.994 - ETA: 7s - loss: 0.0189 - acc: 0.99 - ETA: 6s -  - ETA: 5s - loss: 0.018\n",
      "2020-06-06 09:38:41.592318 End of fit\n",
      "acc: 99.06%\n",
      "2020-06-06 09:38:43.373785 Start of fit\n",
      "Epoch 1/5\n",
      "62999/62999 [==============================] - 26s 417us/sample - loss: 0.1587 - acc: 0.9507- ETA: 1s - loss: 0 - ETA: 0s - loss: 0.1591 - acc: 0.95\n",
      "Epoch 2/5\n",
      "62999/62999 [==============================] - 25s 394us/sample - loss: 0.0442 - acc: 0.98701s - loss: 0.0440 - acc:  - ETA: 0s - loss: 0.0442 \n",
      "Epoch 3/5\n",
      "62999/62999 [==============================] - 25s 393us/sample - loss: 0.0312 - acc: 0.9899s - - ETA: 1s - loss:  - ETA: 0s - loss: 0.0313 - acc: 0\n",
      "Epoch 4/5\n",
      "62999/62999 [==============================] - 24s 389us/sample - loss: 0.0228 - acc: 0.9927 - loss: 0.0223 - - ETA: 4s - loss - ET - ETA: 0s - loss: 0.0228\n",
      "Epoch 5/5\n",
      "62999/62999 [==============================] - 24s 388us/sample - loss: 0.0196 - acc: 0.9939 - loss: 0.019 - ETA: 0s - loss: 0.0196 - acc: 0\n",
      "2020-06-06 09:40:49.343229 End of fit\n",
      "acc: 99.19%\n",
      "2020-06-06 09:40:51.092958 Start of fit\n",
      "Epoch 1/5\n",
      "63000/63000 [==============================] - 25s 391us/sample - loss: 0.1711 - acc: 0.9460 - loss: 0.2107 - acc: 0.9 - ETA: 6s - loss: 0.2089 - acc: 0.93 - ETA: 6s - - ETA: 4s - loss: 0.1957 - acc: - ETA: 1s - loss: 0.1 - ETA: 0s - loss: 0.1734 - acc:\n",
      "Epoch 2/5\n",
      "63000/63000 [==============================] - 24s 381us/sample - loss: 0.0440 - acc: 0.9858 - loss: 0.0442 - acc: 0.\n",
      "Epoch 3/5\n",
      "63000/63000 [==============================] - 24s 379us/sample - loss: 0.0300 - acc: 0.9903 - loss: 0.0298 - a - ETA: 4s - - ETA: 3s -  - ETA: 1s \n",
      "Epoch 4/5\n",
      "63000/63000 [==============================] - 24s 382us/sample - loss: 0.0226 - acc: 0.9928\n",
      "Epoch 5/5\n",
      "63000/63000 [==============================] - 24s 386us/sample - loss: 0.0179 - acc: 0.9942 - loss: 0.0183  - ETA - ETA: 5s - loss: 0.0182 - - ETA: - ETA: 0s - loss: 0.0181 - ac\n",
      "2020-06-06 09:42:53.225778 End of fit\n",
      "acc: 99.10%\n",
      "2020-06-06 09:42:54.977337 Start of fit\n",
      "Epoch 1/5\n",
      "63001/63001 [==============================] - 24s 385us/sample - loss: 0.1648 - acc: 0.9484 - loss: 0.1679 \n",
      "Epoch 2/5\n",
      "63001/63001 [==============================] - 24s 379us/sample - loss: 0.0455 - acc: 0.9858s - loss: 0.0479 - acc: 0.98 - ETA: 11s - lo - ETA: 10s - lo\n",
      "Epoch 3/5\n",
      "63001/63001 [==============================] - 24s 383us/sample - loss: 0.0316 - acc: 0.9901s - loss: 0.0300 - - ETA: 14s - loss: 0. - ETA: 13s - loss: 0.0300 - acc: 0.99 - E - ETA: 12s - loss: 0.0292 - a - ETA: 1 - ETA: 2s - loss: 0.0315 - acc: 0. \n",
      "Epoch 4/5\n",
      "63001/63001 [==============================] - 24s 382us/sample - loss: 0.0240 - acc: 0.9925s - ETA: 2s - loss: 0.0236 - acc: 0.9\n",
      "Epoch 5/5\n",
      "63001/63001 [==============================] - 24s 380us/sample - loss: 0.0200 - acc: 0.9939 - loss: 0.0201\n",
      "2020-06-06 09:44:56.493116 End of fit\n",
      "acc: 99.10%\n",
      "2020-06-06 09:44:58.285804 Start of fit\n",
      "Epoch 1/5\n",
      "63002/63002 [==============================] - 24s 385us/sample - loss: 0.1719 - acc: 0.9456 - loss: 0.2000 - acc: 0.936 - ETA: 5s - loss: 0.1996 - acc - ETA: 4s - loss: 0.1966 -  - ETA: 3s - loss: 0.1924 - acc: 0. - ETA - ETA: 1s - \n",
      "Epoch 2/5\n",
      "63002/63002 [==============================] - 24s 378us/sample - loss: 0.0462 - acc: 0.9854 - loss: 0.0471 - ac - ETA: 2s - loss: 0.0468 - a - ETA: 1s - loss: 0 - ETA: 0s - loss: 0.0464\n",
      "Epoch 3/5\n",
      "63002/63002 [==============================] - 25s 393us/sample - loss: 0.0322 - acc: 0.9902\n",
      "Epoch 4/5\n",
      "63002/63002 [==============================] - 24s 381us/sample - loss: 0.0244 - acc: 0.9922 - loss: 0.0243 - acc: 0.992 - ETA: 0s - loss: 0.0\n",
      "Epoch 5/5\n",
      "63002/63002 [==============================] - 25s 394us/sample - loss: 0.0190 - acc: 0.9940 - loss: 0.0177 - ETA: 7s -  - ETA: 6s - loss: 0.0186 -  - ETA: 5s - - ETA: 2s - loss: 0. - ETA: 1s - loss: 0.\n",
      "2020-06-06 09:47:01.171548 End of fit\n",
      "acc: 99.16%\n",
      "2020-06-06 09:47:03.001310 Start of fit\n",
      "Epoch 1/5\n",
      "63003/63003 [==============================] - ETA: 0s - loss: 0.1731 - acc: 0.9456- ETA: 6s - loss: 0.2123 - acc:  - - ETA:  - 25s 403us/sample - loss: 0.1729 - acc: 0.9457\n",
      "Epoch 2/5\n",
      "63003/63003 [==============================] - 25s 401us/sample - loss: 0.0457 - acc: 0.9854\n",
      "Epoch 3/5\n",
      "63003/63003 [==============================] - 25s 399us/sample - loss: 0.0314 - acc: 0.9902\n",
      "Epoch 4/5\n",
      "63003/63003 [==============================] - 24s 378us/sample - loss: 0.0239 - acc: 0.9923\n",
      "Epoch 5/5\n",
      "63003/63003 [==============================] - 24s 382us/sample - loss: 0.0190 - acc: 0.9943\n",
      "2020-06-06 09:49:08.018459 End of fit\n",
      "acc: 98.79%\n",
      "2020-06-06 09:49:09.997873 Start of fit\n",
      "Epoch 1/5\n",
      "63004/63004 [==============================] - 24s 383us/sample - loss: 0.1673 - acc: 0.9480\n",
      "Epoch 2/5\n",
      "63004/63004 [==============================] - 24s 379us/sample - loss: 0.0446 - acc: 0.9862 - lo\n",
      "Epoch 3/5\n",
      "63004/63004 [==============================] - 24s 379us/sample - loss: 0.0302 - acc: 0.9907 - lo\n",
      "Epoch 4/5\n",
      "63004/63004 [==============================] - 24s 381us/sample - loss: 0.0233 - acc: 0.9928\n",
      "Epoch 5/5\n",
      "63004/63004 [==============================] - 24s 380us/sample - loss: 0.0174 - acc: 0.9944 - - ETA: 3s - loss: 0.0172\n",
      "2020-06-06 09:51:11.159504 End of fit\n",
      "acc: 98.96%\n",
      "2020-06-06 09:51:12.981260 Start of fit\n",
      "Epoch 1/5\n",
      "63004/63004 [==============================] - 24s 380us/sample - loss: 0.1645 - acc: 0.9492\n",
      "Epoch 2/5\n",
      "63004/63004 [==============================] - 23s 371us/sample - loss: 0.0457 - acc: 0.9857\n",
      "Epoch 3/5\n",
      "63004/63004 [==============================] - 23s 371us/sample - loss: 0.0319 - acc: 0.9899 -  - ETA:\n",
      "Epoch 4/5\n",
      "63004/63004 [==============================] - 24s 380us/sample - loss: 0.0241 - acc: 0.9928\n",
      "Epoch 5/5\n",
      "63004/63004 [==============================] - 23s 372us/sample - loss: 0.0191 - acc: 0.9942\n",
      "2020-06-06 09:53:12.365814 End of fit\n",
      "acc: 99.23%\n",
      "99.08% (+/- 0.12%)\n",
      "2020-06-06 09:53:13.842586 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 0 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 6 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7 7\n",
      " 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 5 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "ndx_errs (array([  33,  115,  195,  241,  247,  300,  318,  320,  321,  341,  358,  381,  444,  445,  464,  479,  495,  542,  551,  565,  582,  583,  628,  646,  659,  691,  707,  740,  791,  839,  844,  877,\n",
      "        881,  924,  938,  939,  947,  951,  957, 1014, 1039, 1062, 1068, 1082, 1089, 1107, 1112, 1192, 1202, 1226, 1242, 1247, 1260, 1289, 1299, 1319, 1325, 1326, 1364, 1394, 1465, 1466, 1500, 1522,\n",
      "       1523, 1530, 1553, 1559, 1681, 1709, 1717, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1823, 1850, 1855, 1865, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2053, 2063, 2082, 2093, 2098, 2109,\n",
      "       2118, 2129, 2130, 2135, 2168, 2177, 2182, 2189, 2197, 2224, 2237, 2293, 2298, 2299, 2325, 2339, 2371, 2387, 2393, 2406, 2422, 2426, 2437, 2454, 2462, 2488, 2533, 2582, 2597, 2607, 2648, 2654,\n",
      "       2730, 2758, 2771, 2810, 2863, 2896, 2901, 2927, 2939, 2952, 2953, 3005, 3060, 3062, 3073, 3117, 3160, 3206, 3225, 3262, 3269, 3333, 3369, 3384, 3405, 3456, 3475, 3503, 3520, 3558, 3559, 3597,\n",
      "       3599, 3629, 3654, 3662, 3702, 3727, 3751, 3757, 3767, 3780, 3796, 3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3976, 4017, 4027, 4056, 4065, 4075, 4078, 4116, 4140, 4163, 4176, 4194, 4199,\n",
      "       4224, 4289, 4306, 4317, 4330, 4341, 4344, 4374, 4435, 4451, 4483, 4497, 4500, 4504, 4521, 4575, 4578, 4635, 4639, 4671, 4690, 4699, 4731, 4737, 4761, 4785, 4807, 4814, 4823, 4837, 4860, 4879,\n",
      "       4886, 4890, 4966, 5068, 5176, 5209, 5586, 5600, 5676, 5678, 5691, 5714, 5734, 5757, 5835, 5841, 5887, 5888, 5891, 5906, 5936, 5937, 5955, 5997, 6011, 6023, 6035, 6059, 6071, 6081, 6091, 6166,\n",
      "       6172, 6173, 6505, 6555, 6569, 6571, 6577, 6597, 6625, 6651, 7121, 7432, 7434, 7492, 7545, 7637, 7797, 7821, 8059, 8094, 8095, 8277, 8279, 8290, 8325, 8408, 8416, 8520, 8527, 9009, 9015, 9024,\n",
      "       9280, 9544, 9613, 9624, 9634, 9642, 9655, 9664, 9686, 9719, 9729, 9741, 9745, 9751, 9768, 9770, 9779, 9808, 9811, 9839, 9879, 9904, 9905, 9944], dtype=int64),)\n",
      "num correct is  9688  an accuracy of  0.9688\n"
     ]
    }
   ],
   "source": [
    "Config.JUST_DO_BASELINE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.JUST_DO_BASELINE=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-06 10:05:41.664250 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7 7\n",
      " 1 0 1 7 8 9 0 1 2 3 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "X_num_images 70000 X_image_num_pixels 784\n",
      "num_extra_rows 0\n",
      "2020-06-06 10:05:42.396844 Start of fit\n",
      "Epoch 1/5\n",
      "62995/62995 [==============================] - 24s 388us/sample - loss: 0.1689 - acc: 0.9476\n",
      "Epoch 2/5\n",
      "62995/62995 [==============================] - 24s 380us/sample - loss: 0.0458 - acc: 0.9858\n",
      "Epoch 3/5\n",
      "62995/62995 [==============================] - 24s 387us/sample - loss: 0.0313 - acc: 0.9903 - loss: 0.0313 - acc: 0.9 - ETA - ETA: 5s - loss: 0.0309 -  - ETA: 4s - loss: 0.0314 - ETA: 3s - l\n",
      "Epoch 4/5\n",
      "62995/62995 [==============================] - 25s 390us/sample - loss: 0.0236 - acc: 0.9922 - loss: 0.  - ETA: 0s - loss: 0.0238 - \n",
      "Epoch 5/5\n",
      "62995/62995 [==============================] - 25s 393us/sample - loss: 0.0194 - acc: 0.9940 - loss:  - ETA: 1s - loss: 0.0196 -  - ETA: 0s - loss: 0.0196 - ac\n",
      "2020-06-06 10:07:45.902762 End of fit\n",
      "acc: 99.04%\n",
      "2020-06-06 10:07:47.788836 Start of fit\n",
      "Epoch 1/5\n",
      "62996/62996 [==============================] - 25s 398us/sample - loss: 0.1711 - acc: 0.9464s - loss: 0.24 - ETA: 9s - loss - ETA: 8s - loss: 0.2257 - acc: 0. - ETA: 8s - loss: 0.2234 - acc: 0 - ETA: 8 - ETA: 1s - \n",
      "Epoch 2/5\n",
      "62996/62996 [==============================] - 25s 393us/sample - loss: 0.0449 - acc: 0.9857 - loss: 0.0 - ETA: 0s - loss: 0.0448 \n",
      "Epoch 3/5\n",
      "62996/62996 [==============================] - 25s 397us/sample - loss: 0.0311 - acc: 0.9902 - loss: 0 - ETA: 1s - loss: 0.0312 - acc: - ETA: 1s - los - ETA: 0s - loss: 0.0311 - acc: 0.990\n",
      "Epoch 4/5\n",
      "62996/62996 [==============================] - 26s 407us/sample - loss: 0.0234 - acc: 0.9928 - ETA: 12s - ETA: 6\n",
      "Epoch 5/5\n",
      "62996/62996 [==============================] - 25s 401us/sample - loss: 0.0184 - acc: 0.9947\n",
      "2020-06-06 10:09:55.012911 End of fit\n",
      "acc: 98.96%\n",
      "2020-06-06 10:09:56.937337 Start of fit\n",
      "Epoch 1/5\n",
      "62996/62996 [==============================] - 25s 401us/sample - loss: 0.1665 - acc: 0.9487\n",
      "Epoch 2/5\n",
      "62996/62996 [==============================] - 25s 397us/sample - loss: 0.0429 - acc: 0.9867\n",
      "Epoch 3/5\n",
      "62996/62996 [==============================] - 24s 389us/sample - loss: 0.0303 - acc: 0.9905\n",
      "Epoch 4/5\n",
      "62996/62996 [==============================] - 24s 389us/sample - loss: 0.0225 - acc: 0.9930\n",
      "Epoch 5/5\n",
      "62996/62996 [==============================] - 25s 391us/sample - loss: 0.0173 - acc: 0.9948\n",
      "2020-06-06 10:12:02.245865 End of fit\n",
      "acc: 99.00%\n",
      "2020-06-06 10:12:04.156552 Start of fit\n",
      "Epoch 1/5\n",
      "62999/62999 [==============================] - 25s 396us/sample - loss: 0.1690 - acc: 0.9469 - loss: 0.1707 - acc\n",
      "Epoch 2/5\n",
      "62999/62999 [==============================] - 24s 387us/sample - loss: 0.0468 - acc: 0.9854  - ETA: 1s - los\n",
      "Epoch 3/5\n",
      "62999/62999 [==============================] - 24s 388us/sample - loss: 0.0318 - acc: 0.9903 - loss: 0.0323  - ETA: 6s - l - ET - ETA: 0s - loss: 0.0318\n",
      "Epoch 4/5\n",
      "62999/62999 [==============================] - 25s 392us/sample - loss: 0.0234 - acc: 0.9929 - loss: 0.0236 - ac\n",
      "Epoch 5/5\n",
      "62999/62999 [==============================] - 25s 391us/sample - loss: 0.0193 - acc: 0.9941 - lo\n",
      "2020-06-06 10:14:08.780235 End of fit\n",
      "acc: 99.04%\n",
      "2020-06-06 10:14:10.729973 Start of fit\n",
      "Epoch 1/5\n",
      "63000/63000 [==============================] - 25s 394us/sample - loss: 0.1758 - acc: 0.9441\n",
      "Epoch 2/5\n",
      "63000/63000 [==============================] - ETA: 0s - loss: 0.0462 - acc: 0.9854- ETA: 5 - ETA: 1s - loss: - 25s 399us/sample - loss: 0.0462 - acc: 0.9854\n",
      "Epoch 3/5\n",
      "63000/63000 [==============================] - 25s 393us/sample - loss: 0.0312 - acc: 0.9902s - loss: 0.02 - ETA: \n",
      "Epoch 4/5\n",
      "63000/63000 [==============================] - 24s 388us/sample - loss: 0.0231 - acc: 0.9925 - l - ETA: 2s - loss: 0.0231 - ac - ETA: 2s - loss: 0.0228 - - ETA: 1s \n",
      "Epoch 5/5\n",
      "63000/63000 [==============================] - 24s 387us/sample - loss: 0.0178 - acc: 0.9943\n",
      "2020-06-06 10:16:15.865342 End of fit\n",
      "acc: 98.93%\n",
      "2020-06-06 10:16:17.821518 Start of fit\n",
      "Epoch 1/5\n",
      "63001/63001 [==============================] - 25s 390us/sample - loss: 0.1638 - acc: 0.9480\n",
      "Epoch 2/5\n",
      "63001/63001 [==============================] - 24s 388us/sample - loss: 0.0449 - acc: 0.9860 - loss: 0.0451 - acc: 0.985 - ETA: 0s - loss: 0.0450 - acc: 0.98\n",
      "Epoch 3/5\n",
      "63001/63001 [==============================] - 25s 390us/sample - loss: 0.0315 - acc: 0.9904\n",
      "Epoch 4/5\n",
      "63001/63001 [==============================] - 25s 389us/sample - loss: 0.0235 - acc: 0.9930 - loss: 0.0235 - acc:\n",
      "Epoch 5/5\n",
      "63001/63001 [==============================] - 25s 392us/sample - loss: 0.0192 - acc: 0.9942 - loss: 0.\n",
      "2020-06-06 10:18:22.248039 End of fit\n",
      "acc: 99.04%\n",
      "2020-06-06 10:18:24.229589 Start of fit\n",
      "Epoch 1/5\n",
      "63002/63002 [==============================] - 25s 393us/sample - loss: 0.1673 - acc: 0.9471\n",
      "Epoch 2/5\n",
      "63002/63002 [==============================] - 25s 391us/sample - loss: 0.0448 - acc: 0.9863\n",
      "Epoch 3/5\n",
      "63002/63002 [==============================] - 25s 390us/sample - loss: 0.0319 - acc: 0.9899 - loss: 0.0319 - acc: 0.990\n",
      "Epoch 4/5\n",
      "63002/63002 [==============================] - 24s 386us/sample - loss: 0.0236 - acc: 0.9927 - los\n",
      "Epoch 5/5\n",
      "63002/63002 [==============================] - 25s 396us/sample - loss: 0.0191 - acc: 0.9942 - loss: 0.0192 - acc: 0.99 - ETA: 1s - lo\n",
      "2020-06-06 10:20:29.268307 End of fit\n",
      "acc: 98.81%\n",
      "2020-06-06 10:20:31.251436 Start of fit\n",
      "Epoch 1/5\n",
      "63003/63003 [==============================] - 25s 401us/sample - loss: 0.1682 - acc: 0.9484 - loss: 0.1763 - acc: 0.94 - ETA: 1s - lo\n",
      "Epoch 2/5\n",
      "63003/63003 [==============================] - 25s 402us/sample - loss: 0.0453 - acc: 0.9860 - l\n",
      "Epoch 3/5\n",
      "63003/63003 [==============================] - 25s 393us/sample - loss: 0.0307 - acc: 0.9900\n",
      "Epoch 4/5\n",
      "63003/63003 [==============================] - 25s 394us/sample - loss: 0.0229 - acc: 0.9929\n",
      "Epoch 5/5\n",
      "63003/63003 [==============================] - 25s 392us/sample - loss: 0.0187 - acc: 0.9941 -  - ETA: 0s - loss: 0.0187 - acc: 0.994 - ETA: 0s - loss: 0.0187 - acc:\n",
      "2020-06-06 10:22:37.768997 End of fit\n",
      "acc: 99.06%\n",
      "2020-06-06 10:22:39.795377 Start of fit\n",
      "Epoch 1/5\n",
      "63004/63004 [==============================] - 25s 396us/sample - loss: 0.1636 - acc: 0.9483\n",
      "Epoch 2/5\n",
      "63004/63004 [==============================] - 26s 409us/sample - loss: 0.0434 - acc: 0.9862\n",
      "Epoch 3/5\n",
      "63004/63004 [==============================] - 26s 407us/sample - loss: 0.0299 - acc: 0.9905 - loss: 0.0300 \n",
      "Epoch 4/5\n",
      "63004/63004 [==============================] - 25s 396us/sample - loss: 0.0230 - acc: 0.9928: 9s - loss: 0.0 - ETA: 8s - - ETA: 7s  - ET - ETA: 0s - loss: 0.023\n",
      "Epoch 5/5\n",
      "63004/63004 [==============================] - 25s 393us/sample - loss: 0.0180 - acc: 0.9944\n",
      "2020-06-06 10:24:47.557212 End of fit\n",
      "acc: 98.56%\n",
      "2020-06-06 10:24:49.605128 Start of fit\n",
      "Epoch 1/5\n",
      "63004/63004 [==============================] - 25s 400us/sample - loss: 0.1674 - acc: 0.9480 - loss: 0.1692 - acc\n",
      "Epoch 2/5\n",
      "63004/63004 [==============================] - 25s 394us/sample - loss: 0.0473 - acc: 0.9853\n",
      "Epoch 3/5\n",
      "63004/63004 [==============================] - 25s 393us/sample - loss: 0.0325 - acc: 0.9902 - loss: 0.0\n",
      "Epoch 4/5\n",
      "63004/63004 [==============================] - 25s 390us/sample - loss: 0.0250 - acc: 0.9922\n",
      "Epoch 5/5\n",
      "63004/63004 [==============================] - 25s 391us/sample - loss: 0.0203 - acc: 0.9938 - lo\n",
      "2020-06-06 10:26:55.322750 End of fit\n",
      "acc: 99.13%\n",
      "98.96% (+/- 0.16%)\n",
      "2020-06-06 10:26:57.171184 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 0 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 6 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7 7\n",
      " 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 5 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "ndx_errs (array([  33,  115,  195,  241,  247,  300,  318,  320,  321,  341,  358,  381,  444,  445,  464,  479,  495,  542,  551,  565,  582,  583,  628,  646,  659,  691,  707,  740,  791,  839,  844,  877,\n",
      "        881,  924,  938,  939,  947,  951,  957, 1014, 1039, 1062, 1068, 1082, 1089, 1107, 1112, 1192, 1202, 1226, 1242, 1247, 1260, 1289, 1299, 1319, 1325, 1326, 1364, 1394, 1465, 1466, 1500, 1522,\n",
      "       1523, 1530, 1553, 1559, 1681, 1709, 1717, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1823, 1850, 1855, 1865, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2053, 2063, 2082, 2093, 2098, 2109,\n",
      "       2118, 2129, 2130, 2135, 2168, 2177, 2182, 2189, 2197, 2224, 2237, 2293, 2298, 2299, 2325, 2339, 2371, 2387, 2393, 2406, 2422, 2426, 2437, 2454, 2462, 2488, 2533, 2582, 2597, 2607, 2648, 2654,\n",
      "       2730, 2758, 2771, 2810, 2863, 2896, 2901, 2927, 2939, 2952, 2953, 3005, 3060, 3062, 3073, 3117, 3160, 3206, 3225, 3262, 3269, 3333, 3369, 3384, 3405, 3456, 3475, 3503, 3520, 3558, 3559, 3597,\n",
      "       3599, 3629, 3654, 3662, 3702, 3727, 3751, 3757, 3767, 3780, 3796, 3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3976, 4017, 4027, 4056, 4065, 4075, 4078, 4116, 4140, 4163, 4176, 4194, 4199,\n",
      "       4224, 4289, 4306, 4317, 4330, 4341, 4344, 4374, 4435, 4451, 4483, 4497, 4500, 4504, 4521, 4575, 4578, 4635, 4639, 4671, 4690, 4699, 4731, 4737, 4761, 4785, 4807, 4814, 4823, 4837, 4860, 4879,\n",
      "       4886, 4890, 4966, 5068, 5176, 5209, 5586, 5600, 5676, 5678, 5691, 5714, 5734, 5757, 5835, 5841, 5887, 5888, 5891, 5906, 5936, 5937, 5955, 5997, 6011, 6023, 6035, 6059, 6071, 6081, 6091, 6166,\n",
      "       6172, 6173, 6505, 6555, 6569, 6571, 6577, 6597, 6625, 6651, 7121, 7432, 7434, 7492, 7545, 7637, 7797, 7821, 8059, 8094, 8095, 8277, 8279, 8290, 8325, 8408, 8416, 8520, 8527, 9009, 9015, 9024,\n",
      "       9280, 9544, 9613, 9624, 9634, 9642, 9655, 9664, 9686, 9719, 9729, 9741, 9745, 9751, 9768, 9770, 9779, 9808, 9811, 9839, 9879, 9904, 9905, 9944], dtype=int64),)\n",
      "num correct is  9688  an accuracy of  0.9688\n"
     ]
    }
   ],
   "source": [
    "Config.JUST_DO_BASELINE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.JUST_DO_BASELINE=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-06 14:42:44.645986 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 9 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 9 8 7 2 3 0 4 4 2 4 1 9 5 7 7 2 8 2 6 8 5 7 7 9 1 8 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 9 2 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 8 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 2 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 3 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 6 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 3 8 8 2 7 5 8 9 6 1 8 4 1 2 5 9 1 9 7 5 4 0 8 9 9 1 0 5 2 3 7\n",
      " 8 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 8 4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 2 1 7 0 6 5 4 3 8 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 2 3 1 9 7 5 1 0 8 4 6 2 6 7 9 3 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 5 8 0 3 7 2 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 7 8 3 3 6 7 2 8 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 8 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5 4 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 5\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 8 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 8 8 8 7 4 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 2 3 2 3 9 1 7 4 0 3 5 5 8 6 3 2 6 7 6 6 3 2 7 8 1 1 7 5 6 4 9 5 1 3 3 4 7 8 9 1 1 6 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "X_num_images 7000 X_image_num_pixels 784\n",
      "num_extra_rows 0\n",
      "2020-06-06 14:42:45.102296 Start of fit\n",
      "Epoch 1/5\n",
      "6296/6296 [==============================] - 3s 503us/sample - loss: 0.6520 - acc: 0.7940\n",
      "Epoch 2/5\n",
      "6296/6296 [==============================] - 2s 397us/sample - loss: 0.2046 - acc: 0.9398\n",
      "Epoch 3/5\n",
      "6296/6296 [==============================] - 2s 395us/sample - loss: 0.1331 - acc: 0.9574\n",
      "Epoch 4/5\n",
      "6296/6296 [==============================] - 3s 412us/sample - loss: 0.0928 - acc: 0.9711s - loss: 0.0907 - acc: \n",
      "Epoch 5/5\n",
      "6296/6296 [==============================] - 3s 401us/sample - loss: 0.0670 - acc: 0.9790\n",
      "2020-06-06 14:43:00.138856 End of fit\n",
      "acc: 97.44%\n",
      "2020-06-06 14:43:01.079336 Start of fit\n",
      "Epoch 1/5\n",
      "6297/6297 [==============================] - 3s 485us/sample - loss: 0.6940 - acc: 0.7835\n",
      "Epoch 2/5\n",
      "6297/6297 [==============================] - 3s 402us/sample - loss: 0.2042 - acc: 0.9365\n",
      "Epoch 3/5\n",
      "6297/6297 [==============================] - 3s 412us/sample - loss: 0.1235 - acc: 0.9600\n",
      "Epoch 4/5\n",
      "6297/6297 [==============================] - 3s 425us/sample - loss: 0.0932 - acc: 0.9694\n",
      "Epoch 5/5\n",
      "6297/6297 [==============================] - 3s 398us/sample - loss: 0.0687 - acc: 0.9787\n",
      "2020-06-06 14:43:16.257555 End of fit\n",
      "acc: 98.01%\n",
      "2020-06-06 14:43:17.211279 Start of fit\n",
      "Epoch 1/5\n",
      "6297/6297 [==============================] - 3s 479us/sample - loss: 0.6730 - acc: 0.7810\n",
      "Epoch 2/5\n",
      "6297/6297 [==============================] - 3s 405us/sample - loss: 0.1994 - acc: 0.9412\n",
      "Epoch 3/5\n",
      "6297/6297 [==============================] - 3s 410us/sample - loss: 0.1262 - acc: 0.9606s - loss: 0 - ETA: 0s - loss: 0.1270 - acc: \n",
      "Epoch 4/5\n",
      "6297/6297 [==============================] - 3s 425us/sample - loss: 0.0845 - acc: 0.9741\n",
      "Epoch 5/5\n",
      "6297/6297 [==============================] - 3s 416us/sample - loss: 0.0622 - acc: 0.9795\n",
      "2020-06-06 14:43:32.540761 End of fit\n",
      "acc: 95.87%\n",
      "2020-06-06 14:43:33.504794 Start of fit\n",
      "Epoch 1/5\n",
      "6298/6298 [==============================] - 3s 480us/sample - loss: 0.6815 - acc: 0.7864s - \n",
      "Epoch 2/5\n",
      "6298/6298 [==============================] - 3s 413us/sample - loss: 0.2061 - acc: 0.9374\n",
      "Epoch 3/5\n",
      "6298/6298 [==============================] - 3s 419us/sample - loss: 0.1262 - acc: 0.9605\n",
      "Epoch 4/5\n",
      "6298/6298 [==============================] - 3s 418us/sample - loss: 0.0865 - acc: 0.9727s \n",
      "Epoch 5/5\n",
      "6298/6298 [==============================] - 3s 437us/sample - loss: 0.0675 - acc: 0.9789\n",
      "2020-06-06 14:43:49.047995 End of fit\n",
      "acc: 97.15%\n",
      "2020-06-06 14:43:50.051827 Start of fit\n",
      "Epoch 1/5\n",
      "6298/6298 [==============================] - 3s 481us/sample - loss: 0.7378 - acc: 0.7702\n",
      "Epoch 2/5\n",
      "6298/6298 [==============================] - 3s 408us/sample - loss: 0.2044 - acc: 0.9398s - loss: 0.2118 -\n",
      "Epoch 3/5\n",
      "6298/6298 [==============================] - 3s 421us/sample - loss: 0.1320 - acc: 0.9597\n",
      "Epoch 4/5\n",
      "6298/6298 [==============================] - 3s 402us/sample - loss: 0.0951 - acc: 0.9692\n",
      "Epoch 5/5\n",
      "6298/6298 [==============================] - 2s 393us/sample - loss: 0.0663 - acc: 0.9794s - loss: 0.0668 - acc: 0.979\n",
      "2020-06-06 14:44:05.239050 End of fit\n",
      "acc: 93.87%\n",
      "2020-06-06 14:44:06.236107 Start of fit\n",
      "Epoch 1/5\n",
      "6301/6301 [==============================] - 3s 481us/sample - loss: 0.6767 - acc: 0.7850s -\n",
      "Epoch 2/5\n",
      "6301/6301 [==============================] - 2s 394us/sample - loss: 0.2003 - acc: 0.9389\n",
      "Epoch 3/5\n",
      "6301/6301 [==============================] - 3s 407us/sample - loss: 0.1201 - acc: 0.9627\n",
      "Epoch 4/5\n",
      "6301/6301 [==============================] - 3s 418us/sample - loss: 0.0863 - acc: 0.9737\n",
      "Epoch 5/5\n",
      "6301/6301 [==============================] - 2s 395us/sample - loss: 0.0671 - acc: 0.9789\n",
      "2020-06-06 14:44:21.385901 End of fit\n",
      "acc: 96.28%\n",
      "2020-06-06 14:44:22.423756 Start of fit\n",
      "Epoch 1/5\n",
      "6301/6301 [==============================] - 3s 476us/sample - loss: 0.7090 - acc: 0.7788\n",
      "Epoch 2/5\n",
      "6301/6301 [==============================] - 3s 400us/sample - loss: 0.2171 - acc: 0.9345s - loss: 0.2204 - acc: 0.\n",
      "Epoch 3/5\n",
      "6301/6301 [==============================] - 3s 405us/sample - loss: 0.1321 - acc: 0.9584s - loss: 0.1356 - acc: 0.9\n",
      "Epoch 4/5\n",
      "6301/6301 [==============================] - 2s 390us/sample - loss: 0.0956 - acc: 0.9710\n",
      "Epoch 5/5\n",
      "6301/6301 [==============================] - 2s 391us/sample - loss: 0.0684 - acc: 0.9795s - l\n",
      "2020-06-06 14:44:37.399886 End of fit\n",
      "acc: 96.85%\n",
      "2020-06-06 14:44:38.672951 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 3s 493us/sample - loss: 0.6902 - acc: 0.7855\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 3s 401us/sample - loss: 0.2167 - acc: 0.9342\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 3s 416us/sample - loss: 0.1396 - acc: 0.9589\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 3s 406us/sample - loss: 0.1005 - acc: 0.9661s - loss: 0.1049  - ETA: 1s - loss: 0.\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 440us/sample - loss: 0.0781 - acc: 0.9762\n",
      "2020-06-06 14:44:54.269269 End of fit\n",
      "acc: 97.99%\n",
      "2020-06-06 14:44:55.334136 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 3s 504us/sample - loss: 0.7209 - acc: 0.7751\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 3s 427us/sample - loss: 0.2116 - acc: 0.9358\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 3s 424us/sample - loss: 0.1319 - acc: 0.9613\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 3s 441us/sample - loss: 0.0928 - acc: 0.9713\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 419us/sample - loss: 0.0710 - acc: 0.9794\n",
      "2020-06-06 14:45:11.410038 End of fit\n",
      "acc: 95.55%\n",
      "2020-06-06 14:45:12.489859 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 3s 526us/sample - loss: 0.7419 - acc: 0.7692s - loss: \n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 3s 438us/sample - loss: 0.2030 - acc: 0.9361\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 3s 425us/sample - loss: 0.1279 - acc: 0.9589s - loss: 0.1299 -\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 3s 458us/sample - loss: 0.0883 - acc: 0.9734s - loss: 0.0\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 432us/sample - loss: 0.0630 - acc: 0.9799\n",
      "2020-06-06 14:45:28.960949 End of fit\n",
      "acc: 97.13%\n",
      "96.61% (+/- 1.20%)\n",
      "2020-06-06 14:45:29.920582 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 9 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 1 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 3 9 7 9 6 2 7 8 4 7 3 6 1 3 6 4 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 1 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 1 9 9 5 5 1 5 6 0 3 1 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 1 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 1 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 8 8 7 2 6 0 6 4 2 9 1 9 5 7 7 2 6 2 6 8 5 7 7 4 1 0 1 3 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 9 2 9 2 0 4 0\n",
      " 0 2 8 1 7 1 7 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 7 7 9 3 6 4 6 0 7 1 1 2 1 5 3 3 9 7 5 6 5 4 1 3 8 1 0 5 1 9 1 5 5 6 1 8 5 1 4 9 4 6 7 2 5 0 6 8 6 3 7 2 0 8 8 5 4 1 1 4 0 7 3 7 6 1 6 2 1 4 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 5 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 0 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 7 8 8 2 7 5 8 9 6 1 8 4 1 2 5 8 1 9 7 5 4 0 8 9 9 1 0 5 8 3 7\n",
      " 0 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 7 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 1 9 4 0 0 8 3 2 7 1 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 9 8 3 3 9 3 3 3 7 8 0 2 7 1 7 0 6 5 4 3 3 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 1 3 1 9 7 5 1 0 8 4 6 2 6 7 9 9 2 9 8 2 2 9 1 7 3 5 9 1 8 0 2 0 5 6 1 3 7 6 7 1 2 0 8 0 3 7 7 4 0 9 1 8 6 7 1 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 1 8 3 3 6 9 2 4 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 9 4 8 5 5 4 0 5 2 1 6 8 4 5 0 4 0 6 1 5 3 2 6 7 2 6 9 3 1 4 6 2 5 9 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 3 3 1 4 5 6 8 9 4 1 9\n",
      " 3 8 0 6 2 1 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 4 1 7 9 6 1 1 2 4 0 1 7 7 4 3 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 6 2 2 5 6 0 8 2 9 2 8 8 8 8 7 9 4 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 7 3 0 3 9 1 1 4 0 3 5 5 6 6 5 0 6 7 6 6 3 2 7 9 1 1 7 4 6 4 9 5 1 5 3 4 7 8 9 1 1 0 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "ndx_errs (array([ 24,  43,  77,  80,  92, 111, 115, 149, 159, 175, 195, 241, 245, 247, 250, 257, 264, 266, 268, 290, 300, 303, 320, 321, 324, 326, 338, 341, 349, 358, 362, 367, 381, 389, 403, 445, 464, 479,\n",
      "       492, 495, 511, 542, 543, 547, 551, 571, 582, 583, 591, 613, 628, 635, 646, 654, 659, 667, 684, 689, 691, 707, 714, 717, 726, 740, 781, 791, 795, 797, 830, 839, 844, 866, 881, 882, 924, 926,\n",
      "       930, 936, 938, 939, 947, 951, 957, 965], dtype=int64),)\n",
      "num correct is  916  an accuracy of  0.916\n"
     ]
    }
   ],
   "source": [
    "Config.JUST_DO_BASELINE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=6_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=1_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.JUST_DO_BASELINE=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-06 14:45:37.909202 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 9 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 9 8 7 2 3 0 4 4 2 4 1 9 5 7 7 2 8 2 6 8 5 7 7 9 1 8 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 9 2 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 8 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 2 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 3 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 6 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 3 8 8 2 7 5 8 9 6 1 8 4 1 2 5 9 1 9 7 5 4 0 8 9 9 1 0 5 2 3 7\n",
      " 8 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 8 4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 2 1 7 0 6 5 4 3 8 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 2 3 1 9 7 5 1 0 8 4 6 2 6 7 9 3 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 5 8 0 3 7 2 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 7 8 3 3 6 7 2 8 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 8 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5 4 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 5\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 8 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 8 8 8 7 4 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 2 3 2 3 9 1 7 4 0 3 5 5 8 6 3 2 6 7 6 6 3 2 7 8 1 1 7 5 6 4 9 5 1 3 3 4 7 8 9 1 1 6 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "X_num_images 7000 X_image_num_pixels 784\n",
      "num_extra_rows 0\n",
      "2020-06-06 14:45:38.382188 Start of fit\n",
      "Epoch 1/5\n",
      "6296/6296 [==============================] - 3s 494us/sample - loss: 0.6742 - acc: 0.7894\n",
      "Epoch 2/5\n",
      "6296/6296 [==============================] - 3s 407us/sample - loss: 0.2061 - acc: 0.9354s - loss: 0.2319 - - ETA: 0s - loss: 0.2114 - a\n",
      "Epoch 3/5\n",
      "6296/6296 [==============================] - 3s 409us/sample - loss: 0.1245 - acc: 0.9617\n",
      "Epoch 4/5\n",
      "6296/6296 [==============================] - 3s 426us/sample - loss: 0.0873 - acc: 0.9719s - loss: 0.1333 - acc: 0 - \n",
      "Epoch 5/5\n",
      "6296/6296 [==============================] - 3s 404us/sample - loss: 0.0660 - acc: 0.9798\n",
      "2020-06-06 14:45:54.122583 End of fit\n",
      "acc: 97.30%\n",
      "2020-06-06 14:45:55.240936 Start of fit\n",
      "Epoch 1/5\n",
      "6297/6297 [==============================] - 3s 498us/sample - loss: 0.7457 - acc: 0.7681\n",
      "Epoch 2/5\n",
      "6297/6297 [==============================] - 3s 443us/sample - loss: 0.2194 - acc: 0.9314\n",
      "Epoch 3/5\n",
      "6297/6297 [==============================] - 3s 438us/sample - loss: 0.1409 - acc: 0.9560\n",
      "Epoch 4/5\n",
      "6297/6297 [==============================] - 3s 448us/sample - loss: 0.0944 - acc: 0.9725\n",
      "Epoch 5/5\n",
      "6297/6297 [==============================] - 3s 423us/sample - loss: 0.0678 - acc: 0.9800s - loss: 0.0676 - \n",
      "2020-06-06 14:46:11.724566 End of fit\n",
      "acc: 94.88%\n",
      "2020-06-06 14:46:12.846106 Start of fit\n",
      "Epoch 1/5\n",
      "6297/6297 [==============================] - 3s 501us/sample - loss: 0.6971 - acc: 0.7834s - loss: 2.1520 - acc:  - ETA:\n",
      "Epoch 2/5\n",
      "6297/6297 [==============================] - 3s 416us/sample - loss: 0.2050 - acc: 0.9373s - loss: 0.2210\n",
      "Epoch 3/5\n",
      "6297/6297 [==============================] - 3s 402us/sample - loss: 0.1334 - acc: 0.9605\n",
      "Epoch 4/5\n",
      "6297/6297 [==============================] - 3s 406us/sample - loss: 0.0919 - acc: 0.9709\n",
      "Epoch 5/5\n",
      "6297/6297 [==============================] - 3s 416us/sample - loss: 0.0697 - acc: 0.9784\n",
      "2020-06-06 14:46:28.564602 End of fit\n",
      "acc: 97.16%\n",
      "2020-06-06 14:46:29.699347 Start of fit\n",
      "Epoch 1/5\n",
      "6298/6298 [==============================] - 3s 505us/sample - loss: 0.6982 - acc: 0.7812s - loss: 0.9652 - ETA: 0s - loss: 0.7621 - acc:\n",
      "Epoch 2/5\n",
      "6298/6298 [==============================] - 3s 438us/sample - loss: 0.2202 - acc: 0.9317\n",
      "Epoch 3/5\n",
      "6298/6298 [==============================] - 3s 398us/sample - loss: 0.1315 - acc: 0.9586s - loss: 0.1429 - acc: 0.95 - ETA: 1s - l\n",
      "Epoch 4/5\n",
      "6298/6298 [==============================] - 3s 402us/sample - loss: 0.0972 - acc: 0.9698\n",
      "Epoch 5/5\n",
      "6298/6298 [==============================] - 3s 404us/sample - loss: 0.0750 - acc: 0.9776\n",
      "2020-06-06 14:46:45.489932 End of fit\n",
      "acc: 96.01%\n",
      "2020-06-06 14:46:46.647585 Start of fit\n",
      "Epoch 1/5\n",
      "6298/6298 [==============================] - 3s 515us/sample - loss: 0.7218 - acc: 0.7755\n",
      "Epoch 2/5\n",
      "6298/6298 [==============================] - 3s 412us/sample - loss: 0.2060 - acc: 0.9365\n",
      "Epoch 3/5\n",
      "6298/6298 [==============================] - 3s 435us/sample - loss: 0.1228 - acc: 0.9617\n",
      "Epoch 4/5\n",
      "6298/6298 [==============================] - 3s 433us/sample - loss: 0.0903 - acc: 0.9695\n",
      "Epoch 5/5\n",
      "6298/6298 [==============================] - 3s 421us/sample - loss: 0.0626 - acc: 0.9811\n",
      "2020-06-06 14:47:02.944576 End of fit\n",
      "acc: 96.87%\n",
      "2020-06-06 14:47:04.113437 Start of fit\n",
      "Epoch 1/5\n",
      "6301/6301 [==============================] - 3s 505us/sample - loss: 0.7305 - acc: 0.7780\n",
      "Epoch 2/5\n",
      "6301/6301 [==============================] - 3s 416us/sample - loss: 0.2125 - acc: 0.9368\n",
      "Epoch 3/5\n",
      "6301/6301 [==============================] - 3s 419us/sample - loss: 0.1269 - acc: 0.9591s - loss: 0.1375 -\n",
      "Epoch 4/5\n",
      "6301/6301 [==============================] - 3s 409us/sample - loss: 0.0902 - acc: 0.9697s - loss: 0.091\n",
      "Epoch 5/5\n",
      "6301/6301 [==============================] - 3s 403us/sample - loss: 0.0738 - acc: 0.9752\n",
      "2020-06-06 14:47:19.995681 End of fit\n",
      "acc: 96.71%\n",
      "2020-06-06 14:47:21.184742 Start of fit\n",
      "Epoch 1/5\n",
      "6301/6301 [==============================] - 3s 524us/sample - loss: 0.6744 - acc: 0.7851\n",
      "Epoch 2/5\n",
      "6301/6301 [==============================] - 3s 456us/sample - loss: 0.2017 - acc: 0.9375\n",
      "Epoch 3/5\n",
      "6301/6301 [==============================] - 3s 416us/sample - loss: 0.1250 - acc: 0.9602\n",
      "Epoch 4/5\n",
      "6301/6301 [==============================] - 3s 410us/sample - loss: 0.0885 - acc: 0.9710\n",
      "Epoch 5/5\n",
      "6301/6301 [==============================] - 3s 427us/sample - loss: 0.0698 - acc: 0.9765s - los - ETA: 1s - loss: 0\n",
      "2020-06-06 14:47:37.628338 End of fit\n",
      "acc: 94.99%\n",
      "2020-06-06 14:47:38.832703 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 3s 514us/sample - loss: 0.7664 - acc: 0.7578\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 3s 422us/sample - loss: 0.2239 - acc: 0.9323\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 3s 434us/sample - loss: 0.1348 - acc: 0.9573\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 3s 423us/sample - loss: 0.0916 - acc: 0.9727\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 457us/sample - loss: 0.0706 - acc: 0.9778\n",
      "2020-06-06 14:47:55.419880 End of fit\n",
      "acc: 96.84%\n",
      "2020-06-06 14:47:56.633912 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 3s 533us/sample - loss: 0.6977 - acc: 0.7820\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 3s 428us/sample - loss: 0.2010 - acc: 0.9359\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 3s 431us/sample - loss: 0.1212 - acc: 0.9624\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 3s 413us/sample - loss: 0.0846 - acc: 0.9738\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 444us/sample - loss: 0.0610 - acc: 0.9802\n",
      "2020-06-06 14:48:13.248987 End of fit\n",
      "acc: 95.55%\n",
      "2020-06-06 14:48:14.477316 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 3s 517us/sample - loss: 0.7176 - acc: 0.7771s - loss: 0.902\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 3s 429us/sample - loss: 0.2169 - acc: 0.9345\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 3s 427us/sample - loss: 0.1389 - acc: 0.9554\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 3s 424us/sample - loss: 0.0940 - acc: 0.9705\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 412us/sample - loss: 0.0664 - acc: 0.9787\n",
      "2020-06-06 14:48:31.183934 End of fit\n",
      "acc: 95.69%\n",
      "96.20% (+/- 0.85%)\n",
      "2020-06-06 14:48:32.284472 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 9 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 1 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 3 9 7 9 6 2 7 8 4 7 3 6 1 3 6 4 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 1 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 1 9 9 5 5 1 5 6 0 3 1 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 1 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 1 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 8 8 7 2 6 0 6 4 2 9 1 9 5 7 7 2 6 2 6 8 5 7 7 4 1 0 1 3 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 9 2 9 2 0 4 0\n",
      " 0 2 8 1 7 1 7 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 7 7 9 3 6 4 6 0 7 1 1 2 1 5 3 3 9 7 5 6 5 4 1 3 8 1 0 5 1 9 1 5 5 6 1 8 5 1 4 9 4 6 7 2 5 0 6 8 6 3 7 2 0 8 8 5 4 1 1 4 0 7 3 7 6 1 6 2 1 4 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 5 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 0 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 7 8 8 2 7 5 8 9 6 1 8 4 1 2 5 8 1 9 7 5 4 0 8 9 9 1 0 5 8 3 7\n",
      " 0 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 7 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 1 9 4 0 0 8 3 2 7 1 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 9 8 3 3 9 3 3 3 7 8 0 2 7 1 7 0 6 5 4 3 3 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 1 3 1 9 7 5 1 0 8 4 6 2 6 7 9 9 2 9 8 2 2 9 1 7 3 5 9 1 8 0 2 0 5 6 1 3 7 6 7 1 2 0 8 0 3 7 7 4 0 9 1 8 6 7 1 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 1 8 3 3 6 9 2 4 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 9 4 8 5 5 4 0 5 2 1 6 8 4 5 0 4 0 6 1 5 3 2 6 7 2 6 9 3 1 4 6 2 5 9 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 3 3 1 4 5 6 8 9 4 1 9\n",
      " 3 8 0 6 2 1 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 4 1 7 9 6 1 1 2 4 0 1 7 7 4 3 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 6 2 2 5 6 0 8 2 9 2 8 8 8 8 7 9 4 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 7 3 0 3 9 1 1 4 0 3 5 5 6 6 5 0 6 7 6 6 3 2 7 9 1 1 7 4 6 4 9 5 1 5 3 4 7 8 9 1 1 0 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "ndx_errs (array([ 24,  43,  77,  80,  92, 111, 115, 149, 159, 175, 195, 241, 245, 247, 250, 257, 264, 266, 268, 290, 300, 303, 320, 321, 324, 326, 338, 341, 349, 358, 362, 367, 381, 389, 403, 445, 464, 479,\n",
      "       492, 495, 511, 542, 543, 547, 551, 571, 582, 583, 591, 613, 628, 635, 646, 654, 659, 667, 684, 689, 691, 707, 714, 717, 726, 740, 781, 791, 795, 797, 830, 839, 844, 866, 881, 882, 924, 926,\n",
      "       930, 936, 938, 939, 947, 951, 957, 965], dtype=int64),)\n",
      "num correct is  916  an accuracy of  0.916\n"
     ]
    }
   ],
   "source": [
    "Config.JUST_DO_BASELINE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=6_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=1_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.JUST_DO_BASELINE=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat the largest improvement for kNN small set of images\n",
    "\n",
    "## overlapping quadrants by 1/8; all with weighted centroids\n",
    "\n",
    "## The initial run was\n",
    "- kNN acc overlap 1/8 (6,000 94.1%; 60,000 )\n",
    "\n",
    "## The baseline average for small set of images using kNN is\n",
    "- kNN acc overlap 1/8 (6,000 91.6%; 60,000 )\n",
    "\n",
    "## Error reduction is (2.5/8.4)=29.76%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-06 15:05:14.730571 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 9 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 9 8 7 2 3 0 4 4 2 4 1 9 5 7 7 2 8 2 6 8 5 7 7 9 1 8 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 9 2 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 8 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 2 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 3 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 6 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 3 8 8 2 7 5 8 9 6 1 8 4 1 2 5 9 1 9 7 5 4 0 8 9 9 1 0 5 2 3 7\n",
      " 8 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 8 4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 2 1 7 0 6 5 4 3 8 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 2 3 1 9 7 5 1 0 8 4 6 2 6 7 9 3 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 5 8 0 3 7 2 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 7 8 3 3 6 7 2 8 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 8 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5 4 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 5\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 8 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 8 8 8 7 4 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 2 3 2 3 9 1 7 4 0 3 5 5 8 6 3 2 6 7 6 6 3 2 7 8 1 1 7 5 6 4 9 5 1 3 3 4 7 8 9 1 1 6 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "<class 'numpy.ndarray'> (0, 128)\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "fill_up_last_row.shape (7000, 12)\n",
      "X_num_images 7000 X_image_num_pixels 912\n",
      "num_extra_rows 5\n",
      "2020-06-06 15:07:18.147304 Start of fit\n",
      "Epoch 1/5\n",
      "6296/6296 [==============================] - 4s 567us/sample - loss: 0.8194 - acc: 0.7397\n",
      "Epoch 2/5\n",
      "6296/6296 [==============================] - 3s 483us/sample - loss: 0.2925 - acc: 0.9039\n",
      "Epoch 3/5\n",
      "6296/6296 [==============================] - 3s 519us/sample - loss: 0.1965 - acc: 0.9371s - l\n",
      "Epoch 4/5\n",
      "6296/6296 [==============================] - 3s 509us/sample - loss: 0.1478 - acc: 0.9512\n",
      "Epoch 5/5\n",
      "6296/6296 [==============================] - 3s 495us/sample - loss: 0.1200 - acc: 0.9625\n",
      "2020-06-06 15:07:36.893586 End of fit\n",
      "acc: 96.31%\n",
      "2020-06-06 15:07:38.266520 Start of fit\n",
      "Epoch 1/5\n",
      "6297/6297 [==============================] - 4s 585us/sample - loss: 0.8359 - acc: 0.7299s - los\n",
      "Epoch 2/5\n",
      "6297/6297 [==============================] - 3s 495us/sample - loss: 0.2897 - acc: 0.9085\n",
      "Epoch 3/5\n",
      "6297/6297 [==============================] - 3s 520us/sample - loss: 0.1947 - acc: 0.9387\n",
      "Epoch 4/5\n",
      "6297/6297 [==============================] - 3s 485us/sample - loss: 0.1490 - acc: 0.9527\n",
      "Epoch 5/5\n",
      "6297/6297 [==============================] - 3s 529us/sample - loss: 0.1134 - acc: 0.9643\n",
      "2020-06-06 15:07:57.305752 End of fit\n",
      "acc: 95.59%\n",
      "2020-06-06 15:07:58.684992 Start of fit\n",
      "Epoch 1/5\n",
      "6297/6297 [==============================] - 4s 599us/sample - loss: 0.8173 - acc: 0.7294\n",
      "Epoch 2/5\n",
      "6297/6297 [==============================] - 3s 496us/sample - loss: 0.3002 - acc: 0.9063\n",
      "Epoch 3/5\n",
      "6297/6297 [==============================] - 3s 499us/sample - loss: 0.1994 - acc: 0.9366s\n",
      "Epoch 4/5\n",
      "6297/6297 [==============================] - 3s 497us/sample - loss: 0.1495 - acc: 0.9514s - loss: 0.1480 - acc: 0.952\n",
      "Epoch 5/5\n",
      "6297/6297 [==============================] - 3s 507us/sample - loss: 0.1226 - acc: 0.9579\n",
      "2020-06-06 15:08:17.656418 End of fit\n",
      "acc: 92.18%\n",
      "2020-06-06 15:08:19.027884 Start of fit\n",
      "Epoch 1/5\n",
      "6298/6298 [==============================] - 4s 588us/sample - loss: 0.8553 - acc: 0.7253\n",
      "Epoch 2/5\n",
      "6298/6298 [==============================] - 3s 502us/sample - loss: 0.2984 - acc: 0.9077\n",
      "Epoch 3/5\n",
      "6298/6298 [==============================] - 3s 507us/sample - loss: 0.1999 - acc: 0.9373s - lo - ETA: 0s - loss: 0.1962\n",
      "Epoch 4/5\n",
      "6298/6298 [==============================] - 3s 488us/sample - loss: 0.1498 - acc: 0.9533s - loss: 0.1441 - \n",
      "Epoch 5/5\n",
      "6298/6298 [==============================] - 3s 489us/sample - loss: 0.1157 - acc: 0.9628s - loss: \n",
      "2020-06-06 15:08:37.872493 End of fit\n",
      "acc: 94.44%\n",
      "2020-06-06 15:08:39.237962 Start of fit\n",
      "Epoch 1/5\n",
      "6298/6298 [==============================] - 4s 594us/sample - loss: 0.8249 - acc: 0.7263\n",
      "Epoch 2/5\n",
      "6298/6298 [==============================] - 3s 496us/sample - loss: 0.3015 - acc: 0.9004\n",
      "Epoch 3/5\n",
      "6298/6298 [==============================] - 3s 534us/sample - loss: 0.2057 - acc: 0.9339s - loss: 0.2109 - acc - ETA: 2s - loss: 0.2287 - acc: 0 - ETA: 2s - loss: 0.2280 -  - ETA: 1s - los\n",
      "Epoch 4/5\n",
      "6298/6298 [==============================] - 3s 517us/sample - loss: 0.1596 - acc: 0.9476\n",
      "Epoch 5/5\n",
      "6298/6298 [==============================] - 3s 508us/sample - loss: 0.1200 - acc: 0.9600s - loss: 0.1207 -  - ETA: 0s - loss: 0.1231 - acc: - ETA: 0s - loss: 0.1200 - acc: 0.\n",
      "2020-06-06 15:08:58.587845 End of fit\n",
      "acc: 94.02%\n",
      "2020-06-06 15:08:59.981448 Start of fit\n",
      "Epoch 1/5\n",
      "6301/6301 [==============================] - 4s 617us/sample - loss: 0.8598 - acc: 0.7223\n",
      "Epoch 2/5\n",
      "6301/6301 [==============================] - 3s 507us/sample - loss: 0.2990 - acc: 0.9053 - ETA: 1s - loss: 0.\n",
      "Epoch 3/5\n",
      "6301/6301 [==============================] - 3s 522us/sample - loss: 0.2018 - acc: 0.9349\n",
      "Epoch 4/5\n",
      "6301/6301 [==============================] - 3s 511us/sample - loss: 0.1491 - acc: 0.9521s - loss: 0.1622 - acc - ETA: 1s - loss: 0.1575 - ac - ETA: 1s - loss: 0.1549 - acc - ETA: 0s - loss: 0.1493 - a\n",
      "Epoch 5/5\n",
      "6301/6301 [==============================] - 3s 548us/sample - loss: 0.1194 - acc: 0.9637s - loss: 0.1243 - acc:  - ETA: 1s - loss: 0.\n",
      "2020-06-06 15:09:19.792760 End of fit\n",
      "acc: 95.57%\n",
      "2020-06-06 15:09:21.192020 Start of fit\n",
      "Epoch 1/5\n",
      "6301/6301 [==============================] - 4s 619us/sample - loss: 0.7983 - acc: 0.7392s - loss: 0.9611 - - ETA: 0s - loss: 0.8174 - acc: 0.\n",
      "Epoch 2/5\n",
      "6301/6301 [==============================] - 3s 525us/sample - loss: 0.2821 - acc: 0.9122s -  - ETA: 1s - loss: 0 - ETA: 0s - loss: 0.2898 - acc: 0.\n",
      "Epoch 3/5\n",
      "6301/6301 [==============================] - 4s 557us/sample - loss: 0.1962 - acc: 0.9392s - loss: 0.2\n",
      "Epoch 4/5\n",
      "6301/6301 [==============================] - 3s 521us/sample - loss: 0.1487 - acc: 0.9530\n",
      "Epoch 5/5\n",
      "6301/6301 [==============================] - 3s 547us/sample - loss: 0.1215 - acc: 0.9578\n",
      "2020-06-06 15:09:41.370198 End of fit\n",
      "acc: 94.56%\n",
      "2020-06-06 15:09:42.795021 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 4s 626us/sample - loss: 0.8846 - acc: 0.7088s - loss: 1. - ETA: 0s - loss: 0.9588 - acc:\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 3s 520us/sample - loss: 0.3009 - acc: 0.9047s\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 4s 562us/sample - loss: 0.2009 - acc: 0.9361\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 4s 601us/sample - loss: 0.1441 - acc: 0.9534s - loss: 0.1469 - a - ETA: 2s - loss: 0.1535 - acc: 0.95 - ETA: 1s - loss: 0.1522 - acc: 0.95 - ETA: 1s - loss: 0.1532 - acc: 0.9 - ETA: 1s - los\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 530us/sample - loss: 0.1113 - acc: 0.9630s - loss: 0.1158 - ac\n",
      "2020-06-06 15:10:03.528603 End of fit\n",
      "acc: 95.26%\n",
      "2020-06-06 15:10:04.981386 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 4s 612us/sample - loss: 0.8089 - acc: 0.7321\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 3s 527us/sample - loss: 0.2845 - acc: 0.9096s - loss: 0.29\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 3s 497us/sample - loss: 0.1929 - acc: 0.9381s - lo\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 3s 519us/sample - loss: 0.1481 - acc: 0.9508s - loss: 0.1520 -  - ETA: 0s - loss: 0.1496 -\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 524us/sample - loss: 0.1236 - acc: 0.9605\n",
      "2020-06-06 15:10:24.727156 End of fit\n",
      "acc: 94.11%\n",
      "2020-06-06 15:10:26.188275 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 4s 599us/sample - loss: 0.8237 - acc: 0.7267s - loss: 1.\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 3s 499us/sample - loss: 0.2920 - acc: 0.9064\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 3s 498us/sample - loss: 0.1973 - acc: 0.9362\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 3s 497us/sample - loss: 0.1517 - acc: 0.9523\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 3s 510us/sample - loss: 0.1135 - acc: 0.9646\n",
      "2020-06-06 15:10:45.501911 End of fit\n",
      "acc: 94.97%\n",
      "94.70% (+/- 1.09%)\n",
      "2020-06-06 15:10:46.798743 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 8 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 9 9 8 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 9 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 3 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 5 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 8 8 7 2 6 0 6 4 2 9 1 9 5 7 7 2 8 2 6 8 5 7 7 9 1 0 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 0 5 7 7 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 5 6 5 6 1 3 8 1 0 5 1 3 1 5 0 6 1 8 5 1 4 9 4 6 7 2 5 0 6 5 6 3 7 2 0 8 8 5 9 1 1 4 0 7 3 7 6 1 6 2 1 7 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 8 0 6 4 8 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 7 8 8 2 7 5 8 9 6 1 8 4 1 2 6 3 1 9 7 5 4 0 8 9 9 1 0 5 2 3 7\n",
      " 0 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 9 4 6 4 2 1 8 2 5 4 8 3 4 0 0 2 3 2 7 4 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 9 8 3 3 9 3 3 3 7 8 0 8 7 1 7 0 6 5 4 3 3 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 9 8 6 0 2 4 0 2 2 3 1 9 7 5 1 0 8 4 6 2 6 7 9 9 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 0 8 0 3 7 8 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 9 8 3 3 6 7 2 4 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 3 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 3 5 9 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 9 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 5\n",
      " 3 8 0 1 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 0 1 7 7 4 2 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 6 2 2 5 6 0 8 2 9 2 8 8 8 8 7 9 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 7 3 0 3 9 1 7 4 0 3 5 5 8 6 3 0 6 7 6 6 3 2 7 9 1 1 7 4 6 4 9 6 1 3 0 4 7 8 9 1 1 0 9 1 4 4 5 4 0 6 2 2 8 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "ndx_errs (array([115, 119, 149, 151, 169, 187, 217, 241, 245, 247, 250, 266, 318, 320, 321, 338, 352, 358, 362, 376, 381, 389, 444, 445, 448, 464, 478, 479, 495, 532, 543, 551, 571, 583, 591, 605, 628, 654,\n",
      "       659, 684, 691, 714, 738, 740, 760, 795, 839, 844, 866, 881, 924, 926, 939, 947, 951, 955, 958, 965, 976], dtype=int64),)\n",
      "num correct is  941  an accuracy of  0.9410000000000001\n",
      "2020-06-06 15:10:56.114634 end\n"
     ]
    }
   ],
   "source": [
    "Config.OVERLAP_QUADS_RATIO=0.125\n",
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=6_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=1_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "Config.OVERLAP_QUADS_RATIO=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat the largest improvement for kNN large 60,000 set of images\n",
    "\n",
    "## overlapping quadrants by 1/8; all with weighted centroids\n",
    "\n",
    "- kNN acc weighted overlap 1/8 (6,000 ; 60,000 97.12%)\n",
    "\n",
    "## The initial run was\n",
    "- kNN acc weighted overlap 1/8 (6,000 ; 60,000 97.12%)\n",
    "\n",
    "## and the baseline is\n",
    "- kNN acc weighted overlap 1/8 (6,000 ; 60,000 96.88%)\n",
    "\n",
    "## an error reduction of (.24/3.12)=7.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-06 15:13:33.155523 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7 7\n",
      " 1 0 1 7 8 9 0 1 2 3 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "<class 'numpy.ndarray'> (0, 128)\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "****************************** 6000 ******************************\n",
      "****************************** 8000 ******************************\n",
      "****************************** 10000 ******************************\n",
      "****************************** 12000 ******************************\n",
      "****************************** 14000 ******************************\n",
      "****************************** 16000 ******************************\n",
      "****************************** 18000 ******************************\n",
      "****************************** 20000 ******************************\n",
      "****************************** 22000 ******************************\n",
      "****************************** 24000 ******************************\n",
      "****************************** 26000 ******************************\n",
      "****************************** 28000 ******************************\n",
      "****************************** 30000 ******************************\n",
      "****************************** 32000 ******************************\n",
      "****************************** 34000 ******************************\n",
      "****************************** 36000 ******************************\n",
      "****************************** 38000 ******************************\n",
      "****************************** 40000 ******************************\n",
      "****************************** 42000 ******************************\n",
      "****************************** 44000 ******************************\n",
      "****************************** 46000 ******************************\n",
      "****************************** 48000 ******************************\n",
      "****************************** 50000 ******************************\n",
      "****************************** 52000 ******************************\n",
      "****************************** 54000 ******************************\n",
      "****************************** 56000 ******************************\n",
      "****************************** 58000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 912)\n",
      "****************************** 1999 ******************************\n",
      "fill_up_last_row.shape (61999, 12)\n",
      "X_num_images 61999 X_image_num_pixels 912\n",
      "num_extra_rows 5\n",
      "2020-06-06 17:18:49.366125 Start of fit\n",
      "Epoch 1/5\n",
      "55796/55796 [==============================] - 29s 523us/sample - loss: 0.2651 - acc: 0.9150\n",
      "Epoch 2/5\n",
      "55796/55796 [==============================] - 28s 502us/sample - loss: 0.0827 - acc: 0.9741\n",
      "Epoch 3/5\n",
      "55796/55796 [==============================] - 29s 513us/sample - loss: 0.0581 - acc: 0.9820s - loss: 0.0591 - acc: 0. - ETA: 9s - - ETA: 7s -  - ETA: 6s - loss: 0.0590 - ETA: 5s - loss: 0.0589 - acc: 0.9 - ETA: - ETA: 2s - loss: 0.0 - ETA: 1s\n",
      "Epoch 4/5\n",
      "55796/55796 [==============================] - 29s 515us/sample - loss: 0.0439 - acc: 0.9860  - ETA: 0s - loss: 0.0438 -\n",
      "Epoch 5/5\n",
      "55796/55796 [==============================] - 29s 520us/sample - loss: 0.0360 - acc: 0.9884 - loss: 0.0353 - acc: - ETA: 7s - loss: 0.03 - ETA: 5s -  - ETA: 1s - l\n",
      "2020-06-06 17:21:16.678834 End of fit\n",
      "acc: 98.13%\n",
      "2020-06-06 17:21:19.747310 Start of fit\n",
      "Epoch 1/5\n",
      "55796/55796 [==============================] - 30s 530us/sample - loss: 0.2718 - acc: 0.9138\n",
      "Epoch 2/5\n",
      "55796/55796 [==============================] - 29s 528us/sample - loss: 0.0888 - acc: 0.9719 - loss: 0.0889 \n",
      "Epoch 3/5\n",
      "55796/55796 [==============================] - 30s 529us/sample - loss: 0.0623 - acc: 0.9805\n",
      "Epoch 4/5\n",
      "55796/55796 [==============================] - 29s 517us/sample - loss: 0.0481 - acc: 0.9849\n",
      "Epoch 5/5\n",
      "55796/55796 [==============================] - 29s 513us/sample - loss: 0.0384 - acc: 0.9878\n",
      "2020-06-06 17:23:48.761049 End of fit\n",
      "acc: 98.60%\n",
      "2020-06-06 17:23:51.821055 Start of fit\n",
      "Epoch 1/5\n",
      "55796/55796 [==============================] - 30s 531us/sample - loss: 0.2530 - acc: 0.9200\n",
      "Epoch 2/5\n",
      "55796/55796 [==============================] - 29s 514us/sample - loss: 0.0831 - acc: 0.9747\n",
      "Epoch 3/5\n",
      "55796/55796 [==============================] - 29s 518us/sample - loss: 0.0583 - acc: 0.9822 - loss: 0.0593 - acc: 0.98 - ETA: 1s - loss: 0.0591 - acc: 0.98 - ETA: 1s - lo - ETA: 0s - loss: 0.0584 - acc: 0.982\n",
      "Epoch 4/5\n",
      "55796/55796 [==============================] - 29s 518us/sample - loss: 0.0445 - acc: 0.9857 - loss: 0.0447 - \n",
      "Epoch 5/5\n",
      "55796/55796 [==============================] - 29s 521us/sample - loss: 0.0349 - acc: 0.9888 -  - ETA: 0s - loss: 0.0346\n",
      "2020-06-06 17:26:19.931809 End of fit\n",
      "acc: 98.08%\n",
      "2020-06-06 17:26:22.955726 Start of fit\n",
      "Epoch 1/5\n",
      "55798/55798 [==============================] - 28s 507us/sample - loss: 0.2555 - acc: 0.9199\n",
      "Epoch 2/5\n",
      "55798/55798 [==============================] - 28s 508us/sample - loss: 0.0846 - acc: 0.9735 - loss: 0.0864 - acc - ETA: 3s - loss: 0.08 - ETA: 2s - loss: 0.0860 - acc: 0.973 - ETA: 2s - loss: 0.0859 - - ETA: 1s - loss: 0.0856 - acc: 0 - ETA: 0s - loss: 0.085\n",
      "Epoch 3/5\n",
      "55798/55798 [==============================] - 28s 504us/sample - loss: 0.0582 - acc: 0.9821 - loss: 0 - ETA: 8s - - ETA: 1\n",
      "Epoch 4/5\n",
      "55798/55798 [==============================] - 28s 494us/sample - loss: 0.0450 - acc: 0.9863\n",
      "Epoch 5/5\n",
      "55798/55798 [==============================] - 28s 499us/sample - loss: 0.0358 - acc: 0.9888\n",
      "2020-06-06 17:28:46.226962 End of fit\n",
      "acc: 98.40%\n",
      "2020-06-06 17:28:49.287844 Start of fit\n",
      "Epoch 1/5\n",
      "55798/55798 [==============================] - 29s 520us/sample - loss: 0.2611 - acc: 0.9161\n",
      "Epoch 2/5\n",
      "55798/55798 [==============================] - 29s 517us/sample - loss: 0.0869 - acc: 0.9721\n",
      "Epoch 3/5\n",
      "55798/55798 [==============================] - 29s 517us/sample - loss: 0.0596 - acc: 0.9807\n",
      "Epoch 4/5\n",
      "55798/55798 [==============================] - 28s 504us/sample - loss: 0.0453 - acc: 0.9856 - loss: 0.044 - \n",
      "Epoch 5/5\n",
      "55798/55798 [==============================] - 28s 504us/sample - loss: 0.0361 - acc: 0.9885 - loss: 0.0360 - acc: \n",
      "2020-06-06 17:31:15.338288 End of fit\n",
      "acc: 98.39%\n",
      "2020-06-06 17:31:18.440324 Start of fit\n",
      "Epoch 1/5\n",
      "55798/55798 [==============================] - 29s 513us/sample - loss: 0.2557 - acc: 0.9188\n",
      "Epoch 2/5\n",
      "55798/55798 [==============================] - 28s 505us/sample - loss: 0.0849 - acc: 0.9727- ETA: 0s - loss: 0.0855 - \n",
      "Epoch 3/5\n",
      "55798/55798 [==============================] - 28s 501us/sample - loss: 0.0576 - acc: 0.9817 - loss: 0.\n",
      "Epoch 4/5\n",
      "55798/55798 [==============================] - 28s 504us/sample - loss: 0.0438 - acc: 0.9861\n",
      "Epoch 5/5\n",
      "55798/55798 [==============================] - 28s 511us/sample - loss: 0.0329 - acc: 0.9895\n",
      "2020-06-06 17:33:42.939559 End of fit\n",
      "acc: 97.73%\n",
      "2020-06-06 17:33:46.033592 Start of fit\n",
      "Epoch 1/5\n",
      "55800/55800 [==============================] - 29s 518us/sample - loss: 0.2623 - acc: 0.9180\n",
      "Epoch 2/5\n",
      "55800/55800 [==============================] - 28s 509us/sample - loss: 0.0835 - acc: 0.9735\n",
      "Epoch 3/5\n",
      "55800/55800 [==============================] - 28s 507us/sample - loss: 0.0579 - acc: 0.9822 - loss: 0.0578 - acc:  - ETA: 0s - loss: 0.0576 - acc: 0\n",
      "Epoch 4/5\n",
      "55800/55800 [==============================] - 29s 512us/sample - loss: 0.0437 - acc: 0.9859 - los\n",
      "Epoch 5/5\n",
      "55800/55800 [==============================] - 28s 511us/sample - loss: 0.0362 - acc: 0.9890\n",
      "2020-06-06 17:36:13.289255 End of fit\n",
      "acc: 98.39%\n",
      "2020-06-06 17:36:16.407366 Start of fit\n",
      "Epoch 1/5\n",
      "55801/55801 [==============================] - 29s 516us/sample - loss: 0.2707 - acc: 0.9137 - lo\n",
      "Epoch 2/5\n",
      "55801/55801 [==============================] - 28s 502us/sample - loss: 0.0885 - acc: 0.9721- ETA\n",
      "Epoch 3/5\n",
      "55801/55801 [==============================] - 27s 491us/sample - loss: 0.0610 - acc: 0.9808\n",
      "Epoch 4/5\n",
      "55801/55801 [==============================] - 27s 485us/sample - loss: 0.0471 - acc: 0.9854s -\n",
      "Epoch 5/5\n",
      "55801/55801 [==============================] - 27s 489us/sample - loss: 0.0372 - acc: 0.9879 - loss: 0.0374 - acc: 0\n",
      "2020-06-06 17:38:38.200411 End of fit\n",
      "acc: 98.71%\n",
      "2020-06-06 17:38:41.329112 Start of fit\n",
      "Epoch 1/5\n",
      "55803/55803 [==============================] - 29s 517us/sample - loss: 0.2468 - acc: 0.9228\n",
      "Epoch 2/5\n",
      "55803/55803 [==============================] - 28s 499us/sample - loss: 0.0830 - acc: 0.9734\n",
      "Epoch 3/5\n",
      "55803/55803 [==============================] - 28s 499us/sample - loss: 0.0586 - acc: 0.9818\n",
      "Epoch 4/5\n",
      "55803/55803 [==============================] - 28s 495us/sample - loss: 0.0451 - acc: 0.9857\n",
      "Epoch 5/5\n",
      "55803/55803 [==============================] - 27s 491us/sample - loss: 0.0364 - acc: 0.9889\n",
      "2020-06-06 17:41:04.060648 End of fit\n",
      "acc: 98.37%\n",
      "2020-06-06 17:41:07.217036 Start of fit\n",
      "Epoch 1/5\n",
      "55805/55805 [==============================] - 29s 516us/sample - loss: 0.2594 - acc: 0.9186 - loss: 0.27 - ETA: 1s - lo\n",
      "Epoch 2/5\n",
      "55805/55805 [==============================] - 28s 498us/sample - loss: 0.0835 - acc: 0.9736\n",
      "Epoch 3/5\n",
      "55805/55805 [==============================] - 28s 502us/sample - loss: 0.0568 - acc: 0.9820\n",
      "Epoch 4/5\n",
      "55805/55805 [==============================] - 27s 493us/sample - loss: 0.0445 - acc: 0.9862\n",
      "Epoch 5/5\n",
      "55805/55805 [==============================] - 28s 503us/sample - loss: 0.0354 - acc: 0.9887\n",
      "2020-06-06 17:43:30.618156 End of fit\n",
      "acc: 98.42%\n",
      "98.32% (+/- 0.26%)\n",
      "2020-06-06 17:43:33.312319 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 4 8 9 6 9 6 8 3 6 6 8 5 1 4 2 4 4 5 1 1 9 0 2 4 9 5 7 1 8 3 5 6 9 8 7 1 1 6 7 6 3 2 2 0 8 9\n",
      " 2 5 1 0 8 1 4 5 7 9 6 9 0 6 1 5 5 8 3 8 2 6 5 0 7 4 6 1 3 4 7 3 2 3 4 2 5 2 7 1 7 2 6 4 1 5 7 8 6 0 1 8 2 5 7 7 6 9 3 5 2 4 2 4 0 8 8 3 4 9 2 7 5 8 6 3 6 0 8 6 7 3 6 4 9 4 6 6 3 0 4 1 0 1 4 6 2 9 1\n",
      " 1 0 6 3 9]\n",
      "ndx_errs (array([ 151,  241,  247,  320,  321,  338,  340,  362,  376,  381,  444,  445,  448,  464,  478,  479,  495,  519,  571,  578,  582,  628,  659,  689,  691,  716,  740,  791,  810,  839,  844,  938,\n",
      "        939,  947,  951,  957, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1192, 1212, 1226, 1228, 1232, 1242, 1247, 1270, 1289, 1299, 1319, 1326, 1328, 1331, 1364, 1393, 1414, 1466,\n",
      "       1500, 1522, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1878, 1901, 1955, 1970, 1984], dtype=int64),)\n",
      "num correct is  1910  an accuracy of  0.9554777388694348\n",
      "****************************** 3999 ******************************\n",
      "fill_up_last_row.shape (63999, 12)\n",
      "X_num_images 63999 X_image_num_pixels 912\n",
      "num_extra_rows 5\n",
      "2020-06-06 17:46:55.645211 Start of fit\n",
      "Epoch 1/5\n",
      "57595/57595 [==============================] - 30s 527us/sample - loss: 0.2462 - acc: 0.9210 - loss - ETA: 1s - lo\n",
      "Epoch 2/5\n",
      "57595/57595 [==============================] - 30s 520us/sample - loss: 0.0828 - acc: 0.9736\n",
      "Epoch 3/5\n",
      "57595/57595 [==============================] - 29s 512us/sample - loss: 0.0582 - acc: 0.9814\n",
      "Epoch 4/5\n",
      "57595/57595 [==============================] - 29s 506us/sample - loss: 0.0446 - acc: 0.9859 - loss: 0.0450 \n",
      "Epoch 5/5\n",
      "57595/57595 [==============================] - 29s 511us/sample - loss: 0.0363 - acc: 0.9886 - ETA:  - ETA: 2s - loss: 0.0365 - - ETA: 1s - loss: \n",
      "2020-06-06 17:49:27.563122 End of fit\n",
      "acc: 98.58%\n",
      "2020-06-06 17:49:31.351275 Start of fit\n",
      "Epoch 1/5\n",
      "57595/57595 [==============================] - 29s 509us/sample - loss: 0.2518 - acc: 0.9199\n",
      "Epoch 2/5\n",
      "57595/57595 [==============================] - 29s 501us/sample - loss: 0.0821 - acc: 0.9741\n",
      "Epoch 3/5\n",
      "57595/57595 [==============================] - 29s 505us/sample - loss: 0.0576 - acc: 0.9817 - loss: 0.0586 - acc:  -\n",
      "Epoch 4/5\n",
      "57595/57595 [==============================] - 29s 503us/sample - loss: 0.0431 - acc: 0.9864\n",
      "Epoch 5/5\n",
      "57595/57595 [==============================] - 29s 505us/sample - loss: 0.0350 - acc: 0.9886\n",
      "2020-06-06 17:52:00.065967 End of fit\n",
      "acc: 98.38%\n",
      "2020-06-06 17:52:03.373048 Start of fit\n",
      "Epoch 1/5\n",
      "57596/57596 [==============================] - 30s 529us/sample - loss: 0.2608 - acc: 0.9159\n",
      "Epoch 2/5\n",
      "57596/57596 [==============================] - 30s 514us/sample - loss: 0.0853 - acc: 0.9729\n",
      "Epoch 3/5\n",
      "57596/57596 [==============================] - 30s 520us/sample - loss: 0.0591 - acc: 0.9812 - loss: - ETA: 3s - los - ETA: 2s - loss: 0.0594 -  - ETA: 1s - \n",
      "Epoch 4/5\n",
      "57596/57596 [==============================] - 31s 535us/sample - loss: 0.0445 - acc: 0.9860 - loss: - ETA: 1s - loss: 0.0\n",
      "Epoch 5/5\n",
      "57596/57596 [==============================] - 31s 545us/sample - loss: 0.0354 - acc: 0.9890\n",
      "2020-06-06 17:54:38.954287 End of fit\n",
      "acc: 98.45%\n",
      "2020-06-06 17:54:42.423025 Start of fit\n",
      "Epoch 1/5\n",
      "57598/57598 [==============================] - 31s 532us/sample - loss: 0.2593 - acc: 0.9180\n",
      "Epoch 2/5\n",
      "57598/57598 [==============================] - 31s 533us/sample - loss: 0.0830 - acc: 0.9736\n",
      "Epoch 3/5\n",
      "57598/57598 [==============================] - 30s 524us/sample - loss: 0.0570 - acc: 0.9822 - l\n",
      "Epoch 4/5\n",
      "57598/57598 [==============================] - 30s 528us/sample - loss: 0.0424 - acc: 0.9870 - loss: -\n",
      "Epoch 5/5\n",
      "57598/57598 [==============================] - 30s 526us/sample - loss: 0.0351 - acc: 0.9894\n",
      "2020-06-06 17:57:18.092047 End of fit\n",
      "acc: 97.97%\n",
      "2020-06-06 17:57:21.557074 Start of fit\n",
      "Epoch 1/5\n",
      "57598/57598 [==============================] - 32s 553us/sample - loss: 0.2521 - acc: 0.9207\n",
      "Epoch 2/5\n",
      "57598/57598 [==============================] - 32s 555us/sample - loss: 0.0836 - acc: 0.9738 - loss: 0.0835 - \n",
      "Epoch 3/5\n",
      "57598/57598 [==============================] - 31s 532us/sample - loss: 0.0579 - acc: 0.9813\n",
      "Epoch 4/5\n",
      "57598/57598 [==============================] - 30s 522us/sample - loss: 0.0450 - acc: 0.9858\n",
      "Epoch 5/5\n",
      "57598/57598 [==============================] - 30s 517us/sample - loss: 0.0356 - acc: 0.9883\n",
      "2020-06-06 17:59:59.338888 End of fit\n",
      "acc: 98.63%\n",
      "2020-06-06 18:00:02.777812 Start of fit\n",
      "Epoch 1/5\n",
      "57599/57599 [==============================] - 31s 543us/sample - loss: 0.2458 - acc: 0.9225\n",
      "Epoch 2/5\n",
      "57599/57599 [==============================] - 31s 541us/sample - loss: 0.0823 - acc: 0.9733\n",
      "Epoch 3/5\n",
      "57599/57599 [==============================] - 30s 525us/sample - loss: 0.0561 - acc: 0.9820\n",
      "Epoch 4/5\n",
      "57599/57599 [==============================] - 30s 527us/sample - loss: 0.0425 - acc: 0.9867\n",
      "Epoch 5/5\n",
      "57599/57599 [==============================] - 30s 526us/sample - loss: 0.0340 - acc: 0.9889 - loss: 0.0349 - a - ETA: 5s - loss: 0.0347 -  - ET - ETA: 2\n",
      "2020-06-06 18:02:39.712742 End of fit\n",
      "acc: 98.19%\n",
      "2020-06-06 18:02:43.126481 Start of fit\n",
      "Epoch 1/5\n",
      "57602/57602 [==============================] - 31s 546us/sample - loss: 0.2545 - acc: 0.9185\n",
      "Epoch 2/5\n",
      "57602/57602 [==============================] - 30s 526us/sample - loss: 0.0829 - acc: 0.9737\n",
      "Epoch 3/5\n",
      "57602/57602 [==============================] - 30s 521us/sample - loss: 0.0574 - acc: 0.9817\n",
      "Epoch 4/5\n",
      "57602/57602 [==============================] - 30s 517us/sample - loss: 0.0445 - acc: 0.9858 - loss: 0. - ETA:\n",
      "Epoch 5/5\n",
      "57602/57602 [==============================] - 29s 506us/sample - loss: 0.0354 - acc: 0.9885 - loss: 0.03\n",
      "2020-06-06 18:05:17.406341 End of fit\n",
      "acc: 98.28%\n",
      "2020-06-06 18:05:20.848310 Start of fit\n",
      "Epoch 1/5\n",
      "57602/57602 [==============================] - 31s 531us/sample - loss: 0.2500 - acc: 0.9218 - loss: 0.2506 - acc: 0.9\n",
      "Epoch 2/5\n",
      "57602/57602 [==============================] - 30s 512us/sample - loss: 0.0843 - acc: 0.9730\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57602/57602 [==============================] - 29s 507us/sample - loss: 0.0592 - acc: 0.9817 - loss: 0.0592 - acc: 0.981\n",
      "Epoch 4/5\n",
      "57602/57602 [==============================] - 31s 532us/sample - loss: 0.0450 - acc: 0.9860- ETA: 1s - loss:\n",
      "Epoch 5/5\n",
      "57602/57602 [==============================] - 30s 527us/sample - loss: 0.0364 - acc: 0.9885\n",
      "2020-06-06 18:07:55.318230 End of fit\n",
      "acc: 98.39%\n",
      "2020-06-06 18:07:58.847702 Start of fit\n",
      "Epoch 1/5\n",
      "57602/57602 [==============================] - 31s 545us/sample - loss: 0.2577 - acc: 0.9177\n",
      "Epoch 2/5\n",
      "57602/57602 [==============================] - 31s 530us/sample - loss: 0.0871 - acc: 0.9720\n",
      "Epoch 3/5\n",
      "57602/57602 [==============================] - 31s 532us/sample - loss: 0.0600 - acc: 0.9813 - loss\n",
      "Epoch 4/5\n",
      "57602/57602 [==============================] - 30s 525us/sample - loss: 0.0459 - acc: 0.9858 - loss: 0.0464 - ac - ETA: 4s - loss: 0.0467 - acc: - ETA: 3s - los - ETA: 2s  - ETA: 0s - loss: 0.0461 - acc:  - ETA: 0s - loss: 0.0461 - acc: 0.9\n",
      "Epoch 5/5\n",
      "57602/57602 [==============================] - 30s 525us/sample - loss: 0.0377 - acc: 0.9883\n",
      "2020-06-06 18:10:35.596281 End of fit\n",
      "acc: 98.16%\n",
      "2020-06-06 18:10:39.121534 Start of fit\n",
      "Epoch 1/5\n",
      "57604/57604 [==============================] - 31s 544us/sample - loss: 0.2580 - acc: 0.9177\n",
      "Epoch 2/5\n",
      "57604/57604 [==============================] - 30s 522us/sample - loss: 0.0834 - acc: 0.9745\n",
      "Epoch 3/5\n",
      "57604/57604 [==============================] - 31s 546us/sample - loss: 0.0573 - acc: 0.9820\n",
      "Epoch 4/5\n",
      "57604/57604 [==============================] - 32s 549us/sample - loss: 0.0447 - acc: 0.9860\n",
      "Epoch 5/5\n",
      "57604/57604 [==============================] - 32s 559us/sample - loss: 0.0348 - acc: 0.9887 - los\n",
      "2020-06-06 18:13:19.443405 End of fit\n",
      "acc: 98.26%\n",
      "98.33% (+/- 0.19%)\n",
      "2020-06-06 18:13:22.398833 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 9 1 1 0 7 5 9 9 1 9 5 9 2 5 0 4 1 0 8 9 0 8 9 8 9 4 2 5 7 9 8 9 8 0 9 9 6 8 9 9 5 9 8 5 1\n",
      " 0 3 3 5 2 1 6 3 0 2 8 1 5 6 2 3 0 2 2 6 4 3 5 5 1 7 2 1 6 9 1 3 9 5 5 1 6 2 2 8 6 7 1 4 6 0 6 0 3 3 2 2 3 6 8 9 8 5 3 8 5 4 5 2 0 5 6 3 2 8 3 9 9 3 7 9 4 6 7 1 3 7 3 6 6 0 9 0 1 9 9 2 8 8 0 1 6 9 7\n",
      " 5 3 4 7 4]\n",
      "ndx_errs (array([ 151,  241,  247,  320,  321,  338,  340,  362,  376,  381,  444,  445,  448,  464,  478,  479,  495,  519,  571,  578,  582,  628,  659,  689,  691,  716,  740,  791,  810,  839,  844,  938,\n",
      "        939,  947,  951,  957, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1192, 1212, 1226, 1228, 1232, 1242, 1247, 1270, 1289, 1299, 1319, 1326, 1328, 1331, 1364, 1393, 1414, 1466,\n",
      "       1500, 1522, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2044, 2052, 2070, 2093, 2098, 2109, 2118,\n",
      "       2129, 2130, 2135, 2168, 2177, 2182, 2189, 2224, 2237, 2282, 2293, 2298, 2371, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2462, 2574, 2582, 2607, 2648, 2654, 2730, 2771, 2810, 2853, 2877, 2896,\n",
      "       2927, 2939, 2953, 2998, 3060, 3062, 3073, 3117, 3206, 3261, 3289, 3333, 3369, 3405, 3429, 3475, 3503, 3542, 3558, 3559, 3597, 3629, 3702, 3718, 3726, 3767, 3780, 3808, 3811, 3838, 3853, 3902,\n",
      "       3926, 3941, 3968], dtype=int64),)\n",
      "num correct is  3836  an accuracy of  0.9592398099524881\n",
      "****************************** 5999 ******************************\n",
      "fill_up_last_row.shape (65999, 12)\n",
      "X_num_images 65999 X_image_num_pixels 912\n",
      "num_extra_rows 5\n",
      "2020-06-06 18:19:40.025169 Start of fit\n",
      "Epoch 1/5\n",
      "59395/59395 [==============================] - 32s 539us/sample - loss: 0.2544 - acc: 0.9186\n",
      "Epoch 2/5\n",
      "59395/59395 [==============================] - 31s 520us/sample - loss: 0.0829 - acc: 0.9742\n",
      "Epoch 3/5\n",
      "59395/59395 [==============================] - 31s 528us/sample - loss: 0.0579 - acc: 0.9817\n",
      "Epoch 4/5\n",
      "59395/59395 [==============================] - 31s 519us/sample - loss: 0.0445 - acc: 0.9862 - loss: 0.0443 - acc: - ETA: 0s - loss: 0.0445 -\n",
      "Epoch 5/5\n",
      "59395/59395 [==============================] - 31s 523us/sample - loss: 0.0351 - acc: 0.9896\n",
      "2020-06-06 18:22:19.949810 End of fit\n",
      "acc: 98.53%\n",
      "2020-06-06 18:22:23.686466 Start of fit\n",
      "Epoch 1/5\n",
      "59397/59397 [==============================] - 32s 544us/sample - loss: 0.2495 - acc: 0.9195\n",
      "Epoch 2/5\n",
      "59397/59397 [==============================] - 31s 522us/sample - loss: 0.0834 - acc: 0.9743\n",
      "Epoch 3/5\n",
      "59397/59397 [==============================] - 31s 519us/sample - loss: 0.0559 - acc: 0.9821\n",
      "Epoch 4/5\n",
      "59397/59397 [==============================] - 31s 525us/sample - loss: 0.0451 - acc: 0.9859 - loss:\n",
      "Epoch 5/5\n",
      "59397/59397 [==============================] - 31s 519us/sample - loss: 0.0353 - acc: 0.9886- ETA: 3 - ETA: 1\n",
      "2020-06-06 18:25:03.827165 End of fit\n",
      "acc: 98.02%\n",
      "2020-06-06 18:25:07.492453 Start of fit\n",
      "Epoch 1/5\n",
      "59397/59397 [==============================] - 32s 542us/sample - loss: 0.2404 - acc: 0.9228\n",
      "Epoch 2/5\n",
      "59397/59397 [==============================] - 31s 523us/sample - loss: 0.0811 - acc: 0.9741\n",
      "Epoch 3/5\n",
      "59397/59397 [==============================] - 31s 522us/sample - loss: 0.0565 - acc: 0.9822\n",
      "Epoch 4/5\n",
      "59397/59397 [==============================] - 31s 527us/sample - loss: 0.0433 - acc: 0.9861 - los - ETA: 0s - loss: 0.0431 -\n",
      "Epoch 5/5\n",
      "59397/59397 [==============================] - 31s 520us/sample - loss: 0.0344 - acc: 0.9889\n",
      "2020-06-06 18:27:48.383852 End of fit\n",
      "acc: 98.20%\n",
      "2020-06-06 18:27:52.174492 Start of fit\n",
      "Epoch 1/5\n",
      "59399/59399 [==============================] - 33s 549us/sample - loss: 0.2625 - acc: 0.9158\n",
      "Epoch 2/5\n",
      "59399/59399 [==============================] - 31s 530us/sample - loss: 0.0838 - acc: 0.9731 - loss: \n",
      "Epoch 3/5\n",
      "59399/59399 [==============================] - 31s 527us/sample - loss: 0.0578 - acc: 0.9817\n",
      "Epoch 4/5\n",
      "59399/59399 [==============================] - 31s 526us/sample - loss: 0.0435 - acc: 0.9863 - loss: 0.0432 - acc: 0.9\n",
      "Epoch 5/5\n",
      "59399/59399 [==============================] - 31s 528us/sample - loss: 0.0344 - acc: 0.9889\n",
      "2020-06-06 18:30:34.238336 End of fit\n",
      "acc: 96.97%\n",
      "2020-06-06 18:30:37.919413 Start of fit\n",
      "Epoch 1/5\n",
      "59399/59399 [==============================] - 33s 551us/sample - loss: 0.2522 - acc: 0.9190\n",
      "Epoch 2/5\n",
      "59399/59399 [==============================] - 32s 532us/sample - loss: 0.0777 - acc: 0.9760\n",
      "Epoch 3/5\n",
      "59399/59399 [==============================] - 31s 529us/sample - loss: 0.0556 - acc: 0.9824\n",
      "Epoch 4/5\n",
      "59399/59399 [==============================] - 32s 538us/sample - loss: 0.0422 - acc: 0.9865\n",
      "Epoch 5/5\n",
      "59399/59399 [==============================] - 31s 529us/sample - loss: 0.0343 - acc: 0.9892\n",
      "2020-06-06 18:33:21.165247 End of fit\n",
      "acc: 98.47%\n",
      "2020-06-06 18:33:24.854622 Start of fit\n",
      "Epoch 1/5\n",
      "59399/59399 [==============================] - 33s 549us/sample - loss: 0.2511 - acc: 0.9205\n",
      "Epoch 2/5\n",
      "59399/59399 [==============================] - 32s 531us/sample - loss: 0.0827 - acc: 0.9735\n",
      "Epoch 3/5\n",
      "59399/59399 [==============================] - 31s 528us/sample - loss: 0.0577 - acc: 0.9815\n",
      "Epoch 4/5\n",
      "59399/59399 [==============================] - 32s 537us/sample - loss: 0.0427 - acc: 0.9860\n",
      "Epoch 5/5\n",
      "59399/59399 [==============================] - 31s 529us/sample - loss: 0.0350 - acc: 0.9886s - loss - ETA: 5s - loss: 0.03 - ETA\n",
      "2020-06-06 18:36:07.680809 End of fit\n",
      "acc: 98.55%\n",
      "2020-06-06 18:36:11.448695 Start of fit\n",
      "Epoch 1/5\n",
      "59400/59400 [==============================] - 33s 549us/sample - loss: 0.2532 - acc: 0.9178\n",
      "Epoch 2/5\n",
      "59400/59400 [==============================] - 32s 538us/sample - loss: 0.0835 - acc: 0.9735\n",
      "Epoch 3/5\n",
      "59400/59400 [==============================] - 32s 533us/sample - loss: 0.0567 - acc: 0.9820\n",
      "Epoch 4/5\n",
      "59400/59400 [==============================] - 31s 530us/sample - loss: 0.0442 - acc: 0.9862 - loss: 0.0441 - acc: 0.\n",
      "Epoch 5/5\n",
      "59400/59400 [==============================] - 34s 572us/sample - loss: 0.0339 - acc: 0.9890\n",
      "2020-06-06 18:38:57.269548 End of fit\n",
      "acc: 97.89%\n",
      "2020-06-06 18:39:01.926861 Start of fit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "59400/59400 [==============================] - 33s 556us/sample - loss: 0.2457 - acc: 0.9218\n",
      "Epoch 2/5\n",
      "59400/59400 [==============================] - 32s 538us/sample - loss: 0.0848 - acc: 0.9730 - loss: 0.\n",
      "Epoch 3/5\n",
      "59400/59400 [==============================] - 31s 530us/sample - loss: 0.0589 - acc: 0.9811\n",
      "Epoch 4/5\n",
      "59400/59400 [==============================] - 32s 536us/sample - loss: 0.0445 - acc: 0.9857 - loss: 0\n",
      "Epoch 5/5\n",
      "59400/59400 [==============================] - 32s 538us/sample - loss: 0.0370 - acc: 0.9882\n",
      "2020-06-06 18:41:46.451464 End of fit\n",
      "acc: 98.26%\n",
      "2020-06-06 18:41:50.435140 Start of fit\n",
      "Epoch 1/5\n",
      "59402/59402 [==============================] - 33s 556us/sample - loss: 0.2445 - acc: 0.9221 - loss: 0.2480 - a\n",
      "Epoch 2/5\n",
      "59402/59402 [==============================] - 33s 553us/sample - loss: 0.0761 - acc: 0.9758\n",
      "Epoch 3/5\n",
      "59402/59402 [==============================] - 32s 540us/sample - loss: 0.0530 - acc: 0.9831 - loss: 0.0529 - acc:\n",
      "Epoch 4/5\n",
      "59402/59402 [==============================] - 32s 535us/sample - loss: 0.0419 - acc: 0.9863- ETA: 0s - loss: 0.0417 - ac\n",
      "Epoch 5/5\n",
      "59402/59402 [==============================] - 31s 527us/sample - loss: 0.0335 - acc: 0.9893\n",
      "2020-06-06 18:44:36.485191 End of fit\n",
      "acc: 98.11%\n",
      "2020-06-06 18:44:40.624973 Start of fit\n",
      "Epoch 1/5\n",
      "59403/59403 [==============================] - 32s 545us/sample - loss: 0.2386 - acc: 0.9223\n",
      "Epoch 2/5\n",
      "59403/59403 [==============================] - 31s 522us/sample - loss: 0.0787 - acc: 0.9755\n",
      "Epoch 3/5\n",
      "59403/59403 [==============================] - 31s 527us/sample - loss: 0.0557 - acc: 0.9821\n",
      "Epoch 4/5\n",
      "59403/59403 [==============================] - 31s 523us/sample - loss: 0.0437 - acc: 0.9860\n",
      "Epoch 5/5\n",
      "59403/59403 [==============================] - 31s 528us/sample - loss: 0.0336 - acc: 0.9891\n",
      "2020-06-06 18:47:22.388252 End of fit\n",
      "acc: 98.50%\n",
      "98.15% (+/- 0.45%)\n",
      "2020-06-06 18:47:25.703702 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 2 3 4 5 6 7 8 9 8 7 1 3 7 5 2 8 0 7 3 9 9 0 9 1 1 5 8 8 6 3 2 1 8 3 2 6 5 6 7 6 1 0 5 3 1 9\n",
      " 2 1 9 6 0 4 6 1 7 3 8 9 2 9 6 5 8 3 5 7 1 6 1 0 9 6 2 5 4 2 3 4 4 6 0 0 2 0 1 2 3 4 3 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 8 4 5 6 7 8 9 8 6 5 0 6 8 9 4 1 9 5 8 0 4 8 9 1 4 0 5 3 2 1 5 4 0 7 6 0 1 7 0\n",
      " 6 8 9 3 1]\n",
      "ndx_errs (array([ 151,  241,  247,  320,  321,  338,  340,  362,  376,  381,  444,  445,  448,  464,  478,  479,  495,  519,  571,  578,  582,  628,  659,  689,  691,  716,  740,  791,  810,  839,  844,  938,\n",
      "        939,  947,  951,  957, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1192, 1212, 1226, 1228, 1232, 1242, 1247, 1270, 1289, 1299, 1319, 1326, 1328, 1331, 1364, 1393, 1414, 1466,\n",
      "       1500, 1522, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2044, 2052, 2070, 2093, 2098, 2109, 2118,\n",
      "       2129, 2130, 2135, 2168, 2177, 2182, 2189, 2224, 2237, 2282, 2293, 2298, 2371, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2462, 2574, 2582, 2607, 2648, 2654, 2730, 2771, 2810, 2853, 2877, 2896,\n",
      "       2927, 2939, 2953, 2998, 3060, 3062, 3073, 3117, 3206, 3261, 3289, 3333, 3369, 3405, 3429, 3475, 3503, 3542, 3558, 3559, 3597, 3629, 3702, 3718, 3726, 3767, 3780, 3808, 3811, 3838, 3853, 3902,\n",
      "       3926, 3941, 3968, 4007, 4053, 4065, 4075, 4078, 4116, 4163, 4176, 4224, 4238, 4271, 4284, 4289, 4294, 4297, 4306, 4317, 4355, 4483, 4497, 4500, 4598, 4639, 4671, 4690, 4724, 4761, 4785, 4807,\n",
      "       4823, 4837, 4860, 4879, 4886, 4890, 4893, 4943, 4966, 4978, 4990, 5001, 5138, 5176, 5288, 5532, 5600, 5634, 5714, 5734, 5769, 5835, 5867, 5888, 5906, 5937, 5955, 5973, 5982, 5997], dtype=int64),)\n",
      "num correct is  5777  an accuracy of  0.9629938323053843\n",
      "****************************** 7999 ******************************\n",
      "fill_up_last_row.shape (67999, 12)\n",
      "X_num_images 67999 X_image_num_pixels 912\n",
      "num_extra_rows 5\n",
      "2020-06-06 18:56:36.060050 Start of fit\n",
      "Epoch 1/5\n",
      "61195/61195 [==============================] - 34s 553us/sample - loss: 0.2392 - acc: 0.9228\n",
      "Epoch 2/5\n",
      "61195/61195 [==============================] - 33s 538us/sample - loss: 0.0803 - acc: 0.9745\n",
      "Epoch 3/5\n",
      "61195/61195 [==============================] - 33s 533us/sample - loss: 0.0545 - acc: 0.9828\n",
      "Epoch 4/5\n",
      "61195/61195 [==============================] - 32s 524us/sample - loss: 0.0420 - acc: 0.9869\n",
      "Epoch 5/5\n",
      "61195/61195 [==============================] - 32s 521us/sample - loss: 0.0331 - acc: 0.9895\n",
      "2020-06-06 18:59:24.391986 End of fit\n",
      "acc: 98.54%\n",
      "2020-06-06 18:59:28.749451 Start of fit\n",
      "Epoch 1/5\n",
      "61195/61195 [==============================] - 34s 548us/sample - loss: 0.2309 - acc: 0.9269\n",
      "Epoch 2/5\n",
      "61195/61195 [==============================] - 33s 538us/sample - loss: 0.0776 - acc: 0.9761\n",
      "Epoch 3/5\n",
      "61195/61195 [==============================] - 33s 535us/sample - loss: 0.0552 - acc: 0.9827 \n",
      "Epoch 4/5\n",
      "61195/61195 [==============================] - 32s 529us/sample - loss: 0.0424 - acc: 0.9862\n",
      "Epoch 5/5\n",
      "61195/61195 [==============================] - 33s 547us/sample - loss: 0.0329 - acc: 0.9896\n",
      "2020-06-06 19:02:18.353059 End of fit\n",
      "acc: 98.59%\n",
      "2020-06-06 19:02:22.593269 Start of fit\n",
      "Epoch 1/5\n",
      "61196/61196 [==============================] - 34s 564us/sample - loss: 0.2425 - acc: 0.9225 - loss: 0.2451 -\n",
      "Epoch 2/5\n",
      "61196/61196 [==============================] - 33s 539us/sample - loss: 0.0822 - acc: 0.9743\n",
      "Epoch 3/5\n",
      "61196/61196 [==============================] - 32s 529us/sample - loss: 0.0578 - acc: 0.9816\n",
      "Epoch 4/5\n",
      "61196/61196 [==============================] - 32s 526us/sample - loss: 0.0449 - acc: 0.9861\n",
      "Epoch 5/5\n",
      "61196/61196 [==============================] - 32s 523us/sample - loss: 0.0362 - acc: 0.9884\n",
      "2020-06-06 19:05:11.531172 End of fit\n",
      "acc: 97.03%\n",
      "2020-06-06 19:05:15.855761 Start of fit\n",
      "Epoch 1/5\n",
      "61196/61196 [==============================] - 33s 545us/sample - loss: 0.2489 - acc: 0.9202 - loss: 0.2499 - acc: 0.\n",
      "Epoch 2/5\n",
      "61196/61196 [==============================] - 33s 533us/sample - loss: 0.0800 - acc: 0.9753\n",
      "Epoch 3/5\n",
      "61196/61196 [==============================] - 32s 523us/sample - loss: 0.0559 - acc: 0.9826\n",
      "Epoch 4/5\n",
      "61196/61196 [==============================] - 32s 516us/sample - loss: 0.0424 - acc: 0.9863 - l - ETA: 6 - E\n",
      "Epoch 5/5\n",
      "61196/61196 [==============================] - 32s 518us/sample - loss: 0.0338 - acc: 0.9894 - loss: 0.0337\n",
      "2020-06-06 19:08:02.050130 End of fit\n",
      "acc: 98.56%\n",
      "2020-06-06 19:08:06.274850 Start of fit\n",
      "Epoch 1/5\n",
      "61199/61199 [==============================] - 34s 550us/sample - loss: 0.2413 - acc: 0.9223 -  - ETA: 1s - loss: 0\n",
      "Epoch 2/5\n",
      "61199/61199 [==============================] - 33s 542us/sample - loss: 0.0787 - acc: 0.9751\n",
      "Epoch 3/5\n",
      "61199/61199 [==============================] - 33s 534us/sample - loss: 0.0535 - acc: 0.9831\n",
      "Epoch 4/5\n",
      "61199/61199 [==============================] - 32s 530us/sample - loss: 0.0413 - acc: 0.9868\n",
      "Epoch 5/5\n",
      "61199/61199 [==============================] - 32s 528us/sample - loss: 0.0336 - acc: 0.9891\n",
      "2020-06-06 19:10:55.274284 End of fit\n",
      "acc: 98.38%\n",
      "2020-06-06 19:10:59.524460 Start of fit\n",
      "Epoch 1/5\n",
      "61199/61199 [==============================] - 34s 559us/sample - loss: 0.2385 - acc: 0.9236 - loss: \n",
      "Epoch 2/5\n",
      "61199/61199 [==============================] - 34s 554us/sample - loss: 0.0818 - acc: 0.9737\n",
      "Epoch 3/5\n",
      "61199/61199 [==============================] - 34s 551us/sample - loss: 0.0564 - acc: 0.9824\n",
      "Epoch 4/5\n",
      "61199/61199 [==============================] - 34s 550us/sample - loss: 0.0439 - acc: 0.9861\n",
      "Epoch 5/5\n",
      "61199/61199 [==============================] - 33s 543us/sample - loss: 0.0348 - acc: 0.9891 - \n",
      "2020-06-06 19:13:54.278779 End of fit\n",
      "acc: 98.65%\n",
      "2020-06-06 19:13:58.436007 Start of fit\n",
      "Epoch 1/5\n",
      "61200/61200 [==============================] - 35s 564us/sample - loss: 0.2454 - acc: 0.9216 - loss: 0.2461 - acc: 0.9\n",
      "Epoch 2/5\n",
      "61200/61200 [==============================] - 33s 538us/sample - loss: 0.0819 - acc: 0.9741\n",
      "Epoch 3/5\n",
      "61200/61200 [==============================] - 32s 527us/sample - loss: 0.0568 - acc: 0.9818\n",
      "Epoch 4/5\n",
      "61200/61200 [==============================] - 32s 521us/sample - loss: 0.0434 - acc: 0.9858\n",
      "Epoch 5/5\n",
      "61200/61200 [==============================] - 32s 522us/sample - loss: 0.0349 - acc: 0.9891 - los \n",
      "2020-06-06 19:16:46.962200 End of fit\n",
      "acc: 98.37%\n",
      "2020-06-06 19:16:51.729423 Start of fit\n",
      "Epoch 1/5\n",
      "61203/61203 [==============================] - 34s 558us/sample - loss: 0.2456 - acc: 0.9209\n",
      "Epoch 2/5\n",
      "61203/61203 [==============================] - 33s 533us/sample - loss: 0.0774 - acc: 0.9759 - l\n",
      "Epoch 3/5\n",
      "61203/61203 [==============================] - 33s 535us/sample - loss: 0.0534 - acc: 0.9832\n",
      "Epoch 4/5\n",
      "61203/61203 [==============================] - 32s 523us/sample - loss: 0.0413 - acc: 0.9868\n",
      "Epoch 5/5\n",
      "61203/61203 [==============================] - 32s 529us/sample - loss: 0.0344 - acc: 0.9894\n",
      "2020-06-06 19:19:40.418396 End of fit\n",
      "acc: 98.32%\n",
      "2020-06-06 19:19:44.544804 Start of fit\n",
      "Epoch 1/5\n",
      "61204/61204 [==============================] - ETA: 0s - loss: 0.2481 - acc: 0.920 - 34s 556us/sample - loss: 0.2480 - acc: 0.9200\n",
      "Epoch 2/5\n",
      "61204/61204 [==============================] - 33s 538us/sample - loss: 0.0787 - acc: 0.9750\n",
      "Epoch 3/5\n",
      "61204/61204 [==============================] - 34s 548us/sample - loss: 0.0544 - acc: 0.9831\n",
      "Epoch 4/5\n",
      "61204/61204 [==============================] - 33s 533us/sample - loss: 0.0421 - acc: 0.9870 - loss: 0.0421\n",
      "Epoch 5/5\n",
      "61204/61204 [==============================] - 33s 531us/sample - loss: 0.0340 - acc: 0.9891\n",
      "2020-06-06 19:22:35.137645 End of fit\n",
      "acc: 98.31%\n",
      "2020-06-06 19:22:39.303255 Start of fit\n",
      "Epoch 1/5\n",
      "61204/61204 [==============================] - 33s 540us/sample - loss: 0.2383 - acc: 0.9242\n",
      "Epoch 2/5\n",
      "61204/61204 [==============================] - 33s 537us/sample - loss: 0.0775 - acc: 0.9755\n",
      "Epoch 3/5\n",
      "61204/61204 [==============================] - 33s 533us/sample - loss: 0.0551 - acc: 0.9829 - loss: 0.0554\n",
      "Epoch 4/5\n",
      "61204/61204 [==============================] - 33s 534us/sample - loss: 0.0430 - acc: 0.9861\n",
      "Epoch 5/5\n",
      "61204/61204 [==============================] - 33s 542us/sample - loss: 0.0344 - acc: 0.9888\n",
      "2020-06-06 19:25:28.676507 End of fit\n",
      "acc: 98.59%\n",
      "98.33% (+/- 0.45%)\n",
      "2020-06-06 19:25:32.324333 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 3 5 6 7 8 9 0 1 2 3 5 6 7 8 9 9 7 0 9 0 1 5 8 8 0 9 3 2 7 8 4 6 1 0 4 9 4 2 0 5 0 1 6 9 3 2\n",
      " 9 1 6 0 1 1 8 7 7 6 3 6 0 7 2 4 1 7 0 6 7 1 2 5 8 1 1 2 8 7 6 8 7 1 6 2 9 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 8 9 5 7 0 3 1 6 8 4 1 5 6 4 2 7 8 1 3 4 3 4 7 2 0 5 0 1 9 2 3\n",
      " 2 3 5 5 7]\n",
      "ndx_errs (array([ 151,  241,  247,  320,  321,  338,  340,  362,  376,  381,  444,  445,  448,  464,  478,  479,  495,  519,  571,  578,  582,  628,  659,  689,  691,  716,  740,  791,  810,  839,  844,  938,\n",
      "        939,  947,  951,  957, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1192, 1212, 1226, 1228, 1232, 1242, 1247, 1270, 1289, 1299, 1319, 1326, 1328, 1331, 1364, 1393, 1414, 1466,\n",
      "       1500, 1522, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2044, 2052, 2070, 2093, 2098, 2109, 2118,\n",
      "       2129, 2130, 2135, 2168, 2177, 2182, 2189, 2224, 2237, 2282, 2293, 2298, 2371, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2462, 2574, 2582, 2607, 2648, 2654, 2730, 2771, 2810, 2853, 2877, 2896,\n",
      "       2927, 2939, 2953, 2998, 3060, 3062, 3073, 3117, 3206, 3261, 3289, 3333, 3369, 3405, 3429, 3475, 3503, 3542, 3558, 3559, 3597, 3629, 3702, 3718, 3726, 3767, 3780, 3808, 3811, 3838, 3853, 3902,\n",
      "       3926, 3941, 3968, 4007, 4053, 4065, 4075, 4078, 4116, 4163, 4176, 4224, 4238, 4271, 4284, 4289, 4294, 4297, 4306, 4317, 4355, 4483, 4497, 4500, 4598, 4639, 4671, 4690, 4724, 4761, 4785, 4807,\n",
      "       4823, 4837, 4860, 4879, 4886, 4890, 4893, 4943, 4966, 4978, 4990, 5001, 5138, 5176, 5288, 5532, 5600, 5634, 5714, 5734, 5769, 5835, 5867, 5888, 5906, 5937, 5955, 5973, 5982, 5997, 6011, 6023,\n",
      "       6035, 6059, 6071, 6081, 6091, 6157, 6160, 6166, 6172, 6173, 6505, 6555, 6560, 6597, 6651, 6755, 6783, 6813, 7094, 7216, 7233, 7333, 7432, 7434, 7498, 7545, 7637, 7821, 7921], dtype=int64),)\n",
      "num correct is  7746  an accuracy of  0.9683710463807976\n",
      "****************************** 9999 ******************************\n",
      "fill_up_last_row.shape (69999, 12)\n",
      "X_num_images 69999 X_image_num_pixels 912\n",
      "num_extra_rows 5\n",
      "2020-06-06 19:37:35.124139 Start of fit\n",
      "Epoch 1/5\n",
      "62994/62994 [==============================] - 36s 572us/sample - loss: 0.2459 - acc: 0.9221\n",
      "Epoch 2/5\n",
      "62994/62994 [==============================] - 34s 541us/sample - loss: 0.0793 - acc: 0.9754\n",
      "Epoch 3/5\n",
      "62994/62994 [==============================] - 34s 534us/sample - loss: 0.0564 - acc: 0.9821\n",
      "Epoch 4/5\n",
      "62994/62994 [==============================] - 34s 533us/sample - loss: 0.0413 - acc: 0.9866\n",
      "Epoch 5/5\n",
      "62994/62994 [==============================] - 33s 532us/sample - loss: 0.0345 - acc: 0.9889\n",
      "2020-06-06 19:40:31.822428 End of fit\n",
      "acc: 98.70%\n",
      "2020-06-06 19:40:36.182103 Start of fit\n",
      "Epoch 1/5\n",
      "62995/62995 [==============================] - 36s 570us/sample - loss: 0.2457 - acc: 0.9215 - loss: 0.2484 - \n",
      "Epoch 2/5\n",
      "62995/62995 [==============================] - 35s 553us/sample - loss: 0.0761 - acc: 0.9762\n",
      "Epoch 3/5\n",
      "62995/62995 [==============================] - 35s 552us/sample - loss: 0.0523 - acc: 0.9836\n",
      "Epoch 4/5\n",
      "62995/62995 [==============================] - 35s 559us/sample - loss: 0.0408 - acc: 0.9867\n",
      "Epoch 5/5\n",
      "62995/62995 [==============================] - 35s 554us/sample - loss: 0.0324 - acc: 0.9893\n",
      "2020-06-06 19:43:37.445248 End of fit\n",
      "acc: 98.12%\n",
      "2020-06-06 19:43:41.934915 Start of fit\n",
      "Epoch 1/5\n",
      "62995/62995 [==============================] - 36s 570us/sample - loss: 0.2432 - acc: 0.9219\n",
      "Epoch 2/5\n",
      "62995/62995 [==============================] - 34s 541us/sample - loss: 0.0799 - acc: 0.9758\n",
      "Epoch 3/5\n",
      "62995/62995 [==============================] - 34s 547us/sample - loss: 0.0558 - acc: 0.9825\n",
      "Epoch 4/5\n",
      "62995/62995 [==============================] - 34s 537us/sample - loss: 0.0426 - acc: 0.9865 - loss: 0.0427 - acc: 0.98\n",
      "Epoch 5/5\n",
      "62995/62995 [==============================] - 34s 541us/sample - loss: 0.0341 - acc: 0.9892\n",
      "2020-06-06 19:46:39.755951 End of fit\n",
      "acc: 98.12%\n",
      "2020-06-06 19:46:44.478778 Start of fit\n",
      "Epoch 1/5\n",
      "62998/62998 [==============================] - 36s 569us/sample - loss: 0.2323 - acc: 0.9262\n",
      "Epoch 2/5\n",
      "62998/62998 [==============================] - 35s 549us/sample - loss: 0.0790 - acc: 0.9751\n",
      "Epoch 3/5\n",
      "62998/62998 [==============================] - 34s 547us/sample - loss: 0.0544 - acc: 0.9828\n",
      "Epoch 4/5\n",
      "62998/62998 [==============================] - 34s 539us/sample - loss: 0.0423 - acc: 0.9865\n",
      "Epoch 5/5\n",
      "62998/62998 [==============================] - 33s 531us/sample - loss: 0.0342 - acc: 0.9890\n",
      "2020-06-06 19:49:42.627129 End of fit\n",
      "acc: 98.66%\n",
      "2020-06-06 19:49:47.335231 Start of fit\n",
      "Epoch 1/5\n",
      "62999/62999 [==============================] - 36s 576us/sample - loss: 0.2407 - acc: 0.9227\n",
      "Epoch 2/5\n",
      "62999/62999 [==============================] - 35s 557us/sample - loss: 0.0796 - acc: 0.9751\n",
      "Epoch 3/5\n",
      "62999/62999 [==============================] - 34s 543us/sample - loss: 0.0556 - acc: 0.9820 - loss: 0.05\n",
      "Epoch 4/5\n",
      "62999/62999 [==============================] - 34s 544us/sample - loss: 0.0425 - acc: 0.9864\n",
      "Epoch 5/5\n",
      "62999/62999 [==============================] - 34s 543us/sample - loss: 0.0349 - acc: 0.9889\n",
      "2020-06-06 19:52:47.036940 End of fit\n",
      "acc: 98.49%\n",
      "2020-06-06 19:52:52.050163 Start of fit\n",
      "Epoch 1/5\n",
      "63001/63001 [==============================] - 36s 574us/sample - loss: 0.2475 - acc: 0.9205\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63001/63001 [==============================] - 35s 557us/sample - loss: 0.0803 - acc: 0.9744\n",
      "Epoch 3/5\n",
      "63001/63001 [==============================] - 34s 543us/sample - loss: 0.0549 - acc: 0.9823\n",
      "Epoch 4/5\n",
      "63001/63001 [==============================] - 34s 546us/sample - loss: 0.0429 - acc: 0.9864\n",
      "Epoch 5/5\n",
      "63001/63001 [==============================] - 34s 544us/sample - loss: 0.0349 - acc: 0.9890\n",
      "2020-06-06 19:55:51.525240 End of fit\n",
      "acc: 98.47%\n",
      "2020-06-06 19:55:56.070733 Start of fit\n",
      "Epoch 1/5\n",
      "63001/63001 [==============================] - 35s 555us/sample - loss: 0.2324 - acc: 0.9248\n",
      "Epoch 2/5\n",
      "63001/63001 [==============================] - 34s 533us/sample - loss: 0.0768 - acc: 0.9762\n",
      "Epoch 3/5\n",
      "63001/63001 [==============================] - 34s 538us/sample - loss: 0.0534 - acc: 0.9833\n",
      "Epoch 4/5\n",
      "63001/63001 [==============================] - 34s 540us/sample - loss: 0.0410 - acc: 0.9870\n",
      "Epoch 5/5\n",
      "63001/63001 [==============================] - 34s 536us/sample - loss: 0.0329 - acc: 0.9898 - loss: 0.032\n",
      "2020-06-06 19:58:52.002410 End of fit\n",
      "acc: 98.30%\n",
      "2020-06-06 19:58:56.513568 Start of fit\n",
      "Epoch 1/5\n",
      "63002/63002 [==============================] - 36s 565us/sample - loss: 0.2327 - acc: 0.9238\n",
      "Epoch 2/5\n",
      "63002/63002 [==============================] - 34s 547us/sample - loss: 0.0754 - acc: 0.9764\n",
      "Epoch 3/5\n",
      "63002/63002 [==============================] - 34s 542us/sample - loss: 0.0528 - acc: 0.9838\n",
      "Epoch 4/5\n",
      "63002/63002 [==============================] - 35s 553us/sample - loss: 0.0404 - acc: 0.9872\n",
      "Epoch 5/5\n",
      "63002/63002 [==============================] - 34s 543us/sample - loss: 0.0315 - acc: 0.9900\n",
      "2020-06-06 20:01:55.357887 End of fit\n",
      "acc: 98.18%\n",
      "2020-06-06 20:02:00.026473 Start of fit\n",
      "Epoch 1/5\n",
      "63003/63003 [==============================] - 36s 568us/sample - loss: 0.2398 - acc: 0.9233\n",
      "Epoch 2/5\n",
      "63003/63003 [==============================] - 35s 548us/sample - loss: 0.0776 - acc: 0.9751\n",
      "Epoch 3/5\n",
      "63003/63003 [==============================] - 35s 553us/sample - loss: 0.0543 - acc: 0.9826\n",
      "Epoch 4/5\n",
      "63003/63003 [==============================] - 34s 545us/sample - loss: 0.0411 - acc: 0.9864\n",
      "Epoch 5/5\n",
      "63003/63003 [==============================] - 35s 549us/sample - loss: 0.0332 - acc: 0.9895\n",
      "2020-06-06 20:04:59.822288 End of fit\n",
      "acc: 98.24%\n",
      "2020-06-06 20:05:04.400425 Start of fit\n",
      "Epoch 1/5\n",
      "63003/63003 [==============================] - 36s 568us/sample - loss: 0.2448 - acc: 0.9223\n",
      "Epoch 2/5\n",
      "63003/63003 [==============================] - 35s 554us/sample - loss: 0.0774 - acc: 0.9755\n",
      "Epoch 3/5\n",
      "63003/63003 [==============================] - 34s 537us/sample - loss: 0.0533 - acc: 0.9827\n",
      "Epoch 4/5\n",
      "63003/63003 [==============================] - 35s 549us/sample - loss: 0.0404 - acc: 0.9874\n",
      "Epoch 5/5\n",
      "63003/63003 [==============================] - 34s 538us/sample - loss: 0.0324 - acc: 0.9897\n",
      "2020-06-06 20:08:03.231169 End of fit\n",
      "acc: 98.27%\n",
      "98.35% (+/- 0.20%)\n",
      "2020-06-06 20:08:07.158140 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 2 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 8 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 5 7 0 6 8 6 3 9 9 8 8 7\n",
      " 7 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 8 8 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0\n",
      " 1 2 3 4 5]\n",
      "ndx_errs (array([ 151,  241,  247,  320,  321,  338,  340,  362,  376,  381,  444,  445,  448,  464,  478,  479,  495,  519,  571,  578,  582,  628,  659,  689,  691,  716,  740,  791,  810,  839,  844,  938,\n",
      "        939,  947,  951,  957, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1192, 1212, 1226, 1228, 1232, 1242, 1247, 1270, 1289, 1299, 1319, 1326, 1328, 1331, 1364, 1393, 1414, 1466,\n",
      "       1500, 1522, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2044, 2052, 2070, 2093, 2098, 2109, 2118,\n",
      "       2129, 2130, 2135, 2168, 2177, 2182, 2189, 2224, 2237, 2282, 2293, 2298, 2371, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2462, 2574, 2582, 2607, 2648, 2654, 2730, 2771, 2810, 2853, 2877, 2896,\n",
      "       2927, 2939, 2953, 2998, 3060, 3062, 3073, 3117, 3206, 3261, 3289, 3333, 3369, 3405, 3429, 3475, 3503, 3542, 3558, 3559, 3597, 3629, 3702, 3718, 3726, 3767, 3780, 3808, 3811, 3838, 3853, 3902,\n",
      "       3926, 3941, 3968, 4007, 4053, 4065, 4075, 4078, 4116, 4163, 4176, 4224, 4238, 4271, 4284, 4289, 4294, 4297, 4306, 4317, 4355, 4483, 4497, 4500, 4598, 4639, 4671, 4690, 4724, 4761, 4785, 4807,\n",
      "       4823, 4837, 4860, 4879, 4886, 4890, 4893, 4943, 4966, 4978, 4990, 5001, 5138, 5176, 5288, 5532, 5600, 5634, 5714, 5734, 5769, 5835, 5867, 5888, 5906, 5937, 5955, 5973, 5982, 5997, 6011, 6023,\n",
      "       6035, 6059, 6071, 6081, 6091, 6157, 6160, 6166, 6172, 6173, 6505, 6555, 6560, 6597, 6651, 6755, 6783, 6813, 7094, 7216, 7233, 7333, 7432, 7434, 7498, 7545, 7637, 7821, 7921, 8279, 8325, 8406,\n",
      "       8408, 8410, 8520, 8527, 9009, 9024, 9280, 9382, 9422, 9534, 9587, 9634, 9642, 9664, 9719, 9729, 9733, 9745, 9751, 9768, 9770, 9779, 9808, 9811, 9839, 9867, 9893, 9904, 9905, 9943, 9944, 9982],\n",
      "      dtype=int64),)\n",
      "num correct is  9711  an accuracy of  0.9711971197119712\n",
      "fill_up_last_row.shape (70000, 12)\n",
      "X_num_images 70000 X_image_num_pixels 912\n",
      "num_extra_rows 5\n",
      "2020-06-06 20:21:24.051032 Start of fit\n",
      "Epoch 1/5\n",
      "62995/62995 [==============================] - 36s 576us/sample - loss: 0.2363 - acc: 0.9247\n",
      "Epoch 2/5\n",
      "62995/62995 [==============================] - 36s 574us/sample - loss: 0.0774 - acc: 0.9757\n",
      "Epoch 3/5\n",
      "62995/62995 [==============================] - 35s 560us/sample - loss: 0.0550 - acc: 0.9818\n",
      "Epoch 4/5\n",
      "62995/62995 [==============================] - 35s 563us/sample - loss: 0.0427 - acc: 0.9868\n",
      "Epoch 5/5\n",
      "62995/62995 [==============================] - 36s 574us/sample - loss: 0.0341 - acc: 0.9895\n",
      "2020-06-06 20:24:30.064563 End of fit\n",
      "acc: 98.47%\n",
      "2020-06-06 20:24:35.060571 Start of fit\n",
      "Epoch 1/5\n",
      "62996/62996 [==============================] - 38s 597us/sample - loss: 0.2406 - acc: 0.9233\n",
      "Epoch 2/5\n",
      "62996/62996 [==============================] - 36s 568us/sample - loss: 0.0799 - acc: 0.9746\n",
      "Epoch 3/5\n",
      "62996/62996 [==============================] - 36s 571us/sample - loss: 0.0533 - acc: 0.9830\n",
      "Epoch 4/5\n",
      "62996/62996 [==============================] - 36s 571us/sample - loss: 0.0418 - acc: 0.9868\n",
      "Epoch 5/5\n",
      "62996/62996 [==============================] - 36s 576us/sample - loss: 0.0344 - acc: 0.9888\n",
      "2020-06-06 20:27:43.553474 End of fit\n",
      "acc: 98.29%\n",
      "2020-06-06 20:27:48.489765 Start of fit\n",
      "Epoch 1/5\n",
      "62996/62996 [==============================] - 37s 590us/sample - loss: 0.2426 - acc: 0.9229 - loss: 0.2449 - a\n",
      "Epoch 2/5\n",
      "62996/62996 [==============================] - 36s 573us/sample - loss: 0.0763 - acc: 0.9763\n",
      "Epoch 3/5\n",
      "62996/62996 [==============================] - 36s 568us/sample - loss: 0.0523 - acc: 0.9835\n",
      "Epoch 4/5\n",
      "62996/62996 [==============================] - 36s 572us/sample - loss: 0.0413 - acc: 0.9869\n",
      "Epoch 5/5\n",
      "62996/62996 [==============================] - 36s 570us/sample - loss: 0.0336 - acc: 0.9894\n",
      "2020-06-06 20:31:05.365859 End of fit\n",
      "acc: 98.34%\n",
      "2020-06-06 20:31:10.122295 Start of fit\n",
      "Epoch 1/5\n",
      "62999/62999 [==============================] - 37s 588us/sample - loss: 0.2298 - acc: 0.9269\n",
      "Epoch 2/5\n",
      "62999/62999 [==============================] - 36s 577us/sample - loss: 0.0778 - acc: 0.9757\n",
      "Epoch 3/5\n",
      "62999/62999 [==============================] - 36s 572us/sample - loss: 0.0545 - acc: 0.9822 - loss: 0.0541 - acc - ETA: 0s - loss: 0.0542 - ac\n",
      "Epoch 4/5\n",
      "62999/62999 [==============================] - 35s 558us/sample - loss: 0.0410 - acc: 0.9868\n",
      "Epoch 5/5\n",
      "62999/62999 [==============================] - 35s 559us/sample - loss: 0.0331 - acc: 0.9895\n",
      "2020-06-06 20:34:16.362367 End of fit\n",
      "acc: 98.51%\n",
      "2020-06-06 20:34:21.629506 Start of fit\n",
      "Epoch 1/5\n",
      "63000/63000 [==============================] - 39s 613us/sample - loss: 0.2357 - acc: 0.9245\n",
      "Epoch 2/5\n",
      "63000/63000 [==============================] - 35s 561us/sample - loss: 0.0763 - acc: 0.9757\n",
      "Epoch 3/5\n",
      "63000/63000 [==============================] - 36s 566us/sample - loss: 0.0511 - acc: 0.9839\n",
      "Epoch 4/5\n",
      "63000/63000 [==============================] - 36s 566us/sample - loss: 0.0396 - acc: 0.9871 - loss: 0.0400 - acc: 0.98 - ETA: 0s - loss: 0.0400 -\n",
      "Epoch 5/5\n",
      "63000/63000 [==============================] - 36s 568us/sample - loss: 0.0319 - acc: 0.9894\n",
      "2020-06-06 20:37:29.636928 End of fit\n",
      "acc: 98.67%\n",
      "2020-06-06 20:37:34.471249 Start of fit\n",
      "Epoch 1/5\n",
      "63001/63001 [==============================] - 37s 592us/sample - loss: 0.2368 - acc: 0.9249\n",
      "Epoch 2/5\n",
      "63001/63001 [==============================] - 37s 581us/sample - loss: 0.0774 - acc: 0.9760\n",
      "Epoch 3/5\n",
      "63001/63001 [==============================] - 37s 581us/sample - loss: 0.0544 - acc: 0.9827 - l\n",
      "Epoch 4/5\n",
      "63001/63001 [==============================] - 36s 579us/sample - loss: 0.0426 - acc: 0.9869 - loss: 0.0\n",
      "Epoch 5/5\n",
      "63001/63001 [==============================] - 37s 581us/sample - loss: 0.0348 - acc: 0.9890\n",
      "2020-06-06 20:40:44.538921 End of fit\n",
      "acc: 98.59%\n",
      "2020-06-06 20:40:49.482970 Start of fit\n",
      "Epoch 1/5\n",
      "63002/63002 [==============================] - 37s 594us/sample - loss: 0.2514 - acc: 0.9199\n",
      "Epoch 2/5\n",
      "63002/63002 [==============================] - 35s 561us/sample - loss: 0.0806 - acc: 0.9746\n",
      "Epoch 3/5\n",
      "63002/63002 [==============================] - 35s 550us/sample - loss: 0.0553 - acc: 0.9820\n",
      "Epoch 4/5\n",
      "63002/63002 [==============================] - 35s 555us/sample - loss: 0.0422 - acc: 0.9868 - loss: 0.0424 \n",
      "Epoch 5/5\n",
      "63002/63002 [==============================] - 35s 556us/sample - loss: 0.0340 - acc: 0.9890\n",
      "2020-06-06 20:43:53.284173 End of fit\n",
      "acc: 98.46%\n",
      "2020-06-06 20:43:58.450511 Start of fit\n",
      "Epoch 1/5\n",
      "63003/63003 [==============================] - 36s 571us/sample - loss: 0.2328 - acc: 0.9251\n",
      "Epoch 2/5\n",
      "63003/63003 [==============================] - 36s 567us/sample - loss: 0.0763 - acc: 0.9766 - loss: 0.0774 - ac - ETA: 2s - l - ETA: 1s - loss: 0.\n",
      "Epoch 3/5\n",
      "63003/63003 [==============================] - 35s 557us/sample - loss: 0.0527 - acc: 0.9837 - loss: 0.0529 \n",
      "Epoch 4/5\n",
      "63003/63003 [==============================] - 35s 556us/sample - loss: 0.0404 - acc: 0.9871\n",
      "Epoch 5/5\n",
      "63003/63003 [==============================] - 35s 558us/sample - loss: 0.0326 - acc: 0.9893\n",
      "2020-06-06 20:47:02.291866 End of fit\n",
      "acc: 98.49%\n",
      "2020-06-06 20:47:07.101400 Start of fit\n",
      "Epoch 1/5\n",
      "63004/63004 [==============================] - 37s 586us/sample - loss: 0.2486 - acc: 0.9194\n",
      "Epoch 2/5\n",
      "63004/63004 [==============================] - 35s 561us/sample - loss: 0.0796 - acc: 0.9755\n",
      "Epoch 3/5\n",
      "63004/63004 [==============================] - 36s 564us/sample - loss: 0.0544 - acc: 0.9829 - loss:  - ETA: 0s - loss: 0.0543 - acc: 0.98\n",
      "Epoch 4/5\n",
      "63004/63004 [==============================] - 34s 543us/sample - loss: 0.0424 - acc: 0.9866\n",
      "Epoch 5/5\n",
      "63004/63004 [==============================] - 35s 554us/sample - loss: 0.0337 - acc: 0.9895\n",
      "2020-06-06 20:50:10.358798 End of fit\n",
      "acc: 98.60%\n",
      "2020-06-06 20:50:15.287458 Start of fit\n",
      "Epoch 1/5\n",
      "63004/63004 [==============================] - 37s 593us/sample - loss: 0.2320 - acc: 0.9268\n",
      "Epoch 2/5\n",
      "63004/63004 [==============================] - 36s 573us/sample - loss: 0.0759 - acc: 0.9759\n",
      "Epoch 3/5\n",
      "63004/63004 [==============================] - 36s 573us/sample - loss: 0.0536 - acc: 0.9832\n",
      "Epoch 4/5\n",
      "63004/63004 [==============================] - 36s 574us/sample - loss: 0.0410 - acc: 0.9872\n",
      "Epoch 5/5\n",
      "63004/63004 [==============================] - 36s 572us/sample - loss: 0.0318 - acc: 0.9900\n",
      "2020-06-06 20:53:23.733670 End of fit\n",
      "acc: 98.31%\n",
      "98.47% (+/- 0.12%)\n",
      "2020-06-06 20:53:28.149645 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 8 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 5 7 0 6 8 6 3 9 9 8 8 7 7\n",
      " 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 8 8 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "ndx_errs (array([ 151,  241,  247,  320,  321,  338,  340,  362,  376,  381,  444,  445,  448,  464,  478,  479,  495,  519,  571,  578,  582,  628,  659,  689,  691,  716,  740,  791,  810,  839,  844,  938,\n",
      "        939,  947,  951,  957, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1192, 1212, 1226, 1228, 1232, 1242, 1247, 1270, 1289, 1299, 1319, 1326, 1328, 1331, 1364, 1393, 1414, 1466,\n",
      "       1500, 1522, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1737, 1754, 1782, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2044, 2052, 2070, 2093, 2098, 2109, 2118,\n",
      "       2129, 2130, 2135, 2168, 2177, 2182, 2189, 2224, 2237, 2282, 2293, 2298, 2371, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2462, 2574, 2582, 2607, 2648, 2654, 2730, 2771, 2810, 2853, 2877, 2896,\n",
      "       2927, 2939, 2953, 2998, 3060, 3062, 3073, 3117, 3206, 3261, 3289, 3333, 3369, 3405, 3429, 3475, 3503, 3542, 3558, 3559, 3597, 3629, 3702, 3718, 3726, 3767, 3780, 3808, 3811, 3838, 3853, 3902,\n",
      "       3926, 3941, 3968, 4007, 4053, 4065, 4075, 4078, 4116, 4163, 4176, 4224, 4238, 4271, 4284, 4289, 4294, 4297, 4306, 4317, 4355, 4483, 4497, 4500, 4598, 4639, 4671, 4690, 4724, 4761, 4785, 4807,\n",
      "       4823, 4837, 4860, 4879, 4886, 4890, 4893, 4943, 4966, 4978, 4990, 5001, 5138, 5176, 5288, 5532, 5600, 5634, 5714, 5734, 5769, 5835, 5867, 5888, 5906, 5937, 5955, 5973, 5982, 5997, 6011, 6023,\n",
      "       6035, 6059, 6071, 6081, 6091, 6157, 6160, 6166, 6172, 6173, 6505, 6555, 6560, 6597, 6651, 6755, 6783, 6813, 7094, 7216, 7233, 7333, 7432, 7434, 7498, 7545, 7637, 7821, 7921, 8279, 8325, 8406,\n",
      "       8408, 8410, 8520, 8527, 9009, 9024, 9280, 9382, 9422, 9534, 9587, 9634, 9642, 9664, 9719, 9729, 9733, 9745, 9751, 9768, 9770, 9779, 9808, 9811, 9839, 9867, 9893, 9904, 9905, 9943, 9944, 9982],\n",
      "      dtype=int64),)\n",
      "num correct is  9712  an accuracy of  0.9712\n",
      "2020-06-06 21:06:41.474947 end\n"
     ]
    }
   ],
   "source": [
    "Config.OVERLAP_QUADS_RATIO=0.125\n",
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "Config.OVERLAP_QUADS_RATIO=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s2bestCNNsmall'></a>\n",
    "<a href='#toc'>Goto Table of Contents</a>\n",
    "\n",
    "## Repeat the largest improvement for CNN small set of images\n",
    "\n",
    "## using weighted centroids with parents\n",
    "\n",
    "- CNN acc (6,000 97.26% (+/- 0.77%); 60,000 )\n",
    "- CNN acc (6,000 96.43% (+/- 1.40%); 60,000 )\n",
    "\n",
    "## and the original was\n",
    "- CNN acc (6,000 97.01% (+/- 0.80%); 60,000 )\n",
    "\n",
    "## for an average of 96.90%\n",
    "\n",
    "## whereas the average of all CNN baseline runs for 6,000 was 96.29%\n",
    "- CNN acc (6,000 96.06% (+/- 1.42%); 60,000 99.00% (+/- 0.21%))\n",
    "\n",
    "\n",
    "## So the error reduction is (.90-.29)/3.71=16.4%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-05 16:01:02.915798 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 9 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 9 8 7 2 3 0 4 4 2 4 1 9 5 7 7 2 8 2 6 8 5 7 7 9 1 8 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 9 2 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 8 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 2 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 3 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 6 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 3 8 8 2 7 5 8 9 6 1 8 4 1 2 5 9 1 9 7 5 4 0 8 9 9 1 0 5 2 3 7\n",
      " 8 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 8 4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 2 1 7 0 6 5 4 3 8 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 2 3 1 9 7 5 1 0 8 4 6 2 6 7 9 3 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 5 8 0 3 7 2 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 7 8 3 3 6 7 2 8 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 8 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5 4 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 5\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 8 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 8 8 8 7 4 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 2 3 2 3 9 1 7 4 0 3 5 5 8 6 3 2 6 7 6 6 3 2 7 8 1 1 7 5 6 4 9 5 1 3 3 4 7 8 9 1 1 6 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "<class 'numpy.ndarray'> (0, 170)\n",
      "<class 'numpy.ndarray'> (0, 954)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 954)\n",
      "fill_up_last_row.shape (7000, 26)\n",
      "X_num_images 7000 X_image_num_pixels 954\n",
      "num_extra_rows 7\n",
      "2020-06-05 16:03:18.014713 Start of fit\n",
      "Epoch 1/5\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.6988 - acc: 0.7745\n",
      "Epoch 2/5\n",
      "6296/6296 [==============================] - 5s 743us/sample - loss: 0.2058 - acc: 0.9344\n",
      "Epoch 3/5\n",
      "6296/6296 [==============================] - 4s 693us/sample - loss: 0.1246 - acc: 0.9625\n",
      "Epoch 4/5\n",
      "6296/6296 [==============================] - 5s 754us/sample - loss: 0.0792 - acc: 0.9735\n",
      "Epoch 5/5\n",
      "6296/6296 [==============================] - 5s 719us/sample - loss: 0.0635 - acc: 0.9782\n",
      "2020-06-05 16:03:57.784388 End of fit\n",
      "acc: 98.01%\n",
      "2020-06-05 16:04:03.981343 Start of fit\n",
      "Epoch 1/5\n",
      "6297/6297 [==============================] - 8s 1ms/sample - loss: 0.6754 - acc: 0.7867\n",
      "Epoch 2/5\n",
      "6297/6297 [==============================] - 4s 710us/sample - loss: 0.2007 - acc: 0.9409\n",
      "Epoch 3/5\n",
      "6297/6297 [==============================] - 4s 699us/sample - loss: 0.1178 - acc: 0.9667\n",
      "Epoch 4/5\n",
      "6297/6297 [==============================] - 4s 707us/sample - loss: 0.0805 - acc: 0.9768s - l\n",
      "Epoch 5/5\n",
      "6297/6297 [==============================] - 4s 666us/sample - loss: 0.0614 - acc: 0.9817s - loss\n",
      "2020-06-05 16:04:42.049728 End of fit\n",
      "acc: 97.30%\n",
      "2020-06-05 16:04:47.907252 Start of fit\n",
      "Epoch 1/5\n",
      "6297/6297 [==============================] - 8s 1ms/sample - loss: 0.7710 - acc: 0.7554: 0s - loss: 0.8062 - acc: 0.7 - ETA: 0s - loss: 0.7782 - acc: 0.75\n",
      "Epoch 2/5\n",
      "6297/6297 [==============================] - 4s 684us/sample - loss: 0.2277 - acc: 0.9311s - loss:  - ETA: 2\n",
      "Epoch 3/5\n",
      "6297/6297 [==============================] - 4s 659us/sample - loss: 0.1316 - acc: 0.9589s -\n",
      "Epoch 4/5\n",
      "6297/6297 [==============================] - 5s 723us/sample - loss: 0.0918 - acc: 0.9709s - loss: 0\n",
      "Epoch 5/5\n",
      "6297/6297 [==============================] - 5s 730us/sample - loss: 0.0628 - acc: 0.9798\n",
      "2020-06-05 16:05:26.357145 End of fit\n",
      "acc: 98.01%\n",
      "2020-06-05 16:05:32.126055 Start of fit\n",
      "Epoch 1/5\n",
      "6298/6298 [==============================] - 8s 1ms/sample - loss: 0.6875 - acc: 0.7858 2s - loss: 0.7996\n",
      "Epoch 2/5\n",
      "6298/6298 [==============================] - 4s 682us/sample - loss: 0.2013 - acc: 0.9387s - loss: 0.2078 - acc: 0\n",
      "Epoch 3/5\n",
      "6298/6298 [==============================] - 5s 718us/sample - loss: 0.1169 - acc: 0.9628s - loss: 0.1152 - acc: 0.963 - ETA: 0s - loss: 0.1155 - \n",
      "Epoch 4/5\n",
      "6298/6298 [==============================] - 4s 685us/sample - loss: 0.0796 - acc: 0.9775\n",
      "Epoch 5/5\n",
      "6298/6298 [==============================] - 4s 702us/sample - loss: 0.0602 - acc: 0.9824\n",
      "2020-06-05 16:06:10.090957 End of fit\n",
      "acc: 97.72%\n",
      "2020-06-05 16:06:15.878441 Start of fit\n",
      "Epoch 1/5\n",
      "6298/6298 [==============================] - 8s 1ms/sample - loss: 0.6873 - acc: 0.7799\n",
      "Epoch 2/5\n",
      "6298/6298 [==============================] - 4s 681us/sample - loss: 0.1997 - acc: 0.9359\n",
      "Epoch 3/5\n",
      "6298/6298 [==============================] - 4s 690us/sample - loss: 0.1209 - acc: 0.9614s - loss: 0.1344 - acc: 0. - ETA: 3s - loss: 0.10 - ETA: 2s - - ETA: 0s - loss: 0.1207 - ac\n",
      "Epoch 4/5\n",
      "6298/6298 [==============================] - 4s 698us/sample - loss: 0.0844 - acc: 0.9733s - loss: 0.09\n",
      "Epoch 5/5\n",
      "6298/6298 [==============================] - 4s 670us/sample - loss: 0.0588 - acc: 0.9814\n",
      "2020-06-05 16:06:53.783247 End of fit\n",
      "acc: 96.87%\n",
      "2020-06-05 16:06:59.428182 Start of fit\n",
      "Epoch 1/5\n",
      "6301/6301 [==============================] - 8s 1ms/sample - loss: 0.6466 - acc: 0.8034\n",
      "Epoch 2/5\n",
      "6301/6301 [==============================] - 4s 683us/sample - loss: 0.1804 - acc: 0.9456\n",
      "Epoch 3/5\n",
      "6301/6301 [==============================] - 5s 731us/sample - loss: 0.1150 - acc: 0.9633\n",
      "Epoch 4/5\n",
      "6301/6301 [==============================] - 5s 725us/sample - loss: 0.0755 - acc: 0.9778s - loss: 0.0764 - acc: 0.977 - ETA: 1s - loss: 0.077\n",
      "Epoch 5/5\n",
      "6301/6301 [==============================] - 4s 703us/sample - loss: 0.0584 - acc: 0.9832\n",
      "2020-06-05 16:07:38.076332 End of fit\n",
      "acc: 97.71%\n",
      "2020-06-05 16:07:43.732190 Start of fit\n",
      "Epoch 1/5\n",
      "6301/6301 [==============================] - 8s 1ms/sample - loss: 0.7606 - acc: 0.7542\n",
      "Epoch 2/5\n",
      "6301/6301 [==============================] - 5s 753us/sample - loss: 0.2034 - acc: 0.9384s - lo\n",
      "Epoch 3/5\n",
      "6301/6301 [==============================] - 4s 692us/sample - loss: 0.1155 - acc: 0.9625\n",
      "Epoch 4/5\n",
      "6301/6301 [==============================] - 4s 691us/sample - loss: 0.0817 - acc: 0.9735\n",
      "Epoch 5/5\n",
      "6301/6301 [==============================] - 4s 680us/sample - loss: 0.0589 - acc: 0.9806\n",
      "2020-06-05 16:09:09.679950 End of fit\n",
      "acc: 96.85%\n",
      "2020-06-05 16:09:16.241417 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 8s 1ms/sample - loss: 0.6836 - acc: 0.7773\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 4s 712us/sample - loss: 0.2009 - acc: 0.9362\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 4s 707us/sample - loss: 0.1224 - acc: 0.9629\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 5s 743us/sample - loss: 0.0836 - acc: 0.9746s - loss: 0\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 5s 783us/sample - loss: 0.0563 - acc: 0.9832s - loss: 0.\n",
      "2020-06-05 16:09:57.425829 End of fit\n",
      "acc: 98.13%\n",
      "2020-06-05 16:10:03.444094 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 8s 1ms/sample - loss: 0.7370 - acc: 0.7652\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 4s 688us/sample - loss: 0.1994 - acc: 0.9413\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 5s 717us/sample - loss: 0.1174 - acc: 0.9654s - loss: 0.1197 -\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 4s 685us/sample - loss: 0.0759 - acc: 0.9756s - loss: 0.0758 - a\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 5s 718us/sample - loss: 0.0568 - acc: 0.9821\n",
      "2020-06-05 16:10:42.267940 End of fit\n",
      "acc: 96.12%\n",
      "2020-06-05 16:10:48.888871 Start of fit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 8s 1ms/sample - loss: 0.7031 - acc: 0.7770\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 4s 678us/sample - loss: 0.2042 - acc: 0.9373\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 4s 672us/sample - loss: 0.1264 - acc: 0.9611\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 4s 677us/sample - loss: 0.0800 - acc: 0.9762\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 4s 692us/sample - loss: 0.0595 - acc: 0.9833s - loss: 0.0615 - \n",
      "2020-06-05 16:11:28.378141 End of fit\n",
      "acc: 95.83%\n",
      "97.26% (+/- 0.77%)\n",
      "2020-06-05 16:11:33.916244 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 7 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 8 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 3 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 7 7 9 2 2 4 1 5 8 8 4 2 6 0 6 4 2 9 1 9 5 7 7 2 6 2 6 8 5 7 7 9 1 0 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 7 7 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 5 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 7 2 5 0 6 5 6 3 7 2 0 8 8 5 9 1 1 4 0 7 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 8 0 6 4 8 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 7 8 8 2 7 5 8 9 6 1 8 4 1 2 6 8 1 9 7 5 4 0 8 9 9 1 0 5 8 3 7\n",
      " 0 9 9 0 6 3 9 5 2 1 3 1 3 6 5 7 7 2 2 6 8 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 9 4 6 4 2 1 8 2 5 4 8 3 4 0 0 8 3 2 9 4 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 7 1 7 0 6 5 4 3 3 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 9 8 6 0 2 4 0 2 8 3 1 9 7 5 1 0 8 4 6 2 6 7 9 9 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 0 8 0 3 7 8 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 9 8 3 3 6 7 2 3 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 3 2 7 6 8 4 5 0 4 0 6 1 4 3 2 6 7 2 6 9 3 1 4 6 8 5 9 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 9 8 4 0 2 4 8 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 9\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 9 0 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 2 8 8 7 9 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 7 3 0 3 9 1 4 4 0 3 5 5 8 6 3 0 6 7 6 6 3 2 7 9 1 1 7 9 6 4 9 5 1 5 3 4 7 8 7 1 1 0 9 1 4 4 5 4 0 6 2 2 8 1 5 1 2 0 8 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "ndx_errs (array([ 73, 151, 187, 233, 241, 243, 245, 247, 250, 257, 266, 320, 321, 338, 362, 376, 381, 444, 445, 448, 464, 478, 479, 492, 495, 497, 511, 515, 532, 543, 547, 550, 551, 583, 591, 605, 613, 628,\n",
      "       654, 659, 684, 691, 714, 716, 717, 726, 738, 740, 760, 766, 791, 838, 839, 877, 881, 924, 926, 930, 939, 947, 951, 957, 962, 965, 976, 982], dtype=int64),)\n",
      "num correct is  934  an accuracy of  0.9339999999999999\n",
      "2020-06-05 16:11:43.637926 end\n"
     ]
    }
   ],
   "source": [
    "Config.USE_PARENT_CENTROIDS=True\n",
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=6_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=1_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.USE_PARENT_CENTROIDS=False\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-07 11:56:12.439398 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 9 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 5 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 8 7 9 2 2 4 1 5 9 8 7 2 3 0 4 4 2 4 1 9 5 7 7 2 8 2 6 8 5 7 7 9 1 8 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 9 2 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 8 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 2 2 5 0 6 5 6 3 7 2 0 8 8 5 4 1 1 4 0 3 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 2 6 6 4 9 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 3 8 8 2 7 5 8 9 6 1 8 4 1 2 5 9 1 9 7 5 4 0 8 9 9 1 0 5 2 3 7\n",
      " 8 9 4 0 6 3 9 5 2 1 3 1 3 6 5 7 4 2 2 6 3 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 4 4 6 4 2 1 8 2 5 4 8 8 4 0 0 2 3 2 7 7 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 2 1 7 0 6 5 4 3 8 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 4 0 2 2 3 1 9 7 5 1 0 8 4 6 2 6 7 9 3 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 5 8 0 3 7 2 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 7 8 3 3 6 7 2 8 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 8 2 1 0 8 4 5 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5 4 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 4 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 5\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 4 8 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 8 8 8 7 4 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 2 3 2 3 9 1 7 4 0 3 5 5 8 6 3 2 6 7 6 6 3 2 7 8 1 1 7 5 6 4 9 5 1 3 3 4 7 8 9 1 1 6 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 3 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "<class 'numpy.ndarray'> (0, 170)\n",
      "<class 'numpy.ndarray'> (0, 954)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 954)\n",
      "fill_up_last_row.shape (7000, 26)\n",
      "X_num_images 7000 X_image_num_pixels 954\n",
      "num_extra_rows 7\n",
      "2020-06-07 11:58:30.247566 Start of fit\n",
      "Epoch 1/5\n",
      "6296/6296 [==============================] - 7s 1ms/sample - loss: 0.6897 - acc: 0.7753 2s - loss: 0.832\n",
      "Epoch 2/5\n",
      "6296/6296 [==============================] - 4s 712us/sample - loss: 0.1932 - acc: 0.9417\n",
      "Epoch 3/5\n",
      "6296/6296 [==============================] - 4s 687us/sample - loss: 0.1193 - acc: 0.9627\n",
      "Epoch 4/5\n",
      "6296/6296 [==============================] - 5s 742us/sample - loss: 0.0841 - acc: 0.9735\n",
      "Epoch 5/5\n",
      "6296/6296 [==============================] - 4s 703us/sample - loss: 0.0606 - acc: 0.9811\n",
      "2020-06-07 11:59:06.108165 End of fit\n",
      "acc: 98.44%\n",
      "2020-06-07 11:59:10.971878 Start of fit\n",
      "Epoch 1/5\n",
      "6297/6297 [==============================] - 7s 1ms/sample - loss: 0.6795 - acc: 0.7837\n",
      "Epoch 2/5\n",
      "6297/6297 [==============================] - 4s 678us/sample - loss: 0.1854 - acc: 0.9438\n",
      "Epoch 3/5\n",
      "6297/6297 [==============================] - 4s 675us/sample - loss: 0.1142 - acc: 0.9663\n",
      "Epoch 4/5\n",
      "6297/6297 [==============================] - 4s 689us/sample - loss: 0.0795 - acc: 0.9740\n",
      "Epoch 5/5\n",
      "6297/6297 [==============================] - 4s 690us/sample - loss: 0.0581 - acc: 0.9803\n",
      "2020-06-07 11:59:45.944364 End of fit\n",
      "acc: 93.31%\n",
      "2020-06-07 11:59:50.694371 Start of fit\n",
      "Epoch 1/5\n",
      "6297/6297 [==============================] - 7s 1ms/sample - loss: 0.6624 - acc: 0.7878\n",
      "Epoch 2/5\n",
      "6297/6297 [==============================] - 4s 654us/sample - loss: 0.1900 - acc: 0.9422\n",
      "Epoch 3/5\n",
      "6297/6297 [==============================] - 4s 678us/sample - loss: 0.1141 - acc: 0.9651\n",
      "Epoch 4/5\n",
      "6297/6297 [==============================] - 4s 688us/sample - loss: 0.0759 - acc: 0.9757\n",
      "Epoch 5/5\n",
      "6297/6297 [==============================] - ETA: 0s - loss: 0.0583 - acc: 0.982 - 4s 678us/sample - loss: 0.0581 - acc: 0.9821\n",
      "2020-06-07 12:00:24.850466 End of fit\n",
      "acc: 97.30%\n",
      "2020-06-07 12:00:29.887560 Start of fit\n",
      "Epoch 1/5\n",
      "6298/6298 [==============================] - 7s 1ms/sample - loss: 0.7671 - acc: 0.7487 2s - loss: 0.924\n",
      "Epoch 2/5\n",
      "6298/6298 [==============================] - 4s 672us/sample - loss: 0.2154 - acc: 0.9305\n",
      "Epoch 3/5\n",
      "6298/6298 [==============================] - 4s 634us/sample - loss: 0.1237 - acc: 0.9589s - loss: 0.1260 - acc:\n",
      "Epoch 4/5\n",
      "6298/6298 [==============================] - 4s 690us/sample - loss: 0.0833 - acc: 0.9736s - loss: 0.0843\n",
      "Epoch 5/5\n",
      "6298/6298 [==============================] - 4s 657us/sample - loss: 0.0609 - acc: 0.9822\n",
      "2020-06-07 12:01:06.017795 End of fit\n",
      "acc: 97.15%\n",
      "2020-06-07 12:01:11.112982 Start of fit\n",
      "Epoch 1/5\n",
      "6298/6298 [==============================] - 7s 1ms/sample - loss: 0.7378 - acc: 0.7580\n",
      "Epoch 2/5\n",
      "6298/6298 [==============================] - 4s 666us/sample - loss: 0.1916 - acc: 0.9406\n",
      "Epoch 3/5\n",
      "6298/6298 [==============================] - 4s 619us/sample - loss: 0.1147 - acc: 0.9644s - loss: 0.1162 - acc: 0.96\n",
      "Epoch 4/5\n",
      "6298/6298 [==============================] - 4s 649us/sample - loss: 0.0858 - acc: 0.9722\n",
      "Epoch 5/5\n",
      "6298/6298 [==============================] - 4s 646us/sample - loss: 0.0604 - acc: 0.9806\n",
      "2020-06-07 12:02:13.746871 End of fit\n",
      "acc: 96.72%\n",
      "2020-06-07 12:02:20.183313 Start of fit\n",
      "Epoch 1/5\n",
      "6301/6301 [==============================] - 9s 1ms/sample - loss: 0.6737 - acc: 0.7835\n",
      "Epoch 2/5\n",
      "6301/6301 [==============================] - 5s 733us/sample - loss: 0.1840 - acc: 0.9441\n",
      "Epoch 3/5\n",
      "6301/6301 [==============================] - 5s 716us/sample - loss: 0.1153 - acc: 0.9640\n",
      "Epoch 4/5\n",
      "6301/6301 [==============================] - 5s 851us/sample - loss: 0.0760 - acc: 0.9760\n",
      "Epoch 5/5\n",
      "6301/6301 [==============================] - 5s 740us/sample - loss: 0.0559 - acc: 0.9811\n",
      "2020-06-07 12:03:01.674787 End of fit\n",
      "acc: 96.57%\n",
      "2020-06-07 12:03:07.032638 Start of fit\n",
      "Epoch 1/5\n",
      "6301/6301 [==============================] - 7s 1ms/sample - loss: 0.7084 - acc: 0.7816\n",
      "Epoch 2/5\n",
      "6301/6301 [==============================] - 4s 680us/sample - loss: 0.2014 - acc: 0.9399\n",
      "Epoch 3/5\n",
      "6301/6301 [==============================] - 4s 661us/sample - loss: 0.1158 - acc: 0.9660\n",
      "Epoch 4/5\n",
      "6301/6301 [==============================] - 4s 691us/sample - loss: 0.0807 - acc: 0.9741\n",
      "Epoch 5/5\n",
      "6301/6301 [==============================] - 5s 776us/sample - loss: 0.0574 - acc: 0.9821\n",
      "2020-06-07 12:03:43.866253 End of fit\n",
      "acc: 97.14%\n",
      "2020-06-07 12:03:49.585607 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 8s 1ms/sample - loss: 0.6915 - acc: 0.7768\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 5s 719us/sample - loss: 0.2002 - acc: 0.9367\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 5s 718us/sample - loss: 0.1200 - acc: 0.9619s - loss: 0.\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 5s 756us/sample - loss: 0.0890 - acc: 0.9716\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 5s 719us/sample - loss: 0.0597 - acc: 0.9824\n",
      "2020-06-07 12:04:29.292815 End of fit\n",
      "acc: 95.40%\n",
      "2020-06-07 12:04:34.718985 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 7s 1ms/sample - loss: 0.7012 - acc: 0.7713\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 5s 717us/sample - loss: 0.1887 - acc: 0.9423\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 4s 660us/sample - loss: 0.1106 - acc: 0.9665\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 4s 660us/sample - loss: 0.0760 - acc: 0.9786\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 4s 645us/sample - loss: 0.0530 - acc: 0.9833\n",
      "2020-06-07 12:05:10.604464 End of fit\n",
      "acc: 94.97%\n",
      "2020-06-07 12:05:16.438601 Start of fit\n",
      "Epoch 1/5\n",
      "6304/6304 [==============================] - 7s 1ms/sample - loss: 0.7459 - acc: 0.7606\n",
      "Epoch 2/5\n",
      "6304/6304 [==============================] - 4s 648us/sample - loss: 0.2077 - acc: 0.9348\n",
      "Epoch 3/5\n",
      "6304/6304 [==============================] - 4s 678us/sample - loss: 0.1249 - acc: 0.9624\n",
      "Epoch 4/5\n",
      "6304/6304 [==============================] - 4s 661us/sample - loss: 0.0861 - acc: 0.9749\n",
      "Epoch 5/5\n",
      "6304/6304 [==============================] - 4s 661us/sample - loss: 0.0574 - acc: 0.9811s - loss: \n",
      "2020-06-07 12:05:52.375784 End of fit\n",
      "acc: 97.27%\n",
      "96.43% (+/- 1.40%)\n",
      "2020-06-07 12:05:57.266662 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 7 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 9 8 5 5 1 5 6 0 3 4 4 6 5 4 6 5 4 5 1 4 4 7 2 3 2 7 1 8 1 8 1 8 5 0 8 9 2 3 0 1 1 1 0 9 0 3 1 6\n",
      " 4 2 3 6 1 1 1 3 9 5 2 9 4 5 9 3 9 0 3 6 5 5 7 2 2 7 1 2 8 4 1 7 3 3 8 7 7 9 2 2 4 1 5 8 8 4 2 6 0 6 4 2 9 1 9 5 7 7 2 6 2 6 8 5 7 7 9 1 0 1 8 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 8 2 9 2 0 4 0\n",
      " 0 2 8 4 7 1 2 4 0 2 7 4 3 3 0 0 3 1 9 6 5 2 5 7 7 9 3 0 4 2 0 7 1 1 2 1 5 3 3 9 7 5 6 5 6 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 9 4 6 7 2 5 0 6 5 6 3 7 2 0 8 8 5 9 1 1 4 0 7 3 7 6 1 6 2 1 9 2 8 6 1 9 5\n",
      " 2 5 4 4 2 8 3 8 2 4 5 0 3 1 7 7 5 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 5 9 8 8 3 7 6 0 0 3 0 8 0 6 4 8 3 3 3 2 3 9 1 2 6 8 0 5 6 6 6 7 8 8 2 7 5 8 9 6 1 8 4 1 2 6 8 1 9 7 5 4 0 8 9 9 1 0 5 8 3 7\n",
      " 0 9 9 0 6 3 9 5 2 1 3 1 3 6 5 7 7 2 2 6 8 2 6 5 4 8 9 7 1 3 0 3 8 3 1 9 3 9 4 6 4 2 1 8 2 5 4 8 3 4 0 0 8 3 2 9 4 0 8 7 4 4 7 9 6 9 0 9 8 0 4 6 0 6 3 5 4 8 3 3 9 3 3 3 7 8 0 8 7 1 7 0 6 5 4 3 3 0 9\n",
      " 6 3 8 0 9 9 6 8 6 8 5 9 8 6 0 2 4 0 2 8 3 1 9 7 5 1 0 8 4 6 2 6 7 9 9 2 9 8 2 2 9 2 7 3 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 0 8 0 3 7 8 4 0 9 1 8 6 7 7 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 9 8 3 3 6 7 2 3 5\n",
      " 8 5 1 1 4 4 3 1 0 7 7 0 7 9 4 4 8 5 5 4 0 3 2 7 6 8 4 5 0 4 0 6 1 4 3 2 6 7 2 6 9 3 1 4 6 8 5 9 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 9 8 4 0 2 4 8 1 1 6 4 7 1 9 4 2 4 1 5 5 3 8 3 1 4 5 6 8 9 4 1 9\n",
      " 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 7 3 5 9 6 3 2 6 1 3 6 0 7 2 1 7 1 4 2 4 2 1 7 9 6 1 1 2 9 0 1 7 7 4 8 0 7 3 1 3 1 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 2 8 8 7 9 9 3 0 6 6 3 2 1 3\n",
      " 2 2 9 3 0 0 5 7 8 1 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 7 3 0 3 9 1 4 4 0 3 5 5 8 6 3 0 6 7 6 6 3 2 7 9 1 1 7 9 6 4 9 5 1 5 3 4 7 8 7 1 1 0 9 1 4 4 5 4 0 6 2 2 8 1 5 1 2 0 8 8 1 2 6 7 1 6\n",
      " 2 3 9 0 1 2 2 0 8 9]\n",
      "ndx_errs (array([ 73, 151, 187, 233, 241, 243, 245, 247, 250, 257, 266, 320, 321, 338, 362, 376, 381, 444, 445, 448, 464, 478, 479, 492, 495, 497, 511, 515, 532, 543, 547, 550, 551, 583, 591, 605, 613, 628,\n",
      "       654, 659, 684, 691, 714, 716, 717, 726, 738, 740, 760, 766, 791, 838, 839, 877, 881, 924, 926, 930, 939, 947, 951, 957, 962, 965, 976, 982], dtype=int64),)\n",
      "num correct is  934  an accuracy of  0.9339999999999999\n",
      "2020-06-07 12:06:07.093590 end\n"
     ]
    }
   ],
   "source": [
    "Config.USE_PARENT_CENTROIDS=True\n",
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=6_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=1_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.USE_PARENT_CENTROIDS=False\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s2bestCNNlarge'></a>\n",
    "<a href='#toc'>Goto Table of Contents</a>\n",
    "\n",
    "## Repeat the largest improvement for CNN large 60,000 set of images\n",
    "\n",
    "## using weighted centroids with parents\n",
    "\n",
    "## The previous run increased CNN to (6,000 ; 60,000 99.13% (+/- 0.09%))\n",
    "\n",
    "## whereas the baseline is\n",
    "- CNN acc (6,000 96.06% (+/- 1.42%); 60,000 99.00% (+/- 0.21%))\n",
    "\n",
    "## This run's result is\n",
    "99.06% (+/- 0.09%)\n",
    "\n",
    "## so an average of \n",
    "\n",
    "## and an error reduction of\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-07 04:40:37.819266 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7 7\n",
      " 1 0 1 7 8 9 0 1 2 3 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "<class 'numpy.ndarray'> (0, 170)\n",
      "<class 'numpy.ndarray'> (0, 954)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "****************************** 6000 ******************************\n",
      "****************************** 8000 ******************************\n",
      "****************************** 10000 ******************************\n",
      "****************************** 12000 ******************************\n",
      "****************************** 14000 ******************************\n",
      "****************************** 16000 ******************************\n",
      "****************************** 18000 ******************************\n",
      "****************************** 20000 ******************************\n",
      "****************************** 22000 ******************************\n",
      "****************************** 24000 ******************************\n",
      "****************************** 26000 ******************************\n",
      "****************************** 28000 ******************************\n",
      "****************************** 30000 ******************************\n",
      "****************************** 32000 ******************************\n",
      "****************************** 34000 ******************************\n",
      "****************************** 36000 ******************************\n",
      "****************************** 38000 ******************************\n",
      "****************************** 40000 ******************************\n",
      "****************************** 42000 ******************************\n",
      "****************************** 44000 ******************************\n",
      "****************************** 46000 ******************************\n",
      "****************************** 48000 ******************************\n",
      "****************************** 50000 ******************************\n",
      "****************************** 52000 ******************************\n",
      "****************************** 54000 ******************************\n",
      "****************************** 56000 ******************************\n",
      "****************************** 58000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 954)\n",
      "****************************** 1999 ******************************\n",
      "fill_up_last_row.shape (61999, 26)\n",
      "X_num_images 61999 X_image_num_pixels 954\n",
      "num_extra_rows 7\n",
      "2020-06-07 06:52:04.912213 Start of fit\n",
      "Epoch 1/5\n",
      "55796/55796 [==============================] - 34s 613us/sample - loss: 0.1772 - acc: 0.9439\n",
      "Epoch 2/5\n",
      "55796/55796 [==============================] - 32s 574us/sample - loss: 0.0463 - acc: 0.9859\n",
      "Epoch 3/5\n",
      "55796/55796 [==============================] - 32s 571us/sample - loss: 0.0326 - acc: 0.9903\n",
      "Epoch 4/5\n",
      "55796/55796 [==============================] - 32s 576us/sample - loss: 0.0239 - acc: 0.9924\n",
      "Epoch 5/5\n",
      "55796/55796 [==============================] - 32s 576us/sample - loss: 0.0188 - acc: 0.9944\n",
      "2020-06-07 06:54:58.182292 End of fit\n",
      "acc: 99.11%\n",
      "2020-06-07 06:55:03.435362 Start of fit\n",
      "Epoch 1/5\n",
      "55796/55796 [==============================] - 34s 617us/sample - loss: 0.1760 - acc: 0.9450\n",
      "Epoch 2/5\n",
      "55796/55796 [==============================] - 33s 592us/sample - loss: 0.0466 - acc: 0.9860\n",
      "Epoch 3/5\n",
      "55796/55796 [==============================] - 33s 590us/sample - loss: 0.0330 - acc: 0.9904\n",
      "Epoch 4/5\n",
      "55796/55796 [==============================] - 33s 596us/sample - loss: 0.0236 - acc: 0.9924\n",
      "Epoch 5/5\n",
      "55796/55796 [==============================] - 33s 589us/sample - loss: 0.0190 - acc: 0.9942\n",
      "2020-06-07 06:57:56.787908 End of fit\n",
      "acc: 99.05%\n",
      "2020-06-07 06:58:02.233121 Start of fit\n",
      "Epoch 1/5\n",
      "55796/55796 [==============================] - 33s 595us/sample - loss: 0.1714 - acc: 0.9463 - loss: 0.175\n",
      "Epoch 2/5\n",
      "55796/55796 [==============================] - 32s 570us/sample - loss: 0.0450 - acc: 0.9861\n",
      "Epoch 3/5\n",
      "55796/55796 [==============================] - 32s 572us/sample - loss: 0.0308 - acc: 0.9908\n",
      "Epoch 4/5\n",
      "55796/55796 [==============================] - 32s 572us/sample - loss: 0.0230 - acc: 0.9930 - loss: 0.023\n",
      "Epoch 5/5\n",
      "55796/55796 [==============================] - 32s 573us/sample - loss: 0.0177 - acc: 0.9949\n",
      "2020-06-07 07:00:50.527681 End of fit\n",
      "acc: 98.89%\n",
      "2020-06-07 07:00:55.552373 Start of fit\n",
      "Epoch 1/5\n",
      "55798/55798 [==============================] - 35s 622us/sample - loss: 0.1809 - acc: 0.9439\n",
      "Epoch 2/5\n",
      "55798/55798 [==============================] - 34s 602us/sample - loss: 0.0474 - acc: 0.9854\n",
      "Epoch 3/5\n",
      "55798/55798 [==============================] - 33s 592us/sample - loss: 0.0324 - acc: 0.9895\n",
      "Epoch 4/5\n",
      "55798/55798 [==============================] - 33s 584us/sample - loss: 0.0232 - acc: 0.9928\n",
      "Epoch 5/5\n",
      "55798/55798 [==============================] - 32s 571us/sample - loss: 0.0186 - acc: 0.9941\n",
      "2020-06-07 07:03:48.795466 End of fit\n",
      "acc: 99.06%\n",
      "2020-06-07 07:03:53.642946 Start of fit\n",
      "Epoch 1/5\n",
      "55798/55798 [==============================] - 35s 620us/sample - loss: 0.1742 - acc: 0.9446\n",
      "Epoch 2/5\n",
      "55798/55798 [==============================] - 34s 605us/sample - loss: 0.0465 - acc: 0.9851\n",
      "Epoch 3/5\n",
      "55798/55798 [==============================] - 34s 607us/sample - loss: 0.0317 - acc: 0.9904\n",
      "Epoch 4/5\n",
      "55798/55798 [==============================] - 33s 586us/sample - loss: 0.0232 - acc: 0.9927\n",
      "Epoch 5/5\n",
      "55798/55798 [==============================] - 32s 572us/sample - loss: 0.0183 - acc: 0.9945\n",
      "2020-06-07 07:06:47.111044 End of fit\n",
      "acc: 98.92%\n",
      "2020-06-07 07:06:52.224366 Start of fit\n",
      "Epoch 1/5\n",
      "55798/55798 [==============================] - 33s 592us/sample - loss: 0.1670 - acc: 0.9475\n",
      "Epoch 2/5\n",
      "55798/55798 [==============================] - 32s 566us/sample - loss: 0.0435 - acc: 0.9866 - loss: 0.0434 - acc: 0.\n",
      "Epoch 3/5\n",
      "55798/55798 [==============================] - 32s 565us/sample - loss: 0.0306 - acc: 0.9906\n",
      "Epoch 4/5\n",
      "55798/55798 [==============================] - 32s 567us/sample - loss: 0.0229 - acc: 0.9929\n",
      "Epoch 5/5\n",
      "55798/55798 [==============================] - 32s 567us/sample - loss: 0.0180 - acc: 0.9947\n",
      "2020-06-07 07:09:39.234816 End of fit\n",
      "acc: 98.98%\n",
      "2020-06-07 07:09:44.179315 Start of fit\n",
      "Epoch 1/5\n",
      "55800/55800 [==============================] - 34s 615us/sample - loss: 0.1708 - acc: 0.9459\n",
      "Epoch 2/5\n",
      "55800/55800 [==============================] - 35s 625us/sample - loss: 0.0456 - acc: 0.9861 - loss: 0.04\n",
      "Epoch 3/5\n",
      "55800/55800 [==============================] - 33s 594us/sample - loss: 0.0323 - acc: 0.9904 - loss: 0.0\n",
      "Epoch 4/5\n",
      "55800/55800 [==============================] - 33s 594us/sample - loss: 0.0251 - acc: 0.9920\n",
      "Epoch 5/5\n",
      "55800/55800 [==============================] - 33s 590us/sample - loss: 0.0187 - acc: 0.9944\n",
      "2020-06-07 07:12:39.431183 End of fit\n",
      "acc: 99.06%\n",
      "2020-06-07 07:12:44.467751 Start of fit\n",
      "Epoch 1/5\n",
      "55801/55801 [==============================] - 35s 621us/sample - loss: 0.1765 - acc: 0.9445\n",
      "Epoch 2/5\n",
      "55801/55801 [==============================] - 33s 588us/sample - loss: 0.0457 - acc: 0.9863\n",
      "Epoch 3/5\n",
      "55801/55801 [==============================] - 33s 586us/sample - loss: 0.0309 - acc: 0.9905\n",
      "Epoch 4/5\n",
      "55801/55801 [==============================] - 33s 584us/sample - loss: 0.0233 - acc: 0.9929\n",
      "Epoch 5/5\n",
      "55801/55801 [==============================] - 32s 569us/sample - loss: 0.0188 - acc: 0.9941\n",
      "2020-06-07 07:15:35.779114 End of fit\n",
      "acc: 99.10%\n",
      "2020-06-07 07:15:41.348663 Start of fit\n",
      "Epoch 1/5\n",
      "55803/55803 [==============================] - 37s 664us/sample - loss: 0.1760 - acc: 0.9444\n",
      "Epoch 2/5\n",
      "55803/55803 [==============================] - 35s 622us/sample - loss: 0.0462 - acc: 0.9854\n",
      "Epoch 3/5\n",
      "55803/55803 [==============================] - 33s 595us/sample - loss: 0.0313 - acc: 0.9902\n",
      "Epoch 4/5\n",
      "55803/55803 [==============================] - 34s 609us/sample - loss: 0.0234 - acc: 0.9925\n",
      "Epoch 5/5\n",
      "55803/55803 [==============================] - 33s 586us/sample - loss: 0.0187 - acc: 0.9942\n",
      "2020-06-07 07:18:39.786616 End of fit\n",
      "acc: 99.32%\n",
      "2020-06-07 07:18:45.124073 Start of fit\n",
      "Epoch 1/5\n",
      "55805/55805 [==============================] - 35s 635us/sample - loss: 0.1695 - acc: 0.9467\n",
      "Epoch 2/5\n",
      "55805/55805 [==============================] - 35s 620us/sample - loss: 0.0446 - acc: 0.9861\n",
      "Epoch 3/5\n",
      "55805/55805 [==============================] - 34s 601us/sample - loss: 0.0296 - acc: 0.9908\n",
      "Epoch 4/5\n",
      "55805/55805 [==============================] - 35s 619us/sample - loss: 0.0213 - acc: 0.9935\n",
      "Epoch 5/5\n",
      "55805/55805 [==============================] - 34s 603us/sample - loss: 0.0174 - acc: 0.9949\n",
      "2020-06-07 07:21:44.709963 End of fit\n",
      "acc: 98.77%\n",
      "99.03% (+/- 0.14%)\n",
      "2020-06-07 07:21:49.171535 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 4 8 9 6 9 6 8 3 6 6 8 5 1 4 2 4 4 5 1 1 9 0 2 4 9 5 7 1 8 3 5 6 9 8 7 1 1 6 7 6 3 2 2 0 8 9\n",
      " 2 5 1 0 8 1 4 5 7 9 6 9 0 6 1 5 5 8 3 8 2 6 5 0 7 4 6 1 3 4 7 3 2 3 4 2 5 2 7 1 7 2 6 4 1 5 7 8 6 0 1 8 2 5 7 7 6 9 3 5 2 4 2 4 0 8 8 3 4 9 2 7 5 8 6 3 6 0 8 6 7 3 6 4 9 4 6 6 3 0 4 1 0 1 4 6 2 9 1\n",
      " 1 0 6 3 9]\n",
      "ndx_errs (array([ 151,  241,  247,  318,  320,  321,  362,  376,  381,  444,  445,  448,  464,  479,  495,  519,  550,  578,  582,  628,  659,  691,  716,  726,  740,  760,  839,  881,  883,  924,  926,  938,\n",
      "        939,  947,  951,  956, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1181, 1192, 1226, 1228, 1232, 1242, 1247, 1248, 1270, 1283, 1289, 1299, 1319, 1326, 1331, 1364, 1393, 1414,\n",
      "       1500, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1732, 1737, 1790, 1813, 1878, 1901, 1955, 1970, 1984], dtype=int64),)\n",
      "num correct is  1912  an accuracy of  0.9564782391195598\n",
      "****************************** 3999 ******************************\n",
      "fill_up_last_row.shape (63999, 26)\n",
      "X_num_images 63999 X_image_num_pixels 954\n",
      "num_extra_rows 7\n",
      "2020-06-07 07:25:20.903212 Start of fit\n",
      "Epoch 1/5\n",
      "57595/57595 [==============================] - 37s 643us/sample - loss: 0.1759 - acc: 0.9442\n",
      "Epoch 2/5\n",
      "57595/57595 [==============================] - 36s 624us/sample - loss: 0.0453 - acc: 0.9860\n",
      "Epoch 3/5\n",
      "57595/57595 [==============================] - 37s 634us/sample - loss: 0.0303 - acc: 0.9905\n",
      "Epoch 4/5\n",
      "57595/57595 [==============================] - 36s 631us/sample - loss: 0.0241 - acc: 0.9925\n",
      "Epoch 5/5\n",
      "57595/57595 [==============================] - 37s 635us/sample - loss: 0.0180 - acc: 0.9941\n",
      "2020-06-07 07:28:31.744725 End of fit\n",
      "acc: 98.91%\n",
      "2020-06-07 07:28:37.736736 Start of fit\n",
      "Epoch 1/5\n",
      "57595/57595 [==============================] - 37s 649us/sample - loss: 0.1687 - acc: 0.9475\n",
      "Epoch 2/5\n",
      "57595/57595 [==============================] - 35s 612us/sample - loss: 0.0445 - acc: 0.9858\n",
      "Epoch 3/5\n",
      "57595/57595 [==============================] - 36s 626us/sample - loss: 0.0314 - acc: 0.9899\n",
      "Epoch 4/5\n",
      "57595/57595 [==============================] - 36s 624us/sample - loss: 0.0235 - acc: 0.9927\n",
      "Epoch 5/5\n",
      "57595/57595 [==============================] - 36s 618us/sample - loss: 0.0179 - acc: 0.9940\n",
      "2020-06-07 07:31:46.057004 End of fit\n",
      "acc: 98.80%\n",
      "2020-06-07 07:31:51.528738 Start of fit\n",
      "Epoch 1/5\n",
      "57596/57596 [==============================] - 37s 651us/sample - loss: 0.1769 - acc: 0.9443\n",
      "Epoch 2/5\n",
      "57596/57596 [==============================] - 35s 613us/sample - loss: 0.0470 - acc: 0.9859\n",
      "Epoch 3/5\n",
      "57596/57596 [==============================] - 34s 599us/sample - loss: 0.0315 - acc: 0.9904\n",
      "Epoch 4/5\n",
      "57596/57596 [==============================] - 35s 600us/sample - loss: 0.0231 - acc: 0.9930\n",
      "Epoch 5/5\n",
      "57596/57596 [==============================] - 34s 593us/sample - loss: 0.0183 - acc: 0.9943\n",
      "2020-06-07 07:34:55.368257 End of fit\n",
      "acc: 99.00%\n",
      "2020-06-07 07:35:01.228201 Start of fit\n",
      "Epoch 1/5\n",
      "57598/57598 [==============================] - 37s 648us/sample - loss: 0.1693 - acc: 0.9460 - loss: 0.1715 - ac\n",
      "Epoch 2/5\n",
      "57598/57598 [==============================] - 36s 619us/sample - loss: 0.0448 - acc: 0.9862\n",
      "Epoch 3/5\n",
      "57598/57598 [==============================] - 35s 612us/sample - loss: 0.0313 - acc: 0.9906\n",
      "Epoch 4/5\n",
      "57598/57598 [==============================] - 35s 613us/sample - loss: 0.0235 - acc: 0.9928\n",
      "Epoch 5/5\n",
      "57598/57598 [==============================] - 35s 606us/sample - loss: 0.0185 - acc: 0.9942\n",
      "2020-06-07 07:38:07.775801 End of fit\n",
      "acc: 99.02%\n",
      "2020-06-07 07:38:13.592106 Start of fit\n",
      "Epoch 1/5\n",
      "57598/57598 [==============================] - 37s 641us/sample - loss: 0.1718 - acc: 0.9456\n",
      "Epoch 2/5\n",
      "57598/57598 [==============================] - 35s 606us/sample - loss: 0.0461 - acc: 0.9861\n",
      "Epoch 3/5\n",
      "57598/57598 [==============================] - 35s 600us/sample - loss: 0.0328 - acc: 0.9899\n",
      "Epoch 4/5\n",
      "57598/57598 [==============================] - 35s 608us/sample - loss: 0.0241 - acc: 0.9926 - lo\n",
      "Epoch 5/5\n",
      "57598/57598 [==============================] - 35s 615us/sample - loss: 0.0184 - acc: 0.9942 -\n",
      "2020-06-07 07:41:18.997049 End of fit\n",
      "acc: 98.89%\n",
      "2020-06-07 07:41:24.949539 Start of fit\n",
      "Epoch 1/5\n",
      "57599/57599 [==============================] - 37s 645us/sample - loss: 0.1796 - acc: 0.9435 -\n",
      "Epoch 2/5\n",
      "57599/57599 [==============================] - 35s 609us/sample - loss: 0.0467 - acc: 0.9853 - loss: 0.0467 - acc: 0.98\n",
      "Epoch 3/5\n",
      "57599/57599 [==============================] - 35s 615us/sample - loss: 0.0321 - acc: 0.9901\n",
      "Epoch 4/5\n",
      "57599/57599 [==============================] - 35s 611us/sample - loss: 0.0236 - acc: 0.9925 -\n",
      "Epoch 5/5\n",
      "57599/57599 [==============================] - 35s 613us/sample - loss: 0.0189 - acc: 0.9943\n",
      "2020-06-07 07:44:31.480448 End of fit\n",
      "acc: 98.92%\n",
      "2020-06-07 07:44:37.405412 Start of fit\n",
      "Epoch 1/5\n",
      "57602/57602 [==============================] - 37s 641us/sample - loss: 0.1829 - acc: 0.9423\n",
      "Epoch 2/5\n",
      "57602/57602 [==============================] - 35s 611us/sample - loss: 0.0480 - acc: 0.9846\n",
      "Epoch 3/5\n",
      "57602/57602 [==============================] - 35s 614us/sample - loss: 0.0331 - acc: 0.9895\n",
      "Epoch 4/5\n",
      "57602/57602 [==============================] - 34s 593us/sample - loss: 0.0246 - acc: 0.9923\n",
      "Epoch 5/5\n",
      "57602/57602 [==============================] - 34s 593us/sample - loss: 0.0200 - acc: 0.9941\n",
      "2020-06-07 07:47:41.393765 End of fit\n",
      "acc: 99.02%\n",
      "2020-06-07 07:47:46.985779 Start of fit\n",
      "Epoch 1/5\n",
      "57602/57602 [==============================] - 45s 785us/sample - loss: 0.1716 - acc: 0.9467\n",
      "Epoch 2/5\n",
      "57602/57602 [==============================] - 36s 632us/sample - loss: 0.0457 - acc: 0.9862\n",
      "Epoch 3/5\n",
      "57602/57602 [==============================] - 37s 637us/sample - loss: 0.0312 - acc: 0.9906\n",
      "Epoch 4/5\n",
      "57602/57602 [==============================] - 37s 636us/sample - loss: 0.0237 - acc: 0.9927\n",
      "Epoch 5/5\n",
      "57602/57602 [==============================] - 36s 631us/sample - loss: 0.0183 - acc: 0.9946 - loss: 0\n",
      "2020-06-07 07:51:06.757457 End of fit\n",
      "acc: 98.97%\n",
      "2020-06-07 07:51:12.578369 Start of fit\n",
      "Epoch 1/5\n",
      "57602/57602 [==============================] - 37s 643us/sample - loss: 0.1813 - acc: 0.9428\n",
      "Epoch 2/5\n",
      "57602/57602 [==============================] - 36s 623us/sample - loss: 0.0456 - acc: 0.9860\n",
      "Epoch 3/5\n",
      "57602/57602 [==============================] - 36s 627us/sample - loss: 0.0322 - acc: 0.9898\n",
      "Epoch 4/5\n",
      "57602/57602 [==============================] - 36s 621us/sample - loss: 0.0239 - acc: 0.9928\n",
      "Epoch 5/5\n",
      "57602/57602 [==============================] - 36s 627us/sample - loss: 0.0184 - acc: 0.9939\n",
      "2020-06-07 07:54:23.519688 End of fit\n",
      "acc: 99.14%\n",
      "2020-06-07 07:54:29.813647 Start of fit\n",
      "Epoch 1/5\n",
      "57604/57604 [==============================] - 38s 654us/sample - loss: 0.1703 - acc: 0.9473\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57604/57604 [==============================] - 35s 601us/sample - loss: 0.0445 - acc: 0.9861\n",
      "Epoch 3/5\n",
      "57604/57604 [==============================] - 35s 605us/sample - loss: 0.0307 - acc: 0.9905\n",
      "Epoch 4/5\n",
      "57604/57604 [==============================] - 34s 590us/sample - loss: 0.0226 - acc: 0.9933\n",
      "Epoch 5/5\n",
      "57604/57604 [==============================] - 34s 591us/sample - loss: 0.0179 - acc: 0.9943\n",
      "2020-06-07 07:57:36.000654 End of fit\n",
      "acc: 99.00%\n",
      "98.97% (+/- 0.09%)\n",
      "2020-06-07 07:57:40.851410 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 9 1 1 0 7 5 9 9 1 9 5 9 2 5 0 4 1 0 8 9 0 8 9 8 9 4 2 5 7 9 8 9 8 0 9 9 6 8 9 9 5 9 8 6 1\n",
      " 0 3 3 5 2 1 6 3 0 2 8 1 5 6 2 3 0 2 2 6 4 3 5 5 1 7 2 1 6 9 1 3 9 5 5 1 6 2 2 8 6 7 1 4 6 0 6 0 3 3 2 2 3 6 8 9 8 5 3 8 5 4 5 2 0 5 6 3 2 8 3 9 9 3 7 9 4 6 7 1 3 7 3 6 6 0 9 0 1 9 9 2 8 8 0 1 6 9 7\n",
      " 5 3 4 7 4]\n",
      "ndx_errs (array([ 151,  241,  247,  318,  320,  321,  362,  376,  381,  444,  445,  448,  464,  479,  495,  519,  550,  578,  582,  628,  659,  691,  716,  726,  740,  760,  839,  881,  883,  924,  926,  938,\n",
      "        939,  947,  951,  956, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1181, 1192, 1226, 1228, 1232, 1242, 1247, 1248, 1270, 1283, 1289, 1299, 1319, 1326, 1331, 1364, 1393, 1414,\n",
      "       1500, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1732, 1737, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2098, 2109, 2118, 2129, 2130, 2135,\n",
      "       2177, 2182, 2189, 2224, 2237, 2282, 2292, 2293, 2298, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2462, 2574, 2607, 2648, 2654, 2721, 2730, 2758, 2771, 2810, 2851, 2853, 2896, 2927, 2939, 2945,\n",
      "       2952, 2953, 2998, 3005, 3030, 3060, 3062, 3073, 3117, 3136, 3206, 3240, 3262, 3289, 3323, 3333, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3629, 3664, 3702, 3718, 3726, 3742, 3757, 3767, 3780,\n",
      "       3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3968], dtype=int64),)\n",
      "num correct is  3830  an accuracy of  0.9577394348587147\n",
      "****************************** 5999 ******************************\n",
      "fill_up_last_row.shape (65999, 26)\n",
      "X_num_images 65999 X_image_num_pixels 954\n",
      "num_extra_rows 7\n",
      "2020-06-07 08:04:12.135724 Start of fit\n",
      "Epoch 1/5\n",
      "59395/59395 [==============================] - 37s 631us/sample - loss: 0.1624 - acc: 0.9491\n",
      "Epoch 2/5\n",
      "59395/59395 [==============================] - 36s 605us/sample - loss: 0.0448 - acc: 0.9857\n",
      "Epoch 3/5\n",
      "59395/59395 [==============================] - 35s 598us/sample - loss: 0.0314 - acc: 0.9903\n",
      "Epoch 4/5\n",
      "59395/59395 [==============================] - 36s 601us/sample - loss: 0.0223 - acc: 0.9933\n",
      "Epoch 5/5\n",
      "59395/59395 [==============================] - 36s 611us/sample - loss: 0.0182 - acc: 0.9943\n",
      "2020-06-07 08:07:23.061257 End of fit\n",
      "acc: 98.82%\n",
      "2020-06-07 08:07:29.475959 Start of fit\n",
      "Epoch 1/5\n",
      "59397/59397 [==============================] - 39s 658us/sample - loss: 0.1672 - acc: 0.9470\n",
      "Epoch 2/5\n",
      "59397/59397 [==============================] - 37s 628us/sample - loss: 0.0447 - acc: 0.9863\n",
      "Epoch 3/5\n",
      "59397/59397 [==============================] - 36s 611us/sample - loss: 0.0306 - acc: 0.9904\n",
      "Epoch 4/5\n",
      "59397/59397 [==============================] - 36s 605us/sample - loss: 0.0229 - acc: 0.9928\n",
      "Epoch 5/5\n",
      "59397/59397 [==============================] - 36s 602us/sample - loss: 0.0183 - acc: 0.9941\n",
      "2020-06-07 08:10:42.382798 End of fit\n",
      "acc: 99.02%\n",
      "2020-06-07 08:10:48.709397 Start of fit\n",
      "Epoch 1/5\n",
      "59397/59397 [==============================] - 38s 635us/sample - loss: 0.1673 - acc: 0.9478\n",
      "Epoch 2/5\n",
      "59397/59397 [==============================] - 37s 618us/sample - loss: 0.0462 - acc: 0.9856\n",
      "Epoch 3/5\n",
      "59397/59397 [==============================] - 36s 611us/sample - loss: 0.0307 - acc: 0.9904\n",
      "Epoch 4/5\n",
      "59397/59397 [==============================] - 36s 606us/sample - loss: 0.0237 - acc: 0.9927\n",
      "Epoch 5/5\n",
      "59397/59397 [==============================] - 36s 614us/sample - loss: 0.0188 - acc: 0.9942\n",
      "2020-06-07 08:14:00.464971 End of fit\n",
      "acc: 99.05%\n",
      "2020-06-07 08:14:06.586962 Start of fit\n",
      "Epoch 1/5\n",
      "59399/59399 [==============================] - 39s 660us/sample - loss: 0.1711 - acc: 0.9463\n",
      "Epoch 2/5\n",
      "59399/59399 [==============================] - 38s 642us/sample - loss: 0.0463 - acc: 0.9862\n",
      "Epoch 3/5\n",
      "59399/59399 [==============================] - 38s 633us/sample - loss: 0.0320 - acc: 0.9901\n",
      "Epoch 4/5\n",
      "59399/59399 [==============================] - 37s 624us/sample - loss: 0.0226 - acc: 0.9929\n",
      "Epoch 5/5\n",
      "59399/59399 [==============================] - 37s 619us/sample - loss: 0.0180 - acc: 0.9943\n",
      "2020-06-07 08:17:24.039640 End of fit\n",
      "acc: 98.91%\n",
      "2020-06-07 08:17:30.426991 Start of fit\n",
      "Epoch 1/5\n",
      "59399/59399 [==============================] - 39s 662us/sample - loss: 0.1686 - acc: 0.9461\n",
      "Epoch 2/5\n",
      "59399/59399 [==============================] - 38s 636us/sample - loss: 0.0446 - acc: 0.9855\n",
      "Epoch 3/5\n",
      "59399/59399 [==============================] - 37s 629us/sample - loss: 0.0310 - acc: 0.9903\n",
      "Epoch 4/5\n",
      "59399/59399 [==============================] - 38s 634us/sample - loss: 0.0226 - acc: 0.9930\n",
      "Epoch 5/5\n",
      "59399/59399 [==============================] - 39s 655us/sample - loss: 0.0175 - acc: 0.9946\n",
      "2020-06-07 08:21:35.362360 End of fit\n",
      "acc: 98.89%\n",
      "2020-06-07 08:21:45.242552 Start of fit\n",
      "Epoch 1/5\n",
      "59399/59399 [==============================] - 39s 660us/sample - loss: 0.1550 - acc: 0.9507\n",
      "Epoch 2/5\n",
      "59399/59399 [==============================] - 37s 624us/sample - loss: 0.0430 - acc: 0.9862\n",
      "Epoch 3/5\n",
      "59399/59399 [==============================] - 37s 626us/sample - loss: 0.0295 - acc: 0.9911\n",
      "Epoch 4/5\n",
      "59399/59399 [==============================] - 37s 618us/sample - loss: 0.0227 - acc: 0.9928\n",
      "Epoch 5/5\n",
      "59399/59399 [==============================] - 37s 627us/sample - loss: 0.0180 - acc: 0.9944\n",
      "2020-06-07 08:25:11.395953 End of fit\n",
      "acc: 99.03%\n",
      "2020-06-07 08:25:18.108923 Start of fit\n",
      "Epoch 1/5\n",
      "59400/59400 [==============================] - 39s 663us/sample - loss: 0.1686 - acc: 0.9458\n",
      "Epoch 2/5\n",
      "59400/59400 [==============================] - 38s 634us/sample - loss: 0.0443 - acc: 0.9866\n",
      "Epoch 3/5\n",
      "59400/59400 [==============================] - 37s 629us/sample - loss: 0.0309 - acc: 0.9905\n",
      "Epoch 4/5\n",
      "59400/59400 [==============================] - 38s 635us/sample - loss: 0.0229 - acc: 0.9928\n",
      "Epoch 5/5\n",
      "59400/59400 [==============================] - 38s 633us/sample - loss: 0.0173 - acc: 0.9945\n",
      "2020-06-07 08:28:37.802564 End of fit\n",
      "acc: 98.82%\n",
      "2020-06-07 08:28:44.427440 Start of fit\n",
      "Epoch 1/5\n",
      "59400/59400 [==============================] - 41s 682us/sample - loss: 0.1732 - acc: 0.9460\n",
      "Epoch 2/5\n",
      "59400/59400 [==============================] - 38s 640us/sample - loss: 0.0449 - acc: 0.9863\n",
      "Epoch 3/5\n",
      "59400/59400 [==============================] - 40s 667us/sample - loss: 0.0318 - acc: 0.9905\n",
      "Epoch 4/5\n",
      "59400/59400 [==============================] - 38s 639us/sample - loss: 0.0238 - acc: 0.9927\n",
      "Epoch 5/5\n",
      "59400/59400 [==============================] - 38s 645us/sample - loss: 0.0185 - acc: 0.9946\n",
      "2020-06-07 08:32:09.063062 End of fit\n",
      "acc: 98.67%\n",
      "2020-06-07 08:32:16.302771 Start of fit\n",
      "Epoch 1/5\n",
      "59402/59402 [==============================] - 40s 681us/sample - loss: 0.1634 - acc: 0.9486\n",
      "Epoch 2/5\n",
      "59402/59402 [==============================] - 39s 651us/sample - loss: 0.0431 - acc: 0.9862\n",
      "Epoch 3/5\n",
      "59402/59402 [==============================] - 42s 700us/sample - loss: 0.0300 - acc: 0.9906\n",
      "Epoch 4/5\n",
      "59402/59402 [==============================] - 42s 713us/sample - loss: 0.0231 - acc: 0.9930\n",
      "Epoch 5/5\n",
      "59402/59402 [==============================] - 41s 688us/sample - loss: 0.0187 - acc: 0.9942\n",
      "2020-06-07 08:35:51.363524 End of fit\n",
      "acc: 99.00%\n",
      "2020-06-07 08:35:59.169933 Start of fit\n",
      "Epoch 1/5\n",
      "59403/59403 [==============================] - 43s 717us/sample - loss: 0.1747 - acc: 0.9446\n",
      "Epoch 2/5\n",
      "59403/59403 [==============================] - 39s 658us/sample - loss: 0.0453 - acc: 0.9859\n",
      "Epoch 3/5\n",
      "59403/59403 [==============================] - 38s 643us/sample - loss: 0.0325 - acc: 0.9901\n",
      "Epoch 4/5\n",
      "59403/59403 [==============================] - 37s 616us/sample - loss: 0.0235 - acc: 0.9925\n",
      "Epoch 5/5\n",
      "59403/59403 [==============================] - 36s 606us/sample - loss: 0.0191 - acc: 0.9940\n",
      "2020-06-07 08:39:21.862092 End of fit\n",
      "acc: 98.95%\n",
      "98.92% (+/- 0.11%)\n",
      "2020-06-07 08:39:27.654187 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 2 3 4 5 6 7 8 9 8 4 1 3 7 5 2 8 0 7 3 9 9 0 9 1 1 5 8 8 6 3 2 1 8 3 2 6 5 6 9 6 1 0 5 3 1 9\n",
      " 2 1 9 6 0 4 6 1 7 3 8 9 2 9 6 5 8 3 5 4 1 6 1 0 9 6 2 5 4 2 3 4 4 6 0 0 2 0 1 2 3 4 3 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 8 4 5 6 7 8 9 8 6 5 0 6 8 9 4 1 9 5 8 0 9 8 9 1 4 0 5 3 2 1 5 4 0 7 6 0 1 7 0\n",
      " 6 8 9 3 1]\n",
      "ndx_errs (array([ 151,  241,  247,  318,  320,  321,  362,  376,  381,  444,  445,  448,  464,  479,  495,  519,  550,  578,  582,  628,  659,  691,  716,  726,  740,  760,  839,  881,  883,  924,  926,  938,\n",
      "        939,  947,  951,  956, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1181, 1192, 1226, 1228, 1232, 1242, 1247, 1248, 1270, 1283, 1289, 1299, 1319, 1326, 1331, 1364, 1393, 1414,\n",
      "       1500, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1732, 1737, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2098, 2109, 2118, 2129, 2130, 2135,\n",
      "       2177, 2182, 2189, 2224, 2237, 2282, 2292, 2293, 2298, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2462, 2574, 2607, 2648, 2654, 2721, 2730, 2758, 2771, 2810, 2851, 2853, 2896, 2927, 2939, 2945,\n",
      "       2952, 2953, 2998, 3005, 3030, 3060, 3062, 3073, 3117, 3136, 3206, 3240, 3262, 3289, 3323, 3333, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3629, 3664, 3702, 3718, 3726, 3742, 3757, 3767, 3780,\n",
      "       3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3968, 4007, 4065, 4072, 4075, 4078, 4116, 4176, 4224, 4269, 4271, 4284, 4289, 4294, 4297, 4306, 4355, 4360, 4437, 4483, 4489, 4497, 4500, 4505,\n",
      "       4567, 4575, 4578, 4598, 4639, 4671, 4731, 4737, 4743, 4761, 4785, 4807, 4823, 4837, 4860, 4874, 4886, 4890, 4893, 4911, 4943, 4966, 4976, 4990, 5068, 5176, 5278, 5532, 5600, 5634, 5705, 5769,\n",
      "       5835, 5841, 5858, 5867, 5887, 5888, 5906, 5914, 5937, 5955, 5973, 5975, 5982, 5997], dtype=int64),)\n",
      "num correct is  5761  an accuracy of  0.9603267211201867\n",
      "****************************** 7999 ******************************\n",
      "fill_up_last_row.shape (67999, 26)\n",
      "X_num_images 67999 X_image_num_pixels 954\n",
      "num_extra_rows 7\n",
      "2020-06-07 08:48:55.108304 Start of fit\n",
      "Epoch 1/5\n",
      "61195/61195 [==============================] - 41s 663us/sample - loss: 0.1636 - acc: 0.9479\n",
      "Epoch 2/5\n",
      "61195/61195 [==============================] - 39s 640us/sample - loss: 0.0442 - acc: 0.9865\n",
      "Epoch 3/5\n",
      "61195/61195 [==============================] - 39s 638us/sample - loss: 0.0305 - acc: 0.9907 - loss: 0\n",
      "Epoch 4/5\n",
      "61195/61195 [==============================] - 39s 636us/sample - loss: 0.0235 - acc: 0.9930\n",
      "Epoch 5/5\n",
      "61195/61195 [==============================] - 39s 637us/sample - loss: 0.0176 - acc: 0.9945\n",
      "2020-06-07 08:52:21.015655 End of fit\n",
      "acc: 98.97%\n",
      "2020-06-07 08:52:27.566008 Start of fit\n",
      "Epoch 1/5\n",
      "61195/61195 [==============================] - 40s 660us/sample - loss: 0.1630 - acc: 0.9494\n",
      "Epoch 2/5\n",
      "61195/61195 [==============================] - 39s 634us/sample - loss: 0.0442 - acc: 0.9855\n",
      "Epoch 3/5\n",
      "61195/61195 [==============================] - 39s 632us/sample - loss: 0.0300 - acc: 0.9909\n",
      "Epoch 4/5\n",
      "61195/61195 [==============================] - 39s 632us/sample - loss: 0.0222 - acc: 0.9930\n",
      "Epoch 5/5\n",
      "61195/61195 [==============================] - 39s 639us/sample - loss: 0.0173 - acc: 0.9947\n",
      "2020-06-07 08:55:52.195997 End of fit\n",
      "acc: 99.09%\n",
      "2020-06-07 08:55:58.496974 Start of fit\n",
      "Epoch 1/5\n",
      "61196/61196 [==============================] - 41s 664us/sample - loss: 0.1576 - acc: 0.9503\n",
      "Epoch 2/5\n",
      "61196/61196 [==============================] - 39s 643us/sample - loss: 0.0424 - acc: 0.9868\n",
      "Epoch 3/5\n",
      "61196/61196 [==============================] - 40s 647us/sample - loss: 0.0287 - acc: 0.9913\n",
      "Epoch 4/5\n",
      "61196/61196 [==============================] - 39s 636us/sample - loss: 0.0215 - acc: 0.9933\n",
      "Epoch 5/5\n",
      "61196/61196 [==============================] - 39s 644us/sample - loss: 0.0171 - acc: 0.9949\n",
      "2020-06-07 08:59:25.475665 End of fit\n",
      "acc: 99.32%\n",
      "2020-06-07 08:59:32.114573 Start of fit\n",
      "Epoch 1/5\n",
      "61196/61196 [==============================] - 41s 677us/sample - loss: 0.1659 - acc: 0.9477\n",
      "Epoch 2/5\n",
      "61196/61196 [==============================] - 39s 645us/sample - loss: 0.0438 - acc: 0.9860\n",
      "Epoch 3/5\n",
      "61196/61196 [==============================] - 40s 651us/sample - loss: 0.0306 - acc: 0.9904\n",
      "Epoch 4/5\n",
      "61196/61196 [==============================] - 40s 653us/sample - loss: 0.0227 - acc: 0.9929\n",
      "Epoch 5/5\n",
      "61196/61196 [==============================] - 40s 654us/sample - loss: 0.0176 - acc: 0.9944\n",
      "2020-06-07 09:03:01.713331 End of fit\n",
      "acc: 98.78%\n",
      "2020-06-07 09:03:08.562919 Start of fit\n",
      "Epoch 1/5\n",
      "61199/61199 [==============================] - 42s 689us/sample - loss: 0.1654 - acc: 0.9486\n",
      "Epoch 2/5\n",
      "61199/61199 [==============================] - 41s 665us/sample - loss: 0.0453 - acc: 0.9861\n",
      "Epoch 3/5\n",
      "61199/61199 [==============================] - 40s 658us/sample - loss: 0.0319 - acc: 0.9905\n",
      "Epoch 4/5\n",
      "61199/61199 [==============================] - 41s 666us/sample - loss: 0.0236 - acc: 0.9926\n",
      "Epoch 5/5\n",
      "61199/61199 [==============================] - 38s 620us/sample - loss: 0.0176 - acc: 0.9945\n",
      "2020-06-07 09:06:39.801705 End of fit\n",
      "acc: 99.06%\n",
      "2020-06-07 09:06:46.219736 Start of fit\n",
      "Epoch 1/5\n",
      "61199/61199 [==============================] - 42s 689us/sample - loss: 0.1720 - acc: 0.9458\n",
      "Epoch 2/5\n",
      "61199/61199 [==============================] - 39s 638us/sample - loss: 0.0441 - acc: 0.9864\n",
      "Epoch 3/5\n",
      "61199/61199 [==============================] - 40s 656us/sample - loss: 0.0309 - acc: 0.9903\n",
      "Epoch 4/5\n",
      "61199/61199 [==============================] - 39s 637us/sample - loss: 0.0223 - acc: 0.9931\n",
      "Epoch 5/5\n",
      "61199/61199 [==============================] - 39s 645us/sample - loss: 0.0180 - acc: 0.9942\n",
      "2020-06-07 09:10:15.364632 End of fit\n",
      "acc: 99.07%\n",
      "2020-06-07 09:10:21.938937 Start of fit\n",
      "Epoch 1/5\n",
      "61200/61200 [==============================] - 43s 709us/sample - loss: 0.1693 - acc: 0.9480\n",
      "Epoch 2/5\n",
      "61200/61200 [==============================] - 41s 665us/sample - loss: 0.0438 - acc: 0.9866\n",
      "Epoch 3/5\n",
      "61200/61200 [==============================] - 41s 668us/sample - loss: 0.0302 - acc: 0.9912\n",
      "Epoch 4/5\n",
      "61200/61200 [==============================] - 42s 687us/sample - loss: 0.0231 - acc: 0.9929\n",
      "Epoch 5/5\n",
      "61200/61200 [==============================] - 40s 660us/sample - loss: 0.0180 - acc: 0.9944\n",
      "2020-06-07 09:13:59.961361 End of fit\n",
      "acc: 99.18%\n",
      "2020-06-07 09:14:07.139607 Start of fit\n",
      "Epoch 1/5\n",
      "61203/61203 [==============================] - 43s 700us/sample - loss: 0.1683 - acc: 0.9472\n",
      "Epoch 2/5\n",
      "61203/61203 [==============================] - 41s 666us/sample - loss: 0.0450 - acc: 0.9864\n",
      "Epoch 3/5\n",
      "61203/61203 [==============================] - 40s 653us/sample - loss: 0.0306 - acc: 0.9904\n",
      "Epoch 4/5\n",
      "61203/61203 [==============================] - 41s 675us/sample - loss: 0.0237 - acc: 0.9924\n",
      "Epoch 5/5\n",
      "61203/61203 [==============================] - 40s 659us/sample - loss: 0.0169 - acc: 0.9951\n",
      "2020-06-07 09:17:42.493981 End of fit\n",
      "acc: 98.94%\n",
      "2020-06-07 09:17:49.099832 Start of fit\n",
      "Epoch 1/5\n",
      "61204/61204 [==============================] - 43s 698us/sample - loss: 0.1525 - acc: 0.9525\n",
      "Epoch 2/5\n",
      "61204/61204 [==============================] - 41s 674us/sample - loss: 0.0428 - acc: 0.9870\n",
      "Epoch 3/5\n",
      "61204/61204 [==============================] - 41s 665us/sample - loss: 0.0297 - acc: 0.9912\n",
      "Epoch 4/5\n",
      "61204/61204 [==============================] - 41s 668us/sample - loss: 0.0226 - acc: 0.9929\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61204/61204 [==============================] - 41s 674us/sample - loss: 0.0179 - acc: 0.9944\n",
      "2020-06-07 09:21:27.514743 End of fit\n",
      "acc: 99.10%\n",
      "2020-06-07 09:21:34.690033 Start of fit\n",
      "Epoch 1/5\n",
      "61204/61204 [==============================] - 41s 670us/sample - loss: 0.1641 - acc: 0.9483\n",
      "Epoch 2/5\n",
      "61204/61204 [==============================] - 39s 634us/sample - loss: 0.0435 - acc: 0.9868 - loss: 0.0437 \n",
      "Epoch 3/5\n",
      "61204/61204 [==============================] - 39s 634us/sample - loss: 0.0305 - acc: 0.9907\n",
      "Epoch 4/5\n",
      "61204/61204 [==============================] - 39s 639us/sample - loss: 0.0234 - acc: 0.9934\n",
      "Epoch 5/5\n",
      "61204/61204 [==============================] - 38s 626us/sample - loss: 0.0175 - acc: 0.9944\n",
      "2020-06-07 09:25:00.768881 End of fit\n",
      "acc: 99.22%\n",
      "99.07% (+/- 0.15%)\n",
      "2020-06-07 09:25:06.531671 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 3 5 6 7 8 9 0 1 2 3 5 6 7 8 9 9 7 0 9 0 1 5 8 8 0 9 3 2 7 8 4 6 1 0 4 9 4 2 0 5 0 1 6 9 3 2\n",
      " 9 1 6 0 1 1 8 7 7 6 3 6 0 7 2 4 1 7 0 6 7 1 2 5 8 1 1 2 8 7 6 8 7 1 6 2 9 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 8 9 5 7 0 3 1 6 8 4 1 5 6 4 2 7 8 1 3 4 3 4 7 2 0 5 0 1 9 2 3\n",
      " 2 3 5 5 7]\n",
      "ndx_errs (array([ 151,  241,  247,  318,  320,  321,  362,  376,  381,  444,  445,  448,  464,  479,  495,  519,  550,  578,  582,  628,  659,  691,  716,  726,  740,  760,  839,  881,  883,  924,  926,  938,\n",
      "        939,  947,  951,  956, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1181, 1192, 1226, 1228, 1232, 1242, 1247, 1248, 1270, 1283, 1289, 1299, 1319, 1326, 1331, 1364, 1393, 1414,\n",
      "       1500, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1732, 1737, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2098, 2109, 2118, 2129, 2130, 2135,\n",
      "       2177, 2182, 2189, 2224, 2237, 2282, 2292, 2293, 2298, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2462, 2574, 2607, 2648, 2654, 2721, 2730, 2758, 2771, 2810, 2851, 2853, 2896, 2927, 2939, 2945,\n",
      "       2952, 2953, 2998, 3005, 3030, 3060, 3062, 3073, 3117, 3136, 3206, 3240, 3262, 3289, 3323, 3333, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3629, 3664, 3702, 3718, 3726, 3742, 3757, 3767, 3780,\n",
      "       3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3968, 4007, 4065, 4072, 4075, 4078, 4116, 4176, 4224, 4269, 4271, 4284, 4289, 4294, 4297, 4306, 4355, 4360, 4437, 4483, 4489, 4497, 4500, 4505,\n",
      "       4567, 4575, 4578, 4598, 4639, 4671, 4731, 4737, 4743, 4761, 4785, 4807, 4823, 4837, 4860, 4874, 4886, 4890, 4893, 4911, 4943, 4966, 4976, 4990, 5068, 5176, 5278, 5532, 5600, 5634, 5705, 5769,\n",
      "       5835, 5841, 5858, 5867, 5887, 5888, 5906, 5914, 5937, 5955, 5973, 5975, 5982, 5997, 6023, 6035, 6037, 6071, 6081, 6091, 6157, 6166, 6172, 6173, 6555, 6560, 6597, 6641, 6651, 6755, 6783, 6813,\n",
      "       7216, 7333, 7432, 7434, 7492, 7545, 7797, 7921], dtype=int64),)\n",
      "num correct is  7735  an accuracy of  0.9669958744843106\n",
      "****************************** 9999 ******************************\n",
      "fill_up_last_row.shape (69999, 26)\n",
      "X_num_images 69999 X_image_num_pixels 954\n",
      "num_extra_rows 7\n",
      "2020-06-07 09:37:26.809605 Start of fit\n",
      "Epoch 1/5\n",
      "62994/62994 [==============================] - 45s 722us/sample - loss: 0.1642 - acc: 0.9480\n",
      "Epoch 2/5\n",
      "62994/62994 [==============================] - 43s 676us/sample - loss: 0.0418 - acc: 0.9873\n",
      "Epoch 3/5\n",
      "62994/62994 [==============================] - 42s 672us/sample - loss: 0.0306 - acc: 0.9911\n",
      "Epoch 4/5\n",
      "62994/62994 [==============================] - 42s 662us/sample - loss: 0.0224 - acc: 0.9930\n",
      "Epoch 5/5\n",
      "62994/62994 [==============================] - 41s 658us/sample - loss: 0.0173 - acc: 0.9944\n",
      "2020-06-07 09:41:13.619579 End of fit\n",
      "acc: 99.07%\n",
      "2020-06-07 09:41:21.647648 Start of fit\n",
      "Epoch 1/5\n",
      "62995/62995 [==============================] - 44s 692us/sample - loss: 0.1562 - acc: 0.9505\n",
      "Epoch 2/5\n",
      "62995/62995 [==============================] - 41s 644us/sample - loss: 0.0411 - acc: 0.9872\n",
      "Epoch 3/5\n",
      "62995/62995 [==============================] - 41s 648us/sample - loss: 0.0290 - acc: 0.9912 - loss: 0.0288 - acc: 0.9 - ETA: 1s - \n",
      "Epoch 4/5\n",
      "62995/62995 [==============================] - 42s 663us/sample - loss: 0.0218 - acc: 0.9936\n",
      "Epoch 5/5\n",
      "62995/62995 [==============================] - 42s 663us/sample - loss: 0.0175 - acc: 0.9948\n",
      "2020-06-07 09:45:01.688267 End of fit\n",
      "acc: 99.16%\n",
      "2020-06-07 09:45:10.452353 Start of fit\n",
      "Epoch 1/5\n",
      "62995/62995 [==============================] - 44s 706us/sample - loss: 0.1559 - acc: 0.9513\n",
      "Epoch 2/5\n",
      "62995/62995 [==============================] - 41s 659us/sample - loss: 0.0420 - acc: 0.9864\n",
      "Epoch 3/5\n",
      "62995/62995 [==============================] - 42s 663us/sample - loss: 0.0294 - acc: 0.9910\n",
      "Epoch 4/5\n",
      "62995/62995 [==============================] - 42s 663us/sample - loss: 0.0215 - acc: 0.9928\n",
      "Epoch 5/5\n",
      "62995/62995 [==============================] - 40s 638us/sample - loss: 0.0167 - acc: 0.9952\n",
      "2020-06-07 09:48:52.762064 End of fit\n",
      "acc: 98.97%\n",
      "2020-06-07 09:49:01.260324 Start of fit\n",
      "Epoch 1/5\n",
      "62998/62998 [==============================] - 45s 713us/sample - loss: 0.1622 - acc: 0.9501\n",
      "Epoch 2/5\n",
      "62998/62998 [==============================] - 43s 675us/sample - loss: 0.0431 - acc: 0.9868\n",
      "Epoch 3/5\n",
      "62998/62998 [==============================] - 43s 677us/sample - loss: 0.0296 - acc: 0.9905\n",
      "Epoch 4/5\n",
      "62998/62998 [==============================] - 42s 670us/sample - loss: 0.0219 - acc: 0.9930\n",
      "Epoch 5/5\n",
      "62998/62998 [==============================] - 40s 634us/sample - loss: 0.0173 - acc: 0.9945\n",
      "2020-06-07 09:52:45.385943 End of fit\n",
      "acc: 99.14%\n",
      "2020-06-07 09:52:53.216578 Start of fit\n",
      "Epoch 1/5\n",
      "62999/62999 [==============================] - 46s 726us/sample - loss: 0.1612 - acc: 0.9493\n",
      "Epoch 2/5\n",
      "62999/62999 [==============================] - 42s 672us/sample - loss: 0.0420 - acc: 0.9866\n",
      "Epoch 3/5\n",
      "62999/62999 [==============================] - 42s 669us/sample - loss: 0.0290 - acc: 0.9906 \n",
      "Epoch 4/5\n",
      "62999/62999 [==============================] - 42s 673us/sample - loss: 0.0216 - acc: 0.9932\n",
      "Epoch 5/5\n",
      "62999/62999 [==============================] - 42s 669us/sample - loss: 0.0175 - acc: 0.9947\n",
      "2020-06-07 09:56:39.423601 End of fit\n",
      "acc: 98.94%\n",
      "2020-06-07 09:56:47.983896 Start of fit\n",
      "Epoch 1/5\n",
      "63001/63001 [==============================] - 49s 774us/sample - loss: 0.1622 - acc: 0.9481\n",
      "Epoch 2/5\n",
      "63001/63001 [==============================] - 44s 704us/sample - loss: 0.0421 - acc: 0.9869\n",
      "Epoch 3/5\n",
      "63001/63001 [==============================] - 44s 701us/sample - loss: 0.0294 - acc: 0.9907\n",
      "Epoch 4/5\n",
      "63001/63001 [==============================] - 45s 713us/sample - loss: 0.0229 - acc: 0.9929\n",
      "Epoch 5/5\n",
      "63001/63001 [==============================] - 44s 706us/sample - loss: 0.0171 - acc: 0.9950 - loss: 0.0\n",
      "2020-06-07 10:00:46.518116 End of fit\n",
      "acc: 98.90%\n",
      "2020-06-07 10:00:55.484983 Start of fit\n",
      "Epoch 1/5\n",
      "63001/63001 [==============================] - 47s 747us/sample - loss: 0.1530 - acc: 0.9515\n",
      "Epoch 2/5\n",
      "63001/63001 [==============================] - 44s 705us/sample - loss: 0.0409 - acc: 0.9872\n",
      "Epoch 3/5\n",
      "63001/63001 [==============================] - 45s 720us/sample - loss: 0.0284 - acc: 0.9912\n",
      "Epoch 4/5\n",
      "63001/63001 [==============================] - 46s 731us/sample - loss: 0.0215 - acc: 0.9935 - loss: 0.0217 - ac - ETA: 0s - loss: 0.0215 - acc: 0.99\n",
      "Epoch 5/5\n",
      "63001/63001 [==============================] - 44s 703us/sample - loss: 0.0163 - acc: 0.9950\n",
      "2020-06-07 10:04:55.292106 End of fit\n",
      "acc: 99.29%\n",
      "2020-06-07 10:05:03.820037 Start of fit\n",
      "Epoch 1/5\n",
      "63002/63002 [==============================] - 45s 709us/sample - loss: 0.1544 - acc: 0.9509\n",
      "Epoch 2/5\n",
      "63002/63002 [==============================] - 45s 710us/sample - loss: 0.0402 - acc: 0.9879\n",
      "Epoch 3/5\n",
      "63002/63002 [==============================] - 41s 651us/sample - loss: 0.0280 - acc: 0.9911\n",
      "Epoch 4/5\n",
      "63002/63002 [==============================] - 41s 646us/sample - loss: 0.0213 - acc: 0.9936\n",
      "Epoch 5/5\n",
      "63002/63002 [==============================] - 40s 632us/sample - loss: 0.0167 - acc: 0.9951\n",
      "2020-06-07 10:08:46.748050 End of fit\n",
      "acc: 98.93%\n",
      "2020-06-07 10:08:55.391745 Start of fit\n",
      "Epoch 1/5\n",
      "63003/63003 [==============================] - 43s 678us/sample - loss: 0.1614 - acc: 0.9485\n",
      "Epoch 2/5\n",
      "63003/63003 [==============================] - 41s 646us/sample - loss: 0.0446 - acc: 0.9857\n",
      "Epoch 3/5\n",
      "63003/63003 [==============================] - 41s 657us/sample - loss: 0.0303 - acc: 0.9904\n",
      "Epoch 4/5\n",
      "63003/63003 [==============================] - 41s 645us/sample - loss: 0.0228 - acc: 0.9930 - loss: 0.0\n",
      "Epoch 5/5\n",
      "63003/63003 [==============================] - 39s 624us/sample - loss: 0.0177 - acc: 0.9945\n",
      "2020-06-07 10:12:32.695319 End of fit\n",
      "acc: 98.84%\n",
      "2020-06-07 10:12:40.893451 Start of fit\n",
      "Epoch 1/5\n",
      "63003/63003 [==============================] - 43s 687us/sample - loss: 0.1519 - acc: 0.9521\n",
      "Epoch 2/5\n",
      "63003/63003 [==============================] - 39s 620us/sample - loss: 0.0409 - acc: 0.9877\n",
      "Epoch 3/5\n",
      "63003/63003 [==============================] - 40s 638us/sample - loss: 0.0277 - acc: 0.9913\n",
      "Epoch 4/5\n",
      "63003/63003 [==============================] - 41s 647us/sample - loss: 0.0220 - acc: 0.9933\n",
      "Epoch 5/5\n",
      "63003/63003 [==============================] - 41s 659us/sample - loss: 0.0172 - acc: 0.9945 - loss:\n",
      "2020-06-07 10:16:18.050850 End of fit\n",
      "acc: 98.96%\n",
      "99.02% (+/- 0.13%)\n",
      "2020-06-07 10:16:24.222876 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 2 0 7 7 5 8 2 9 8 6 7 3 4 6 5 7 0 4 7 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 6 7 0 6 8 6 3 9 9 8 8 7\n",
      " 7 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0\n",
      " 1 2 3 4 5]\n",
      "ndx_errs (array([ 151,  241,  247,  318,  320,  321,  362,  376,  381,  444,  445,  448,  464,  479,  495,  519,  550,  578,  582,  628,  659,  691,  716,  726,  740,  760,  839,  881,  883,  924,  926,  938,\n",
      "        939,  947,  951,  956, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1181, 1192, 1226, 1228, 1232, 1242, 1247, 1248, 1270, 1283, 1289, 1299, 1319, 1326, 1331, 1364, 1393, 1414,\n",
      "       1500, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1732, 1737, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2098, 2109, 2118, 2129, 2130, 2135,\n",
      "       2177, 2182, 2189, 2224, 2237, 2282, 2292, 2293, 2298, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2462, 2574, 2607, 2648, 2654, 2721, 2730, 2758, 2771, 2810, 2851, 2853, 2896, 2927, 2939, 2945,\n",
      "       2952, 2953, 2998, 3005, 3030, 3060, 3062, 3073, 3117, 3136, 3206, 3240, 3262, 3289, 3323, 3333, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3629, 3664, 3702, 3718, 3726, 3742, 3757, 3767, 3780,\n",
      "       3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3968, 4007, 4065, 4072, 4075, 4078, 4116, 4176, 4224, 4269, 4271, 4284, 4289, 4294, 4297, 4306, 4355, 4360, 4437, 4483, 4489, 4497, 4500, 4505,\n",
      "       4567, 4575, 4578, 4598, 4639, 4671, 4731, 4737, 4743, 4761, 4785, 4807, 4823, 4837, 4860, 4874, 4886, 4890, 4893, 4911, 4943, 4966, 4976, 4990, 5068, 5176, 5278, 5532, 5600, 5634, 5705, 5769,\n",
      "       5835, 5841, 5858, 5867, 5887, 5888, 5906, 5914, 5937, 5955, 5973, 5975, 5982, 5997, 6023, 6035, 6037, 6071, 6081, 6091, 6157, 6166, 6172, 6173, 6555, 6560, 6597, 6641, 6651, 6755, 6783, 6813,\n",
      "       7216, 7333, 7432, 7434, 7492, 7545, 7797, 7921, 8095, 8277, 8279, 8325, 8406, 8408, 8410, 8520, 8527, 9009, 9024, 9211, 9280, 9382, 9422, 9587, 9624, 9634, 9642, 9664, 9719, 9729, 9745, 9749,\n",
      "       9751, 9768, 9770, 9779, 9792, 9811, 9832, 9839, 9863, 9867, 9883, 9893, 9904, 9905, 9982], dtype=int64),)\n",
      "num correct is  9696  an accuracy of  0.9696969696969697\n",
      "fill_up_last_row.shape (70000, 26)\n",
      "X_num_images 70000 X_image_num_pixels 954\n",
      "num_extra_rows 7\n",
      "2020-06-07 10:29:54.929126 Start of fit\n",
      "Epoch 1/5\n",
      "62995/62995 [==============================] - 43s 690us/sample - loss: 0.1631 - acc: 0.9482\n",
      "Epoch 2/5\n",
      "62995/62995 [==============================] - ETA: 0s - loss: 0.0428 - acc: 0.986 - 40s 639us/sample - loss: 0.0428 - acc: 0.9866\n",
      "Epoch 3/5\n",
      "62995/62995 [==============================] - 40s 635us/sample - loss: 0.0297 - acc: 0.9907\n",
      "Epoch 4/5\n",
      "62995/62995 [==============================] - 42s 661us/sample - loss: 0.0221 - acc: 0.9935\n",
      "Epoch 5/5\n",
      "62995/62995 [==============================] - 42s 660us/sample - loss: 0.0173 - acc: 0.9949\n",
      "2020-06-07 10:33:36.704077 End of fit\n",
      "acc: 98.92%\n",
      "2020-06-07 10:33:46.846143 Start of fit\n",
      "Epoch 1/5\n",
      "62996/62996 [==============================] - 42s 672us/sample - loss: 0.1625 - acc: 0.9494\n",
      "Epoch 2/5\n",
      "62996/62996 [==============================] - 41s 657us/sample - loss: 0.0432 - acc: 0.9869\n",
      "Epoch 3/5\n",
      "62996/62996 [==============================] - 40s 633us/sample - loss: 0.0293 - acc: 0.9908\n",
      "Epoch 4/5\n",
      "62996/62996 [==============================] - 40s 643us/sample - loss: 0.0220 - acc: 0.9935\n",
      "Epoch 5/5\n",
      "62996/62996 [==============================] - 40s 633us/sample - loss: 0.0179 - acc: 0.9945\n",
      "2020-06-07 10:37:24.727704 End of fit\n",
      "acc: 98.96%\n",
      "2020-06-07 10:37:34.059762 Start of fit\n",
      "Epoch 1/5\n",
      "62996/62996 [==============================] - 48s 762us/sample - loss: 0.1626 - acc: 0.9493\n",
      "Epoch 2/5\n",
      "62996/62996 [==============================] - 45s 717us/sample - loss: 0.0443 - acc: 0.9860 - loss: 0.04\n",
      "Epoch 3/5\n",
      "62996/62996 [==============================] - 44s 691us/sample - loss: 0.0292 - acc: 0.9907\n",
      "Epoch 4/5\n",
      "62996/62996 [==============================] - 45s 718us/sample - loss: 0.0223 - acc: 0.9927 - loss: 0.0223 -\n",
      "Epoch 5/5\n",
      "62996/62996 [==============================] - 45s 718us/sample - loss: 0.0170 - acc: 0.9947 - loss: 0.0163 -  - ETA: 1s - \n",
      "2020-06-07 10:41:34.540252 End of fit\n",
      "acc: 99.04%\n",
      "2020-06-07 10:41:42.791050 Start of fit\n",
      "Epoch 1/5\n",
      "62999/62999 [==============================] - 49s 771us/sample - loss: 0.1620 - acc: 0.9489 - loss: 0.1629 - acc\n",
      "Epoch 2/5\n",
      "62999/62999 [==============================] - 44s 692us/sample - loss: 0.0432 - acc: 0.9868\n",
      "Epoch 3/5\n",
      "62999/62999 [==============================] - 43s 690us/sample - loss: 0.0295 - acc: 0.9907\n",
      "Epoch 4/5\n",
      "62999/62999 [==============================] - 44s 701us/sample - loss: 0.0228 - acc: 0.9932\n",
      "Epoch 5/5\n",
      "62999/62999 [==============================] - 44s 696us/sample - loss: 0.0175 - acc: 0.9947\n",
      "2020-06-07 10:45:40.004550 End of fit\n",
      "acc: 99.11%\n",
      "2020-06-07 10:45:49.098893 Start of fit\n",
      "Epoch 1/5\n",
      "63000/63000 [==============================] - 48s 757us/sample - loss: 0.1591 - acc: 0.9499\n",
      "Epoch 2/5\n",
      "63000/63000 [==============================] - 44s 705us/sample - loss: 0.0427 - acc: 0.9874 - loss: - ETA: \n",
      "Epoch 3/5\n",
      "63000/63000 [==============================] - 44s 702us/sample - loss: 0.0292 - acc: 0.9912 - lo\n",
      "Epoch 4/5\n",
      "63000/63000 [==============================] - 43s 687us/sample - loss: 0.0213 - acc: 0.9936\n",
      "Epoch 5/5\n",
      "63000/63000 [==============================] - 43s 686us/sample - loss: 0.0176 - acc: 0.9945\n",
      "2020-06-07 10:49:44.830394 End of fit\n",
      "acc: 98.99%\n",
      "2020-06-07 10:49:52.727204 Start of fit\n",
      "Epoch 1/5\n",
      "63001/63001 [==============================] - 48s 760us/sample - loss: 0.1579 - acc: 0.9507 - loss: 0.1588 - acc\n",
      "Epoch 2/5\n",
      "63001/63001 [==============================] - 44s 701us/sample - loss: 0.0422 - acc: 0.9870\n",
      "Epoch 3/5\n",
      "63001/63001 [==============================] - 45s 715us/sample - loss: 0.0292 - acc: 0.9913 - loss: 0.029\n",
      "Epoch 4/5\n",
      "63001/63001 [==============================] - 45s 707us/sample - loss: 0.0215 - acc: 0.9930 - loss: 0.0212 - \n",
      "Epoch 5/5\n",
      "63001/63001 [==============================] - 45s 718us/sample - loss: 0.0171 - acc: 0.9949 - \n",
      "2020-06-07 10:53:50.941987 End of fit\n",
      "acc: 99.07%\n",
      "2020-06-07 10:53:58.424644 Start of fit\n",
      "Epoch 1/5\n",
      "63002/63002 [==============================] - 47s 745us/sample - loss: 0.1564 - acc: 0.9515\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63002/63002 [==============================] - 43s 677us/sample - loss: 0.0411 - acc: 0.9868\n",
      "Epoch 3/5\n",
      "63002/63002 [==============================] - 43s 679us/sample - loss: 0.0290 - acc: 0.9912 -\n",
      "Epoch 4/5\n",
      "63002/63002 [==============================] - 43s 682us/sample - loss: 0.0226 - acc: 0.9931\n",
      "Epoch 5/5\n",
      "63002/63002 [==============================] - 43s 679us/sample - loss: 0.0172 - acc: 0.9948\n",
      "2020-06-07 10:57:47.621879 End of fit\n",
      "acc: 99.21%\n",
      "2020-06-07 10:57:55.376820 Start of fit\n",
      "Epoch 1/5\n",
      "63003/63003 [==============================] - 46s 737us/sample - loss: 0.1638 - acc: 0.9481\n",
      "Epoch 2/5\n",
      "63003/63003 [==============================] - 44s 693us/sample - loss: 0.0420 - acc: 0.9864\n",
      "Epoch 3/5\n",
      "63003/63003 [==============================] - 44s 702us/sample - loss: 0.0281 - acc: 0.9914\n",
      "Epoch 4/5\n",
      "63003/63003 [==============================] - 44s 694us/sample - loss: 0.0219 - acc: 0.9933\n",
      "Epoch 5/5\n",
      "63003/63003 [==============================] - 44s 699us/sample - loss: 0.0165 - acc: 0.9947\n",
      "2020-06-07 11:01:49.840852 End of fit\n",
      "acc: 99.17%\n",
      "2020-06-07 11:01:57.973011 Start of fit\n",
      "Epoch 1/5\n",
      "63004/63004 [==============================] - 47s 742us/sample - loss: 0.1577 - acc: 0.9506\n",
      "Epoch 2/5\n",
      "63004/63004 [==============================] - 43s 690us/sample - loss: 0.0403 - acc: 0.9871\n",
      "Epoch 3/5\n",
      "63004/63004 [==============================] - 43s 689us/sample - loss: 0.0281 - acc: 0.9914\n",
      "Epoch 4/5\n",
      "63004/63004 [==============================] - 43s 682us/sample - loss: 0.0218 - acc: 0.9936\n",
      "Epoch 5/5\n",
      "63004/63004 [==============================] - 44s 696us/sample - loss: 0.0170 - acc: 0.9946\n",
      "2020-06-07 11:05:50.234182 End of fit\n",
      "acc: 99.06%\n",
      "2020-06-07 11:05:58.350666 Start of fit\n",
      "Epoch 1/5\n",
      "63004/63004 [==============================] - 45s 715us/sample - loss: 0.1668 - acc: 0.9472 - l\n",
      "Epoch 2/5\n",
      "63004/63004 [==============================] - 43s 686us/sample - loss: 0.0438 - acc: 0.9867\n",
      "Epoch 3/5\n",
      "63004/63004 [==============================] - 43s 676us/sample - loss: 0.0300 - acc: 0.9911\n",
      "Epoch 4/5\n",
      "63004/63004 [==============================] - 44s 705us/sample - loss: 0.0230 - acc: 0.9929\n",
      "Epoch 5/5\n",
      "63004/63004 [==============================] - 43s 676us/sample - loss: 0.0173 - acc: 0.9949\n",
      "2020-06-07 11:09:47.640762 End of fit\n",
      "acc: 99.04%\n",
      "99.06% (+/- 0.09%)\n",
      "2020-06-07 11:09:54.116699 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 5 7 0 4 7 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 6 7 0 6 8 6 3 9 9 8 8 7 7\n",
      " 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "ndx_errs (array([ 151,  241,  247,  318,  320,  321,  362,  376,  381,  444,  445,  448,  464,  479,  495,  519,  550,  578,  582,  628,  659,  691,  716,  726,  740,  760,  839,  881,  883,  924,  926,  938,\n",
      "        939,  947,  951,  956, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1181, 1192, 1226, 1228, 1232, 1242, 1247, 1248, 1270, 1283, 1289, 1299, 1319, 1326, 1331, 1364, 1393, 1414,\n",
      "       1500, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1732, 1737, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2098, 2109, 2118, 2129, 2130, 2135,\n",
      "       2177, 2182, 2189, 2224, 2237, 2282, 2292, 2293, 2298, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2462, 2574, 2607, 2648, 2654, 2721, 2730, 2758, 2771, 2810, 2851, 2853, 2896, 2927, 2939, 2945,\n",
      "       2952, 2953, 2998, 3005, 3030, 3060, 3062, 3073, 3117, 3136, 3206, 3240, 3262, 3289, 3323, 3333, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3629, 3664, 3702, 3718, 3726, 3742, 3757, 3767, 3780,\n",
      "       3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3968, 4007, 4065, 4072, 4075, 4078, 4116, 4176, 4224, 4269, 4271, 4284, 4289, 4294, 4297, 4306, 4355, 4360, 4437, 4483, 4489, 4497, 4500, 4505,\n",
      "       4567, 4575, 4578, 4598, 4639, 4671, 4731, 4737, 4743, 4761, 4785, 4807, 4823, 4837, 4860, 4874, 4886, 4890, 4893, 4911, 4943, 4966, 4976, 4990, 5068, 5176, 5278, 5532, 5600, 5634, 5705, 5769,\n",
      "       5835, 5841, 5858, 5867, 5887, 5888, 5906, 5914, 5937, 5955, 5973, 5975, 5982, 5997, 6023, 6035, 6037, 6071, 6081, 6091, 6157, 6166, 6172, 6173, 6555, 6560, 6597, 6641, 6651, 6755, 6783, 6813,\n",
      "       7216, 7333, 7432, 7434, 7492, 7545, 7797, 7921, 8095, 8277, 8279, 8325, 8406, 8408, 8410, 8520, 8527, 9009, 9024, 9211, 9280, 9382, 9422, 9587, 9624, 9634, 9642, 9664, 9719, 9729, 9745, 9749,\n",
      "       9751, 9768, 9770, 9779, 9792, 9811, 9832, 9839, 9863, 9867, 9883, 9893, 9904, 9905, 9982], dtype=int64),)\n",
      "num correct is  9697  an accuracy of  0.9697\n",
      "2020-06-07 11:23:21.110661 end\n"
     ]
    }
   ],
   "source": [
    "Config.USE_PARENT_CENTROIDS=True\n",
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.USE_PARENT_CENTROIDS=False\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-05 16:11:43.715738 start\n",
      "ytest [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 8 7 0 4 2 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 5 7 0 6 8 6 3 9 9 8 2 7 7\n",
      " 1 0 1 7 8 9 0 1 2 3 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "<class 'numpy.ndarray'> (0, 170)\n",
      "<class 'numpy.ndarray'> (0, 954)\n",
      "****************************** 0 ******************************\n",
      "****************************** 2000 ******************************\n",
      "****************************** 4000 ******************************\n",
      "****************************** 6000 ******************************\n",
      "****************************** 8000 ******************************\n",
      "****************************** 10000 ******************************\n",
      "****************************** 12000 ******************************\n",
      "****************************** 14000 ******************************\n",
      "****************************** 16000 ******************************\n",
      "****************************** 18000 ******************************\n",
      "****************************** 20000 ******************************\n",
      "****************************** 22000 ******************************\n",
      "****************************** 24000 ******************************\n",
      "****************************** 26000 ******************************\n",
      "****************************** 28000 ******************************\n",
      "****************************** 30000 ******************************\n",
      "****************************** 32000 ******************************\n",
      "****************************** 34000 ******************************\n",
      "****************************** 36000 ******************************\n",
      "****************************** 38000 ******************************\n",
      "****************************** 40000 ******************************\n",
      "****************************** 42000 ******************************\n",
      "****************************** 44000 ******************************\n",
      "****************************** 46000 ******************************\n",
      "****************************** 48000 ******************************\n",
      "****************************** 50000 ******************************\n",
      "****************************** 52000 ******************************\n",
      "****************************** 54000 ******************************\n",
      "****************************** 56000 ******************************\n",
      "****************************** 58000 ******************************\n",
      "<class 'numpy.ndarray'> (0, 954)\n",
      "****************************** 1999 ******************************\n",
      "fill_up_last_row.shape (61999, 26)\n",
      "X_num_images 61999 X_image_num_pixels 954\n",
      "num_extra_rows 7\n",
      "2020-06-05 18:22:41.986046 Start of fit\n",
      "Epoch 1/5\n",
      "55796/55796 [==============================] - 45s 802us/sample - loss: 0.1840 - acc: 0.9413\n",
      "Epoch 2/5\n",
      "55796/55796 [==============================] - 38s 678us/sample - loss: 0.0475 - acc: 0.9853\n",
      "Epoch 3/5\n",
      "55796/55796 [==============================] - 39s 700us/sample - loss: 0.0321 - acc: 0.9899\n",
      "Epoch 4/5\n",
      "55796/55796 [==============================] - 39s 693us/sample - loss: 0.0227 - acc: 0.9930\n",
      "Epoch 5/5\n",
      "55796/55796 [==============================] - 37s 668us/sample - loss: 0.0185 - acc: 0.9945 - loss: 0.0185 - acc: 0.994\n",
      "2020-06-05 18:26:19.278550 End of fit\n",
      "acc: 98.34%\n",
      "2020-06-05 18:26:31.967592 Start of fit\n",
      "Epoch 1/5\n",
      "55796/55796 [==============================] - 46s 828us/sample - loss: 0.1777 - acc: 0.9449\n",
      "Epoch 2/5\n",
      "55796/55796 [==============================] - 37s 665us/sample - loss: 0.0455 - acc: 0.9859\n",
      "Epoch 3/5\n",
      "55796/55796 [==============================] - 38s 682us/sample - loss: 0.0319 - acc: 0.9900\n",
      "Epoch 4/5\n",
      "55796/55796 [==============================] - 38s 673us/sample - loss: 0.0234 - acc: 0.9929\n",
      "Epoch 5/5\n",
      "55796/55796 [==============================] - 37s 669us/sample - loss: 0.0177 - acc: 0.9947\n",
      "2020-06-05 18:30:09.765370 End of fit\n",
      "acc: 98.89%\n",
      "2020-06-05 18:30:22.146368 Start of fit\n",
      "Epoch 1/5\n",
      "55796/55796 [==============================] - 43s 767us/sample - loss: 0.1703 - acc: 0.9453\n",
      "Epoch 2/5\n",
      "55796/55796 [==============================] - 39s 703us/sample - loss: 0.0465 - acc: 0.9851\n",
      "Epoch 3/5\n",
      "55796/55796 [==============================] - ETA: 0s - loss: 0.0305 - acc: 0.9902- ETA: 0s - loss: 0.0305  - 38s 687us/sample - loss: 0.0305 - acc: 0.9902\n",
      "Epoch 4/5\n",
      "55796/55796 [==============================] - 37s 661us/sample - loss: 0.0237 - acc: 0.9923\n",
      "Epoch 5/5\n",
      "55796/55796 [==============================] - 38s 685us/sample - loss: 0.0181 - acc: 0.9946 - loss: 0.0180 - ac\n",
      "2020-06-05 18:33:58.669124 End of fit\n",
      "acc: 98.74%\n",
      "2020-06-05 18:34:11.130043 Start of fit\n",
      "Epoch 1/5\n",
      "55798/55798 [==============================] - 45s 807us/sample - loss: 0.1734 - acc: 0.9456\n",
      "Epoch 2/5\n",
      "55798/55798 [==============================] - 39s 697us/sample - loss: 0.0449 - acc: 0.9862 - loss: 0.0451 -\n",
      "Epoch 3/5\n",
      "55798/55798 [==============================] - 38s 687us/sample - loss: 0.0310 - acc: 0.9899\n",
      "Epoch 4/5\n",
      "55798/55798 [==============================] - 38s 677us/sample - loss: 0.0237 - acc: 0.9929 - loss: 0.023\n",
      "Epoch 5/5\n",
      "55798/55798 [==============================] - 37s 668us/sample - loss: 0.0177 - acc: 0.9943\n",
      "2020-06-05 18:37:50.507464 End of fit\n",
      "acc: 99.06%\n",
      "2020-06-05 18:38:02.294829 Start of fit\n",
      "Epoch 1/5\n",
      "55798/55798 [==============================] - 43s 769us/sample - loss: 0.1834 - acc: 0.9421\n",
      "Epoch 2/5\n",
      "55798/55798 [==============================] - 39s 699us/sample - loss: 0.0479 - acc: 0.9851\n",
      "Epoch 3/5\n",
      "55798/55798 [==============================] - ETA: 0s - loss: 0.0312 - acc: 0.990 - 37s 669us/sample - loss: 0.0312 - acc: 0.9906\n",
      "Epoch 4/5\n",
      "55798/55798 [==============================] - 39s 696us/sample - loss: 0.0234 - acc: 0.9928\n",
      "Epoch 5/5\n",
      "55798/55798 [==============================] - 37s 669us/sample - loss: 0.0189 - acc: 0.9940\n",
      "2020-06-05 18:41:38.624920 End of fit\n",
      "acc: 98.73%\n",
      "2020-06-05 18:41:51.422103 Start of fit\n",
      "Epoch 1/5\n",
      "55798/55798 [==============================] - 43s 766us/sample - loss: 0.1777 - acc: 0.9438 - loss: 0.1778 - acc: 0.943\n",
      "Epoch 2/5\n",
      "55798/55798 [==============================] - 38s 681us/sample - loss: 0.0441 - acc: 0.9861 - loss: \n",
      "Epoch 3/5\n",
      "55798/55798 [==============================] - 38s 680us/sample - loss: 0.0316 - acc: 0.9904\n",
      "Epoch 4/5\n",
      "55798/55798 [==============================] - 38s 674us/sample - loss: 0.0233 - acc: 0.9930\n",
      "Epoch 5/5\n",
      "55798/55798 [==============================] - 38s 680us/sample - loss: 0.0189 - acc: 0.9940\n",
      "2020-06-05 18:45:27.714296 End of fit\n",
      "acc: 98.76%\n",
      "2020-06-05 18:45:39.963581 Start of fit\n",
      "Epoch 1/5\n",
      "55800/55800 [==============================] - 47s 837us/sample - loss: 0.1920 - acc: 0.9397\n",
      "Epoch 2/5\n",
      "55800/55800 [==============================] - 38s 680us/sample - loss: 0.0488 - acc: 0.9854\n",
      "Epoch 3/5\n",
      "55800/55800 [==============================] - 40s 709us/sample - loss: 0.0341 - acc: 0.9893\n",
      "Epoch 4/5\n",
      "55800/55800 [==============================] - 38s 680us/sample - loss: 0.0250 - acc: 0.9929\n",
      "Epoch 5/5\n",
      "55800/55800 [==============================] - 37s 670us/sample - loss: 0.0189 - acc: 0.9940\n",
      "2020-06-05 18:49:20.026094 End of fit\n",
      "acc: 98.89%\n",
      "2020-06-05 18:49:31.867295 Start of fit\n",
      "Epoch 1/5\n",
      "55801/55801 [==============================] - 44s 796us/sample - loss: 0.1805 - acc: 0.9433 -\n",
      "Epoch 2/5\n",
      "55801/55801 [==============================] - 39s 691us/sample - loss: 0.0479 - acc: 0.9856\n",
      "Epoch 3/5\n",
      "55801/55801 [==============================] - 39s 700us/sample - loss: 0.0326 - acc: 0.9901\n",
      "Epoch 4/5\n",
      "55801/55801 [==============================] - 41s 726us/sample - loss: 0.0244 - acc: 0.9923\n",
      "Epoch 5/5\n",
      "55801/55801 [==============================] - 38s 677us/sample - loss: 0.0188 - acc: 0.9942\n",
      "2020-06-05 18:53:13.625398 End of fit\n",
      "acc: 98.95%\n",
      "2020-06-05 18:53:25.315769 Start of fit\n",
      "Epoch 1/5\n",
      "55803/55803 [==============================] - 44s 780us/sample - loss: 0.1808 - acc: 0.9429\n",
      "Epoch 2/5\n",
      "55803/55803 [==============================] - 38s 682us/sample - loss: 0.0466 - acc: 0.9853\n",
      "Epoch 3/5\n",
      "55803/55803 [==============================] - 39s 691us/sample - loss: 0.0319 - acc: 0.9903\n",
      "Epoch 4/5\n",
      "55803/55803 [==============================] - 37s 664us/sample - loss: 0.0234 - acc: 0.9928\n",
      "Epoch 5/5\n",
      "55803/55803 [==============================] - 38s 674us/sample - loss: 0.0182 - acc: 0.9942\n",
      "2020-06-05 18:56:57.923001 End of fit\n",
      "acc: 99.05%\n",
      "2020-06-05 18:57:08.898537 Start of fit\n",
      "Epoch 1/5\n",
      "55805/55805 [==============================] - 44s 795us/sample - loss: 0.1710 - acc: 0.9460\n",
      "Epoch 2/5\n",
      "55805/55805 [==============================] - 38s 689us/sample - loss: 0.0449 - acc: 0.9858\n",
      "Epoch 3/5\n",
      "55805/55805 [==============================] - 38s 690us/sample - loss: 0.0301 - acc: 0.9905\n",
      "Epoch 4/5\n",
      "55805/55805 [==============================] - 38s 682us/sample - loss: 0.0229 - acc: 0.9926\n",
      "Epoch 5/5\n",
      "55805/55805 [==============================] - 37s 672us/sample - loss: 0.0175 - acc: 0.9945\n",
      "2020-06-05 19:00:43.844034 End of fit\n",
      "acc: 98.98%\n",
      "98.84% (+/- 0.20%)\n",
      "2020-06-05 19:00:53.660111 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 4 8 9 6 9 6 8 3 6 6 8 5 1 4 2 4 4 5 1 1 9 0 2 4 9 5 7 1 8 3 5 6 9 8 7 1 1 6 7 6 3 2 2 0 8 9\n",
      " 2 5 1 0 8 1 4 5 7 9 6 9 0 6 1 5 5 8 3 8 2 6 5 0 7 4 6 1 3 4 7 3 2 3 4 2 5 2 7 1 7 2 6 4 1 5 7 8 6 0 1 8 2 5 7 7 6 9 3 5 2 4 2 4 0 8 8 3 4 9 2 7 5 8 6 3 6 0 8 6 7 3 6 4 9 4 6 6 3 0 4 1 0 1 4 6 2 9 1\n",
      " 1 0 6 3 9]\n",
      "ndx_errs (array([ 151,  241,  247,  318,  320,  321,  362,  376,  381,  444,  445,  448,  464,  479,  495,  519,  550,  578,  582,  628,  659,  691,  716,  726,  740,  760,  839,  881,  883,  924,  926,  938,\n",
      "        939,  947,  951,  956, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1181, 1192, 1226, 1228, 1232, 1242, 1247, 1248, 1270, 1283, 1289, 1299, 1319, 1326, 1331, 1364, 1393, 1414,\n",
      "       1500, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1732, 1737, 1790, 1813, 1878, 1901, 1955, 1970, 1984], dtype=int64),)\n",
      "num correct is  1912  an accuracy of  0.9564782391195598\n",
      "****************************** 3999 ******************************\n",
      "fill_up_last_row.shape (63999, 26)\n",
      "X_num_images 63999 X_image_num_pixels 954\n",
      "num_extra_rows 7\n",
      "2020-06-05 19:04:25.171800 Start of fit\n",
      "Epoch 1/5\n",
      "57595/57595 [==============================] - 45s 786us/sample - loss: 0.1669 - acc: 0.9475\n",
      "Epoch 2/5\n",
      "57595/57595 [==============================] - 39s 678us/sample - loss: 0.0456 - acc: 0.9859\n",
      "Epoch 3/5\n",
      "57595/57595 [==============================] - 39s 682us/sample - loss: 0.0318 - acc: 0.9903\n",
      "Epoch 4/5\n",
      "57595/57595 [==============================] - 40s 697us/sample - loss: 0.0247 - acc: 0.9924\n",
      "Epoch 5/5\n",
      "57595/57595 [==============================] - 39s 675us/sample - loss: 0.0177 - acc: 0.9945\n",
      "2020-06-05 19:08:06.713846 End of fit\n",
      "acc: 99.06%\n",
      "2020-06-05 19:08:17.827800 Start of fit\n",
      "Epoch 1/5\n",
      "57595/57595 [==============================] - 46s 796us/sample - loss: 0.1790 - acc: 0.9436\n",
      "Epoch 2/5\n",
      "57595/57595 [==============================] - 40s 686us/sample - loss: 0.0459 - acc: 0.9861\n",
      "Epoch 3/5\n",
      "57595/57595 [==============================] - 40s 697us/sample - loss: 0.0320 - acc: 0.9901\n",
      "Epoch 4/5\n",
      "57595/57595 [==============================] - 39s 686us/sample - loss: 0.0248 - acc: 0.9922\n",
      "Epoch 5/5\n",
      "57595/57595 [==============================] - 40s 687us/sample - loss: 0.0188 - acc: 0.9941 - loss - ETA: 4s - loss: 0. -\n",
      "2020-06-05 19:12:00.722259 End of fit\n",
      "acc: 98.84%\n",
      "2020-06-05 19:12:11.097220 Start of fit\n",
      "Epoch 1/5\n",
      "57596/57596 [==============================] - 45s 776us/sample - loss: 0.1647 - acc: 0.9483 - loss: 0.1673 \n",
      "Epoch 2/5\n",
      "57596/57596 [==============================] - 40s 688us/sample - loss: 0.0448 - acc: 0.9861 2s - loss: 0.045 - ETA: 1s - loss: 0.0449 \n",
      "Epoch 3/5\n",
      "57596/57596 [==============================] - 40s 699us/sample - loss: 0.0318 - acc: 0.9899\n",
      "Epoch 4/5\n",
      "57596/57596 [==============================] - 40s 702us/sample - loss: 0.0239 - acc: 0.9927\n",
      "Epoch 5/5\n",
      "57596/57596 [==============================] - 39s 682us/sample - loss: 0.0184 - acc: 0.9943\n",
      "2020-06-05 19:15:53.669306 End of fit\n",
      "acc: 99.09%\n",
      "2020-06-05 19:16:04.918896 Start of fit\n",
      "Epoch 1/5\n",
      "57598/57598 [==============================] - 44s 769us/sample - loss: 0.1847 - acc: 0.9414\n",
      "Epoch 2/5\n",
      "57598/57598 [==============================] - 40s 695us/sample - loss: 0.0475 - acc: 0.9855\n",
      "Epoch 3/5\n",
      "57598/57598 [==============================] - 40s 695us/sample - loss: 0.0334 - acc: 0.9897 - loss: 0.0334 - acc: 0.98 - ETA: 0s - loss: 0.0334 - acc\n",
      "Epoch 4/5\n",
      "57598/57598 [==============================] - 41s 709us/sample - loss: 0.0249 - acc: 0.9924s - loss: 0.0243 - acc: 0. - ETA: 0s - loss: 0.0248 - \n",
      "Epoch 5/5\n",
      "57598/57598 [==============================] - 41s 709us/sample - loss: 0.0188 - acc: 0.9940 - \n",
      "2020-06-05 19:19:49.312383 End of fit\n",
      "acc: 98.98%\n",
      "2020-06-05 19:20:00.537595 Start of fit\n",
      "Epoch 1/5\n",
      "57598/57598 [==============================] - 47s 813us/sample - loss: 0.1790 - acc: 0.9438\n",
      "Epoch 2/5\n",
      "57598/57598 [==============================] - 39s 683us/sample - loss: 0.0469 - acc: 0.9849\n",
      "Epoch 3/5\n",
      "57598/57598 [==============================] - 39s 670us/sample - loss: 0.0316 - acc: 0.9903\n",
      "Epoch 4/5\n",
      "57598/57598 [==============================] - 38s 666us/sample - loss: 0.0244 - acc: 0.9922\n",
      "Epoch 5/5\n",
      "57598/57598 [==============================] - 40s 691us/sample - loss: 0.0186 - acc: 0.9942\n",
      "2020-06-05 19:23:40.797568 End of fit\n",
      "acc: 99.06%\n",
      "2020-06-05 19:23:51.372775 Start of fit\n",
      "Epoch 1/5\n",
      "57599/57599 [==============================] - 45s 782us/sample - loss: 0.1786 - acc: 0.9446\n",
      "Epoch 2/5\n",
      "57599/57599 [==============================] - 40s 703us/sample - loss: 0.0473 - acc: 0.9854\n",
      "Epoch 3/5\n",
      "57599/57599 [==============================] - 40s 696us/sample - loss: 0.0310 - acc: 0.9905\n",
      "Epoch 4/5\n",
      "57599/57599 [==============================] - 41s 712us/sample - loss: 0.0236 - acc: 0.9930\n",
      "Epoch 5/5\n",
      "57599/57599 [==============================] - 40s 701us/sample - loss: 0.0187 - acc: 0.9945\n",
      "2020-06-05 19:27:36.694805 End of fit\n",
      "acc: 98.48%\n",
      "2020-06-05 19:27:50.295965 Start of fit\n",
      "Epoch 1/5\n",
      "57602/57602 [==============================] - 46s 800us/sample - loss: 0.1708 - acc: 0.9469\n",
      "Epoch 2/5\n",
      "57602/57602 [==============================] - 41s 714us/sample - loss: 0.0463 - acc: 0.9857 - loss: 0.0464 - acc: 0\n",
      "Epoch 3/5\n",
      "57602/57602 [==============================] - 40s 694us/sample - loss: 0.0327 - acc: 0.9895\n",
      "Epoch 4/5\n",
      "57602/57602 [==============================] - 40s 691us/sample - loss: 0.0246 - acc: 0.9926\n",
      "Epoch 5/5\n",
      "57602/57602 [==============================] - 39s 680us/sample - loss: 0.0203 - acc: 0.9942\n",
      "2020-06-05 19:31:34.173562 End of fit\n",
      "acc: 99.34%\n",
      "2020-06-05 19:31:46.380375 Start of fit\n",
      "Epoch 1/5\n",
      "57602/57602 [==============================] - 45s 785us/sample - loss: 0.1672 - acc: 0.9477 - lo - ETA: 1s - loss: 0.170\n",
      "Epoch 2/5\n",
      "57602/57602 [==============================] - 40s 700us/sample - loss: 0.0483 - acc: 0.9852 - loss: \n",
      "Epoch 3/5\n",
      "57602/57602 [==============================] - 40s 700us/sample - loss: 0.0329 - acc: 0.9900 - loss: 0.0330 - acc: 0.99\n",
      "Epoch 4/5\n",
      "57602/57602 [==============================] - 39s 678us/sample - loss: 0.0247 - acc: 0.9924\n",
      "Epoch 5/5\n",
      "57602/57602 [==============================] - 39s 685us/sample - loss: 0.0188 - acc: 0.9941\n",
      "2020-06-05 19:35:31.109109 End of fit\n",
      "acc: 99.02%\n",
      "2020-06-05 19:35:42.963700 Start of fit\n",
      "Epoch 1/5\n",
      "57602/57602 [==============================] - 44s 757us/sample - loss: 0.1695 - acc: 0.9460\n",
      "Epoch 2/5\n",
      "57602/57602 [==============================] - 40s 691us/sample - loss: 0.0467 - acc: 0.9853 - loss: 0.0470 - acc: 0. \n",
      "Epoch 3/5\n",
      "57602/57602 [==============================] - 39s 679us/sample - loss: 0.0320 - acc: 0.9901\n",
      "Epoch 4/5\n",
      "57602/57602 [==============================] - 39s 670us/sample - loss: 0.0232 - acc: 0.9927\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57602/57602 [==============================] - 39s 671us/sample - loss: 0.0177 - acc: 0.9944 - loss: 0.0180 - acc: 0.994 - ETA: 3s - loss: 0 - ETA: 1s - l\n",
      "2020-06-05 19:39:22.009957 End of fit\n",
      "acc: 98.92%\n",
      "2020-06-05 19:39:32.609796 Start of fit\n",
      "Epoch 1/5\n",
      "57604/57604 [==============================] - 44s 764us/sample - loss: 0.1751 - acc: 0.9439 - l\n",
      "Epoch 2/5\n",
      "57604/57604 [==============================] - 39s 683us/sample - loss: 0.0467 - acc: 0.9851\n",
      "Epoch 3/5\n",
      "57604/57604 [==============================] - 40s 689us/sample - loss: 0.0315 - acc: 0.9899\n",
      "Epoch 4/5\n",
      "57604/57604 [==============================] - 40s 690us/sample - loss: 0.0229 - acc: 0.9927\n",
      "Epoch 5/5\n",
      "57604/57604 [==============================] - 40s 691us/sample - loss: 0.0186 - acc: 0.9945 - loss: 0.0185 - ac\n",
      "2020-06-05 19:43:14.282697 End of fit\n",
      "acc: 99.00%\n",
      "98.98% (+/- 0.21%)\n",
      "2020-06-05 19:43:23.177676 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 9 1 1 0 7 5 9 9 1 9 5 9 2 5 0 4 1 0 8 9 0 8 9 8 9 4 2 5 7 9 8 9 8 0 9 9 6 8 9 9 5 9 8 6 1\n",
      " 0 3 3 5 2 1 6 3 0 2 8 1 5 6 2 3 0 2 2 6 4 3 5 5 1 7 2 1 6 9 1 3 9 5 5 1 6 2 2 8 6 7 1 4 6 0 6 0 3 3 2 2 3 6 8 9 8 5 3 8 5 4 5 2 0 5 6 3 2 8 3 9 9 3 7 9 4 6 7 1 3 7 3 6 6 0 9 0 1 9 9 2 8 8 0 1 6 9 7\n",
      " 5 3 4 7 4]\n",
      "ndx_errs (array([ 151,  241,  247,  318,  320,  321,  362,  376,  381,  444,  445,  448,  464,  479,  495,  519,  550,  578,  582,  628,  659,  691,  716,  726,  740,  760,  839,  881,  883,  924,  926,  938,\n",
      "        939,  947,  951,  956, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1181, 1192, 1226, 1228, 1232, 1242, 1247, 1248, 1270, 1283, 1289, 1299, 1319, 1326, 1331, 1364, 1393, 1414,\n",
      "       1500, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1732, 1737, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2098, 2109, 2118, 2129, 2130, 2135,\n",
      "       2177, 2182, 2189, 2224, 2237, 2282, 2292, 2293, 2298, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2462, 2574, 2607, 2648, 2654, 2721, 2730, 2758, 2771, 2810, 2851, 2853, 2896, 2927, 2939, 2945,\n",
      "       2952, 2953, 2998, 3005, 3030, 3060, 3062, 3073, 3117, 3136, 3206, 3240, 3262, 3289, 3323, 3333, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3629, 3664, 3702, 3718, 3726, 3742, 3757, 3767, 3780,\n",
      "       3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3968], dtype=int64),)\n",
      "num correct is  3830  an accuracy of  0.9577394348587147\n",
      "****************************** 5999 ******************************\n",
      "fill_up_last_row.shape (65999, 26)\n",
      "X_num_images 65999 X_image_num_pixels 954\n",
      "num_extra_rows 7\n",
      "2020-06-05 19:49:50.946215 Start of fit\n",
      "Epoch 1/5\n",
      "59395/59395 [==============================] - 47s 789us/sample - loss: 0.1715 - acc: 0.9464 - loss: 0.1855 - ETA: 0s - loss: 0.1729 - acc: \n",
      "Epoch 2/5\n",
      "59395/59395 [==============================] - 41s 698us/sample - loss: 0.0443 - acc: 0.9862 - loss: 0.0443 - acc: 0.98 - ETA: \n",
      "Epoch 3/5\n",
      "59395/59395 [==============================] - 41s 687us/sample - loss: 0.0306 - acc: 0.9904\n",
      "Epoch 4/5\n",
      "59395/59395 [==============================] - 40s 674us/sample - loss: 0.0226 - acc: 0.9928\n",
      "Epoch 5/5\n",
      "59395/59395 [==============================] - 40s 674us/sample - loss: 0.0169 - acc: 0.9951\n",
      "2020-06-05 19:53:38.599588 End of fit\n",
      "acc: 99.14%\n",
      "2020-06-05 19:53:50.447852 Start of fit\n",
      "Epoch 1/5\n",
      "59397/59397 [==============================] - 48s 802us/sample - loss: 0.1692 - acc: 0.9462 -\n",
      "Epoch 2/5\n",
      "59397/59397 [==============================] - 41s 688us/sample - loss: 0.0461 - acc: 0.9854\n",
      "Epoch 3/5\n",
      "59397/59397 [==============================] - 41s 686us/sample - loss: 0.0310 - acc: 0.9908\n",
      "Epoch 4/5\n",
      "59397/59397 [==============================] - 42s 701us/sample - loss: 0.0233 - acc: 0.9932 -  - ETA: 0s - loss: 0.0234 - \n",
      "Epoch 5/5\n",
      "59397/59397 [==============================] - 41s 689us/sample - loss: 0.0182 - acc: 0.9947\n",
      "2020-06-05 19:57:41.516635 End of fit\n",
      "acc: 98.76%\n",
      "2020-06-05 19:57:52.603096 Start of fit\n",
      "Epoch 1/5\n",
      "59397/59397 [==============================] - 46s 774us/sample - loss: 0.1672 - acc: 0.9476\n",
      "Epoch 2/5\n",
      "59397/59397 [==============================] - 41s 686us/sample - loss: 0.0444 - acc: 0.9861\n",
      "Epoch 3/5\n",
      "59397/59397 [==============================] - 41s 692us/sample - loss: 0.0308 - acc: 0.9903\n",
      "Epoch 4/5\n",
      "59397/59397 [==============================] - 41s 687us/sample - loss: 0.0233 - acc: 0.9928\n",
      "Epoch 5/5\n",
      "59397/59397 [==============================] - 42s 713us/sample - loss: 0.0176 - acc: 0.9943\n",
      "2020-06-05 20:01:42.798006 End of fit\n",
      "acc: 99.11%\n",
      "2020-06-05 20:01:53.964205 Start of fit\n",
      "Epoch 1/5\n",
      "59399/59399 [==============================] - 46s 777us/sample - loss: 0.1799 - acc: 0.9430\n",
      "Epoch 2/5\n",
      "59399/59399 [==============================] - 42s 705us/sample - loss: 0.0463 - acc: 0.9856 - lo\n",
      "Epoch 3/5\n",
      "59399/59399 [==============================] - 41s 688us/sample - loss: 0.0330 - acc: 0.9898\n",
      "Epoch 4/5\n",
      "59399/59399 [==============================] - 42s 705us/sample - loss: 0.0241 - acc: 0.9924\n",
      "Epoch 5/5\n",
      "59399/59399 [==============================] - 43s 719us/sample - loss: 0.0192 - acc: 0.9942\n",
      "2020-06-05 20:05:46.384201 End of fit\n",
      "acc: 99.03%\n",
      "2020-06-05 20:05:58.358520 Start of fit\n",
      "Epoch 1/5\n",
      "59399/59399 [==============================] - 46s 777us/sample - loss: 0.1696 - acc: 0.9464\n",
      "Epoch 2/5\n",
      "59399/59399 [==============================] - 42s 701us/sample - loss: 0.0441 - acc: 0.9866 - loss: 0.0442 - ac\n",
      "Epoch 3/5\n",
      "59399/59399 [==============================] - 48s 806us/sample - loss: 0.0311 - acc: 0.9903\n",
      "Epoch 4/5\n",
      "59399/59399 [==============================] - 43s 721us/sample - loss: 0.0229 - acc: 0.9928\n",
      "Epoch 5/5\n",
      "59399/59399 [==============================] - 42s 702us/sample - loss: 0.0177 - acc: 0.9948 - loss: 0.0176 - ac\n",
      "2020-06-05 20:09:57.915339 End of fit\n",
      "acc: 98.97%\n",
      "2020-06-05 20:10:10.974096 Start of fit\n",
      "Epoch 1/5\n",
      "59399/59399 [==============================] - 48s 812us/sample - loss: 0.1641 - acc: 0.9490 - loss - ETA: 3s - loss: 0.1719 - acc: 0. - ETA: 3s - los - ETA: 1s - loss: 0\n",
      "Epoch 2/5\n",
      "59399/59399 [==============================] - 42s 706us/sample - loss: 0.0443 - acc: 0.9863\n",
      "Epoch 3/5\n",
      "59399/59399 [==============================] - 43s 716us/sample - loss: 0.0311 - acc: 0.9901\n",
      "Epoch 4/5\n",
      "59399/59399 [==============================] - 42s 701us/sample - loss: 0.0240 - acc: 0.9926\n",
      "Epoch 5/5\n",
      "59399/59399 [==============================] - 43s 720us/sample - loss: 0.0179 - acc: 0.9944\n",
      "2020-06-05 20:14:07.490366 End of fit\n",
      "acc: 99.23%\n",
      "2020-06-05 20:14:19.421986 Start of fit\n",
      "Epoch 1/5\n",
      "59400/59400 [==============================] - 47s 793us/sample - loss: 0.1691 - acc: 0.9470\n",
      "Epoch 2/5\n",
      "59400/59400 [==============================] - 43s 717us/sample - loss: 0.0455 - acc: 0.9859 - loss: 0.0453 - a\n",
      "Epoch 3/5\n",
      "59400/59400 [==============================] - 42s 712us/sample - loss: 0.0321 - acc: 0.9902 - loss: 0.0321 - acc\n",
      "Epoch 4/5\n",
      "59400/59400 [==============================] - 41s 693us/sample - loss: 0.0236 - acc: 0.9930\n",
      "Epoch 5/5\n",
      "59400/59400 [==============================] - 42s 713us/sample - loss: 0.0185 - acc: 0.9944s - loss: 0.0185 - ETA: 1s - loss: 0.0185 - acc:  - ETA: 1s - loss: 0\n",
      "2020-06-05 20:18:14.550279 End of fit\n",
      "acc: 98.71%\n",
      "2020-06-05 20:18:25.805195 Start of fit\n",
      "Epoch 1/5\n",
      "59400/59400 [==============================] - 48s 804us/sample - loss: 0.1593 - acc: 0.9490ETA:  - ETA: 4s - loss: 0.1721 - acc: 0.944 - ETA: 4s - loss: 0.1717 -  - ETA: 3s - loss: 0.1690 - - ETA: 2s  - ETA: 0s - loss: 0.1604 - acc\n",
      "Epoch 2/5\n",
      "59400/59400 [==============================] - 42s 700us/sample - loss: 0.0433 - acc: 0.9866\n",
      "Epoch 3/5\n",
      "59400/59400 [==============================] - 42s 703us/sample - loss: 0.0294 - acc: 0.9908\n",
      "Epoch 4/5\n",
      "59400/59400 [==============================] - 42s 705us/sample - loss: 0.0220 - acc: 0.9930 - loss: 0.0219 - acc: 0.99 - ETA: 0s - loss: 0.0219\n",
      "Epoch 5/5\n",
      "59400/59400 [==============================] - 41s 697us/sample - loss: 0.0170 - acc: 0.9948\n",
      "2020-06-05 20:22:18.888298 End of fit\n",
      "acc: 99.09%\n",
      "2020-06-05 20:22:29.926196 Start of fit\n",
      "Epoch 1/5\n",
      "59402/59402 [==============================] - 46s 780us/sample - loss: 0.1669 - acc: 0.9483\n",
      "Epoch 2/5\n",
      "59402/59402 [==============================] - 41s 695us/sample - loss: 0.0439 - acc: 0.9866\n",
      "Epoch 3/5\n",
      "59402/59402 [==============================] - 42s 712us/sample - loss: 0.0302 - acc: 0.9903\n",
      "Epoch 4/5\n",
      "59402/59402 [==============================] - 42s 707us/sample - loss: 0.0224 - acc: 0.9934 - loss: 0.0225\n",
      "Epoch 5/5\n",
      "59402/59402 [==============================] - 42s 713us/sample - loss: 0.0179 - acc: 0.9944 \n",
      "2020-06-05 20:26:22.202718 End of fit\n",
      "acc: 98.82%\n",
      "2020-06-05 20:26:33.175938 Start of fit\n",
      "Epoch 1/5\n",
      "59403/59403 [==============================] - 46s 774us/sample - loss: 0.1702 - acc: 0.9454s - loss: 0.1722 - \n",
      "Epoch 2/5\n",
      "59403/59403 [==============================] - 41s 698us/sample - loss: 0.0454 - acc: 0.9860 -  - ETA: 1s - loss: 0.04\n",
      "Epoch 3/5\n",
      "59403/59403 [==============================] - 42s 707us/sample - loss: 0.0310 - acc: 0.9901\n",
      "Epoch 4/5\n",
      "59403/59403 [==============================] - 43s 718us/sample - loss: 0.0237 - acc: 0.9927 - loss: 0.0238 - acc: 0.99\n",
      "Epoch 5/5\n",
      "59403/59403 [==============================] - 42s 701us/sample - loss: 0.0177 - acc: 0.9949\n",
      "2020-06-05 20:30:24.564582 End of fit\n",
      "acc: 98.67%\n",
      "98.95% (+/- 0.19%)\n",
      "2020-06-05 20:30:33.542123 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 2 3 4 5 6 7 8 9 8 4 1 3 7 5 2 8 0 7 3 9 9 0 9 1 1 5 8 8 6 3 2 1 8 3 2 6 5 6 9 6 1 0 5 3 1 9\n",
      " 2 1 9 6 0 4 6 1 7 3 8 9 2 9 6 5 8 3 5 4 1 6 1 0 9 6 2 5 4 2 3 4 4 6 0 0 2 0 1 2 3 4 3 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 8 4 5 6 7 8 9 8 6 5 0 6 8 9 4 1 9 5 8 0 9 8 9 1 4 0 5 3 2 1 5 4 0 7 6 0 1 7 0\n",
      " 6 8 9 3 1]\n",
      "ndx_errs (array([ 151,  241,  247,  318,  320,  321,  362,  376,  381,  444,  445,  448,  464,  479,  495,  519,  550,  578,  582,  628,  659,  691,  716,  726,  740,  760,  839,  881,  883,  924,  926,  938,\n",
      "        939,  947,  951,  956, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1181, 1192, 1226, 1228, 1232, 1242, 1247, 1248, 1270, 1283, 1289, 1299, 1319, 1326, 1331, 1364, 1393, 1414,\n",
      "       1500, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1732, 1737, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2098, 2109, 2118, 2129, 2130, 2135,\n",
      "       2177, 2182, 2189, 2224, 2237, 2282, 2292, 2293, 2298, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2462, 2574, 2607, 2648, 2654, 2721, 2730, 2758, 2771, 2810, 2851, 2853, 2896, 2927, 2939, 2945,\n",
      "       2952, 2953, 2998, 3005, 3030, 3060, 3062, 3073, 3117, 3136, 3206, 3240, 3262, 3289, 3323, 3333, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3629, 3664, 3702, 3718, 3726, 3742, 3757, 3767, 3780,\n",
      "       3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3968, 4007, 4065, 4072, 4075, 4078, 4116, 4176, 4224, 4269, 4271, 4284, 4289, 4294, 4297, 4306, 4355, 4360, 4437, 4483, 4489, 4497, 4500, 4505,\n",
      "       4567, 4575, 4578, 4598, 4639, 4671, 4731, 4737, 4743, 4761, 4785, 4807, 4823, 4837, 4860, 4874, 4886, 4890, 4893, 4911, 4943, 4966, 4976, 4990, 5068, 5176, 5278, 5532, 5600, 5634, 5705, 5769,\n",
      "       5835, 5841, 5858, 5867, 5887, 5888, 5906, 5914, 5937, 5955, 5973, 5975, 5982, 5997], dtype=int64),)\n",
      "num correct is  5761  an accuracy of  0.9603267211201867\n",
      "****************************** 7999 ******************************\n",
      "fill_up_last_row.shape (67999, 26)\n",
      "X_num_images 67999 X_image_num_pixels 954\n",
      "num_extra_rows 7\n",
      "2020-06-05 20:39:56.327697 Start of fit\n",
      "Epoch 1/5\n",
      "61195/61195 [==============================] - 47s 776us/sample - loss: 0.1700 - acc: 0.9471 - loss: 0.1792 - acc: 0.94\n",
      "Epoch 2/5\n",
      "61195/61195 [==============================] - 44s 711us/sample - loss: 0.0432 - acc: 0.9865 - l\n",
      "Epoch 3/5\n",
      "61195/61195 [==============================] - 42s 687us/sample - loss: 0.0291 - acc: 0.9909\n",
      "Epoch 4/5\n",
      "61195/61195 [==============================] - 43s 695us/sample - loss: 0.0218 - acc: 0.9932\n",
      "Epoch 5/5\n",
      "61195/61195 [==============================] - 43s 697us/sample - loss: 0.0172 - acc: 0.9947\n",
      "2020-06-05 20:43:52.231629 End of fit\n",
      "acc: 99.19%\n",
      "2020-06-05 20:44:03.159182 Start of fit\n",
      "Epoch 1/5\n",
      "61195/61195 [==============================] - 47s 772us/sample - loss: 0.1680 - acc: 0.9466\n",
      "Epoch 2/5\n",
      "61195/61195 [==============================] - 43s 699us/sample - loss: 0.0451 - acc: 0.9858\n",
      "Epoch 3/5\n",
      "61195/61195 [==============================] - 42s 690us/sample - loss: 0.0313 - acc: 0.9900 - lo -\n",
      "Epoch 4/5\n",
      "61195/61195 [==============================] - 42s 689us/sample - loss: 0.0234 - acc: 0.9928\n",
      "Epoch 5/5\n",
      "61195/61195 [==============================] - 42s 691us/sample - loss: 0.0178 - acc: 0.9943 \n",
      "2020-06-05 20:47:57.805470 End of fit\n",
      "acc: 99.16%\n",
      "2020-06-05 20:48:08.225699 Start of fit\n",
      "Epoch 1/5\n",
      "61196/61196 [==============================] - 49s 797us/sample - loss: 0.1519 - acc: 0.9518\n",
      "Epoch 2/5\n",
      "61196/61196 [==============================] - 43s 711us/sample - loss: 0.0421 - acc: 0.9870 - loss: 0.0421 - acc: 0.986\n",
      "Epoch 3/5\n",
      "61196/61196 [==============================] - 44s 720us/sample - loss: 0.0293 - acc: 0.9908\n",
      "Epoch 4/5\n",
      "61196/61196 [==============================] - 43s 704us/sample - loss: 0.0217 - acc: 0.9931 ETA: 0s - loss: 0.0218 -\n",
      "Epoch 5/5\n",
      "61196/61196 [==============================] - 43s 698us/sample - loss: 0.0172 - acc: 0.9944 - loss: 0.0169 - acc:  - ETA: 1s - loss: 0.0173 - acc: 0.994 - ETA: 1s - loss: 0.0173\n",
      "2020-06-05 20:52:08.195841 End of fit\n",
      "acc: 99.03%\n",
      "2020-06-05 20:52:20.083681 Start of fit\n",
      "Epoch 1/5\n",
      "61196/61196 [==============================] - 49s 808us/sample - loss: 0.1636 - acc: 0.9486s - loss: 0.1659 -\n",
      "Epoch 2/5\n",
      "61196/61196 [==============================] - 43s 703us/sample - loss: 0.0435 - acc: 0.9865\n",
      "Epoch 3/5\n",
      "61196/61196 [==============================] - 43s 699us/sample - loss: 0.0296 - acc: 0.9908 - los - ETA: 2s - loss: 0.0300 - acc: - ETA: 2s - loss: 0.0298 - - ETA: 1s - loss: 0.0297 - ETA: 0s - loss: 0.0297 - acc: 0.9 - ETA: 0s - loss: 0.0297 - acc: 0\n",
      "Epoch 4/5\n",
      "61196/61196 [==============================] - 43s 709us/sample - loss: 0.0223 - acc: 0.9928 - ETA: 10s - loss: 0.0 - ETA: 9s - loss: 0.0\n",
      "Epoch 5/5\n",
      "61196/61196 [==============================] - 44s 717us/sample - loss: 0.0177 - acc: 0.9944\n",
      "2020-06-05 20:56:20.428616 End of fit\n",
      "acc: 99.18%\n",
      "2020-06-05 20:56:31.743685 Start of fit\n",
      "Epoch 1/5\n",
      "61199/61199 [==============================] - 50s 812us/sample - loss: 0.1577 - acc: 0.9502\n",
      "Epoch 2/5\n",
      "61199/61199 [==============================] - 45s 728us/sample - loss: 0.0440 - acc: 0.9865 - loss: 0.0438 - acc: 0.9\n",
      "Epoch 3/5\n",
      "61199/61199 [==============================] - 44s 725us/sample - loss: 0.0313 - acc: 0.9909\n",
      "Epoch 4/5\n",
      "61199/61199 [==============================] - 45s 735us/sample - loss: 0.0243 - acc: 0.9926\n",
      "Epoch 5/5\n",
      "61199/61199 [==============================] - 44s 724us/sample - loss: 0.0181 - acc: 0.9942 -  - ETA: 1s - loss: 0.\n",
      "2020-06-05 21:00:39.182121 End of fit\n",
      "acc: 99.12%\n",
      "2020-06-05 21:00:52.139505 Start of fit\n",
      "Epoch 1/5\n",
      "61199/61199 [==============================] - 48s 782us/sample - loss: 0.1658 - acc: 0.9468\n",
      "Epoch 2/5\n",
      "61199/61199 [==============================] - 44s 715us/sample - loss: 0.0461 - acc: 0.9861\n",
      "Epoch 3/5\n",
      "61199/61199 [==============================] - 43s 704us/sample - loss: 0.0312 - acc: 0.9907\n",
      "Epoch 4/5\n",
      "61199/61199 [==============================] - 43s 708us/sample - loss: 0.0230 - acc: 0.9928\n",
      "Epoch 5/5\n",
      "61199/61199 [==============================] - 43s 703us/sample - loss: 0.0180 - acc: 0.9940\n",
      "2020-06-05 21:04:52.879900 End of fit\n",
      "acc: 98.96%\n",
      "2020-06-05 21:05:05.076803 Start of fit\n",
      "Epoch 1/5\n",
      "61200/61200 [==============================] - 49s 808us/sample - loss: 0.1710 - acc: 0.9461 - lo - ETA: 0s - loss: 0.1735 - acc: 0.945 - ETA: 0s - loss: 0.1733 - a\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61200/61200 [==============================] - 44s 722us/sample - loss: 0.0437 - acc: 0.9867\n",
      "Epoch 3/5\n",
      "61200/61200 [==============================] - 44s 715us/sample - loss: 0.0296 - acc: 0.9908\n",
      "Epoch 4/5\n",
      "61200/61200 [==============================] - 43s 694us/sample - loss: 0.0235 - acc: 0.9926\n",
      "Epoch 5/5\n",
      "61200/61200 [==============================] - 43s 700us/sample - loss: 0.0181 - acc: 0.9945\n",
      "2020-06-05 21:09:08.691100 End of fit\n",
      "acc: 99.06%\n",
      "2020-06-05 21:09:20.016693 Start of fit\n",
      "Epoch 1/5\n",
      "61203/61203 [==============================] - 48s 791us/sample - loss: 0.1722 - acc: 0.9469\n",
      "Epoch 2/5\n",
      "61203/61203 [==============================] - 43s 708us/sample - loss: 0.0463 - acc: 0.9861\n",
      "Epoch 3/5\n",
      "61203/61203 [==============================] - 43s 707us/sample - loss: 0.0313 - acc: 0.9907\n",
      "Epoch 4/5\n",
      "61203/61203 [==============================] - 42s 694us/sample - loss: 0.0232 - acc: 0.9925\n",
      "Epoch 5/5\n",
      "61203/61203 [==============================] - 43s 701us/sample - loss: 0.0177 - acc: 0.9947\n",
      "2020-06-05 21:13:19.720766 End of fit\n",
      "acc: 99.06%\n",
      "2020-06-05 21:13:34.403289 Start of fit\n",
      "Epoch 1/5\n",
      "61204/61204 [==============================] - 48s 781us/sample - loss: 0.1614 - acc: 0.9493\n",
      "Epoch 2/5\n",
      "61204/61204 [==============================] - 44s 714us/sample - loss: 0.0433 - acc: 0.9870\n",
      "Epoch 3/5\n",
      "61204/61204 [==============================] - 43s 705us/sample - loss: 0.0294 - acc: 0.9909 - loss: 0.0294 - acc\n",
      "Epoch 4/5\n",
      "61204/61204 [==============================] - 43s 704us/sample - loss: 0.0230 - acc: 0.9928 - loss: 0.0231 - acc: \n",
      "Epoch 5/5\n",
      "61204/61204 [==============================] - 43s 703us/sample - loss: 0.0174 - acc: 0.9945\n",
      "2020-06-05 21:17:34.913136 End of fit\n",
      "acc: 99.19%\n",
      "2020-06-05 21:17:46.185055 Start of fit\n",
      "Epoch 1/5\n",
      "61204/61204 [==============================] - 49s 794us/sample - loss: 0.1558 - acc: 0.9510\n",
      "Epoch 2/5\n",
      "61204/61204 [==============================] - 43s 702us/sample - loss: 0.0454 - acc: 0.9859\n",
      "Epoch 3/5\n",
      "61204/61204 [==============================] - 43s 696us/sample - loss: 0.0312 - acc: 0.9903 - loss: 0.0317 - ETA: 1s - loss:  - ETA: 0s - loss: 0.0312 - acc: 0.\n",
      "Epoch 4/5\n",
      "61204/61204 [==============================] - 44s 715us/sample - loss: 0.0228 - acc: 0.9930\n",
      "Epoch 5/5\n",
      "61204/61204 [==============================] - 43s 699us/sample - loss: 0.0181 - acc: 0.9941\n",
      "2020-06-05 21:21:46.656612 End of fit\n",
      "acc: 99.35%\n",
      "99.13% (+/- 0.11%)\n",
      "2020-06-05 21:21:56.530118 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 3 5 6 7 8 9 0 1 2 3 5 6 7 8 9 9 7 0 9 0 1 5 8 8 0 9 3 2 7 8 4 6 1 0 4 9 4 2 0 5 0 1 6 9 3 2\n",
      " 9 1 6 0 1 1 8 7 7 6 3 6 0 7 2 4 1 7 0 6 7 1 2 5 8 1 1 2 8 7 6 8 7 1 6 2 9 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 8 9 5 7 0 3 1 6 8 4 1 5 6 4 2 7 8 1 3 4 3 4 7 2 0 5 0 1 9 2 3\n",
      " 2 3 5 5 7]\n",
      "ndx_errs (array([ 151,  241,  247,  318,  320,  321,  362,  376,  381,  444,  445,  448,  464,  479,  495,  519,  550,  578,  582,  628,  659,  691,  716,  726,  740,  760,  839,  881,  883,  924,  926,  938,\n",
      "        939,  947,  951,  956, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1181, 1192, 1226, 1228, 1232, 1242, 1247, 1248, 1270, 1283, 1289, 1299, 1319, 1326, 1331, 1364, 1393, 1414,\n",
      "       1500, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1732, 1737, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2098, 2109, 2118, 2129, 2130, 2135,\n",
      "       2177, 2182, 2189, 2224, 2237, 2282, 2292, 2293, 2298, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2462, 2574, 2607, 2648, 2654, 2721, 2730, 2758, 2771, 2810, 2851, 2853, 2896, 2927, 2939, 2945,\n",
      "       2952, 2953, 2998, 3005, 3030, 3060, 3062, 3073, 3117, 3136, 3206, 3240, 3262, 3289, 3323, 3333, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3629, 3664, 3702, 3718, 3726, 3742, 3757, 3767, 3780,\n",
      "       3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3968, 4007, 4065, 4072, 4075, 4078, 4116, 4176, 4224, 4269, 4271, 4284, 4289, 4294, 4297, 4306, 4355, 4360, 4437, 4483, 4489, 4497, 4500, 4505,\n",
      "       4567, 4575, 4578, 4598, 4639, 4671, 4731, 4737, 4743, 4761, 4785, 4807, 4823, 4837, 4860, 4874, 4886, 4890, 4893, 4911, 4943, 4966, 4976, 4990, 5068, 5176, 5278, 5532, 5600, 5634, 5705, 5769,\n",
      "       5835, 5841, 5858, 5867, 5887, 5888, 5906, 5914, 5937, 5955, 5973, 5975, 5982, 5997, 6023, 6035, 6037, 6071, 6081, 6091, 6157, 6166, 6172, 6173, 6555, 6560, 6597, 6641, 6651, 6755, 6783, 6813,\n",
      "       7216, 7333, 7432, 7434, 7492, 7545, 7797, 7921], dtype=int64),)\n",
      "num correct is  7735  an accuracy of  0.9669958744843106\n",
      "****************************** 9999 ******************************\n",
      "fill_up_last_row.shape (69999, 26)\n",
      "X_num_images 69999 X_image_num_pixels 954\n",
      "num_extra_rows 7\n",
      "2020-06-05 21:34:15.456245 Start of fit\n",
      "Epoch 1/5\n",
      "62994/62994 [==============================] - 56s 895us/sample - loss: 0.1497 - acc: 0.9531\n",
      "Epoch 2/5\n",
      "62994/62994 [==============================] - 49s 782us/sample - loss: 0.0410 - acc: 0.9871\n",
      "Epoch 3/5\n",
      "62994/62994 [==============================] - 46s 726us/sample - loss: 0.0288 - acc: 0.9908\n",
      "Epoch 4/5\n",
      "62994/62994 [==============================] - 46s 724us/sample - loss: 0.0222 - acc: 0.9933 - los - ETA: 7s - loss:\n",
      "Epoch 5/5\n",
      "62994/62994 [==============================] - 46s 734us/sample - loss: 0.0166 - acc: 0.9949 - loss:  - ETA: 0s - loss: 0.0166 - acc: 0.994\n",
      "2020-06-05 21:38:46.881490 End of fit\n",
      "acc: 99.14%\n",
      "2020-06-05 21:39:02.903246 Start of fit\n",
      "Epoch 1/5\n",
      "62995/62995 [==============================] - 51s 814us/sample - loss: 0.1570 - acc: 0.9502\n",
      "Epoch 2/5\n",
      "62995/62995 [==============================] - 44s 706us/sample - loss: 0.0421 - acc: 0.9866 - loss: 0.0419 - acc: 0.9\n",
      "Epoch 3/5\n",
      "62995/62995 [==============================] - 46s 727us/sample - loss: 0.0291 - acc: 0.9905\n",
      "Epoch 4/5\n",
      "62995/62995 [==============================] - 46s 733us/sample - loss: 0.0209 - acc: 0.9937\n",
      "Epoch 5/5\n",
      "62995/62995 [==============================] - 46s 729us/sample - loss: 0.0173 - acc: 0.9947 - loss: \n",
      "2020-06-05 21:43:22.979740 End of fit\n",
      "acc: 99.10%\n",
      "2020-06-05 21:43:42.081858 Start of fit\n",
      "Epoch 1/5\n",
      "62995/62995 [==============================] - 52s 819us/sample - loss: 0.1526 - acc: 0.9523 - loss: 0.1657 - acc: 0. - ETA: 5s - lo\n",
      "Epoch 2/5\n",
      "62995/62995 [==============================] - 45s 717us/sample - loss: 0.0412 - acc: 0.9875\n",
      "Epoch 3/5\n",
      "62995/62995 [==============================] - 44s 700us/sample - loss: 0.0288 - acc: 0.9911s - \n",
      "Epoch 4/5\n",
      "62995/62995 [==============================] - 46s 735us/sample - loss: 0.0217 - acc: 0.9936\n",
      "Epoch 5/5\n",
      "62995/62995 [==============================] - 46s 729us/sample - loss: 0.0168 - acc: 0.9949 - loss: 0. - ETA: 3s - loss: 0.0170 - - ETA: 2\n",
      "2020-06-05 21:48:02.093246 End of fit\n",
      "acc: 99.04%\n",
      "2020-06-05 21:48:15.734400 Start of fit\n",
      "Epoch 1/5\n",
      "62998/62998 [==============================] - 53s 837us/sample - loss: 0.1572 - acc: 0.9507\n",
      "Epoch 2/5\n",
      "62998/62998 [==============================] - 44s 701us/sample - loss: 0.0425 - acc: 0.9870\n",
      "Epoch 3/5\n",
      "62998/62998 [==============================] - 46s 726us/sample - loss: 0.0297 - acc: 0.9906\n",
      "Epoch 4/5\n",
      "62998/62998 [==============================] - 45s 712us/sample - loss: 0.0215 - acc: 0.9937\n",
      "Epoch 5/5\n",
      "62998/62998 [==============================] - 46s 730us/sample - loss: 0.0172 - acc: 0.9949 - loss: \n",
      "2020-06-05 21:52:33.732373 End of fit\n",
      "acc: 99.27%\n",
      "2020-06-05 21:52:48.698962 Start of fit\n",
      "Epoch 1/5\n",
      "62999/62999 [==============================] - 53s 837us/sample - loss: 0.1611 - acc: 0.9495 - loss: 0.1775 - acc: 0.9\n",
      "Epoch 2/5\n",
      "62999/62999 [==============================] - 46s 726us/sample - loss: 0.0422 - acc: 0.9867 - loss: 0.0421 - acc: 0.986 - E - ETA: 1s - loss: 0\n",
      "Epoch 3/5\n",
      "62999/62999 [==============================] - 46s 725us/sample - loss: 0.0297 - acc: 0.9904\n",
      "Epoch 4/5\n",
      "62999/62999 [==============================] - 46s 728us/sample - loss: 0.0221 - acc: 0.9927\n",
      "Epoch 5/5\n",
      "62999/62999 [==============================] - 45s 715us/sample - loss: 0.0172 - acc: 0.9950\n",
      "2020-06-05 21:57:08.124438 End of fit\n",
      "acc: 99.09%\n",
      "2020-06-05 21:57:23.276560 Start of fit\n",
      "Epoch 1/5\n",
      "63001/63001 [==============================] - 52s 830us/sample - loss: 0.1565 - acc: 0.9512 - loss: 0.1596 - ac - ETA: 0s - loss: 0.1579 - acc\n",
      "Epoch 2/5\n",
      "63001/63001 [==============================] - 46s 736us/sample - loss: 0.0426 - acc: 0.9867\n",
      "Epoch 3/5\n",
      "63001/63001 [==============================] - 45s 716us/sample - loss: 0.0293 - acc: 0.9908\n",
      "Epoch 4/5\n",
      "63001/63001 [==============================] - 47s 749us/sample - loss: 0.0225 - acc: 0.9931\n",
      "Epoch 5/5\n",
      "63001/63001 [==============================] - 46s 728us/sample - loss: 0.0175 - acc: 0.9948s - loss: 0.0174\n",
      "2020-06-05 22:01:44.886398 End of fit\n",
      "acc: 99.16%\n",
      "2020-06-05 22:01:59.044507 Start of fit\n",
      "Epoch 1/5\n",
      "63001/63001 [==============================] - 52s 828us/sample - loss: 0.1534 - acc: 0.9520\n",
      "Epoch 2/5\n",
      "63001/63001 [==============================] - 47s 740us/sample - loss: 0.0401 - acc: 0.9874 - loss: 0.0402 - acc: 0.9\n",
      "Epoch 3/5\n",
      "63001/63001 [==============================] - 46s 726us/sample - loss: 0.0294 - acc: 0.9914\n",
      "Epoch 4/5\n",
      "63001/63001 [==============================] - 46s 737us/sample - loss: 0.0217 - acc: 0.9932 - loss: 0.021 - ET\n",
      "Epoch 5/5\n",
      "63001/63001 [==============================] - 46s 725us/sample - loss: 0.0162 - acc: 0.9950\n",
      "2020-06-05 22:06:19.402152 End of fit\n",
      "acc: 99.27%\n",
      "2020-06-05 22:06:30.936469 Start of fit\n",
      "Epoch 1/5\n",
      "63002/63002 [==============================] - 52s 832us/sample - loss: 0.1597 - acc: 0.9493\n",
      "Epoch 2/5\n",
      "63002/63002 [==============================] - 45s 712us/sample - loss: 0.0417 - acc: 0.9871\n",
      "Epoch 3/5\n",
      "63002/63002 [==============================] - 46s 734us/sample - loss: 0.0283 - acc: 0.9915\n",
      "Epoch 4/5\n",
      "63002/63002 [==============================] - 46s 729us/sample - loss: 0.0215 - acc: 0.9934\n",
      "Epoch 5/5\n",
      "63002/63002 [==============================] - 46s 727us/sample - loss: 0.0161 - acc: 0.9953\n",
      "2020-06-05 22:10:49.763385 End of fit\n",
      "acc: 98.84%\n",
      "2020-06-05 22:11:04.726190 Start of fit\n",
      "Epoch 1/5\n",
      "63003/63003 [==============================] - 54s 861us/sample - loss: 0.1680 - acc: 0.9474\n",
      "Epoch 2/5\n",
      "63003/63003 [==============================] - 46s 737us/sample - loss: 0.0445 - acc: 0.9862 - loss: 0.0453 - acc: 0. - ETA: 6s - loss: 0.0454 - ETA: 5s - loss - ETA: 0s - loss: 0.0446 - \n",
      "Epoch 3/5\n",
      "63003/63003 [==============================] - 46s 733us/sample - loss: 0.0304 - acc: 0.9905\n",
      "Epoch 4/5\n",
      "63003/63003 [==============================] - 46s 731us/sample - loss: 0.0232 - acc: 0.9930\n",
      "Epoch 5/5\n",
      "63003/63003 [==============================] - 46s 737us/sample - loss: 0.0182 - acc: 0.9944 - loss: 0.0183 - acc: \n",
      "2020-06-05 22:15:29.152977 End of fit\n",
      "acc: 99.07%\n",
      "2020-06-05 22:15:43.351913 Start of fit\n",
      "Epoch 1/5\n",
      "63003/63003 [==============================] - 51s 811us/sample - loss: 0.1557 - acc: 0.9510\n",
      "Epoch 2/5\n",
      "63003/63003 [==============================] - 45s 713us/sample - loss: 0.0436 - acc: 0.9864\n",
      "Epoch 3/5\n",
      "63003/63003 [==============================] - 46s 722us/sample - loss: 0.0298 - acc: 0.9910\n",
      "Epoch 4/5\n",
      "63003/63003 [==============================] - 46s 736us/sample - loss: 0.0232 - acc: 0.9930\n",
      "Epoch 5/5\n",
      "63003/63003 [==============================] - 46s 733us/sample - loss: 0.0179 - acc: 0.9947\n",
      "2020-06-05 22:20:00.297469 End of fit\n",
      "acc: 98.87%\n",
      "99.09% (+/- 0.14%)\n",
      "2020-06-05 22:20:11.150139 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 2 0 7 7 5 8 2 9 8 6 7 3 4 6 5 7 0 4 7 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 6 7 0 6 8 6 3 9 9 8 8 7\n",
      " 7 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0\n",
      " 1 2 3 4 5]\n",
      "ndx_errs (array([ 151,  241,  247,  318,  320,  321,  362,  376,  381,  444,  445,  448,  464,  479,  495,  519,  550,  578,  582,  628,  659,  691,  716,  726,  740,  760,  839,  881,  883,  924,  926,  938,\n",
      "        939,  947,  951,  956, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1181, 1192, 1226, 1228, 1232, 1242, 1247, 1248, 1270, 1283, 1289, 1299, 1319, 1326, 1331, 1364, 1393, 1414,\n",
      "       1500, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1732, 1737, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2098, 2109, 2118, 2129, 2130, 2135,\n",
      "       2177, 2182, 2189, 2224, 2237, 2282, 2292, 2293, 2298, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2462, 2574, 2607, 2648, 2654, 2721, 2730, 2758, 2771, 2810, 2851, 2853, 2896, 2927, 2939, 2945,\n",
      "       2952, 2953, 2998, 3005, 3030, 3060, 3062, 3073, 3117, 3136, 3206, 3240, 3262, 3289, 3323, 3333, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3629, 3664, 3702, 3718, 3726, 3742, 3757, 3767, 3780,\n",
      "       3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3968, 4007, 4065, 4072, 4075, 4078, 4116, 4176, 4224, 4269, 4271, 4284, 4289, 4294, 4297, 4306, 4355, 4360, 4437, 4483, 4489, 4497, 4500, 4505,\n",
      "       4567, 4575, 4578, 4598, 4639, 4671, 4731, 4737, 4743, 4761, 4785, 4807, 4823, 4837, 4860, 4874, 4886, 4890, 4893, 4911, 4943, 4966, 4976, 4990, 5068, 5176, 5278, 5532, 5600, 5634, 5705, 5769,\n",
      "       5835, 5841, 5858, 5867, 5887, 5888, 5906, 5914, 5937, 5955, 5973, 5975, 5982, 5997, 6023, 6035, 6037, 6071, 6081, 6091, 6157, 6166, 6172, 6173, 6555, 6560, 6597, 6641, 6651, 6755, 6783, 6813,\n",
      "       7216, 7333, 7432, 7434, 7492, 7545, 7797, 7921, 8095, 8277, 8279, 8325, 8406, 8408, 8410, 8520, 8527, 9009, 9024, 9211, 9280, 9382, 9422, 9587, 9624, 9634, 9642, 9664, 9719, 9729, 9745, 9749,\n",
      "       9751, 9768, 9770, 9779, 9792, 9811, 9832, 9839, 9863, 9867, 9883, 9893, 9904, 9905, 9982], dtype=int64),)\n",
      "num correct is  9696  an accuracy of  0.9696969696969697\n",
      "fill_up_last_row.shape (70000, 26)\n",
      "X_num_images 70000 X_image_num_pixels 954\n",
      "num_extra_rows 7\n",
      "2020-06-05 22:33:36.509287 Start of fit\n",
      "Epoch 1/5\n",
      "62995/62995 [==============================] - 71s 1ms/sample - loss: 0.1607 - acc: 0.9494\n",
      "Epoch 2/5\n",
      "62995/62995 [==============================] - 46s 728us/sample - loss: 0.0424 - acc: 0.9870 \n",
      "Epoch 3/5\n",
      "62995/62995 [==============================] - 46s 737us/sample - loss: 0.0295 - acc: 0.9913 - loss: 0.0296 - acc:  - ETA: 0s - loss: 0.0294 \n",
      "Epoch 4/5\n",
      "62995/62995 [==============================] - 46s 731us/sample - loss: 0.0222 - acc: 0.9934 - loss\n",
      "Epoch 5/5\n",
      "62995/62995 [==============================] - 45s 722us/sample - loss: 0.0183 - acc: 0.9945\n",
      "2020-06-05 22:51:14.255473 End of fit\n",
      "acc: 99.01%\n",
      "2020-06-05 22:52:11.045247 Start of fit\n",
      "Epoch 1/5\n",
      "62996/62996 [==============================] - 57s 910us/sample - loss: 0.1562 - acc: 0.9506 - loss:\n",
      "Epoch 2/5\n",
      "62996/62996 [==============================] - 52s 822us/sample - loss: 0.0420 - acc: 0.9871s  - ETA: 4s -\n",
      "Epoch 3/5\n",
      "62996/62996 [==============================] - 47s 739us/sample - loss: 0.0297 - acc: 0.9906 - loss: 0.0297 - ac - ETA: 0s - loss: 0.0295 - acc: 0.99 - ETA: 0s - loss: 0.0296 -\n",
      "Epoch 4/5\n",
      "62996/62996 [==============================] - 47s 752us/sample - loss: 0.0211 - acc: 0.9935 - loss:  - ETA: 1s - loss: 0.0208 - acc: 0 - ETA: 1s - loss: 0.02\n",
      "Epoch 5/5\n",
      "62996/62996 [==============================] - 47s 740us/sample - loss: 0.0175 - acc: 0.9944 - loss: 0.0170 - acc: 0.99 - ETA: 3 - ETA: 1s - loss: \n",
      "2020-06-05 22:57:36.570567 End of fit\n",
      "acc: 99.16%\n",
      "2020-06-05 22:57:58.328848 Start of fit\n",
      "Epoch 1/5\n",
      "62996/62996 [==============================] - 52s 827us/sample - loss: 0.1522 - acc: 0.9525 - loss: 0.1549 - acc:  - ETA: 0s - loss: 0.1538 - ac\n",
      "Epoch 2/5\n",
      "62996/62996 [==============================] - 45s 711us/sample - loss: 0.0426 - acc: 0.9867 - ETA: 0s - loss: 0.0427 - acc: 0.\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62996/62996 [==============================] - 45s 721us/sample - loss: 0.0290 - acc: 0.9907 - los\n",
      "Epoch 4/5\n",
      "62996/62996 [==============================] - 45s 719us/sample - loss: 0.0228 - acc: 0.9928\n",
      "Epoch 5/5\n",
      "62996/62996 [==============================] - 46s 723us/sample - loss: 0.0176 - acc: 0.9943 - loss: 0.0175\n",
      "2020-06-05 23:02:29.534832 End of fit\n",
      "acc: 99.09%\n",
      "2020-06-05 23:02:49.825120 Start of fit\n",
      "Epoch 1/5\n",
      "62999/62999 [==============================] - 54s 850us/sample - loss: 0.1628 - acc: 0.9487\n",
      "Epoch 2/5\n",
      "62999/62999 [==============================] - 46s 733us/sample - loss: 0.0427 - acc: 0.9870\n",
      "Epoch 3/5\n",
      "62999/62999 [==============================] - 47s 754us/sample - loss: 0.0285 - acc: 0.9912s - loss: 0.0  - ETA: 6s - loss:  - ETA: 5s\n",
      "Epoch 4/5\n",
      "62999/62999 [==============================] - 46s 728us/sample - loss: 0.0216 - acc: 0.9935 - loss: 0.02 - ETA: 3s - loss: 0.0220 - \n",
      "Epoch 5/5\n",
      "62999/62999 [==============================] - 46s 727us/sample - loss: 0.0175 - acc: 0.9949\n",
      "2020-06-05 23:07:16.938720 End of fit\n",
      "acc: 98.99%\n",
      "2020-06-05 23:07:30.891273 Start of fit\n",
      "Epoch 1/5\n",
      "63000/63000 [==============================] - 52s 829us/sample - loss: 0.1604 - acc: 0.9509s - ETA: 8s  - ET\n",
      "Epoch 2/5\n",
      "63000/63000 [==============================] - 46s 731us/sample - loss: 0.0429 - acc: 0.9864 - loss:\n",
      "Epoch 3/5\n",
      "63000/63000 [==============================] - 45s 722us/sample - loss: 0.0288 - acc: 0.9908\n",
      "Epoch 4/5\n",
      "63000/63000 [==============================] - 45s 720us/sample - loss: 0.0214 - acc: 0.9933 - loss: 0.0219 - acc: 0. - ETA: 8s - loss: 0. - ETA: 0s - loss: 0.0213\n",
      "Epoch 5/5\n",
      "63000/63000 [==============================] - 45s 714us/sample - loss: 0.0170 - acc: 0.9946\n",
      "2020-06-05 23:11:49.928078 End of fit\n",
      "acc: 98.84%\n",
      "2020-06-05 23:12:05.448755 Start of fit\n",
      "Epoch 1/5\n",
      "63001/63001 [==============================] - 54s 860us/sample - loss: 0.1613 - acc: 0.9497\n",
      "Epoch 2/5\n",
      "63001/63001 [==============================] - 46s 733us/sample - loss: 0.0435 - acc: 0.9865\n",
      "Epoch 3/5\n",
      "63001/63001 [==============================] - 46s 730us/sample - loss: 0.0299 - acc: 0.9910s -  - ETA: 11s - lo - ETA: 8s - loss: 0.0302 - acc: 0. - ETA: 8s - loss: 0.0302 - ETA:  - ETA: 5s - loss: 0.0305 - acc:  - ETA: 4s - loss: 0.0304 - acc: 0.9 - ETA: 4s \n",
      "Epoch 4/5\n",
      "63001/63001 [==============================] - 46s 730us/sample - loss: 0.0226 - acc: 0.9930 - loss: 0. - ETA: 0s - loss: 0.0227 - acc\n",
      "Epoch 5/5\n",
      "63001/63001 [==============================] - 46s 727us/sample - loss: 0.0184 - acc: 0.9945\n",
      "2020-06-05 23:16:30.362279 End of fit\n",
      "acc: 99.14%\n",
      "2020-06-05 23:16:44.858218 Start of fit\n",
      "Epoch 1/5\n",
      "63002/63002 [==============================] - 51s 817us/sample - loss: 0.1657 - acc: 0.9479 - loss: 0.1780  - ETA: 4s - loss: 0.1757 - ac - ETA: 3s - loss: 0.1741 - acc: 0.9\n",
      "Epoch 2/5\n",
      "63002/63002 [==============================] - 46s 728us/sample - loss: 0.0433 - acc: 0.9866\n",
      "Epoch 3/5\n",
      "63002/63002 [==============================] - 46s 736us/sample - loss: 0.0298 - acc: 0.9907 ETA: 4s - loss: 0.0300 - acc: 0 - ETA: 4s - los\n",
      "Epoch 4/5\n",
      "63002/63002 [==============================] - 46s 726us/sample - loss: 0.0224 - acc: 0.9930 - loss: 0.0218 - acc:  - ETA: 5s - loss: 0.0219 - - ETA: 4s - - ETA: 2s\n",
      "Epoch 5/5\n",
      "63002/63002 [==============================] - 46s 724us/sample - loss: 0.0173 - acc: 0.9948 - lo\n",
      "2020-06-05 23:21:06.918349 End of fit\n",
      "acc: 99.19%\n",
      "2020-06-05 23:21:21.531036 Start of fit\n",
      "Epoch 1/5\n",
      "63003/63003 [==============================] - 52s 829us/sample - loss: 0.1584 - acc: 0.9499\n",
      "Epoch 2/5\n",
      "63003/63003 [==============================] - 46s 737us/sample - loss: 0.0431 - acc: 0.98631s - loss\n",
      "Epoch 3/5\n",
      "63003/63003 [==============================] - 47s 746us/sample - loss: 0.0302 - acc: 0.9907\n",
      "Epoch 4/5\n",
      "63003/63003 [==============================] - 47s 750us/sample - loss: 0.0221 - acc: 0.9930 - - ETA: 2s - loss: 0.0221 - acc: 0.99 - ETA: 2s - ETA: 0s - loss: 0.0220 - acc:  - ETA: 0s - loss: 0.0219 - acc:\n",
      "Epoch 5/5\n",
      "63003/63003 [==============================] - 48s 767us/sample - loss: 0.0178 - acc: 0.9946 - loss: 0.0171 - acc:  - ETA - ETA: 4s - - ETA: 2s -  - ETA: 0s - loss: 0.0176\n",
      "2020-06-05 23:25:48.609937 End of fit\n",
      "acc: 98.94%\n",
      "2020-06-05 23:26:05.236336 Start of fit\n",
      "Epoch 1/5\n",
      "63004/63004 [==============================] - 54s 854us/sample - loss: 0.1562 - acc: 0.9504- ETA: 0s - loss: 0.1575 - ac\n",
      "Epoch 2/5\n",
      "63004/63004 [==============================] - 47s 748us/sample - loss: 0.0420 - acc: 0.9869 -\n",
      "Epoch 3/5\n",
      "63004/63004 [==============================] - 47s 754us/sample - loss: 0.0288 - acc: 0.9910 - loss: 0.02 - ETA: 7s - loss: 0.0293 - ETA: 3s  - ETA: 1s - loss:\n",
      "Epoch 4/5\n",
      "63004/63004 [==============================] - 47s 753us/sample - loss: 0.0218 - acc: 0.9934 - loss: 0.02\n",
      "Epoch 5/5\n",
      "63004/63004 [==============================] - 47s 745us/sample - loss: 0.0168 - acc: 0.9948 - loss: 0.0168 - acc: 0.9\n",
      "2020-06-05 23:30:36.897618 End of fit\n",
      "acc: 99.03%\n",
      "2020-06-05 23:30:51.890218 Start of fit\n",
      "Epoch 1/5\n",
      "63004/63004 [==============================] - 54s 855us/sample - loss: 0.1509 - acc: 0.9521s - loss: 0.2081 - ETA: 21s  - ETA: 14s  - ETA: 2s - loss: 0.1549 - acc: - ETA: 1s - loss: 0\n",
      "Epoch 2/5\n",
      "63004/63004 [==============================] - 47s 750us/sample - loss: 0.0419 - acc: 0.9871\n",
      "Epoch 3/5\n",
      "63004/63004 [==============================] - 47s 745us/sample - loss: 0.0296 - acc: 0.9910 - loss: 0.0293 - ac - ETA: 3s - lo - ETA:\n",
      "Epoch 4/5\n",
      "63004/63004 [==============================] - 47s 743us/sample - loss: 0.0225 - acc: 0.9931 - loss: 0.0225 - acc: 0.993\n",
      "Epoch 5/5\n",
      "63004/63004 [==============================] - 48s 758us/sample - loss: 0.0177 - acc: 0.9948 - loss: 0.0174 - acc - ET\n",
      "2020-06-05 23:35:22.672382 End of fit\n",
      "acc: 99.09%\n",
      "99.05% (+/- 0.10%)\n",
      "2020-06-05 23:35:34.001048 end of verbatim_from_book_CNN\n",
      "predicted_labels [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6\n",
      " 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5 8 5 6 6 5 7 8 1 0 1 6 4 6 7 3 1 7 1 8 2 0 2 ... 0 7 7 5 8 2 9 8 6 7 3 4 6 5 7 0 4 7 7 7 5 4 3 4 2 8 1 5 1 0 2 3 3 6 7 0 6 8 6 3 9 9 8 8 7 7\n",
      " 1 0 1 7 8 9 0 1 0 9 4 5 6 7 8 0 1 2 3 4 7 8 9 7 8 6 4 1 9 3 8 4 4 7 0 1 9 2 8 7 8 2 6 0 6 5 3 3 3 9 1 4 0 6 1 0 0 6 2 1 1 7 7 8 4 6 0 7 0 3 6 8 7 1 5 2 4 9 4 3 6 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0 1\n",
      " 2 3 4 5 6]\n",
      "ndx_errs (array([ 151,  241,  247,  318,  320,  321,  362,  376,  381,  444,  445,  448,  464,  479,  495,  519,  550,  578,  582,  628,  659,  691,  716,  726,  740,  760,  839,  881,  883,  924,  926,  938,\n",
      "        939,  947,  951,  956, 1003, 1014, 1039, 1062, 1077, 1089, 1107, 1112, 1114, 1173, 1181, 1192, 1226, 1228, 1232, 1242, 1247, 1248, 1270, 1283, 1289, 1299, 1319, 1326, 1331, 1364, 1393, 1414,\n",
      "       1500, 1523, 1530, 1549, 1553, 1559, 1634, 1637, 1648, 1681, 1695, 1709, 1718, 1721, 1732, 1737, 1790, 1813, 1878, 1901, 1955, 1970, 1984, 2043, 2044, 2052, 2098, 2109, 2118, 2129, 2130, 2135,\n",
      "       2177, 2182, 2189, 2224, 2237, 2282, 2292, 2293, 2298, 2387, 2393, 2395, 2406, 2414, 2422, 2447, 2462, 2574, 2607, 2648, 2654, 2721, 2730, 2758, 2771, 2810, 2851, 2853, 2896, 2927, 2939, 2945,\n",
      "       2952, 2953, 2998, 3005, 3030, 3060, 3062, 3073, 3117, 3136, 3206, 3240, 3262, 3289, 3323, 3333, 3429, 3475, 3503, 3558, 3559, 3573, 3597, 3629, 3664, 3702, 3718, 3726, 3742, 3757, 3767, 3780,\n",
      "       3808, 3811, 3838, 3853, 3893, 3902, 3926, 3941, 3968, 4007, 4065, 4072, 4075, 4078, 4116, 4176, 4224, 4269, 4271, 4284, 4289, 4294, 4297, 4306, 4355, 4360, 4437, 4483, 4489, 4497, 4500, 4505,\n",
      "       4567, 4575, 4578, 4598, 4639, 4671, 4731, 4737, 4743, 4761, 4785, 4807, 4823, 4837, 4860, 4874, 4886, 4890, 4893, 4911, 4943, 4966, 4976, 4990, 5068, 5176, 5278, 5532, 5600, 5634, 5705, 5769,\n",
      "       5835, 5841, 5858, 5867, 5887, 5888, 5906, 5914, 5937, 5955, 5973, 5975, 5982, 5997, 6023, 6035, 6037, 6071, 6081, 6091, 6157, 6166, 6172, 6173, 6555, 6560, 6597, 6641, 6651, 6755, 6783, 6813,\n",
      "       7216, 7333, 7432, 7434, 7492, 7545, 7797, 7921, 8095, 8277, 8279, 8325, 8406, 8408, 8410, 8520, 8527, 9009, 9024, 9211, 9280, 9382, 9422, 9587, 9624, 9634, 9642, 9664, 9719, 9729, 9745, 9749,\n",
      "       9751, 9768, 9770, 9779, 9792, 9811, 9832, 9839, 9863, 9867, 9883, 9893, 9904, 9905, 9982], dtype=int64),)\n",
      "num correct is  9697  an accuracy of  0.9697\n",
      "2020-06-05 23:49:13.206016 end\n"
     ]
    }
   ],
   "source": [
    "Config.USE_PARENT_CENTROIDS=True\n",
    "Config.WEIGHTED_CENTROID=True\n",
    "Config.APPEND_IMAGE=True\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=60_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=10_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES\n",
    "TREE_HEIGHT=3\n",
    "\n",
    "run_tests()\n",
    "\n",
    "Config.USE_PARENT_CENTROIDS=False\n",
    "Config.WEIGHTED_CENTROID=False\n",
    "Config.APPEND_IMAGE=False\n",
    "Config.NUM_KERAS_TRAIN_IMAGES=12_000\n",
    "Config.NUM_KERAS_TEST_IMAGES=2_000\n",
    "Config.NUM_KERAS_TEST_LABELS=Config.NUM_KERAS_TEST_IMAGES\n",
    "Config.NUM_KERAS_TRAIN_LABELS=Config.NUM_KERAS_TRAIN_IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>\n",
    "<a href='#toc'>Goto Table of Contents</a>\n",
    "\n",
    "## summary\n",
    "\n",
    "\n",
    "### See the whitepaper in this repository for more description of the ideas.\n",
    "\n",
    "### This notebook is experiments with a tree of centroids with an option to append them to the image.\n",
    "\n",
    "### Experiments use one of two types of models for prediction: kNN and CNN. \n",
    "\n",
    "### kNN treats the 28x28 image as an array of 784 pixels and uses L2 distance metric. \n",
    "\n",
    "### CNN is lifted verbatim from the book \"Deep Learning with Python\" by Francois Chollet, 2018 (page 120-122) the inventor of Keras. The CNN is not SOTA but is useful to see whether adding information about centroids improve a neural net model.\n",
    "\n",
    "### The training/testing set of images is either small (6,000/1,000) or large (60,000/10,000).\n",
    "\n",
    "### The bottom line result is the error rate reduction.\n",
    "\n",
    "## Results from experiments\n",
    "\n",
    "| model\\#images | <font size=\"5\">6,000</font> | <font size=\"5\">60,000</font> |\n",
    "| --- | --- | --- |\n",
    "| baseline kNN | <font size=\"5\">91.6%</font> | <font size=\"5\">96.88%</font> |\n",
    "| improved kNN | <font size=\"5\">94.1%</font> | <font size=\"5\">97.12%</font> |\n",
    "\n",
    "### and\n",
    "\n",
    "| model\\#images | <font size=\"5\">6,000</font> | <font size=\"5\">60,000</font> |\n",
    "| --- | --- | --- |\n",
    "| baseline CNN | <font size=\"5\">96.29%</font> | <font size=\"5\">99.02%</font> |\n",
    "| improved CNN | <font size=\"5\">96.90%</font> | <font size=\"5\">99.10%</font> |\n",
    "\n",
    "### From these results, the _*error rate reduction*_ is\n",
    "\n",
    "| model\\#images | <font size=\"5\">6,000</font> | <font size=\"5\">60,000</font> |\n",
    "| --- | --- | --- |\n",
    "| kNN | <font size=\"5\">29.76%</font> | <font size=\"5\">7.7%</font> | \n",
    "| CNN | <font size=\"5\">16.4%</font> | <font size=\"5\">9%</font> | \n",
    "\n",
    "### In the process of getting the above results the following observations were noteworthy and guided which combination of options to try for improvement.\n",
    "\n",
    "### <a href='#s2weightcentroids'>No improvement for weighted centroids (no overlap) with image</a>\n",
    "\n",
    "### <a href='#s2treesizesweighted'>A height of 3 for the tree of centroids seems best</a>\n",
    "\n",
    "### <a href='#s2onlyleaves'>centroid info without image is not an improvement</a>\n",
    "### <a href='#s2onlyleaves'>we need the image for best results. The centroids by themselves is not enough.\n",
    "\n",
    "### <a href='#s2norelativebdy'>always get points relative to the bounding rectangle. </a>\n",
    "\n",
    "\n",
    "### <a href='#s2reprokNNimprove'>kNN improvement for kNN with options weighted centroid but no overlap, nor parents,</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5'></a>\n",
    "<a href='#toc'>Goto Table of Contents</a>\n",
    "\n",
    "## areas for further work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying overlapping concentric doughnuts before doing other areas described in the whitepaper."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
